{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuronSelection_MultiLayer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOmtTG5lpXOQTF1484D1j2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoPao/cubert_keras/blob/main/NeuronSelection_MultiLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJhIuyKtE5RR"
      },
      "outputs": [],
      "source": [
        "!git clone https://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@github.com/MatteoPao/cubert_keras.git\n",
        "\n",
        "%cd cubert_keras/src/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                               \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# %cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_exceptions /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_exceptions\n",
        "%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_variablemisuse /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_variablemisuse"
      ],
      "metadata": {
        "id": "ysjGaI05FGO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ../requirements.txt"
      ],
      "metadata": {
        "id": "9_MMBnaFFILE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from intermediate_layer import read_examples_from_json\n",
        "from keras_bert import load_trained_model_from_checkpoint, get_checkpoint_paths\n",
        "from cubert.full_cubert_tokenizer import FullCuBertTokenizer, CuBertVariableMisuseProcessor, InputExample\n",
        "from cubert import tokenizer_registry\n",
        "\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "EZfgH7TCFL0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"fitness/cubert_fitness/cubert_pretrained_model_variablemisuse\"\n",
        "data_path = \"../cyclomatic_complexity/final/data_cc_3000.jsontxt\"\n",
        "#data_path = \"../cyclomatic_complexity/final/data_cc_NoAWE_1955.jsontxt\"\n",
        "\n",
        "paths = get_checkpoint_paths(model_path)\n",
        "\n",
        "examples = read_examples_from_json(data_path, \"eval\")\n",
        "\n",
        "#Carica il tokenizer\n",
        "tokenizer = FullCuBertTokenizer(code_tokenizer_class=tokenizer_registry.TokenizerEnum.PYTHON.value, vocab_file=paths.vocab)\n",
        "print(\"Tokenizer loaded\")\n",
        "\n",
        "\n",
        "#Tokenizza tutto il dataset\n",
        "features = tokenizer.convert_examples_to_features(examples, [0, 1], 512)\n",
        "print(\"Dataset tokenized\")\n",
        "np.random.shuffle(features)"
      ],
      "metadata": {
        "id": "xeqG_oCsPL3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = []\n",
        "seg = []\n",
        "mas = []\n",
        "label = []\n",
        "\n",
        "for f in features:\n",
        "  inp.append(f.input_ids)\n",
        "  seg.append(f.segment_ids)\n",
        "  mas.append(f.input_mask)\n",
        "  label.append(f.label_id)\n",
        "  \n",
        "data_input = [np.array(inp), np.array(seg), np.array(mas)]\n",
        "\n",
        "dim = 10\n",
        "test_input = [data_input[0][:dim], data_input[1][:dim], data_input[2][:dim]]\n",
        "test_label = label[:dim]\n",
        "\n",
        "print(np.asarray(data_input).shape)\n",
        "print(np.asarray(label).shape)\n",
        "print(np.asarray(test_input).shape)\n",
        "print(np.asarray(test_label).shape)"
      ],
      "metadata": {
        "id": "9367rjxXPPvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = \"Encoder-22-FeedForward-Norm\"\n",
        "\n",
        "#Carica il modello\n",
        "model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, training=True, out_dim=2)\n",
        "model = keras.Model(inputs=model.input, outputs=model.get_layer(layer).output)\n",
        "\n",
        "\n",
        "pred_results = model.predict(data_input, batch_size=16, verbose=1)\n",
        "pred_results = np.transpose(pred_results)\n",
        "\n",
        "#print(\"\\nPrediction completata\")\n",
        "#print(pred_results[0].shape)"
      ],
      "metadata": {
        "id": "Sv-DQImaFvyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Randomizza i label per verificare la veridicitÃ  delle informazioni ricavate\n",
        "#np.random.shuffle(label)\n",
        "\n",
        "label_b = np.asarray(label).astype(bool)\n",
        "#label_b = np.asarray(test_label).astype(bool)\n",
        "\n",
        "save = True\n",
        "%mkdir ../../result\n",
        "\n",
        "#for ind, out_layer in enumerate(outputs):\n",
        "\n",
        "#  print(\"Layer: \" + layers[ind])\n",
        "accuracies = []\n",
        "for line in pred_results:\n",
        "  accuracies.append([])\n",
        "\n",
        "  max = line.max()\n",
        "  min = line.min()\n",
        "  threshold = np.linspace(min, max, num=12)[1:11]\n",
        "\n",
        "  for neuron in line:\n",
        "    best = {'acc':0, 'th':0}\n",
        "    for t in threshold:\n",
        "      \"\"\" OLD\n",
        "      m = tf.keras.metrics.BinaryAccuracy(threshold=t)\n",
        "      m.update_state(label_b[:len(neuron)], neuron)\n",
        "      acc = m.result().numpy() \"\"\"\n",
        "      neuron_b = np.where(neuron>t, True, False)\n",
        "      acc_b = (label_b & neuron_b) | (~label_b & ~neuron_b)\n",
        "      acc = acc_b.mean()\n",
        "\n",
        "      if (1 - acc) > acc:\n",
        "        acc = 1 - acc\n",
        "\n",
        "      if acc > best[\"acc\"]:\n",
        "        best[\"acc\"] = acc\n",
        "        best[\"th\"] = t\n",
        "      \n",
        "    accuracies[-1].append(best)\n",
        "if save:\n",
        "  #Salvo le accuratezze del layer\n",
        "  final_out = {'layer':layer, 'accuracies':accuracies}\n",
        "  print(final_out)\n",
        "  outF = open(\"../../result/\" + layer + \".json\", \"x\")\n",
        "  json_out = json.dumps(final_out)\n",
        "  outF.write(json_out)\n",
        "  outF.close()"
      ],
      "metadata": {
        "id": "XcPPM9Zvw4sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/bestNeuron.zip /content/result\n",
        "from google.colab import files\n",
        "files.download(\"/content/bestNeuron.zip\")\n",
        "!rm -r /content/result"
      ],
      "metadata": {
        "id": "0gdCJo27UlMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}