{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuronSelection_MultiLayer_ALT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMlsRb0dSPDG86HOlTbFfNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoPao/cubert_keras/blob/main/NeuronSelection_MultiLayer_ALT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/MatteoPao/cubert_keras.git\n",
        "\n",
        "%cd cubert_keras/src/"
      ],
      "metadata": {
        "id": "Kod8-rj3PN8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                  \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_exceptions /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_exceptions\n",
        "#%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_variablemisuse /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_variablemisuse\n",
        "%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_epochs_2 /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_epochs_2\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "sx3YOj85PR4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ../requirements.txt\n",
        "!pip install progressbar2\n",
        "from intermediate_layer import read_examples_from_json\n",
        "from keras_bert import load_trained_model_from_checkpoint, get_checkpoint_paths\n",
        "from cubert.full_cubert_tokenizer import FullCuBertTokenizer, CuBertVariableMisuseProcessor, InputExample\n",
        "from cubert import tokenizer_registry\n",
        "\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import progressbar"
      ],
      "metadata": {
        "id": "U21RemFAPWnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"fitness/cubert_fitness/cubert_pretrained_model_epochs_2\"\n",
        "data_path = \"../cyclomatic_complexity/final/data_cc_3000.jsontxt\"\n",
        "#data_path = \"../cyclomatic_complexity/final/data_cc_NoAWE_1955.jsontxt\"\n",
        "\n",
        "paths = get_checkpoint_paths(model_path)\n",
        "\n",
        "examples = read_examples_from_json(data_path, \"eval\")\n",
        "\n",
        "#Carica il tokenizer\n",
        "tokenizer = FullCuBertTokenizer(code_tokenizer_class=tokenizer_registry.TokenizerEnum.PYTHON.value, vocab_file=paths.vocab)\n",
        "print(\"Tokenizer loaded\")\n",
        "\n",
        "\n",
        "#Tokenizza tutto il dataset\n",
        "features = tokenizer.convert_examples_to_features(examples, [0, 1], 512)\n",
        "print(\"Dataset tokenized\")\n",
        "#np.random.shuffle(features)"
      ],
      "metadata": {
        "id": "iusGeARKPd4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = []\n",
        "seg = []\n",
        "mas = []\n",
        "label = []\n",
        "\n",
        "for f in features:\n",
        "  inp.append(f.input_ids)\n",
        "  seg.append(f.segment_ids)\n",
        "  mas.append(f.input_mask)\n",
        "  label.append(f.label_id)\n",
        "  \n",
        "data_input = [np.array(inp), np.array(seg), np.array(mas)]\n",
        "\"\"\"\n",
        "truncated_input = []\n",
        "for index in range(int(len(data_input[0])/8)):\n",
        "  step = int(index*8)\n",
        "  truncated_input.append([data_input[0][step:step+8], data_input[1][step:step+8], data_input[2][step:step+8]])\n",
        "\"\"\"\n",
        "\n",
        "truncated_input = []\n",
        "for index in range(int(len(data_input[0])/8)):\n",
        "  step = int(index*8)\n",
        "  truncated_input.append([data_input[0][step:step+8], data_input[1][step:step+8]])\n",
        "\n",
        "print(np.asarray(truncated_input).shape)"
      ],
      "metadata": {
        "id": "pk7Of3HzPj-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = \"Encoder-10-FeedForward-Norm\"\n",
        "\n",
        "#Carica il modello\n",
        "\n",
        "#model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, training=True, out_dim=2)\n",
        "model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, training=False)\n",
        "model.summary()\n",
        "model = K.function([model.input],\n",
        "                   [model.get_layer(layer_name).output])\n",
        "\n",
        "print(\"Model loaded\")"
      ],
      "metadata": {
        "id": "MhgUhSBBPsvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output in test mode = 0\n",
        "%mkdir results\n",
        "count = 0\n",
        "for input in progressbar.progressbar(truncated_input):\n",
        "  batch_output = model([input, 0])[0]\n",
        "  with open('results/'+ layer_name + '_prediction_' + str(count) + '.npy', 'wb') as file:\n",
        "    np.save(file, batch_output)\n",
        "  count += 1"
      ],
      "metadata": {
        "id": "1uXhMsxo1p6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/prediction.zip /content/cubert_keras/src/results"
      ],
      "metadata": {
        "id": "DUZqFUBFDUvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')\n",
        "\n",
        "%cp -r /content/prediction.zip /content/drive/MyDrive/Tesi_Database/prediction_3000AWE_2epochs\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "HTEXsEvth5D2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}