"function": "\n\ndef test_s3_domain_with_default_root_object(self):\n    cmdline = ((self.prefix + '--origin-domain-name foo.s3.amazonaws.com ') + '--default-root-object index.html')\n    result = {\n        'DistributionConfig': {\n            'Origins': {\n                'Quantity': 1,\n                'Items': [{\n                    'S3OriginConfig': mock.ANY,\n                    'DomainName': 'foo.s3.amazonaws.com',\n                    'Id': mock.ANY,\n                    'OriginPath': '',\n                }],\n            },\n            'CallerReference': mock.ANY,\n            'Comment': '',\n            'Enabled': True,\n            'DefaultCacheBehavior': mock.ANY,\n            'DefaultRootObject': 'index.html',\n        },\n    }\n    self.run_cmd(cmdline)\n    self.assertEqual(self.last_kwargs, result)\n", "label": "Correct"}
{"function": "\n\ndef test_s3_domain_with_default_root_object(self):\n    cmdline = ((self.prefix + '--origin-domain-name foo.s3.amazonaws.com ') + '--default-root-object index.html')\n    result = {\n        'DistributionConfig': {\n            'Origins': {\n                'Quantity': 1,\n                'Items': [{\n                    'S3OriginConfig': mock.ANY,\n                    'DomainName': 'foo.s3.amazonaws.com',\n                    'Id': mock.ANY,\n                    'OriginPath': '',\n                }],\n            },\n            'CallerReference': mock.ANY,\n            'Comment': '',\n            'Enabled': True,\n            'DefaultCacheBehavior': mock.ANY,\n            'DefaultRootObject': 'index.html',\n        },\n    }\n    self.run_cmd(cmdline)\n    self.assertEqual(result.last_kwargs, result)\n", "label": "Variable misuse"}
{"function": "\n\ndef pages_dynamic_tree_menu(context, page, url='/'):\n    '\\n    Render a \"dynamic\" tree menu, with all nodes expanded which are either\\n    ancestors or the current page itself.\\n\\n    Override ``pages/dynamic_tree_menu.html`` if you want to change the\\n    design.\\n\\n    :param page: the current page\\n    :param url: not used anymore\\n    '\n    lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\n    page = get_page_from_string_or_id(page, lang)\n    children = None\n    if (page and ('current_page' in context)):\n        current_page = context['current_page']\n        if ((page.tree_id == current_page.tree_id) and (page.lft <= current_page.lft) and (page.rght >= current_page.rght)):\n            children = page.get_children_for_frontend()\n    context.update({\n        'children': children,\n        'page': page,\n    })\n    return context\n", "label": "Correct"}
{"function": "\n\ndef pages_dynamic_tree_menu(context, page, url='/'):\n    '\\n    Render a \"dynamic\" tree menu, with all nodes expanded which are either\\n    ancestors or the current page itself.\\n\\n    Override ``pages/dynamic_tree_menu.html`` if you want to change the\\n    design.\\n\\n    :param page: the current page\\n    :param url: not used anymore\\n    '\n    lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\n    page = get_page_from_string_or_id(page, lang)\n    children = None\n    if (page and ('current_page' in context)):\n        current_page = children['current_page']\n        if ((page.tree_id == current_page.tree_id) and (page.lft <= current_page.lft) and (page.rght >= current_page.rght)):\n            children = page.get_children_for_frontend()\n    context.update({\n        'children': children,\n        'page': page,\n    })\n    return context\n", "label": "Variable misuse"}
{"function": "\n\ndef remove(path, recursive=False, use_sudo=False):\n    '\\n    Remove a file or directory\\n    '\n    func = ((use_sudo and run_as_root) or run)\n    options = ('-r ' if recursive else '')\n    func('/bin/rm {0}{1}'.format(options, quote(path)))\n", "label": "Correct"}
{"function": "\n\ndef remove(path, recursive=False, use_sudo=False):\n    '\\n    Remove a file or directory\\n    '\n    func = ((recursive and run_as_root) or run)\n    options = ('-r ' if recursive else '')\n    func('/bin/rm {0}{1}'.format(options, quote(path)))\n", "label": "Variable misuse"}
{"function": "\n\ndef marshal_dump(code, f):\n    if isinstance(f, file):\n        marshal.dump(code, f)\n    else:\n        f.write(marshal.dumps(code))\n", "label": "Correct"}
{"function": "\n\ndef marshal_dump(code, f):\n    if isinstance(f, file):\n        marshal.dump(f, f)\n    else:\n        f.write(marshal.dumps(code))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_show_body(self):\n    client = Mock()\n    client.indices.get_settings.return_value = testvars.settings_one\n    client.cluster.state.return_value = testvars.clu_state_one\n    client.indices.stats.return_value = testvars.stats_one\n    ilo = curator.IndexList(client)\n    ao = curator.Alias(name='alias')\n    ao.remove(ilo)\n    ao.add(ilo)\n    body = ao.body()\n    self.assertEqual(testvars.alias_one_body['actions'][0], body['actions'][0])\n    self.assertEqual(testvars.alias_one_body['actions'][1], body['actions'][1])\n", "label": "Correct"}
{"function": "\n\ndef test_show_body(self):\n    client = Mock()\n    client.indices.get_settings.return_value = testvars.settings_one\n    client.cluster.state.return_value = testvars.clu_state_one\n    client.indices.stats.return_value = testvars.stats_one\n    ilo = curator.IndexList(client)\n    ao = curator.Alias(name='alias')\n    ao.remove(ilo)\n    ao.add(ilo)\n    body = ao.body()\n    self.assertEqual(testvars.alias_one_body['actions'][0], client['actions'][0])\n    self.assertEqual(testvars.alias_one_body['actions'][1], body['actions'][1])\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('SoftLayer.API.BaseClient.iter_call')\ndef test_iterate(self, _iter_call):\n    self.client['SERVICE'].METHOD(iter=True)\n    _iter_call.assert_called_with('SERVICE', 'METHOD')\n", "label": "Correct"}
{"function": "\n\n@mock.patch('SoftLayer.API.BaseClient.iter_call')\ndef test_iterate(self, _iter_call):\n    self.client['SERVICE'].METHOD(iter=True)\n    self.assert_called_with('SERVICE', 'METHOD')\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, *args, **kwargs):\n    try:\n        self._call(*args, **kwargs)\n    except Exception as err:\n        stats.incr('callback-failure', 1)\n        logging.exception('Callback Failed: %s', err)\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, *args, **kwargs):\n    try:\n        self._call(*err, **kwargs)\n    except Exception as err:\n        stats.incr('callback-failure', 1)\n        logging.exception('Callback Failed: %s', err)\n", "label": "Variable misuse"}
{"function": "\n\n@register.filter\ndef lookup(h, key):\n    try:\n        return h[key]\n    except KeyError:\n        return ''\n", "label": "Correct"}
{"function": "\n\n@register.filter\ndef lookup(h, key):\n    try:\n        return h[h]\n    except KeyError:\n        return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef __add__(self, other):\n    return self.build('add', self, other)\n", "label": "Correct"}
{"function": "\n\ndef __add__(self, other):\n    return self.build('add', self, self)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef read(cls, handle):\n    self = cls()\n    self._read_luminosity(handle)\n    self.name = handle.attrs['name'].decode('utf-8')\n    self.peeloff = str2bool(handle.attrs['peeloff'])\n    if (handle.attrs['spectrum'] == b'spectrum'):\n        self.spectrum = Table(np.array(handle['spectrum']))\n    elif (handle.attrs['spectrum'] == b'temperature'):\n        self.temperature = handle.attrs['temperature']\n    elif (handle.attrs['spectrum'] == b'lte'):\n        pass\n    else:\n        raise ValueError(('Unexpected value for `spectrum`: %s' % handle.attrs['spectrum']))\n    return self\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef read(cls, handle):\n    self = cls()\n    self._read_luminosity(handle)\n    self.name = handle.attrs['name'].decode('utf-8')\n    handle.peeloff = str2bool(handle.attrs['peeloff'])\n    if (handle.attrs['spectrum'] == b'spectrum'):\n        self.spectrum = Table(np.array(handle['spectrum']))\n    elif (handle.attrs['spectrum'] == b'temperature'):\n        self.temperature = handle.attrs['temperature']\n    elif (handle.attrs['spectrum'] == b'lte'):\n        pass\n    else:\n        raise ValueError(('Unexpected value for `spectrum`: %s' % handle.attrs['spectrum']))\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, context):\n    category = resolve(self.category, context)\n    if isinstance(category, CategoryBase):\n        cat = category\n    else:\n        cat = get_category(category, self.model)\n    try:\n        if (cat is not None):\n            context[self.varname] = drilldown_tree_for_node(cat)\n        else:\n            context[self.varname] = []\n    except:\n        context[self.varname] = []\n    return ''\n", "label": "Correct"}
{"function": "\n\ndef render(self, context):\n    category = resolve(self.category, context)\n    if isinstance(category, CategoryBase):\n        cat = category\n    else:\n        cat = get_category(category, self.model)\n    try:\n        if (category is not None):\n            context[self.varname] = drilldown_tree_for_node(cat)\n        else:\n            context[self.varname] = []\n    except:\n        context[self.varname] = []\n    return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, manufacturer, data):\n    self.manufacturer = manufacturer\n    self.data = list(data)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, manufacturer, data):\n    self.manufacturer = manufacturer\n    self.data = list(manufacturer)\n", "label": "Variable misuse"}
{"function": "\n\ndef process_response(self, request, response):\n    from django.conf import settings\n    from rest_framework.exceptions import PermissionDenied\n    from .access_control import upload_prefix_for_request\n    cookie_name = getattr(settings, 'UPLOAD_PREFIX_COOKIE_NAME', 'upload_prefix')\n    try:\n        response.set_cookie(cookie_name, upload_prefix_for_request(request))\n    except PermissionDenied:\n        response.delete_cookie(cookie_name)\n    return response\n", "label": "Correct"}
{"function": "\n\ndef process_response(self, request, response):\n    from django.conf import settings\n    from rest_framework.exceptions import PermissionDenied\n    from .access_control import upload_prefix_for_request\n    cookie_name = getattr(settings, 'UPLOAD_PREFIX_COOKIE_NAME', 'upload_prefix')\n    try:\n        response.set_cookie(cookie_name, upload_prefix_for_request(cookie_name))\n    except PermissionDenied:\n        response.delete_cookie(cookie_name)\n    return response\n", "label": "Variable misuse"}
{"function": "\n\ndef createLineSet(self, indices, inputlist, materialid):\n    'Create a set of lines for use in this geometry instance.\\n\\n        :param numpy.array indices:\\n          unshaped numpy array that contains the indices for\\n          the inputs referenced in inputlist\\n        :param collada.source.InputList inputlist:\\n          The inputs for this primitive\\n        :param str materialid:\\n          A string containing a symbol that will get used to bind this lineset\\n          to a material when instantiating into a scene\\n\\n        :rtype: :class:`collada.lineset.LineSet`\\n        '\n    inputdict = primitive.Primitive._getInputsFromList(self.collada, self.sourceById, inputlist.getList())\n    return lineset.LineSet(inputdict, materialid, indices)\n", "label": "Correct"}
{"function": "\n\ndef createLineSet(self, indices, inputlist, materialid):\n    'Create a set of lines for use in this geometry instance.\\n\\n        :param numpy.array indices:\\n          unshaped numpy array that contains the indices for\\n          the inputs referenced in inputlist\\n        :param collada.source.InputList inputlist:\\n          The inputs for this primitive\\n        :param str materialid:\\n          A string containing a symbol that will get used to bind this lineset\\n          to a material when instantiating into a scene\\n\\n        :rtype: :class:`collada.lineset.LineSet`\\n        '\n    inputdict = primitive.Primitive._getInputsFromList(self.collada, inputlist.sourceById, inputlist.getList())\n    return lineset.LineSet(inputdict, materialid, indices)\n", "label": "Variable misuse"}
{"function": "\n\ndef stepSlice(self, offset):\n    ' Move the selected structure one slice up or down\\n        :param offset: +1 or -1\\n        :return:\\n        '\n    volumeId = self.volumeSelector.currentNodeId\n    if (volumeId == ''):\n        self.showUnselectedVolumeWarningMessage()\n        return\n    selectedStructure = self.getCurrentSelectedStructure()\n    if (selectedStructure == self.logic.NONE):\n        self.showUnselectedStructureWarningMessage()\n        return\n    if (selectedStructure == self.logic.BOTH):\n        self.logic.stepSlice(volumeId, self.logic.AORTA, offset)\n        newSlice = self.logic.stepSlice(volumeId, self.logic.PA, offset)\n    else:\n        newSlice = self.logic.stepSlice(volumeId, selectedStructure, offset)\n    self.moveRedWindowToSlice(newSlice)\n", "label": "Correct"}
{"function": "\n\ndef stepSlice(self, offset):\n    ' Move the selected structure one slice up or down\\n        :param offset: +1 or -1\\n        :return:\\n        '\n    volumeId = self.volumeSelector.currentNodeId\n    if (volumeId == ''):\n        self.showUnselectedVolumeWarningMessage()\n        return\n    selectedStructure = selectedStructure.getCurrentSelectedStructure()\n    if (selectedStructure == self.logic.NONE):\n        self.showUnselectedStructureWarningMessage()\n        return\n    if (selectedStructure == self.logic.BOTH):\n        self.logic.stepSlice(volumeId, self.logic.AORTA, offset)\n        newSlice = self.logic.stepSlice(volumeId, self.logic.PA, offset)\n    else:\n        newSlice = self.logic.stepSlice(volumeId, selectedStructure, offset)\n    self.moveRedWindowToSlice(newSlice)\n", "label": "Variable misuse"}
{"function": "\n\n@testhelp.context('sysmodel')\ndef testScripts(self):\n    '\\n        Make sure we can attach scripts to groups correctly\\n        '\n\n    def _checkScripts(grp):\n        scripts = grp.troveInfo.scripts\n        for scriptType in scriptTypes:\n            script = getattr(scripts, scriptType).script()\n            self.assertEquals(script, ('# %s' % scriptType))\n    self.addComponent('foo:runtime=1.0')\n    self.addComponent('foo:lib=1.0')\n    self.addCollection('foo=1.0', ['foo:runtime', 'foo:lib'])\n    recipe = []\n    scriptTypes = ('postInstall', 'preRollback', 'postRollback', 'preUpdate', 'postUpdate')\n    for scriptType in scriptTypes:\n        recipe.append(('%s = r.Script(contents=\"# %s\")' % (2 * (scriptType,))))\n    recipe.append(('scripts = r.Scripts(%s)' % ', '.join([' = '.join((x, x)) for x in scriptTypes])))\n    recipe.append('foo = world.find(\"foo\")')\n    recipe.append('groupInner = foo.createGroup(\"group-inner\", scripts=scripts)')\n    recipe.append('r.Group(groupInner, scripts=scripts)')\n    grp = self._build(*recipe)\n    repos = self.openRepository()\n    igrp = repos.getTrove('group-inner', grp.getVersion(), grp.getFlavor())\n    for g in (grp, igrp):\n        _checkScripts(g)\n    grp = self._build(\"grp = world['group-test']\", \"foo = world['foo']\", \"r.name = 'group-bar'\", 'scripts = grp.scripts()', 'r.Group(foo, scripts = scripts)')\n    _checkScripts(grp)\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test', 'foo')\", 'scripts = grp.scripts()', 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Multiple troves in trove set for scripts()')\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test')\", \"scripts = (grp - grp['group-test']).scripts()\", 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Empty trove set for scripts()')\n", "label": "Correct"}
{"function": "\n\n@testhelp.context('sysmodel')\ndef testScripts(self):\n    '\\n        Make sure we can attach scripts to groups correctly\\n        '\n\n    def _checkScripts(grp):\n        scripts = grp.troveInfo.scripts\n        for scriptType in scriptTypes:\n            script = getattr(scripts, scriptType).script()\n            self.assertEquals(script, ('# %s' % scriptType))\n    self.addComponent('foo:runtime=1.0')\n    self.addComponent('foo:lib=1.0')\n    self.addCollection('foo=1.0', ['foo:runtime', 'foo:lib'])\n    recipe = []\n    scriptTypes = ('postInstall', 'preRollback', 'postRollback', 'preUpdate', 'postUpdate')\n    for scriptType in scriptTypes:\n        recipe.append(('%s = r.Script(contents=\"# %s\")' % (2 * (scriptType,))))\n    igrp.append(('scripts = r.Scripts(%s)' % ', '.join([' = '.join((x, x)) for x in scriptTypes])))\n    recipe.append('foo = world.find(\"foo\")')\n    recipe.append('groupInner = foo.createGroup(\"group-inner\", scripts=scripts)')\n    recipe.append('r.Group(groupInner, scripts=scripts)')\n    grp = self._build(*recipe)\n    repos = self.openRepository()\n    igrp = repos.getTrove('group-inner', grp.getVersion(), grp.getFlavor())\n    for g in (grp, igrp):\n        _checkScripts(g)\n    grp = self._build(\"grp = world['group-test']\", \"foo = world['foo']\", \"r.name = 'group-bar'\", 'scripts = grp.scripts()', 'r.Group(foo, scripts = scripts)')\n    _checkScripts(grp)\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test', 'foo')\", 'scripts = grp.scripts()', 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Multiple troves in trove set for scripts()')\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test')\", \"scripts = (grp - grp['group-test']).scripts()\", 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Empty trove set for scripts()')\n", "label": "Variable misuse"}
{"function": "\n\ndef normalize_diff_filename(self, filename):\n    \"Normalize filenames in diffs.\\n\\n        The default behavior of stripping off leading slashes doesn't work for\\n        Perforce (because depot paths start with //), so this overrides it to\\n        just return the filename un-molested.\\n        \"\n    return filename\n", "label": "Correct"}
{"function": "\n\ndef normalize_diff_filename(self, filename):\n    \"Normalize filenames in diffs.\\n\\n        The default behavior of stripping off leading slashes doesn't work for\\n        Perforce (because depot paths start with //), so this overrides it to\\n        just return the filename un-molested.\\n        \"\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_chair_metal_s1.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_chair_metal_s1.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_content_url_encoding_safe(self):\n    s = Site(self.SITE_PATH, config=self.config)\n    s.load()\n    path = '\".jpg/abc'\n    print(s.content_url(path, ''))\n    print(('/' + quote(path, '')))\n    assert (s.content_url(path, '') == ('/' + quote(path, '')))\n", "label": "Correct"}
{"function": "\n\ndef test_content_url_encoding_safe(self):\n    s = Site(self.SITE_PATH, config=self.config)\n    s.load()\n    path = '\".jpg/abc'\n    print(self.content_url(path, ''))\n    print(('/' + quote(path, '')))\n    assert (s.content_url(path, '') == ('/' + quote(path, '')))\n", "label": "Variable misuse"}
{"function": "\n\ndef post_undelete(self, *args, **kwargs):\n    self.post_undelete_called = True\n", "label": "Correct"}
{"function": "\n\ndef post_undelete(self, *args, **kwargs):\n    kwargs.post_undelete_called = True\n", "label": "Variable misuse"}
{"function": "\n\ndef timecolon(data):\n    match = re.search('(\\\\d+:\\\\d+:\\\\d+):(\\\\d+)', data)\n    return ('%s,%s' % (match.group(1), match.group(2)))\n", "label": "Correct"}
{"function": "\n\ndef timecolon(data):\n    match = re.search('(\\\\d+:\\\\d+:\\\\d+):(\\\\d+)', data)\n    return ('%s,%s' % (data.group(1), match.group(2)))\n", "label": "Variable misuse"}
{"function": "\n\ndef getUpdatedBatchJob(self, maxWait):\n    while True:\n        try:\n            (jobID, status, wallTime) = self.updatedJobsQueue.get(timeout=maxWait)\n        except Empty:\n            return None\n        try:\n            self.runningJobs.remove(jobID)\n        except KeyError:\n            pass\n        else:\n            return (jobID, status, wallTime)\n", "label": "Correct"}
{"function": "\n\ndef getUpdatedBatchJob(self, maxWait):\n    while True:\n        try:\n            (jobID, status, wallTime) = self.updatedJobsQueue.get(timeout=maxWait)\n        except Empty:\n            return None\n        try:\n            self.runningJobs.remove(jobID)\n        except KeyError:\n            pass\n        else:\n            return (status, status, wallTime)\n", "label": "Variable misuse"}
{"function": "\n\ndef package_private_devel_path(self, package):\n    'The path to the linked devel space for a given package.'\n    return os.path.join(self.private_devel_path, package.name)\n", "label": "Correct"}
{"function": "\n\ndef package_private_devel_path(self, package):\n    'The path to the linked devel space for a given package.'\n    return os.path.join(self.private_devel_path, self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_getset_owner(self):\n    m = meta.Metadata()\n    o = m.get_owner('files/one')\n    m.set_owner('files/one', *o)\n", "label": "Correct"}
{"function": "\n\ndef test_getset_owner(self):\n    m = meta.Metadata()\n    o = o.get_owner('files/one')\n    m.set_owner('files/one', *o)\n", "label": "Variable misuse"}
{"function": "\n\ndef indent(string, prefix='    '):\n    '\\n    Indent every line of this string.\\n    '\n    return ''.join((('%s%s\\n' % (prefix, s)) for s in string.split('\\n')))\n", "label": "Correct"}
{"function": "\n\ndef indent(string, prefix='    '):\n    '\\n    Indent every line of this string.\\n    '\n    return ''.join((('%s%s\\n' % (s, s)) for s in string.split('\\n')))\n", "label": "Variable misuse"}
{"function": "\n\ndef stories(self, task, params={\n    \n}, **options):\n    'Returns a compact representation of all of the stories on the task.\\n\\n        Parameters\\n        ----------\\n        task : {Id} The task containing the stories to get.\\n        [params] : {Object} Parameters for the request\\n        '\n    path = ('/tasks/%s/stories' % task)\n    return self.client.get_collection(path, params, **options)\n", "label": "Correct"}
{"function": "\n\ndef stories(self, task, params={\n    \n}, **options):\n    'Returns a compact representation of all of the stories on the task.\\n\\n        Parameters\\n        ----------\\n        task : {Id} The task containing the stories to get.\\n        [params] : {Object} Parameters for the request\\n        '\n    path = ('/tasks/%s/stories' % task)\n    return self.client.get_collection(self, params, **options)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_context_types_value(context_id, source, filter_func, codebase):\n    query = CodeElementLink.objects.filter(code_element__kind__is_type=True).filter(index=0).filter(code_element__codebase=codebase).filter(code_reference__source=source)\n    query = filter_func(query, context_id)\n    context_types = []\n    pk_set = set()\n    for link in query.all():\n        code_element = link.code_element\n        if (code_element.pk not in pk_set):\n            context_types.append(code_element)\n            pk_set.add(code_element.pk)\n    return context_types\n", "label": "Correct"}
{"function": "\n\ndef get_context_types_value(context_id, source, filter_func, codebase):\n    query = CodeElementLink.objects.filter(code_element__kind__is_type=True).filter(index=0).filter(code_element__codebase=query).filter(code_reference__source=source)\n    query = filter_func(query, context_id)\n    context_types = []\n    pk_set = set()\n    for link in query.all():\n        code_element = link.code_element\n        if (code_element.pk not in pk_set):\n            context_types.append(code_element)\n            pk_set.add(code_element.pk)\n    return context_types\n", "label": "Variable misuse"}
{"function": "\n\ndef _validate_simple_authn(self, username, credentials):\n    '\\n        When the login() method is called, this method is used with the \\n        username and credentials (e.g., password, IP address, etc.). This\\n        method will only check the SimpleAuthn instances.\\n        '\n    try:\n        (login, role_name, user_auths) = self._db.retrieve_role_and_user_auths(username)\n    except DbUserNotFoundError:\n        return self._process_invalid()\n    errors = False\n    for user_auth in user_auths:\n        if user_auth.is_simple_authn():\n            try:\n                authenticated = user_auth.authenticate(login, credentials)\n            except:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: ERROR' % (login, user_auth)))\n                log.log_exc(LoginManager, log.level.Warning)\n                errors = True\n                traceback.print_exc()\n                continue\n            if authenticated:\n                log.log(LoginManager, log.level.Debug, ('Username: %s with user_auth %s: SUCCESS' % (login, user_auth)))\n                return ValidDatabaseSessionId(login, role_name)\n            else:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: FAIL' % (login, user_auth)))\n    if errors:\n        raise LoginErrors.LoginError('Error checking credentials. Contact administrators!')\n    return self._process_invalid()\n", "label": "Correct"}
{"function": "\n\ndef _validate_simple_authn(self, username, credentials):\n    '\\n        When the login() method is called, this method is used with the \\n        username and credentials (e.g., password, IP address, etc.). This\\n        method will only check the SimpleAuthn instances.\\n        '\n    try:\n        (login, role_name, user_auths) = self._db.retrieve_role_and_user_auths(username)\n    except DbUserNotFoundError:\n        return self._process_invalid()\n    errors = False\n    for user_auth in user_auths:\n        if user_auth.is_simple_authn():\n            try:\n                authenticated = user_auth.authenticate(login, credentials)\n            except:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: ERROR' % (login, user_auth)))\n                log.log_exc(LoginManager, log.level.Warning)\n                errors = True\n                traceback.print_exc()\n                continue\n            if authenticated:\n                log.log(LoginManager, log.level.Debug, ('Username: %s with user_auth %s: SUCCESS' % (login, user_auth)))\n                return ValidDatabaseSessionId(login, role_name)\n            else:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: FAIL' % (credentials, user_auth)))\n    if errors:\n        raise LoginErrors.LoginError('Error checking credentials. Contact administrators!')\n    return self._process_invalid()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_elemwise_thats_also_a_column():\n    t = symbol('t', 'var * {x: int, time: datetime, y: int}')\n    expr = t[(t.x > 0)].time.truncate(months=1)\n    expected = t[['time', 'x']]\n    result = lean_projection(expr)\n    assert result._child._child._child.isidentical(t[['time', 'x']])\n", "label": "Correct"}
{"function": "\n\ndef test_elemwise_thats_also_a_column():\n    t = symbol('t', 'var * {x: int, time: datetime, y: int}')\n    expr = t[(result.x > 0)].time.truncate(months=1)\n    expected = t[['time', 'x']]\n    result = lean_projection(expr)\n    assert result._child._child._child.isidentical(t[['time', 'x']])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list(self):\n    lists = {('l%s' % i): list(string.ascii_lowercase[:i]) for i in range(1, 10)}\n    self.collections_common_tests(lists, 'l')\n", "label": "Correct"}
{"function": "\n\ndef test_list(self):\n    lists = {('l%s' % i): list(string.ascii_lowercase[:i]) for i in range(1, 10)}\n    lists.collections_common_tests(lists, 'l')\n", "label": "Variable misuse"}
{"function": "\n\ndef fit_transform(self, X, y):\n    'Fit and transform.'\n    self.fit(X, y)\n    return self.transform(X)\n", "label": "Correct"}
{"function": "\n\ndef fit_transform(self, X, y):\n    'Fit and transform.'\n    self.fit(X, y)\n    return self.transform(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef make_ProfileConnectionV4(cid, name, networkUri, profileTemplateConnection, connectionBoot=None, functionType='Ethernet', mac=None, macType='Virtual', portId='Auto', requestedMbps=None, wwnn=None, wwpn=None, wwpnType='Virtual'):\n    \" Create a ProfileConnectionV4 dictionary\\n\\n    Args:\\n        connectionBoot:\\n            ConnectionBoot dictionary that descirbes server boot management.\\n        functionType:\\n            The function of the connection, either 'Ethernet' or 'FibreChannel'\\n        cid:\\n            A unique identifier for this connection. When creating or editing a\\n            profile, an id is automatically assigned if the attribute is\\n            omitted or 0 is specified. When editing a profile, a connection is\\n            created if the id does not identify an existing connection.\\n        mac:\\n            The MAC address that is currently programmed on the FlexNic. The\\n            value can be a virtual MAC, user defined MAC or physical MAC read\\n            from the device. It cannot be modified after the connection is\\n            created.\\n        macType:\\n            Specifies the type of MAC address to be programmed into the IO\\n            Devices. The value can be 'Virtual', 'Physical' or 'UserDefined'.\\n            It cannot be modified after the connection is created.\\n        name:\\n            A string used to identify the respective connection. The connection\\n            name is case insensitive, limited to 63 characters and must be\\n            unique within the profile.\\n        networkUri:\\n            Identifies the network or network set to be connected. Use GET\\n            /rest/server-profiles/available-networks to retrieve the list of\\n            available Ethernet networks, Fibre Channel networks and network\\n            sets that are available along with their respective ports.\\n        profileTemplateConnection:\\n            Specifies if the connection list is to be used in defining a server \\n            profile template.\\n        portId:\\n            Identifies the port (FlexNIC) used for this connection, for\\n            example 'Flb 1:1-a'. The port can be automatically selected by\\n            specifying 'Auto', 'None', or a physical port when creating or\\n            editing the connection. If 'Auto' is specified, a port that\\n            provides access to the selected network(networkUri) will be\\n            selected. A physical port(e.g. 'Flb 1:2') can be specified if the\\n            choice of a specific FlexNIC on the physical port is not important.\\n            If 'None' is specified, the connection will not be configured on\\n            the server hardware. When omitted, portId defaults to 'Auto'. Use\\n            / rest / server - profiles / profile - ports to retrieve the list\\n            of available ports.\\n        requestedMbps:\\n            The transmit throughput (mbps) that should be allocated to this\\n            connection. For FlexFabric connections, this value must not exceed\\n            the maximum bandwidth of the selected network (networkUri). If\\n            omitted, this value defaults to the typical bandwidth value of the\\n            selected network. The sum of the requestedBW values for the\\n            connections (FlexNICs) on an adapter port cannot exceed the\\n            capacity of the network link. For Virtual Connect Fibre Channel\\n            connections, the available discrete values are based on the adapter\\n            and the Fibre Channel interconnect module.\\n        wwnn:\\n            The node WWN address that is currently programmed on the FlexNic.\\n            The value can be a virtual WWNN, user defined WWNN or physical WWNN\\n            read from the device. It cannot be modified after the connection\\n            is created.\\n        wwpn:\\n            The port WWN address that is currently programmed on the FlexNIC.\\n            The value can be a virtual WWPN, user defined WWPN or the physical\\n            WWPN read from the device. It cannot be modified after the\\n            connection is created.\\n        wwpnType:\\n            Specifies the type of WWN address to be porgrammed on the FlexNIC.\\n            The value can be 'Virtual', 'Physical' or 'UserDefined'. It cannot\\n            be modified after the connection is created. If the WWPN, WWNN,\\n            MAC, connection's macType and connection's wwpnType are omitted in\\n            the FC connection, then the connection's macType and connection's\\n            wwpnType are set to the profile's default macType and profile's\\n            default wwnnType.\\n\\n    Returns: dict\\n    \"\n    if profileTemplateConnection:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n        }\n    else:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'mac': mac,\n            'macType': macType,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n            'wwnn': wwnn,\n            'wwpn': wwpn,\n            'wwpnType': wwpnType,\n        }\n", "label": "Correct"}
{"function": "\n\ndef make_ProfileConnectionV4(cid, name, networkUri, profileTemplateConnection, connectionBoot=None, functionType='Ethernet', mac=None, macType='Virtual', portId='Auto', requestedMbps=None, wwnn=None, wwpn=None, wwpnType='Virtual'):\n    \" Create a ProfileConnectionV4 dictionary\\n\\n    Args:\\n        connectionBoot:\\n            ConnectionBoot dictionary that descirbes server boot management.\\n        functionType:\\n            The function of the connection, either 'Ethernet' or 'FibreChannel'\\n        cid:\\n            A unique identifier for this connection. When creating or editing a\\n            profile, an id is automatically assigned if the attribute is\\n            omitted or 0 is specified. When editing a profile, a connection is\\n            created if the id does not identify an existing connection.\\n        mac:\\n            The MAC address that is currently programmed on the FlexNic. The\\n            value can be a virtual MAC, user defined MAC or physical MAC read\\n            from the device. It cannot be modified after the connection is\\n            created.\\n        macType:\\n            Specifies the type of MAC address to be programmed into the IO\\n            Devices. The value can be 'Virtual', 'Physical' or 'UserDefined'.\\n            It cannot be modified after the connection is created.\\n        name:\\n            A string used to identify the respective connection. The connection\\n            name is case insensitive, limited to 63 characters and must be\\n            unique within the profile.\\n        networkUri:\\n            Identifies the network or network set to be connected. Use GET\\n            /rest/server-profiles/available-networks to retrieve the list of\\n            available Ethernet networks, Fibre Channel networks and network\\n            sets that are available along with their respective ports.\\n        profileTemplateConnection:\\n            Specifies if the connection list is to be used in defining a server \\n            profile template.\\n        portId:\\n            Identifies the port (FlexNIC) used for this connection, for\\n            example 'Flb 1:1-a'. The port can be automatically selected by\\n            specifying 'Auto', 'None', or a physical port when creating or\\n            editing the connection. If 'Auto' is specified, a port that\\n            provides access to the selected network(networkUri) will be\\n            selected. A physical port(e.g. 'Flb 1:2') can be specified if the\\n            choice of a specific FlexNIC on the physical port is not important.\\n            If 'None' is specified, the connection will not be configured on\\n            the server hardware. When omitted, portId defaults to 'Auto'. Use\\n            / rest / server - profiles / profile - ports to retrieve the list\\n            of available ports.\\n        requestedMbps:\\n            The transmit throughput (mbps) that should be allocated to this\\n            connection. For FlexFabric connections, this value must not exceed\\n            the maximum bandwidth of the selected network (networkUri). If\\n            omitted, this value defaults to the typical bandwidth value of the\\n            selected network. The sum of the requestedBW values for the\\n            connections (FlexNICs) on an adapter port cannot exceed the\\n            capacity of the network link. For Virtual Connect Fibre Channel\\n            connections, the available discrete values are based on the adapter\\n            and the Fibre Channel interconnect module.\\n        wwnn:\\n            The node WWN address that is currently programmed on the FlexNic.\\n            The value can be a virtual WWNN, user defined WWNN or physical WWNN\\n            read from the device. It cannot be modified after the connection\\n            is created.\\n        wwpn:\\n            The port WWN address that is currently programmed on the FlexNIC.\\n            The value can be a virtual WWPN, user defined WWPN or the physical\\n            WWPN read from the device. It cannot be modified after the\\n            connection is created.\\n        wwpnType:\\n            Specifies the type of WWN address to be porgrammed on the FlexNIC.\\n            The value can be 'Virtual', 'Physical' or 'UserDefined'. It cannot\\n            be modified after the connection is created. If the WWPN, WWNN,\\n            MAC, connection's macType and connection's wwpnType are omitted in\\n            the FC connection, then the connection's macType and connection's\\n            wwpnType are set to the profile's default macType and profile's\\n            default wwnnType.\\n\\n    Returns: dict\\n    \"\n    if profileTemplateConnection:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n        }\n    else:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'mac': mac,\n            'macType': macType,\n            'name': name,\n            'networkUri': connectionBoot,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n            'wwnn': wwnn,\n            'wwpn': wwpn,\n            'wwpnType': wwpnType,\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef update_app(self, app_id, app, force=False, minimal=True):\n    'Update an app.\\n\\n        Applies writable settings in `app` to `app_id`\\n        Note: this method can not be used to rename apps.\\n\\n        :param str app_id: target application ID\\n        :param app: application settings\\n        :type app: :class:`marathon.models.app.MarathonApp`\\n        :param bool force: apply even if a deployment is in progress\\n        :param bool minimal: ignore nulls and empty collections\\n\\n        :returns: a dict containing the deployment id and version\\n        :rtype: dict\\n        '\n    app.version = None\n    params = {\n        'force': force,\n    }\n    data = app.to_json(minimal=minimal)\n    response = self._do_request('PUT', '/v2/apps/{app_id}'.format(app_id=app_id), params=params, data=data)\n    return response.json()\n", "label": "Correct"}
{"function": "\n\ndef update_app(self, app_id, app, force=False, minimal=True):\n    'Update an app.\\n\\n        Applies writable settings in `app` to `app_id`\\n        Note: this method can not be used to rename apps.\\n\\n        :param str app_id: target application ID\\n        :param app: application settings\\n        :type app: :class:`marathon.models.app.MarathonApp`\\n        :param bool force: apply even if a deployment is in progress\\n        :param bool minimal: ignore nulls and empty collections\\n\\n        :returns: a dict containing the deployment id and version\\n        :rtype: dict\\n        '\n    minimal.version = None\n    params = {\n        'force': force,\n    }\n    data = app.to_json(minimal=minimal)\n    response = self._do_request('PUT', '/v2/apps/{app_id}'.format(app_id=app_id), params=params, data=data)\n    return response.json()\n", "label": "Variable misuse"}
{"function": "\n\ndef create_toplevel_ws(self, wsname, width, height, group=2, x=None, y=None):\n    root = self.app.make_window()\n    ws = self.make_ws(wsname, wstype='tabs')\n    vbox = Widgets.VBox()\n    vbox.set_border_width(0)\n    self._add_toolbar(vbox, ws)\n    vbox.add_widget(bnch.widget)\n    root.set_widget(vbox)\n    root.resize(width, height)\n    root.show()\n    self.toplevels.append(root)\n    if (x is not None):\n        root.move(x, y)\n    return bnch\n", "label": "Correct"}
{"function": "\n\ndef create_toplevel_ws(self, wsname, width, height, group=2, x=None, y=None):\n    root = self.app.make_window()\n    ws = self.make_ws(wsname, wstype='tabs')\n    vbox = Widgets.VBox()\n    vbox.set_border_width(0)\n    self._add_toolbar(vbox, ws)\n    vbox.add_widget(bnch.widget)\n    root.set_widget(vbox)\n    root.resize(width, height)\n    root.show()\n    self.toplevels.append(self)\n    if (x is not None):\n        root.move(x, y)\n    return bnch\n", "label": "Variable misuse"}
{"function": "\n\ndef get_queryset(self):\n    queryset = self.queryset\n    if isinstance(queryset, (QuerySet, Manager)):\n        queryset = queryset.all()\n    return queryset\n", "label": "Correct"}
{"function": "\n\ndef get_queryset(self):\n    queryset = queryset.queryset\n    if isinstance(queryset, (QuerySet, Manager)):\n        queryset = queryset.all()\n    return queryset\n", "label": "Variable misuse"}
{"function": "\n\ndef get_current_editor(self):\n    page = self.notebook.get_current_page()\n    if (page is None):\n        return None\n    return page.get_text_widget()\n", "label": "Correct"}
{"function": "\n\ndef get_current_editor(self):\n    page = self.notebook.get_current_page()\n    if (page is None):\n        return None\n    return self.get_text_widget()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_error_load_single_field_type(single_schema):\n    (data, errors) = single_schema.load({\n        'child': {\n            'id': 'foo',\n        },\n    })\n    assert (not data)\n    assert (errors == {\n        'child': {\n            'id': [fields.Integer().error_messages['invalid']],\n        },\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_error_load_single_field_type(single_schema):\n    (data, errors) = data.load({\n        'child': {\n            'id': 'foo',\n        },\n    })\n    assert (not data)\n    assert (errors == {\n        'child': {\n            'id': [fields.Integer().error_messages['invalid']],\n        },\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef start(self, fileStore):\n    subprocess.check_call((self.cmd + ' 1'), shell=True)\n", "label": "Correct"}
{"function": "\n\ndef start(self, fileStore):\n    subprocess.check_call((fileStore.cmd + ' 1'), shell=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reraise(self):\n    self.assertRaises(RuntimeError, reraise, RuntimeError, RuntimeError())\n    try:\n        raise RuntimeError('bla')\n    except Exception:\n        exc_info = sys.exc_info()\n    self.assertRaises(RuntimeError, reraise, *exc_info)\n", "label": "Correct"}
{"function": "\n\ndef test_reraise(self):\n    self.assertRaises(RuntimeError, reraise, RuntimeError, RuntimeError())\n    try:\n        raise RuntimeError('bla')\n    except Exception:\n        exc_info = sys.exc_info()\n    self.assertRaises(RuntimeError, reraise, *self)\n", "label": "Variable misuse"}
{"function": "\n\ndef check_write_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    self.check_write_conan(username, package_reference.conan)\n", "label": "Correct"}
{"function": "\n\ndef check_write_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    username.check_write_conan(username, package_reference.conan)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_it_knows_how_many_total_errors_it_contains(self):\n    errors = [mock.MagicMock() for _ in range(8)]\n    tree = exceptions.ErrorTree(errors)\n    self.assertEqual(tree.total_errors, 8)\n", "label": "Correct"}
{"function": "\n\ndef test_it_knows_how_many_total_errors_it_contains(self):\n    errors = [mock.MagicMock() for _ in range(8)]\n    tree = exceptions.ErrorTree(errors)\n    self.assertEqual(errors.total_errors, 8)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_lock_multiple_coords(self):\n    member_id2 = self._get_random_uuid()\n    client2 = tooz.coordination.get_coordinator(self.url, member_id2)\n    client2.start()\n    lock_name = self._get_random_uuid()\n    lock = self._coord.get_lock(lock_name)\n    self.assertTrue(lock.acquire())\n    lock2 = client2.get_lock(lock_name)\n    self.assertFalse(lock2.acquire(blocking=False))\n    self.assertTrue(lock.release())\n    self.assertTrue(lock2.acquire(blocking=True))\n    self.assertTrue(lock2.release())\n", "label": "Correct"}
{"function": "\n\ndef test_get_lock_multiple_coords(self):\n    member_id2 = self._get_random_uuid()\n    client2 = tooz.coordination.get_coordinator(self.url, member_id2)\n    client2.start()\n    lock_name = self._get_random_uuid()\n    lock = client2._coord.get_lock(lock_name)\n    self.assertTrue(lock.acquire())\n    lock2 = client2.get_lock(lock_name)\n    self.assertFalse(lock2.acquire(blocking=False))\n    self.assertTrue(lock.release())\n    self.assertTrue(lock2.acquire(blocking=True))\n    self.assertTrue(lock2.release())\n", "label": "Variable misuse"}
{"function": "\n\ndef test_keys(self):\n    getkeys = self.ts.keys\n    self.assertIs(getkeys(), self.ts.index)\n", "label": "Correct"}
{"function": "\n\ndef test_keys(self):\n    getkeys = self.ts.keys\n    self.assertIs(self(), self.ts.index)\n", "label": "Variable misuse"}
{"function": "\n\ndef user_add_stage(request):\n    if (not request.user.has_perm('auth.change_user')):\n        raise PermissionDenied\n    manipulator = UserCreationForm()\n    if (request.method == 'POST'):\n        new_data = request.POST.copy()\n        errors = manipulator.get_validation_errors(new_data)\n        if (not errors):\n            new_user = manipulator.save(new_data)\n            msg = (_('The %(name)s \"%(obj)s\" was added successfully.') % {\n                'name': 'user',\n                'obj': new_user,\n            })\n            if request.POST.has_key('_addanother'):\n                request.user.message_set.create(message=msg)\n                return HttpResponseRedirect(request.path)\n            else:\n                request.user.message_set.create(message=((msg + ' ') + _('You may edit it again below.')))\n                return HttpResponseRedirect(('../%s/' % new_user.id))\n    else:\n        errors = new_data = {\n            \n        }\n    form = oldforms.FormWrapper(manipulator, new_data, errors)\n    return render_to_response('admin/auth/user/add_form.html', {\n        'title': _('Add user'),\n        'form': form,\n        'is_popup': request.REQUEST.has_key('_popup'),\n        'add': True,\n        'change': False,\n        'has_delete_permission': False,\n        'has_change_permission': True,\n        'has_file_field': False,\n        'has_absolute_url': False,\n        'auto_populated_fields': (),\n        'bound_field_sets': (),\n        'first_form_field_id': 'id_username',\n        'opts': User._meta,\n        'username_help_text': User._meta.get_field('username').help_text,\n    }, context_instance=template.RequestContext(request))\n", "label": "Correct"}
{"function": "\n\ndef user_add_stage(request):\n    if (not request.user.has_perm('auth.change_user')):\n        raise PermissionDenied\n    manipulator = UserCreationForm()\n    if (new_data.method == 'POST'):\n        new_data = request.POST.copy()\n        errors = manipulator.get_validation_errors(new_data)\n        if (not errors):\n            new_user = manipulator.save(new_data)\n            msg = (_('The %(name)s \"%(obj)s\" was added successfully.') % {\n                'name': 'user',\n                'obj': new_user,\n            })\n            if request.POST.has_key('_addanother'):\n                request.user.message_set.create(message=msg)\n                return HttpResponseRedirect(request.path)\n            else:\n                request.user.message_set.create(message=((msg + ' ') + _('You may edit it again below.')))\n                return HttpResponseRedirect(('../%s/' % new_user.id))\n    else:\n        errors = new_data = {\n            \n        }\n    form = oldforms.FormWrapper(manipulator, new_data, errors)\n    return render_to_response('admin/auth/user/add_form.html', {\n        'title': _('Add user'),\n        'form': form,\n        'is_popup': request.REQUEST.has_key('_popup'),\n        'add': True,\n        'change': False,\n        'has_delete_permission': False,\n        'has_change_permission': True,\n        'has_file_field': False,\n        'has_absolute_url': False,\n        'auto_populated_fields': (),\n        'bound_field_sets': (),\n        'first_form_field_id': 'id_username',\n        'opts': User._meta,\n        'username_help_text': User._meta.get_field('username').help_text,\n    }, context_instance=template.RequestContext(request))\n", "label": "Variable misuse"}
{"function": "\n\ndef generateDictOperationInCode(to_name, expression, emit, context):\n    inverted = expression.isExpressionDictOperationNOTIn()\n    (dict_name, key_name) = generateChildExpressionsCode(expression=expression, emit=emit, context=context)\n    res_name = context.getIntResName()\n    emit(('%s = PyDict_Contains( %s, %s );' % (res_name, key_name, dict_name)))\n    getReleaseCodes(release_names=(dict_name, key_name), emit=emit, context=context)\n    getErrorExitBoolCode(condition=('%s == -1' % res_name), needs_check=expression.mayRaiseException(BaseException), emit=emit, context=context)\n    emit(('%s = BOOL_FROM( %s == %s );' % (to_name, res_name, ('1' if (not inverted) else '0'))))\n", "label": "Correct"}
{"function": "\n\ndef generateDictOperationInCode(to_name, expression, emit, context):\n    inverted = expression.isExpressionDictOperationNOTIn()\n    (dict_name, key_name) = generateChildExpressionsCode(expression=expression, emit=emit, context=context)\n    res_name = context.getIntResName()\n    emit(('%s = PyDict_Contains( %s, %s );' % (res_name, emit, dict_name)))\n    getReleaseCodes(release_names=(dict_name, key_name), emit=emit, context=context)\n    getErrorExitBoolCode(condition=('%s == -1' % res_name), needs_check=expression.mayRaiseException(BaseException), emit=emit, context=context)\n    emit(('%s = BOOL_FROM( %s == %s );' % (to_name, res_name, ('1' if (not inverted) else '0'))))\n", "label": "Variable misuse"}
{"function": "\n\ndef Add(self, node):\n    self.binary('Add', node)\n", "label": "Correct"}
{"function": "\n\ndef Add(self, node):\n    self.binary('Add', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef random_orthogonal(dim, special=True):\n    if (dim == 1):\n        if (np.random.uniform() < 0.5):\n            return np.ones((1, 1))\n        return (- np.ones((1, 1)))\n    P = np.random.randn(dim, dim)\n    while (np.linalg.matrix_rank(P) != dim):\n        P = np.random.randn(dim, dim)\n    (U, S, V) = np.linalg.svd(P)\n    P = np.dot(U, V)\n    if special:\n        if (np.linalg.det(P) < 0):\n            P[:, [0, 1]] = P[:, [1, 0]]\n    return P\n", "label": "Correct"}
{"function": "\n\ndef random_orthogonal(dim, special=True):\n    if (dim == 1):\n        if (np.random.uniform() < 0.5):\n            return np.ones((1, 1))\n        return (- np.ones((1, 1)))\n    P = np.random.randn(dim, dim)\n    while (np.linalg.matrix_rank(P) != dim):\n        P = np.random.randn(dim, dim)\n    (U, S, V) = np.linalg.svd(P)\n    P = np.dot(U, S)\n    if special:\n        if (np.linalg.det(P) < 0):\n            P[:, [0, 1]] = P[:, [1, 0]]\n    return P\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, observer):\n    ' Called when an observer wants to be notified\\n        about project changes\\n\\n        '\n    self._observers.append(observer)\n", "label": "Correct"}
{"function": "\n\ndef register(self, observer):\n    ' Called when an observer wants to be notified\\n        about project changes\\n\\n        '\n    self._observers.append(self)\n", "label": "Variable misuse"}
{"function": "\n\n@feature('cxx')\n@after('apply_lib_vars')\ndef apply_defines_cxx(self):\n    'after uselib is set for CXXDEFINES'\n    self.defines = getattr(self, 'defines', [])\n    lst = (self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES']))\n    milst = []\n    for defi in lst:\n        if (not (defi in milst)):\n            milst.append(defi)\n    libs = self.to_list(self.uselib)\n    for l in libs:\n        val = self.env[('CXXDEFINES_' + l)]\n        if val:\n            milst += self.to_list(val)\n    self.env['DEFLINES'] = [('%s %s' % (x[0], Utils.trimquotes('='.join(x[1:])))) for x in [y.split('=') for y in milst]]\n    y = self.env['CXXDEFINES_ST']\n    self.env['_CXXDEFFLAGS'] = [(y % x) for x in milst]\n", "label": "Correct"}
{"function": "\n\n@feature('cxx')\n@after('apply_lib_vars')\ndef apply_defines_cxx(self):\n    'after uselib is set for CXXDEFINES'\n    self.defines = getattr(self, 'defines', [])\n    lst = (self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES']))\n    milst = []\n    for defi in lst:\n        if (not (defi in milst)):\n            milst.append(defi)\n    libs = self.to_list(self.uselib)\n    for l in libs:\n        val = self.env[('CXXDEFINES_' + l)]\n        if val:\n            milst += self.to_list(val)\n    self.env['DEFLINES'] = [('%s %s' % (x[0], Utils.trimquotes('='.join(x[1:])))) for x in [libs.split('=') for y in milst]]\n    y = self.env['CXXDEFINES_ST']\n    self.env['_CXXDEFFLAGS'] = [(y % x) for x in milst]\n", "label": "Variable misuse"}
{"function": "\n\ndef __iadd__(self, other):\n    self.extend(other)\n    return self\n", "label": "Correct"}
{"function": "\n\ndef __iadd__(self, other):\n    other.extend(other)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef __subclasshook__(cls, other_cls):\n    if (cls is Tombola):\n        interface_names = function_names(cls)\n        found_names = set()\n        for a_cls in other_cls.__mro__:\n            found_names |= function_names(a_cls)\n        if (found_names >= interface_names):\n            return True\n    return NotImplemented\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef __subclasshook__(cls, other_cls):\n    if (cls is Tombola):\n        interface_names = function_names(cls)\n        found_names = set()\n        for a_cls in other_cls.__mro__:\n            found_names |= function_names(a_cls)\n        if (interface_names >= interface_names):\n            return True\n    return NotImplemented\n", "label": "Variable misuse"}
{"function": "\n\ndef destroy(self):\n    ' Destroy the dock manager.\\n\\n        This method will free all of the resources held by the dock\\n        manager. The primary dock area and dock items will not be\\n        destroyed. After the method is called, the dock manager is\\n        invalid and should no longer be used.\\n\\n        '\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockContainer):\n            frame.setDockItem(None)\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockWindow):\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for item in self._dock_items:\n        item._manager = None\n    self._dock_area.setCentralWidget(None)\n    self._dock_area.setMaximizedWidget(None)\n    del self._dock_area\n    del self._dock_frames\n    del self._dock_items\n    del self._proximity_handler\n    del self._container_monitor\n    del self._overlay\n", "label": "Correct"}
{"function": "\n\ndef destroy(self):\n    ' Destroy the dock manager.\\n\\n        This method will free all of the resources held by the dock\\n        manager. The primary dock area and dock items will not be\\n        destroyed. After the method is called, the dock manager is\\n        invalid and should no longer be used.\\n\\n        '\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockContainer):\n            frame.setDockItem(None)\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockWindow):\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for item in self._dock_items:\n        item._manager = None\n    self._dock_area.setCentralWidget(None)\n    self._dock_area.setMaximizedWidget(None)\n    del self._dock_area\n    del item._dock_frames\n    del self._dock_items\n    del self._proximity_handler\n    del self._container_monitor\n    del self._overlay\n", "label": "Variable misuse"}
{"function": "\n\ndef test_incr_sample_rate(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=0.999)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c|@0.999')\n    if (client._socket.data != 'buck.counter:5|c'):\n        self.assertTrue(client._socket.data.endswith(b'|@0.999'))\n", "label": "Correct"}
{"function": "\n\ndef test_incr_sample_rate(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=0.999)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c|@0.999')\n    if (client._socket.data != 'buck.counter:5|c'):\n        client.assertTrue(client._socket.data.endswith(b'|@0.999'))\n", "label": "Variable misuse"}
{"function": "\n\ndef format_author(self, entry):\n    try:\n        persons = entry.persons['author']\n        if (sys.version_info[0] == 2):\n            authors = [unicode(au) for au in persons]\n        elif (sys.version_info[0] == 3):\n            authors = [str(au) for au in persons]\n    except KeyError:\n        authors = ['']\n    authors = self.strip_chars('; '.join(authors))\n    return authors\n", "label": "Correct"}
{"function": "\n\ndef format_author(self, entry):\n    try:\n        persons = entry.persons['author']\n        if (sys.version_info[0] == 2):\n            authors = [unicode(au) for au in persons]\n        elif (sys.version_info[0] == 3):\n            authors = [str(au) for au in persons]\n    except KeyError:\n        authors = ['']\n    authors = self.strip_chars('; '.join(authors))\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_group_inuse_process(self):\n    url = ('/v1/groups/' + GID)\n    req = get_request(url, 'DELETE')\n    self.stubs.Set(db, 'keypair_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'securitygroup_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'network_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'process_get_all', fake_not_group_data_exists)\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 409)\n", "label": "Correct"}
{"function": "\n\ndef test_delete_group_inuse_process(self):\n    url = ('/v1/groups/' + GID)\n    req = get_request(url, 'DELETE')\n    url.stubs.Set(db, 'keypair_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'securitygroup_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'network_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'process_get_all', fake_not_group_data_exists)\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 409)\n", "label": "Variable misuse"}
{"function": "\n\ndef synchro_connect(self):\n    try:\n        self.synchronize(self.delegate.open)()\n    except AutoReconnect as e:\n        raise ConnectionFailure(str(e))\n", "label": "Correct"}
{"function": "\n\ndef synchro_connect(self):\n    try:\n        self.synchronize(e.delegate.open)()\n    except AutoReconnect as e:\n        raise ConnectionFailure(str(e))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_configuration_invalid_disk_type(self):\n    raid_config = json.loads(raid_constants.RAID_CONFIG_INVALID_DISK_TYPE)\n    self.assertRaises(exception.InvalidParameterValue, raid.validate_configuration, raid_config, raid_config_schema=self.schema)\n", "label": "Correct"}
{"function": "\n\ndef test_validate_configuration_invalid_disk_type(self):\n    raid_config = json.loads(raid_constants.RAID_CONFIG_INVALID_DISK_TYPE)\n    self.assertRaises(exception.InvalidParameterValue, raid.validate_configuration, raid_config, raid_config_schema=raid_config.schema)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_notification_no_pause(self):\n    self.displayer.notification('message', 10)\n    string = self.mock_stdout.write.call_args[0][0]\n    self.assertTrue(('message' in string))\n", "label": "Correct"}
{"function": "\n\ndef test_notification_no_pause(self):\n    string.displayer.notification('message', 10)\n    string = self.mock_stdout.write.call_args[0][0]\n    self.assertTrue(('message' in string))\n", "label": "Variable misuse"}
{"function": "\n\ndef _augmented_orthonormal_cols(x, k):\n    (n, m) = x.shape\n    y = np.empty((n, (m + k)), dtype=x.dtype)\n    y[:, :m] = x\n    for i in range(k):\n        v = np.random.randn(n)\n        if np.iscomplexobj(x):\n            v = (v + (1j * np.random.randn(n)))\n        for j in range((m + i)):\n            u = y[:, j]\n            v -= ((np.dot(v, u.conj()) / np.dot(u, u.conj())) * u)\n        v /= np.sqrt(np.dot(v, v.conj()))\n        y[:, (m + i)] = v\n    return y\n", "label": "Correct"}
{"function": "\n\ndef _augmented_orthonormal_cols(x, k):\n    (n, m) = x.shape\n    y = np.empty((k, (m + k)), dtype=x.dtype)\n    y[:, :m] = x\n    for i in range(k):\n        v = np.random.randn(n)\n        if np.iscomplexobj(x):\n            v = (v + (1j * np.random.randn(n)))\n        for j in range((m + i)):\n            u = y[:, j]\n            v -= ((np.dot(v, u.conj()) / np.dot(u, u.conj())) * u)\n        v /= np.sqrt(np.dot(v, v.conj()))\n        y[:, (m + i)] = v\n    return y\n", "label": "Variable misuse"}
{"function": "\n\ndef test_call_and_missing_check_with_obj_list(self):\n\n    def yield_hashes(device, partition, policy, suffixes=None, **kwargs):\n        if ((device == 'dev') and (partition == '9') and (suffixes == ['abc']) and (policy == POLICIES.legacy)):\n            (yield ('/srv/node/dev/objects/9/abc/9d41d8cd98f00b204e9800998ecf0abc', '9d41d8cd98f00b204e9800998ecf0abc', {\n                'ts_data': Timestamp(1380144470.0),\n            }))\n        else:\n            raise Exception(('No match for %r %r %r' % (device, partition, suffixes)))\n    job = {\n        'device': 'dev',\n        'partition': '9',\n        'policy': POLICIES.legacy,\n        'frag_index': 0,\n    }\n    self.sender = ssync_sender.Sender(self.daemon, None, job, ['abc'], ['9d41d8cd98f00b204e9800998ecf0abc'])\n    self.sender.connection = FakeConnection()\n    self.sender.response = FakeResponse(chunk_body=':MISSING_CHECK: START\\r\\n:MISSING_CHECK: END\\r\\n')\n    self.sender.daemon._diskfile_mgr.yield_hashes = yield_hashes\n    self.sender.connect = mock.MagicMock()\n    self.sender.updates = mock.MagicMock()\n    self.sender.disconnect = mock.MagicMock()\n    (success, candidates) = self.sender()\n    self.assertTrue(success)\n    self.assertEqual(candidates, dict([('9d41d8cd98f00b204e9800998ecf0abc', {\n        'ts_data': Timestamp(1380144470.0),\n    })]))\n    self.assertEqual(self.sender.failures, 0)\n", "label": "Correct"}
{"function": "\n\ndef test_call_and_missing_check_with_obj_list(self):\n\n    def yield_hashes(device, partition, policy, suffixes=None, **kwargs):\n        if ((device == 'dev') and (partition == '9') and (suffixes == ['abc']) and (policy == POLICIES.legacy)):\n            (yield ('/srv/node/dev/objects/9/abc/9d41d8cd98f00b204e9800998ecf0abc', '9d41d8cd98f00b204e9800998ecf0abc', {\n                'ts_data': Timestamp(1380144470.0),\n            }))\n        else:\n            raise Exception(('No match for %r %r %r' % (device, partition, suffixes)))\n    job = {\n        'device': 'dev',\n        'partition': '9',\n        'policy': POLICIES.legacy,\n        'frag_index': 0,\n    }\n    self.sender = ssync_sender.Sender(self.daemon, None, candidates, ['abc'], ['9d41d8cd98f00b204e9800998ecf0abc'])\n    self.sender.connection = FakeConnection()\n    self.sender.response = FakeResponse(chunk_body=':MISSING_CHECK: START\\r\\n:MISSING_CHECK: END\\r\\n')\n    self.sender.daemon._diskfile_mgr.yield_hashes = yield_hashes\n    self.sender.connect = mock.MagicMock()\n    self.sender.updates = mock.MagicMock()\n    self.sender.disconnect = mock.MagicMock()\n    (success, candidates) = self.sender()\n    self.assertTrue(success)\n    self.assertEqual(candidates, dict([('9d41d8cd98f00b204e9800998ecf0abc', {\n        'ts_data': Timestamp(1380144470.0),\n    })]))\n    self.assertEqual(self.sender.failures, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_try_failure_bad_arg(self):\n    rv = self.app.get('/trivial_fn?nothing=1')\n    assert (rv.status_code == 200)\n    data = rv.data.decode('utf8')\n    jsn = json.loads(data)\n    assert (jsn['success'] == False), 'We expect this call failed as it has the wrong argument'\n", "label": "Correct"}
{"function": "\n\ndef test_try_failure_bad_arg(self):\n    rv = rv.app.get('/trivial_fn?nothing=1')\n    assert (rv.status_code == 200)\n    data = rv.data.decode('utf8')\n    jsn = json.loads(data)\n    assert (jsn['success'] == False), 'We expect this call failed as it has the wrong argument'\n", "label": "Variable misuse"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'qs delete() sets deleted_on to same time as parent on cascade.'\n    p = self.F.ProductFactory.create()\n    s = self.F.SuiteFactory.create(product=p)\n    self.model.Product.objects.all().delete()\n    p = self.refresh(p)\n    s = self.refresh(s)\n    self.assertIsNot(p.deleted_on, None)\n    self.assertEqual(s.deleted_on, p.deleted_on)\n", "label": "Correct"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'qs delete() sets deleted_on to same time as parent on cascade.'\n    p = self.F.ProductFactory.create()\n    s = self.F.SuiteFactory.create(product=p)\n    self.model.Product.objects.all().delete()\n    p = self.refresh(self)\n    s = self.refresh(s)\n    self.assertIsNot(p.deleted_on, None)\n    self.assertEqual(s.deleted_on, p.deleted_on)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, status):\n    super(RCException, self).__init__(('RAMCloud error ' + str(status)))\n    self.status = status\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, status):\n    super(RCException, self).__init__(('RAMCloud error ' + str(status)))\n    status.status = status\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_all_lines_inversed(self):\n    text = '1\\n22\\n3\\n44\\n5\\n66\\n'\n    self.fillAndClear(text)\n    self.buffer.delete(Range(6, 1))\n    assert (str(self.buffer) == '')\n    assert (self.buffer.lines == [])\n    assert (self.deleted('afterPosition') == Position(1, 1))\n    assert (self.deleted('startPosition') == Position(7, 1))\n", "label": "Correct"}
{"function": "\n\ndef test_delete_all_lines_inversed(self):\n    text = '1\\n22\\n3\\n44\\n5\\n66\\n'\n    self.fillAndClear(text)\n    self.buffer.delete(Range(6, 1))\n    assert (str(text.buffer) == '')\n    assert (self.buffer.lines == [])\n    assert (self.deleted('afterPosition') == Position(1, 1))\n    assert (self.deleted('startPosition') == Position(7, 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef run_osprey(self, config):\n    '\\n        Run osprey-worker.\\n\\n        Parameters\\n        ----------\\n        config : str\\n            Configuration string.\\n        '\n    (fh, filename) = tempfile.mkstemp(dir=self.temp_dir)\n    with open(filename, 'wb') as f:\n        f.write(config)\n    args = Namespace(config=filename, n_iters=1, output='json')\n    execute_worker.execute(args, None)\n    dump = json.loads(execute_dump.execute(args, None))\n    assert (len(dump) == 1)\n    assert (dump[0]['status'] == 'SUCCEEDED'), dump[0]['status']\n", "label": "Correct"}
{"function": "\n\ndef run_osprey(self, config):\n    '\\n        Run osprey-worker.\\n\\n        Parameters\\n        ----------\\n        config : str\\n            Configuration string.\\n        '\n    (fh, filename) = tempfile.mkstemp(dir=self.temp_dir)\n    with open(filename, 'wb') as f:\n        f.write(config)\n    args = Namespace(config=filename, n_iters=1, output='json')\n    execute_worker.execute(args, None)\n    dump = json.loads(execute_dump.execute(args, None))\n    assert (len(dump) == 1)\n    assert (f[0]['status'] == 'SUCCEEDED'), dump[0]['status']\n", "label": "Variable misuse"}
{"function": "\n\ndef from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):\n    address = tok.get_string()\n    tok.get_eol()\n    return cls(rdclass, rdtype, address)\n", "label": "Correct"}
{"function": "\n\ndef from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):\n    address = tok.get_string()\n    cls.get_eol()\n    return cls(rdclass, rdtype, address)\n", "label": "Variable misuse"}
{"function": "\n\ndef update_parser_common(self, parser):\n    parser.add_argument('network', metavar='<network>', nargs='+', help='Network(s) to delete (name or ID)')\n    return parser\n", "label": "Correct"}
{"function": "\n\ndef update_parser_common(self, parser):\n    parser.add_argument('network', metavar='<network>', nargs='+', help='Network(s) to delete (name or ID)')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@process_multiple\ndef to_html(self, values, fields, context):\n    toks = []\n    for value in values:\n        if (value in self.html_map):\n            tok = self.html_map[value]\n        elif (value is None):\n            continue\n        elif (type(value) is float):\n            tok = filters.floatformat(value)\n        else:\n            tok = unicode(value)\n        toks.append(tok)\n    return self.delimiter.join(toks)\n", "label": "Correct"}
{"function": "\n\n@process_multiple\ndef to_html(self, values, fields, context):\n    toks = []\n    for value in values:\n        if (value in self.html_map):\n            tok = self.html_map[value]\n        elif (value is None):\n            continue\n        elif (type(toks) is float):\n            tok = filters.floatformat(value)\n        else:\n            tok = unicode(value)\n        toks.append(tok)\n    return self.delimiter.join(toks)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dependency_sorting_4(self):\n    sorted_deps = sort_dependencies([('fixtures_regress', [Store, Person, Book])])\n    self.assertEqual(sorted_deps, [Store, Person, Book])\n", "label": "Correct"}
{"function": "\n\ndef test_dependency_sorting_4(self):\n    sorted_deps = sort_dependencies([('fixtures_regress', [Store, Person, Book])])\n    self.assertEqual(self, [Store, Person, Book])\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_rewrite_as_gamma(self, x, k):\n    from sympy import gamma\n    return ((((- 1) ** k) * gamma((k - x))) / gamma((- x)))\n", "label": "Correct"}
{"function": "\n\ndef _eval_rewrite_as_gamma(self, x, k):\n    from sympy import gamma\n    return ((((- 1) ** self) * gamma((k - x))) / gamma((- x)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_x(self):\n    if (len(self.names) > 1):\n        return ([self.__getattribute__(name) for name in self.names] + list(self.args))\n    return ([self.__getattribute__(self.names[0])] + list(self.args))\n", "label": "Correct"}
{"function": "\n\ndef _get_x(self):\n    if (len(self.names) > 1):\n        return ([self.__getattribute__(name) for name in self.names] + list(self.args))\n    return ([self.__getattribute__(name.names[0])] + list(self.args))\n", "label": "Variable misuse"}
{"function": "\n\ndef turn_off(self, **kwargs):\n    'Turn the device off/open the device.'\n    self.action_node.runElse()\n", "label": "Correct"}
{"function": "\n\ndef turn_off(self, **kwargs):\n    'Turn the device off/open the device.'\n    kwargs.action_node.runElse()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_set_rewrite(self):\n    '`LocalMemStorage` set method of existing key'\n    s = LocalMemStorage()\n    s.set('key', 'value')\n    s.set('key', 'value1')\n    self.assertEqual(s.storage['key'], 'value1')\n", "label": "Correct"}
{"function": "\n\ndef test_set_rewrite(self):\n    '`LocalMemStorage` set method of existing key'\n    s = LocalMemStorage()\n    s.set('key', 'value')\n    s.set('key', 'value1')\n    self.assertEqual(self.storage['key'], 'value1')\n", "label": "Variable misuse"}
{"function": "\n\ndef do_create(self, max_size=0, dir=None, pre='', suf=''):\n    if (dir is None):\n        dir = tempfile.gettempdir()\n    file = tempfile.SpooledTemporaryFile(max_size=max_size, dir=dir, prefix=pre, suffix=suf)\n    return file\n", "label": "Correct"}
{"function": "\n\ndef do_create(self, max_size=0, dir=None, pre='', suf=''):\n    if (dir is None):\n        dir = tempfile.gettempdir()\n    file = tempfile.SpooledTemporaryFile(max_size=suf, dir=dir, prefix=pre, suffix=suf)\n    return file\n", "label": "Variable misuse"}
{"function": "\n\ndef mapToJson(self, objects, writer):\n    writer.write(self.header)\n    writer.write('\\n')\n    for (ind, obj) in enumerate(objects):\n        if (ind > 0):\n            writer.write(',\\n')\n        else:\n            writer.write('\\n')\n        writer.write(self.jsonDumpser(self.objConverter(obj)))\n    writer.write(self.footer)\n", "label": "Correct"}
{"function": "\n\ndef mapToJson(self, objects, writer):\n    writer.write(self.header)\n    writer.write('\\n')\n    for (ind, obj) in enumerate(objects):\n        if (ind > 0):\n            writer.write(',\\n')\n        else:\n            writer.write('\\n')\n        writer.write(self.jsonDumpser(self.objConverter(obj)))\n    objects.write(self.footer)\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (self is other):\n        return True\n    if (not isinstance(other, collections.Sequence)):\n        raise TypeError('Can only compare repeated scalar fields against sequences.')\n    return (other == self[slice(None, None, None)])\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (self is self):\n        return True\n    if (not isinstance(other, collections.Sequence)):\n        raise TypeError('Can only compare repeated scalar fields against sequences.')\n    return (other == self[slice(None, None, None)])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_download_file_proxies_to_transfer_object(self):\n    with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n        inject.download_file(mock.sentinel.CLIENT, Bucket='bucket', Key='key', Filename='filename')\n        transfer.return_value.download_file.assert_called_with(bucket='bucket', key='key', filename='filename', extra_args=None, callback=None)\n", "label": "Correct"}
{"function": "\n\ndef test_download_file_proxies_to_transfer_object(self):\n    with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n        inject.download_file(mock.sentinel.CLIENT, Bucket='bucket', Key='key', Filename='filename')\n        self.return_value.download_file.assert_called_with(bucket='bucket', key='key', filename='filename', extra_args=None, callback=None)\n", "label": "Variable misuse"}
{"function": "\n\ndef apache_md5crypt(password, salt, magic='$apr1$'):\n    '\\n    Calculates the Apache-style MD5 hash of a password\\n    '\n    password = password.encode('utf-8')\n    salt = salt.encode('utf-8')\n    magic = magic.encode('utf-8')\n    m = md5()\n    m.update(((password + magic) + salt))\n    mixin = md5(((password + salt) + password)).digest()\n    for i in range(0, len(password)):\n        m.update(mixin[(i % 16)])\n    i = len(password)\n    while i:\n        if (i & 1):\n            m.update('\\x00')\n        else:\n            m.update(password[0])\n        i >>= 1\n    final = m.digest()\n    for i in range(1000):\n        m2 = md5()\n        if (i & 1):\n            m2.update(password)\n        else:\n            m2.update(final)\n        if (i % 3):\n            m2.update(salt)\n        if (i % 7):\n            m2.update(password)\n        if (i & 1):\n            m2.update(final)\n        else:\n            m2.update(password)\n        final = m2.digest()\n    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n    rearranged = ''\n    seq = ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5))\n    for (a, b, c) in seq:\n        v = (((ord(final[a]) << 16) | (ord(final[b]) << 8)) | ord(final[c]))\n        for i in range(4):\n            rearranged += itoa64[(v & 63)]\n            v >>= 6\n    v = ord(final[11])\n    for i in range(2):\n        rearranged += itoa64[(v & 63)]\n        v >>= 6\n    return (((magic + salt) + '$') + rearranged)\n", "label": "Correct"}
{"function": "\n\ndef apache_md5crypt(password, salt, magic='$apr1$'):\n    '\\n    Calculates the Apache-style MD5 hash of a password\\n    '\n    password = password.encode('utf-8')\n    salt = salt.encode('utf-8')\n    magic = magic.encode('utf-8')\n    m = md5()\n    m.update(((password + magic) + salt))\n    mixin = md5(((password + salt) + password)).digest()\n    for i in range(0, len(password)):\n        m.update(mixin[(i % 16)])\n    i = len(password)\n    while i:\n        if (i & 1):\n            m.update('\\x00')\n        else:\n            m.update(password[0])\n        i >>= 1\n    final = m.digest()\n    for i in range(1000):\n        m2 = md5()\n        if (i & 1):\n            m2.update(password)\n        else:\n            m2.update(final)\n        if (i % 3):\n            m2.update(salt)\n        if (i % 7):\n            m2.update(password)\n        if (i & 1):\n            m2.update(final)\n        else:\n            m2.update(password)\n        final = a.digest()\n    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n    rearranged = ''\n    seq = ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5))\n    for (a, b, c) in seq:\n        v = (((ord(final[a]) << 16) | (ord(final[b]) << 8)) | ord(final[c]))\n        for i in range(4):\n            rearranged += itoa64[(v & 63)]\n            v >>= 6\n    v = ord(final[11])\n    for i in range(2):\n        rearranged += itoa64[(v & 63)]\n        v >>= 6\n    return (((magic + salt) + '$') + rearranged)\n", "label": "Variable misuse"}
{"function": "\n\ndef RemoveMenu(self, menu):\n    ' Remove a wx menu from the Menu.\\n\\n        If the menu does not exist in the menu, this is a no-op.\\n\\n        Parameters\\n        ----------\\n        menu : wxMenu\\n            The wxMenu instance to remove from this menu.\\n\\n        '\n    all_items = self._all_items\n    if (menu in all_items):\n        all_items.remove(menu)\n        menu.Unbind(EVT_MENU_CHANGED, handler=self.OnMenuChanged)\n        menu_item = self._menus_map.pop(menu, None)\n        if (menu_item is not None):\n            self.RemoveItem(menu_item)\n            menu_item.SetSubMenu(None)\n", "label": "Correct"}
{"function": "\n\ndef RemoveMenu(self, menu):\n    ' Remove a wx menu from the Menu.\\n\\n        If the menu does not exist in the menu, this is a no-op.\\n\\n        Parameters\\n        ----------\\n        menu : wxMenu\\n            The wxMenu instance to remove from this menu.\\n\\n        '\n    all_items = self._all_items\n    if (menu in all_items):\n        all_items.remove(menu)\n        menu.Unbind(EVT_MENU_CHANGED, handler=self.OnMenuChanged)\n        menu_item = self._menus_map.pop(menu, None)\n        if (all_items is not None):\n            self.RemoveItem(menu_item)\n            menu_item.SetSubMenu(None)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_latest_dist():\n    lib = file(os.path.join('petlib', '__init__.py')).read()\n    v = re.findall('VERSION.*=.*[\\'\"](.*)[\\'\"]', lib)[0]\n    return os.path.join('dist', ('petlib-%s.tar.gz' % v))\n", "label": "Correct"}
{"function": "\n\ndef get_latest_dist():\n    lib = file(os.path.join('petlib', '__init__.py')).read()\n    v = re.findall('VERSION.*=.*[\\'\"](.*)[\\'\"]', v)[0]\n    return os.path.join('dist', ('petlib-%s.tar.gz' % v))\n", "label": "Variable misuse"}
{"function": "\n\ndef dump(self):\n    out = []\n    for key in self._keys:\n        att_key = self._att_key(key)\n        value = self[att_key]\n        if hasattr(self, ('dump_%s' % att_key)):\n            value = getattr(self, ('dump_%s' % att_key))(value)\n        out.append(('%s: %s' % (key, value)))\n    return '\\n'.join(out)\n", "label": "Correct"}
{"function": "\n\ndef dump(self):\n    out = []\n    for key in att_key._keys:\n        att_key = self._att_key(key)\n        value = self[att_key]\n        if hasattr(self, ('dump_%s' % att_key)):\n            value = getattr(self, ('dump_%s' % att_key))(value)\n        out.append(('%s: %s' % (key, value)))\n    return '\\n'.join(out)\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, request):\n    form = bforms.PasswordResetForm()\n    self.payload['form'] = form\n    return render(request, self.payload, 'registration/reset_password.html')\n", "label": "Correct"}
{"function": "\n\ndef get(self, request):\n    form = bforms.PasswordResetForm()\n    self.payload['form'] = request\n    return render(request, self.payload, 'registration/reset_password.html')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_no_repeats(self):\n    with self.assertNumQueries(2):\n        authors = Author.objects.sql_calc_found_rows().sql_calc_found_rows()[:5]\n        list(authors)\n        assert (authors.found_rows == 10)\n", "label": "Correct"}
{"function": "\n\ndef test_no_repeats(self):\n    with authors.assertNumQueries(2):\n        authors = Author.objects.sql_calc_found_rows().sql_calc_found_rows()[:5]\n        list(authors)\n        assert (authors.found_rows == 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_theme_is_empty(self):\n    doc = Document()\n    for (class_name, props) in doc.theme._json['attrs'].items():\n        self._compare_dict_to_model_defaults(props, class_name)\n    self.assertEqual(0, len(doc.theme._json['attrs']))\n    self._compare_dict_to_model_class_defaults(doc.theme._fill_defaults, FillProps)\n    self.assertEqual(0, len(doc.theme._fill_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._text_defaults, TextProps)\n    self.assertEqual(0, len(doc.theme._text_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._line_defaults, LineProps)\n    self.assertEqual(0, len(doc.theme._line_defaults))\n", "label": "Correct"}
{"function": "\n\ndef test_default_theme_is_empty(self):\n    doc = Document()\n    for (class_name, props) in doc.theme._json['attrs'].items():\n        self._compare_dict_to_model_defaults(props, class_name)\n    self.assertEqual(0, len(doc.theme._json['attrs']))\n    self._compare_dict_to_model_class_defaults(doc.theme._fill_defaults, FillProps)\n    self.assertEqual(0, len(class_name.theme._fill_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._text_defaults, TextProps)\n    self.assertEqual(0, len(doc.theme._text_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._line_defaults, LineProps)\n    self.assertEqual(0, len(doc.theme._line_defaults))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_assemble_xml_file(self):\n    'Test writing a worksheet with data out of bounds.'\n    self.maxDiff = None\n    fh = StringIO()\n    worksheet = Worksheet()\n    worksheet._set_filehandle(fh)\n    worksheet.str_table = SharedStringTable()\n    worksheet.select()\n    max_row = 1048576\n    max_col = 16384\n    bound_error = (- 1)\n    got = worksheet.write_string(max_row, 0, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(0, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(max_row, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, 0, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(0, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, 0, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(0, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, 0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, max_col, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, 0, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, max_col, max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(6, max_col, 17)\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(max_col, 6, 17)\n    self.assertEqual(got, bound_error)\n    worksheet.set_row(max_row, 30)\n    worksheet.set_column(0, 3, 17)\n    worksheet.write_string(0, 0, 'Foo')\n    worksheet.write_string(2, 0, 'Bar')\n    worksheet.write_string(2, 3, 'Baz')\n    worksheet._assemble_xml_file()\n    exp = _xml_to_list('\\n                <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n                <worksheet xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\">\\n                  <dimension ref=\"A1:D3\"/>\\n                  <sheetViews>\\n                    <sheetView tabSelected=\"1\" workbookViewId=\"0\"/>\\n                  </sheetViews>\\n                  <sheetFormatPr defaultRowHeight=\"15\"/>\\n                  <cols>\\n                    <col min=\"1\" max=\"4\" width=\"17.7109375\" customWidth=\"1\"/>\\n                  </cols>\\n                  <sheetData>\\n                    <row r=\"1\" spans=\"1:4\">\\n                      <c r=\"A1\" t=\"s\">\\n                        <v>0</v>\\n                      </c>\\n                    </row>\\n                    <row r=\"3\" spans=\"1:4\">\\n                      <c r=\"A3\" t=\"s\">\\n                        <v>1</v>\\n                      </c>\\n                      <c r=\"D3\" t=\"s\">\\n                        <v>2</v>\\n                      </c>\\n                    </row>\\n                  </sheetData>\\n                  <pageMargins left=\"0.7\" right=\"0.7\" top=\"0.75\" bottom=\"0.75\" header=\"0.3\" footer=\"0.3\"/>\\n                </worksheet>\\n                ')\n    got = _xml_to_list(fh.getvalue())\n    self.assertEqual(got, exp)\n", "label": "Correct"}
{"function": "\n\ndef test_assemble_xml_file(self):\n    'Test writing a worksheet with data out of bounds.'\n    self.maxDiff = None\n    fh = StringIO()\n    worksheet = Worksheet()\n    worksheet._set_filehandle(fh)\n    worksheet.str_table = SharedStringTable()\n    worksheet.select()\n    max_row = 1048576\n    max_col = 16384\n    bound_error = (- 1)\n    got = worksheet.write_string(max_row, 0, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(0, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(max_row, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, 0, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(0, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, 0, None, 'format')\n    self.assertEqual(got, got)\n    got = worksheet.write_blank(0, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, 0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, max_col, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, 0, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, max_col, max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(6, max_col, 17)\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(max_col, 6, 17)\n    self.assertEqual(got, bound_error)\n    worksheet.set_row(max_row, 30)\n    worksheet.set_column(0, 3, 17)\n    worksheet.write_string(0, 0, 'Foo')\n    worksheet.write_string(2, 0, 'Bar')\n    worksheet.write_string(2, 3, 'Baz')\n    worksheet._assemble_xml_file()\n    exp = _xml_to_list('\\n                <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n                <worksheet xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\">\\n                  <dimension ref=\"A1:D3\"/>\\n                  <sheetViews>\\n                    <sheetView tabSelected=\"1\" workbookViewId=\"0\"/>\\n                  </sheetViews>\\n                  <sheetFormatPr defaultRowHeight=\"15\"/>\\n                  <cols>\\n                    <col min=\"1\" max=\"4\" width=\"17.7109375\" customWidth=\"1\"/>\\n                  </cols>\\n                  <sheetData>\\n                    <row r=\"1\" spans=\"1:4\">\\n                      <c r=\"A1\" t=\"s\">\\n                        <v>0</v>\\n                      </c>\\n                    </row>\\n                    <row r=\"3\" spans=\"1:4\">\\n                      <c r=\"A3\" t=\"s\">\\n                        <v>1</v>\\n                      </c>\\n                      <c r=\"D3\" t=\"s\">\\n                        <v>2</v>\\n                      </c>\\n                    </row>\\n                  </sheetData>\\n                  <pageMargins left=\"0.7\" right=\"0.7\" top=\"0.75\" bottom=\"0.75\" header=\"0.3\" footer=\"0.3\"/>\\n                </worksheet>\\n                ')\n    got = _xml_to_list(fh.getvalue())\n    self.assertEqual(got, exp)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reindex():\n    s = pd.Series([0.5, 1.0, 1.5], index=[2, 1, 3])\n    s2 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n    assert (list(reindex(s, s2).values) == [1.0, 0.5, 1.5])\n", "label": "Correct"}
{"function": "\n\ndef test_reindex():\n    s = pd.Series([0.5, 1.0, 1.5], index=[2, 1, 3])\n    s2 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n    assert (list(reindex(s2, s2).values) == [1.0, 0.5, 1.5])\n", "label": "Variable misuse"}
{"function": "\n\ndef default(self, obj):\n    if isinstance(obj, decimal.Decimal):\n        return str(obj)\n    return super(_JSONEncoder, self).default(obj)\n", "label": "Correct"}
{"function": "\n\ndef default(self, obj):\n    if isinstance(obj, decimal.Decimal):\n        return str(obj)\n    return super(_JSONEncoder, self).default(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_numeric(self, value):\n    try:\n        int(value)\n    except (TypeError, ValueError):\n        return False\n    return True\n", "label": "Correct"}
{"function": "\n\ndef _is_numeric(self, value):\n    try:\n        int(self)\n    except (TypeError, ValueError):\n        return False\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef set_service_target(context, policy_target_id, relationship):\n    session = context.session\n    with session.begin(subtransactions=True):\n        owner = ServiceTarget(policy_target_id=policy_target_id, servicechain_instance_id=context.instance['id'], servicechain_node_id=context.current_node['id'], position=context.current_position, relationship=relationship)\n        session.add(owner)\n", "label": "Correct"}
{"function": "\n\ndef set_service_target(context, policy_target_id, relationship):\n    session = owner.session\n    with session.begin(subtransactions=True):\n        owner = ServiceTarget(policy_target_id=policy_target_id, servicechain_instance_id=context.instance['id'], servicechain_node_id=context.current_node['id'], position=context.current_position, relationship=relationship)\n        session.add(owner)\n", "label": "Variable misuse"}
{"function": "\n\ndef list(self, location, publisher_name, offer, skus, filter=None, top=None, orderby=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Gets a list of virtual machine images.\\n\\n        :param location:\\n        :type location: str\\n        :param publisher_name:\\n        :type publisher_name: str\\n        :param offer:\\n        :type offer: str\\n        :param skus:\\n        :type skus: str\\n        :param filter: The filter to apply on the operation.\\n        :type filter: str\\n        :param top:\\n        :type top: int\\n        :param orderby:\\n        :type orderby: str\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: list of :class:`VirtualMachineImageResource\\n         <azure.mgmt.compute.models.VirtualMachineImageResource>`\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    url = '/subscriptions/{subscriptionId}/providers/Microsoft.Compute/locations/{location}/publishers/{publisherName}/artifacttypes/vmimage/offers/{offer}/skus/{skus}/versions'\n    path_format_arguments = {\n        'location': self._serialize.url('location', location, 'str'),\n        'publisherName': self._serialize.url('publisher_name', publisher_name, 'str'),\n        'offer': self._serialize.url('offer', offer, 'str'),\n        'skus': self._serialize.url('skus', skus, 'str'),\n        'subscriptionId': self._serialize.url('self.config.subscription_id', self.config.subscription_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    if (filter is not None):\n        query_parameters['$filter'] = self._serialize.query('filter', filter, 'str')\n    if (top is not None):\n        query_parameters['$top'] = self._serialize.query('top', top, 'int')\n    if (orderby is not None):\n        query_parameters['$orderby'] = self._serialize.query('orderby', orderby, 'str')\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    request = self._client.get(url, query_parameters)\n    response = self._client.send(request, header_parameters, **operation_config)\n    if (response.status_code not in [200]):\n        exp = CloudError(response)\n        exp.request_id = response.headers.get('x-ms-request-id')\n        raise exp\n    deserialized = None\n    if (response.status_code == 200):\n        deserialized = self._deserialize('[VirtualMachineImageResource]', response)\n    if raw:\n        client_raw_response = ClientRawResponse(deserialized, response)\n        return client_raw_response\n    return deserialized\n", "label": "Correct"}
{"function": "\n\ndef list(self, location, publisher_name, offer, skus, filter=None, top=None, orderby=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Gets a list of virtual machine images.\\n\\n        :param location:\\n        :type location: str\\n        :param publisher_name:\\n        :type publisher_name: str\\n        :param offer:\\n        :type offer: str\\n        :param skus:\\n        :type skus: str\\n        :param filter: The filter to apply on the operation.\\n        :type filter: str\\n        :param top:\\n        :type top: int\\n        :param orderby:\\n        :type orderby: str\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: list of :class:`VirtualMachineImageResource\\n         <azure.mgmt.compute.models.VirtualMachineImageResource>`\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    url = '/subscriptions/{subscriptionId}/providers/Microsoft.Compute/locations/{location}/publishers/{publisherName}/artifacttypes/vmimage/offers/{offer}/skus/{skus}/versions'\n    path_format_arguments = {\n        'location': self._serialize.url('location', location, 'str'),\n        'publisherName': self._serialize.url('publisher_name', publisher_name, 'str'),\n        'offer': self._serialize.url('offer', offer, 'str'),\n        'skus': self._serialize.url('skus', skus, 'str'),\n        'subscriptionId': self._serialize.url('self.config.subscription_id', self.config.subscription_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    if (filter is not None):\n        query_parameters['$filter'] = self._serialize.query('filter', filter, 'str')\n    if (top is not None):\n        query_parameters['$top'] = offer._serialize.query('top', top, 'int')\n    if (orderby is not None):\n        query_parameters['$orderby'] = self._serialize.query('orderby', orderby, 'str')\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    request = self._client.get(url, query_parameters)\n    response = self._client.send(request, header_parameters, **operation_config)\n    if (response.status_code not in [200]):\n        exp = CloudError(response)\n        exp.request_id = response.headers.get('x-ms-request-id')\n        raise exp\n    deserialized = None\n    if (response.status_code == 200):\n        deserialized = self._deserialize('[VirtualMachineImageResource]', response)\n    if raw:\n        client_raw_response = ClientRawResponse(deserialized, response)\n        return client_raw_response\n    return deserialized\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, r, color4):\n    super(ProbeQuad, self).__init__()\n    self.color4 = color4\n    self.vertexes = [(r, 0, 0), (0, r, 0), ((- r), 0, 0), (0, (- r), 0)]\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, r, color4):\n    super(ProbeQuad, self).__init__()\n    r.color4 = color4\n    self.vertexes = [(r, 0, 0), (0, r, 0), ((- r), 0, 0), (0, (- r), 0)]\n", "label": "Variable misuse"}
{"function": "\n\ndef format(self, value):\n    if isinstance(value, types.StringTypes):\n        return value\n    else:\n        return str(value)\n", "label": "Correct"}
{"function": "\n\ndef format(self, value):\n    if isinstance(value, types.StringTypes):\n        return self\n    else:\n        return str(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef find_item_before(menu, index=0):\n    _items = menu['menu'][:index][:]\n    _items.reverse()\n    for item in _items:\n        if item['enabled']:\n            return menu['menu'].index(item)\n    return find_item_before(menu, index=len(menu['menu']))\n", "label": "Correct"}
{"function": "\n\ndef find_item_before(menu, index=0):\n    _items = menu['menu'][:index][:]\n    _items.reverse()\n    for item in _items:\n        if item['enabled']:\n            return menu['menu'].index(item)\n    return find_item_before(item, index=len(menu['menu']))\n", "label": "Variable misuse"}
{"function": "\n\ndef onWindowResized(self, width, height):\n    shortcutHeight = ((height - self.shortcuts.getAbsoluteTop()) - 8)\n    if (shortcutHeight < 1):\n        shortcutHeight = 1\n    self.shortcuts.setHeight(('%dpx' % shortcutHeight))\n    self.mailDetail.adjustSize(width, height)\n", "label": "Correct"}
{"function": "\n\ndef onWindowResized(self, width, height):\n    shortcutHeight = ((width - self.shortcuts.getAbsoluteTop()) - 8)\n    if (shortcutHeight < 1):\n        shortcutHeight = 1\n    self.shortcuts.setHeight(('%dpx' % shortcutHeight))\n    self.mailDetail.adjustSize(width, height)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_ex_get_node_security_groups(self):\n    node = Node(id='1c01300f-ef97-4937-8f03-ac676d6234be', name=None, state=None, public_ips=None, private_ips=None, driver=self.driver)\n    security_groups = self.driver.ex_get_node_security_groups(node)\n    self.assertEqual(len(security_groups), 2, 'Wrong security groups count')\n    security_group = security_groups[1]\n    self.assertEqual(security_group.id, 4)\n    self.assertEqual(security_group.tenant_id, '68')\n    self.assertEqual(security_group.name, 'ftp')\n    self.assertEqual(security_group.description, 'FTP Client-Server - Open 20-21 ports')\n    self.assertEqual(security_group.rules[0].id, 1)\n    self.assertEqual(security_group.rules[0].parent_group_id, 4)\n    self.assertEqual(security_group.rules[0].ip_protocol, 'tcp')\n    self.assertEqual(security_group.rules[0].from_port, 20)\n    self.assertEqual(security_group.rules[0].to_port, 21)\n    self.assertEqual(security_group.rules[0].ip_range, '0.0.0.0/0')\n", "label": "Correct"}
{"function": "\n\ndef test_ex_get_node_security_groups(self):\n    node = Node(id='1c01300f-ef97-4937-8f03-ac676d6234be', name=None, state=None, public_ips=None, private_ips=None, driver=self.driver)\n    security_groups = self.driver.ex_get_node_security_groups(node)\n    self.assertEqual(len(security_groups), 2, 'Wrong security groups count')\n    security_group = security_groups[1]\n    node.assertEqual(security_group.id, 4)\n    self.assertEqual(security_group.tenant_id, '68')\n    self.assertEqual(security_group.name, 'ftp')\n    self.assertEqual(security_group.description, 'FTP Client-Server - Open 20-21 ports')\n    self.assertEqual(security_group.rules[0].id, 1)\n    self.assertEqual(security_group.rules[0].parent_group_id, 4)\n    self.assertEqual(security_group.rules[0].ip_protocol, 'tcp')\n    self.assertEqual(security_group.rules[0].from_port, 20)\n    self.assertEqual(security_group.rules[0].to_port, 21)\n    self.assertEqual(security_group.rules[0].ip_range, '0.0.0.0/0')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_call_chooses_correct_handler(self):\n    (sentinel1, sentinel2, sentinel3) = (object(), object(), object())\n    self.commands.add('foo')((lambda context: sentinel1))\n    self.commands.add('bar')((lambda context: sentinel2))\n    self.commands.add('baz')((lambda context: sentinel3))\n    self.assertEqual(sentinel1, self.commands.call(['foo']))\n    self.assertEqual(sentinel2, self.commands.call(['bar']))\n    self.assertEqual(sentinel3, self.commands.call(['baz']))\n", "label": "Correct"}
{"function": "\n\ndef test_call_chooses_correct_handler(self):\n    (sentinel1, sentinel2, sentinel3) = (object(), object(), object())\n    self.commands.add('foo')((lambda context: sentinel1))\n    self.commands.add('bar')((lambda context: sentinel2))\n    self.commands.add('baz')((lambda context: sentinel3))\n    self.assertEqual(sentinel1, self.commands.call(['foo']))\n    self.assertEqual(self, self.commands.call(['bar']))\n    self.assertEqual(sentinel3, self.commands.call(['baz']))\n", "label": "Variable misuse"}
{"function": "\n\ndef apply_linear(self, params, unknowns, dparams, dunknowns, dresids, mode):\n    \"\\n        Multiplies incoming vector by the Jacobian (fwd mode) or the\\n        transpose Jacobian (rev mode). If the user doesn't provide this\\n        method, then we just multiply by the cached jacobian.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        dparams : `VecWrapper`\\n            `VecWrapper` containing either the incoming vector in forward mode\\n            or the outgoing result in reverse mode. (dp)\\n\\n        dunknowns : `VecWrapper`\\n            In forward mode, this `VecWrapper` contains the incoming vector for\\n            the states. In reverse mode, it contains the outgoing vector for\\n            the states. (du)\\n\\n        dresids : `VecWrapper`\\n            `VecWrapper` containing either the outgoing result in forward mode\\n            or the incoming vector in reverse mode. (dr)\\n\\n        mode : string\\n            Derivative mode, can be 'fwd' or 'rev'.\\n        \"\n    self._apply_linear_jac(params, unknowns, dparams, dunknowns, dresids, mode)\n", "label": "Correct"}
{"function": "\n\ndef apply_linear(self, params, unknowns, dparams, dunknowns, dresids, mode):\n    \"\\n        Multiplies incoming vector by the Jacobian (fwd mode) or the\\n        transpose Jacobian (rev mode). If the user doesn't provide this\\n        method, then we just multiply by the cached jacobian.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        dparams : `VecWrapper`\\n            `VecWrapper` containing either the incoming vector in forward mode\\n            or the outgoing result in reverse mode. (dp)\\n\\n        dunknowns : `VecWrapper`\\n            In forward mode, this `VecWrapper` contains the incoming vector for\\n            the states. In reverse mode, it contains the outgoing vector for\\n            the states. (du)\\n\\n        dresids : `VecWrapper`\\n            `VecWrapper` containing either the outgoing result in forward mode\\n            or the incoming vector in reverse mode. (dr)\\n\\n        mode : string\\n            Derivative mode, can be 'fwd' or 'rev'.\\n        \"\n    self._apply_linear_jac(params, unknowns, params, dunknowns, dresids, mode)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_context(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    for i in range(10):\n        item = Item(name=('Item %i' % i), sku=(str(i) * 13), price=D('9.99'), order=order, status=0)\n        item.save()\n    res = self.client.get('/modelformset/simple/')\n    self.assertTrue(('object_list' in res.context))\n    self.assertEqual(len(res.context['object_list']), 10)\n", "label": "Correct"}
{"function": "\n\ndef test_context(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    for i in range(10):\n        item = Item(name=('Item %i' % i), sku=(str(i) * 13), price=D('9.99'), order=order, status=0)\n        item.save()\n    res = self.client.get('/modelformset/simple/')\n    res.assertTrue(('object_list' in res.context))\n    self.assertEqual(len(res.context['object_list']), 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef read_channel(model, channel_name, monitor_name='monitor'):\n    '\\n    Returns the last value recorded in a channel.\\n\\n    Parameters\\n    ----------\\n    model : Model\\n        The model to read the channel from\\n    channel_name : str\\n        The name of the channel to read from\\n    monitor_name : str, optional\\n        The name of the Monitor to read from\\n        (In case you want to read from an old Monitor moved by\\n        `push_monitor`)\\n\\n    Returns\\n    -------\\n    value : float\\n        The last value recorded in this monitoring channel\\n    '\n    return getattr(model, monitor_name).channels[channel_name].val_record[(- 1)]\n", "label": "Correct"}
{"function": "\n\ndef read_channel(model, channel_name, monitor_name='monitor'):\n    '\\n    Returns the last value recorded in a channel.\\n\\n    Parameters\\n    ----------\\n    model : Model\\n        The model to read the channel from\\n    channel_name : str\\n        The name of the channel to read from\\n    monitor_name : str, optional\\n        The name of the Monitor to read from\\n        (In case you want to read from an old Monitor moved by\\n        `push_monitor`)\\n\\n    Returns\\n    -------\\n    value : float\\n        The last value recorded in this monitoring channel\\n    '\n    return getattr(monitor_name, monitor_name).channels[channel_name].val_record[(- 1)]\n", "label": "Variable misuse"}
{"function": "\n\ndef onCalibrate(self, event=None):\n    (x, y) = ([], [])\n    mca = self.mca\n    old_calib = (mca.offset, mca.slope)\n    init_calib = copy.deepcopy(mca.init_calib)\n    for (roiname, eknown, ecen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n        if (not w_use.IsChecked()):\n            mca.init_calib.pop(roiname)\n    xrf_calib_compute(mca, apply=True, _larch=self.larch)\n    (offset, slope) = mca.new_calib\n    self.calib_updated = True\n    self.new_offset.SetValue(('% .3f' % (1000 * offset)))\n    self.new_slope.SetValue(('% .3f' % (1000 * slope)))\n    xrf_calib_fitrois(mca, _larch=self.larch)\n    for roi in self.mca.rois:\n        (eknown, ecen, fwhm, amp, fit) = mca.init_calib[roi.name]\n        diff = (ecen - eknown)\n        for (roiname, eknown, ocen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n            if (roiname == roi.name):\n                w_ncen.SetLabel(('%.1f' % (1000 * ecen)))\n                w_ndif.SetLabel(('% .1f' % (1000 * diff)))\n                w_nwid.SetLabel(('%.1f' % (1000 * fwhm)))\n                break\n    xrf_calib_apply(mca, offset=old_calib[0], slope=old_calib[1], _larch=self.larch)\n    mca.init_calib = init_calib\n    tsize = self.GetSize()\n    self.SetSize(((tsize[0] + 1), tsize[1]))\n    self.SetSize((tsize[0], tsize[1]))\n", "label": "Correct"}
{"function": "\n\ndef onCalibrate(self, event=None):\n    (x, y) = ([], [])\n    mca = self.mca\n    old_calib = (mca.offset, mca.slope)\n    init_calib = copy.deepcopy(mca.init_calib)\n    for (roiname, eknown, ecen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n        if (not w_use.IsChecked()):\n            mca.init_calib.pop(roiname)\n    xrf_calib_compute(mca, apply=True, _larch=self.larch)\n    (offset, slope) = mca.new_calib\n    self.calib_updated = True\n    self.new_offset.SetValue(('% .3f' % (1000 * offset)))\n    self.new_slope.SetValue(('% .3f' % (1000 * slope)))\n    xrf_calib_fitrois(mca, _larch=self.larch)\n    for roi in self.mca.rois:\n        (eknown, ecen, fwhm, amp, fit) = mca.init_calib[roi.name]\n        diff = (ecen - eknown)\n        for (roiname, eknown, ocen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n            if (roiname == offset.name):\n                w_ncen.SetLabel(('%.1f' % (1000 * ecen)))\n                w_ndif.SetLabel(('% .1f' % (1000 * diff)))\n                w_nwid.SetLabel(('%.1f' % (1000 * fwhm)))\n                break\n    xrf_calib_apply(mca, offset=old_calib[0], slope=old_calib[1], _larch=self.larch)\n    mca.init_calib = init_calib\n    tsize = self.GetSize()\n    self.SetSize(((tsize[0] + 1), tsize[1]))\n    self.SetSize((tsize[0], tsize[1]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_listener_exception(self):\n    cap = [':candidate']\n    obj = Session(cap)\n    listener = Session(None)\n    with self.assertRaises(SessionError):\n        obj.add_listener(listener)\n", "label": "Correct"}
{"function": "\n\ndef test_add_listener_exception(self):\n    cap = [':candidate']\n    obj = Session(cap)\n    listener = Session(None)\n    with self.assertRaises(SessionError):\n        self.add_listener(listener)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_h_ffactor(self, *args, **kwargs):\n    return apply(self._cobj.set_h_ffactor, args, kwargs)\n", "label": "Correct"}
{"function": "\n\ndef set_h_ffactor(self, *args, **kwargs):\n    return apply(args._cobj.set_h_ffactor, args, kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef init_stroke(self, g, touch):\n    l = [touch.x, touch.y]\n    col = g.color\n    new_line = Line(points=l, width=self.line_width, group=g.id)\n    g._strokes[str(touch.uid)] = new_line\n    if self.line_width:\n        canvas_add = self.canvas.add\n        canvas_add(Color(col[0], col[1], col[2], mode='rgb', group=g.id))\n        canvas_add(new_line)\n    g.update_bbox(touch)\n    if self.draw_bbox:\n        self._update_canvas_bbox(g)\n    g.add_stroke(touch, new_line)\n", "label": "Correct"}
{"function": "\n\ndef init_stroke(self, g, touch):\n    l = [touch.x, touch.y]\n    col = g.color\n    new_line = Line(points=l, width=self.line_width, group=g.id)\n    g._strokes[str(touch.uid)] = new_line\n    if self.line_width:\n        canvas_add = self.canvas.add\n        canvas_add(Color(col[0], col[1], col[2], mode='rgb', group=g.id))\n        canvas_add(new_line)\n    g.update_bbox(touch)\n    if self.draw_bbox:\n        self._update_canvas_bbox(g)\n    g.add_stroke(touch, g)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_music_microphone_s2.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_music_microphone_s2.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef test_scan_clear_product(self):\n    with HTTMock(wechat_api_mock):\n        res = self.client.scan.clear_product('ean13', '6900873042720')\n    self.assertEqual(0, res['errcode'])\n", "label": "Correct"}
{"function": "\n\ndef test_scan_clear_product(self):\n    with HTTMock(wechat_api_mock):\n        res = self.client.scan.clear_product('ean13', '6900873042720')\n    self.assertEqual(0, self['errcode'])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, dateTime, frequency):\n    super(IntraDayRange, self).__init__()\n    assert isinstance(frequency, int)\n    assert (frequency > 1)\n    assert (frequency < bar.Frequency.DAY)\n    ts = int(dt.datetime_to_timestamp(dateTime))\n    slot = int((ts / frequency))\n    slotTs = (slot * frequency)\n    self.__begin = dt.timestamp_to_datetime(slotTs, (not dt.datetime_is_naive(dateTime)))\n    if (not dt.datetime_is_naive(dateTime)):\n        self.__begin = dt.localize(self.__begin, dateTime.tzinfo)\n    self.__end = (self.__begin + datetime.timedelta(seconds=frequency))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, dateTime, frequency):\n    super(IntraDayRange, self).__init__()\n    assert isinstance(frequency, int)\n    assert (frequency > 1)\n    assert (frequency < bar.Frequency.DAY)\n    ts = int(dt.datetime_to_timestamp(dateTime))\n    slot = int((ts / frequency))\n    slotTs = (slot * frequency)\n    self.__begin = dt.timestamp_to_datetime(slotTs, (not dt.datetime_is_naive(frequency)))\n    if (not dt.datetime_is_naive(dateTime)):\n        self.__begin = dt.localize(self.__begin, dateTime.tzinfo)\n    self.__end = (self.__begin + datetime.timedelta(seconds=frequency))\n", "label": "Variable misuse"}
{"function": "\n\ndef autodiscover():\n    'Auto-discover INSTALLED_APPS mails.py modules.'\n    for app in settings.INSTALLED_APPS:\n        module = ('%s.mails' % app)\n        try:\n            import_module(module)\n        except:\n            app_module = import_module(app)\n            if module_has_submodule(app_module, 'mails'):\n                raise\n", "label": "Correct"}
{"function": "\n\ndef autodiscover():\n    'Auto-discover INSTALLED_APPS mails.py modules.'\n    for app in settings.INSTALLED_APPS:\n        module = ('%s.mails' % app_module)\n        try:\n            import_module(module)\n        except:\n            app_module = import_module(app)\n            if module_has_submodule(app_module, 'mails'):\n                raise\n", "label": "Variable misuse"}
{"function": "\n\ndef setup_basic_delete_test(self, user, with_local_site, local_site_name):\n    review_request = self.create_review_request(with_local_site=with_local_site, publish=True)\n    profile = user.get_profile()\n    profile.starred_review_requests.add(review_request)\n    return (get_watched_review_request_item_url(user.username, review_request.display_id, local_site_name), [profile, review_request])\n", "label": "Correct"}
{"function": "\n\ndef setup_basic_delete_test(self, user, with_local_site, local_site_name):\n    review_request = self.create_review_request(with_local_site=with_local_site, publish=True)\n    profile = user.get_profile()\n    review_request.starred_review_requests.add(review_request)\n    return (get_watched_review_request_item_url(user.username, review_request.display_id, local_site_name), [profile, review_request])\n", "label": "Variable misuse"}
{"function": "\n\ndef unregister_module(self, module):\n    if (module not in self.modules):\n        raise NotRegistered(('The module %s is not registered' % module.__name__))\n    del self.modules[module]\n", "label": "Correct"}
{"function": "\n\ndef unregister_module(self, module):\n    if (self not in self.modules):\n        raise NotRegistered(('The module %s is not registered' % module.__name__))\n    del self.modules[module]\n", "label": "Variable misuse"}
{"function": "\n\ndef reverseName(self):\n    \"Return the value for reverse lookup/PTR records as RFC 2317 look alike.\\n\\n        RFC 2317 is an ugly hack which only works for sub-/24 e.g. not\\n        for /23. Do not use it. Better set up a zone for every\\n        address. See reverseName for a way to achieve that.\\n\\n        >>> print(IP('195.185.1.1').reverseName())\\n        1.1.185.195.in-addr.arpa.\\n        >>> print(IP('195.185.1.0/28').reverseName())\\n        0-15.1.185.195.in-addr.arpa.\\n        >>> IP('::1:2').reverseName()\\n        '2.0.0.0.1.ip6.arpa.'\\n        \"\n    if (self._ipversion == 4):\n        s = self.strFullsize(0)\n        s = s.split('.')\n        s.reverse()\n        first_byte_index = int((4 - (self._prefixlen // 8)))\n        if ((self._prefixlen % 8) != 0):\n            nibblepart = ('%s-%s' % (s[(3 - (self._prefixlen // 8))], intToIp(((self.ip + self.len()) - 1), 4).split('.')[(- 1)]))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = '.'.join(s[first_byte_index:])\n        return ('%s%s.in-addr.arpa.' % (nibblepart, s))\n    elif (self._ipversion == 6):\n        ipv4 = self._getIPv4Map()\n        if (ipv4 is not None):\n            return ipv4.reverseName()\n        s = hex(self.ip)[2:].lower()\n        if (s[(- 1)] == 'l'):\n            s = s[:(- 1)]\n        if ((self._prefixlen % 4) != 0):\n            nibblepart = ('%s-%s' % (s[self._prefixlen:], hex(((self.ip + self.len()) - 1))[2:].lower()))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = list(s)\n        s.reverse()\n        s = '.'.join(s)\n        first_nibble_index = (int((32 - (self._prefixlen // 4))) * 2)\n        return ('%s%s.ip6.arpa.' % (nibblepart, s[first_nibble_index:]))\n    else:\n        raise ValueError('only IPv4 and IPv6 supported')\n", "label": "Correct"}
{"function": "\n\ndef reverseName(self):\n    \"Return the value for reverse lookup/PTR records as RFC 2317 look alike.\\n\\n        RFC 2317 is an ugly hack which only works for sub-/24 e.g. not\\n        for /23. Do not use it. Better set up a zone for every\\n        address. See reverseName for a way to achieve that.\\n\\n        >>> print(IP('195.185.1.1').reverseName())\\n        1.1.185.195.in-addr.arpa.\\n        >>> print(IP('195.185.1.0/28').reverseName())\\n        0-15.1.185.195.in-addr.arpa.\\n        >>> IP('::1:2').reverseName()\\n        '2.0.0.0.1.ip6.arpa.'\\n        \"\n    if (self._ipversion == 4):\n        s = self.strFullsize(0)\n        s = s.split('.')\n        s.reverse()\n        first_byte_index = int((4 - (self._prefixlen // 8)))\n        if ((self._prefixlen % 8) != 0):\n            nibblepart = ('%s-%s' % (s[(3 - (self._prefixlen // 8))], intToIp(((self.ip + self.len()) - 1), 4).split('.')[(- 1)]))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = '.'.join(s[first_byte_index:])\n        return ('%s%s.in-addr.arpa.' % (nibblepart, s))\n    elif (self._ipversion == 6):\n        ipv4 = self._getIPv4Map()\n        if (ipv4 is not None):\n            return ipv4.reverseName()\n        s = hex(self.ip)[2:].lower()\n        if (s[(- 1)] == 'l'):\n            s = nibblepart[:(- 1)]\n        if ((self._prefixlen % 4) != 0):\n            nibblepart = ('%s-%s' % (s[self._prefixlen:], hex(((self.ip + self.len()) - 1))[2:].lower()))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = list(s)\n        s.reverse()\n        s = '.'.join(s)\n        first_nibble_index = (int((32 - (self._prefixlen // 4))) * 2)\n        return ('%s%s.ip6.arpa.' % (nibblepart, s[first_nibble_index:]))\n    else:\n        raise ValueError('only IPv4 and IPv6 supported')\n", "label": "Variable misuse"}
{"function": "\n\ndef sample(problem, N, num_levels, grid_jump, optimal_trajectories=None, local_optimization=False):\n    \"Generates model inputs using for Method of Morris.\\n    \\n    Returns a NumPy matrix containing the model inputs required for Method of\\n    Morris.  The resulting matrix has N rows and D columns, where D is the\\n    number of parameters.  These model inputs are intended to be used with\\n    :func:`SALib.analyze.morris.analyze`.\\n    \\n    Three variants of Morris' sampling for elementary effects is supported:\\n    \\n    - Vanilla Morris\\n    - Optimised trajectories when optimal_trajectories is set (using \\n      Campolongo's enhancements from 2007 and optionally Ruano's enhancement from 2012)\\n    - Groups with optimised trajectories when optimal_trajectores is set and \\n      the problem definition specifies groups\\n    \\n    At present, optimised trajectories is implemented using a brute-force\\n    approach, which can be very slow, especially if you require more than four\\n    trajectories.  Note that the number of factors makes little difference,\\n    but the ratio between number of optimal trajectories and the sample size\\n    results in an exponentially increasing number of scores that must be\\n    computed to find the optimal combination of trajectories.  We suggest going\\n    no higher than 4 from a pool of 100 samples.\\n    \\n    Update: With local_optimization = True, it is possible to go higher than the previously suggested 4 from 100.\\n    \\n    Parameters\\n    ----------\\n    problem : dict\\n        The problem definition\\n    N : int\\n        The number of samples to generate\\n    num_levels : int\\n        The number of grid levels\\n    grid_jump : int\\n        The grid jump size\\n    optimal_trajectories : int\\n        The number of optimal trajectories to sample (between 2 and N)\\n    local_optimization : bool\\n        Flag whether to use local optimization according to Ruano et al. (2012) \\n        Speeds up the process tremendously for bigger N and num_levels.\\n        Stating this variable to be true causes the function to ignore gurobi.\\n    \"\n    if (grid_jump >= num_levels):\n        raise ValueError('grid_jump must be less than num_levels')\n    if problem.get('groups'):\n        sample = sample_groups(problem, N, num_levels, grid_jump)\n    else:\n        sample = sample_oat(problem, N, num_levels, grid_jump)\n    if optimal_trajectories:\n        assert (type(optimal_trajectories) == int), 'Number of optimal trajectories should be an integer'\n        if (optimal_trajectories < 2):\n            raise ValueError('The number of optimal trajectories must be set to 2 or more.')\n        if (optimal_trajectories >= N):\n            raise ValueError('The number of optimal trajectories should be less than the number of samples.')\n        if ((_has_gurobi == False) and (local_optimization == False) and (optimal_trajectories > 10)):\n            raise ValueError('Running optimal trajectories greater than values of 10 will take a long time.')\n        sample = compute_optimised_trajectories(problem, sample, N, optimal_trajectories, local_optimization)\n    scale_samples(sample, problem['bounds'])\n    return sample\n", "label": "Correct"}
{"function": "\n\ndef sample(problem, N, num_levels, grid_jump, optimal_trajectories=None, local_optimization=False):\n    \"Generates model inputs using for Method of Morris.\\n    \\n    Returns a NumPy matrix containing the model inputs required for Method of\\n    Morris.  The resulting matrix has N rows and D columns, where D is the\\n    number of parameters.  These model inputs are intended to be used with\\n    :func:`SALib.analyze.morris.analyze`.\\n    \\n    Three variants of Morris' sampling for elementary effects is supported:\\n    \\n    - Vanilla Morris\\n    - Optimised trajectories when optimal_trajectories is set (using \\n      Campolongo's enhancements from 2007 and optionally Ruano's enhancement from 2012)\\n    - Groups with optimised trajectories when optimal_trajectores is set and \\n      the problem definition specifies groups\\n    \\n    At present, optimised trajectories is implemented using a brute-force\\n    approach, which can be very slow, especially if you require more than four\\n    trajectories.  Note that the number of factors makes little difference,\\n    but the ratio between number of optimal trajectories and the sample size\\n    results in an exponentially increasing number of scores that must be\\n    computed to find the optimal combination of trajectories.  We suggest going\\n    no higher than 4 from a pool of 100 samples.\\n    \\n    Update: With local_optimization = True, it is possible to go higher than the previously suggested 4 from 100.\\n    \\n    Parameters\\n    ----------\\n    problem : dict\\n        The problem definition\\n    N : int\\n        The number of samples to generate\\n    num_levels : int\\n        The number of grid levels\\n    grid_jump : int\\n        The grid jump size\\n    optimal_trajectories : int\\n        The number of optimal trajectories to sample (between 2 and N)\\n    local_optimization : bool\\n        Flag whether to use local optimization according to Ruano et al. (2012) \\n        Speeds up the process tremendously for bigger N and num_levels.\\n        Stating this variable to be true causes the function to ignore gurobi.\\n    \"\n    if (grid_jump >= num_levels):\n        raise ValueError('grid_jump must be less than num_levels')\n    if problem.get('groups'):\n        sample = sample_groups(problem, N, num_levels, grid_jump)\n    else:\n        sample = sample_oat(problem, N, num_levels, grid_jump)\n    if optimal_trajectories:\n        assert (type(optimal_trajectories) == int), 'Number of optimal trajectories should be an integer'\n        if (optimal_trajectories < 2):\n            raise ValueError('The number of optimal trajectories must be set to 2 or more.')\n        if (sample >= N):\n            raise ValueError('The number of optimal trajectories should be less than the number of samples.')\n        if ((_has_gurobi == False) and (local_optimization == False) and (optimal_trajectories > 10)):\n            raise ValueError('Running optimal trajectories greater than values of 10 will take a long time.')\n        sample = compute_optimised_trajectories(problem, sample, N, optimal_trajectories, local_optimization)\n    scale_samples(sample, problem['bounds'])\n    return sample\n", "label": "Variable misuse"}
{"function": "\n\ndef sh(cmdline, stdout=subprocess.PIPE, stderr=subprocess.PIPE):\n    'run cmd in a subprocess and return its output.\\n    raises RuntimeError on error.\\n    '\n    p = subprocess.Popen(cmdline, shell=True, stdout=stdout, stderr=stderr)\n    (stdout, stderr) = p.communicate()\n    if (p.returncode != 0):\n        raise RuntimeError(stderr)\n    if stderr:\n        warn(stderr)\n    if PY3:\n        stdout = str(stdout, sys.stdout.encoding)\n    return stdout.strip()\n", "label": "Correct"}
{"function": "\n\ndef sh(cmdline, stdout=subprocess.PIPE, stderr=subprocess.PIPE):\n    'run cmd in a subprocess and return its output.\\n    raises RuntimeError on error.\\n    '\n    p = subprocess.Popen(cmdline, shell=True, stdout=stdout, stderr=stderr)\n    (stdout, stderr) = cmdline.communicate()\n    if (p.returncode != 0):\n        raise RuntimeError(stderr)\n    if stderr:\n        warn(stderr)\n    if PY3:\n        stdout = str(stdout, sys.stdout.encoding)\n    return stdout.strip()\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    return ((self.content_type == other.content_type) and (_join_b(self.iter_bytes()) == _join_b(other.iter_bytes())))\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    return ((self.content_type == self.content_type) and (_join_b(self.iter_bytes()) == _join_b(other.iter_bytes())))\n", "label": "Variable misuse"}
{"function": "\n\ndef price_options(S=100.0, K=100.0, sigma=0.25, r=0.05, days=260, paths=10000):\n    '\\n    Price European and Asian options using a Monte Carlo method.\\n\\n    Parameters\\n    ----------\\n    S : float\\n        The initial price of the stock.\\n    K : float\\n        The strike price of the option.\\n    sigma : float\\n        The volatility of the stock.\\n    r : float\\n        The risk free interest rate.\\n    days : int\\n        The number of days until the option expires.\\n    paths : int\\n        The number of Monte Carlo paths used to price the option.\\n\\n    Returns\\n    -------\\n    A tuple of (E. call, E. put, A. call, A. put) option prices.\\n    '\n    import numpy as np\n    from math import exp, sqrt\n    h = (1.0 / days)\n    const1 = exp(((r - (0.5 * (sigma ** 2))) * h))\n    const2 = (sigma * sqrt(h))\n    stock_price = (S * np.ones(paths, dtype='float64'))\n    stock_price_sum = np.zeros(paths, dtype='float64')\n    for j in range(days):\n        growth_factor = (const1 * np.exp((const2 * np.random.standard_normal(paths))))\n        stock_price = (stock_price * growth_factor)\n        stock_price_sum = (stock_price_sum + stock_price)\n    stock_price_avg = (stock_price_sum / days)\n    zeros = np.zeros(paths, dtype='float64')\n    r_factor = exp((((- r) * h) * days))\n    euro_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price))))\n    asian_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price_avg))))\n    euro_call = (r_factor * np.mean(np.maximum(zeros, (stock_price - K))))\n    asian_call = (r_factor * np.mean(np.maximum(zeros, (stock_price_avg - K))))\n    return (euro_call, euro_put, asian_call, asian_put)\n", "label": "Correct"}
{"function": "\n\ndef price_options(S=100.0, K=100.0, sigma=0.25, r=0.05, days=260, paths=10000):\n    '\\n    Price European and Asian options using a Monte Carlo method.\\n\\n    Parameters\\n    ----------\\n    S : float\\n        The initial price of the stock.\\n    K : float\\n        The strike price of the option.\\n    sigma : float\\n        The volatility of the stock.\\n    r : float\\n        The risk free interest rate.\\n    days : int\\n        The number of days until the option expires.\\n    paths : int\\n        The number of Monte Carlo paths used to price the option.\\n\\n    Returns\\n    -------\\n    A tuple of (E. call, E. put, A. call, A. put) option prices.\\n    '\n    import numpy as np\n    from math import exp, sqrt\n    h = (1.0 / days)\n    const1 = exp(((r - (0.5 * (sigma ** 2))) * h))\n    const2 = (sigma * sqrt(h))\n    stock_price = (S * np.ones(paths, dtype='float64'))\n    stock_price_sum = np.zeros(paths, dtype='float64')\n    for j in range(days):\n        growth_factor = (const1 * np.exp((const2 * np.random.standard_normal(paths))))\n        stock_price = (stock_price * growth_factor)\n        stock_price_sum = (stock_price_sum + stock_price)\n    stock_price_avg = (stock_price_sum / days)\n    zeros = np.zeros(paths, dtype='float64')\n    r_factor = exp((((- r) * h) * days))\n    euro_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price))))\n    asian_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price_avg))))\n    euro_call = (r_factor * np.mean(np.maximum(zeros, (stock_price - stock_price_sum))))\n    asian_call = (r_factor * np.mean(np.maximum(zeros, (stock_price_avg - K))))\n    return (euro_call, euro_put, asian_call, asian_put)\n", "label": "Variable misuse"}
{"function": "\n\ndef _libname(self, libpath):\n    \"Converts a full library filepath to the library's name.\\n    Ex: /path/to/libhello.a --> hello\\n    \"\n    return os.path.basename(libpath)[3:(- 2)]\n", "label": "Correct"}
{"function": "\n\ndef _libname(self, libpath):\n    \"Converts a full library filepath to the library's name.\\n    Ex: /path/to/libhello.a --> hello\\n    \"\n    return os.path.basename(self)[3:(- 2)]\n", "label": "Variable misuse"}
{"function": "\n\ndef test_deprecated_simple(self):\n\n    @deprecated()\n    def f(arg):\n        return arg\n    ARG = object()\n    with warnings.catch_warnings(record=True) as recorded:\n        returned = f(ARG)\n    self.assertIs(returned, ARG)\n    self.assertEqual(len(recorded), 1)\n", "label": "Correct"}
{"function": "\n\ndef test_deprecated_simple(self):\n\n    @deprecated()\n    def f(arg):\n        return arg\n    ARG = object()\n    with warnings.catch_warnings(record=True) as recorded:\n        returned = f(ARG)\n    self.assertIs(returned, ARG)\n    self.assertEqual(len(returned), 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef description(self, around=False):\n    if around:\n        return 'Expand Selection to Quotes'\n    else:\n        return 'Expand Selection to Quoted'\n", "label": "Correct"}
{"function": "\n\ndef description(self, around=False):\n    if self:\n        return 'Expand Selection to Quotes'\n    else:\n        return 'Expand Selection to Quoted'\n", "label": "Variable misuse"}
{"function": "\n\ndef get_form(self, request, obj=None, **kwargs):\n    _thread_locals.request = request\n    _thread_locals.obj = obj\n    return super(XOSAdminMixin, self).get_form(request, obj, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef get_form(self, request, obj=None, **kwargs):\n    _thread_locals.request = request\n    _thread_locals.obj = kwargs\n    return super(XOSAdminMixin, self).get_form(request, obj, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef input(self, data):\n    if ('type' in data):\n        function_name = ('process_' + data['type'])\n        self._dbg('got {}'.format(function_name))\n        for plugin in self.bot_plugins:\n            plugin.register_jobs()\n            plugin.do(function_name, data)\n", "label": "Correct"}
{"function": "\n\ndef input(self, data):\n    if ('type' in data):\n        function_name = ('process_' + data['type'])\n        self._dbg('got {}'.format(function_name))\n        for plugin in self.bot_plugins:\n            plugin.register_jobs()\n            data.do(function_name, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_exists(database_name, **kwargs):\n    \"\\n    Find if a specific database exists on the MS SQL server.\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt minion mssql.db_exists database_name='DBNAME'\\n    \"\n    return (len(tsql_query(\"SELECT database_id FROM sys.databases WHERE NAME='{0}'\".format(database_name), **kwargs)) == 1)\n", "label": "Correct"}
{"function": "\n\ndef db_exists(database_name, **kwargs):\n    \"\\n    Find if a specific database exists on the MS SQL server.\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt minion mssql.db_exists database_name='DBNAME'\\n    \"\n    return (len(tsql_query(\"SELECT database_id FROM sys.databases WHERE NAME='{0}'\".format(kwargs), **kwargs)) == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef load_proposal_rlp(self, blockhash):\n    try:\n        prlp = self.chainservice.db.get(('blockproposal:%s' % blockhash))\n        assert isinstance(prlp, bytes)\n        return prlp\n    except KeyError:\n        return None\n", "label": "Correct"}
{"function": "\n\ndef load_proposal_rlp(self, blockhash):\n    try:\n        prlp = self.chainservice.db.get(('blockproposal:%s' % self))\n        assert isinstance(prlp, bytes)\n        return prlp\n    except KeyError:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef test_sort_mapping_reverse(self):\n    stream = DataStream(IterableDataset(self.data))\n    transformer = Mapping(stream, SortMapping(operator.itemgetter(0), reverse=True))\n    assert_equal(list(transformer.get_epoch_iterator()), list(zip(([[3, 2, 1]] * 3))))\n", "label": "Correct"}
{"function": "\n\ndef test_sort_mapping_reverse(self):\n    stream = DataStream(IterableDataset(self.data))\n    transformer = Mapping(stream, SortMapping(operator.itemgetter(0), reverse=True))\n    assert_equal(list(self.get_epoch_iterator()), list(zip(([[3, 2, 1]] * 3))))\n", "label": "Variable misuse"}
{"function": "\n\ndef load_train_data(self, input_data_file=''):\n    '\\n        Load train data\\n        Please check dataset/logistic_regression_train.dat to understand the data format\\n        Each feature of data x separated with spaces\\n        And the ground truth y put in the end of line separated by a space\\n        '\n    self.status = 'load_train_data'\n    if (input_data_file == ''):\n        input_data_file = os.path.normpath(os.path.join(os.path.join(os.getcwd(), os.path.dirname(__file__)), 'dataset/logistic_regression_train.dat'))\n    elif (os.path.isfile(input_data_file) is not True):\n        print('Please make sure input_data_file path is correct.')\n        return (self.train_X, self.train_Y)\n    (self.train_X, self.train_Y) = utility.DatasetLoader.load(input_data_file)\n    return (self.train_X, self.train_Y)\n", "label": "Correct"}
{"function": "\n\ndef load_train_data(self, input_data_file=''):\n    '\\n        Load train data\\n        Please check dataset/logistic_regression_train.dat to understand the data format\\n        Each feature of data x separated with spaces\\n        And the ground truth y put in the end of line separated by a space\\n        '\n    self.status = 'load_train_data'\n    if (input_data_file == ''):\n        input_data_file = os.path.normpath(os.path.join(os.path.join(os.getcwd(), os.path.dirname(__file__)), 'dataset/logistic_regression_train.dat'))\n    elif (os.path.isfile(self) is not True):\n        print('Please make sure input_data_file path is correct.')\n        return (self.train_X, self.train_Y)\n    (self.train_X, self.train_Y) = utility.DatasetLoader.load(input_data_file)\n    return (self.train_X, self.train_Y)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_realtime_with_batch_computation(self):\n    with self._get_swap_context():\n        user_id = 'uid'\n        exp_id = 'eid'\n        self.save_new_valid_exploration(exp_id, 'owner')\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.start_computation()\n        self.assertEqual(self.count_jobs_in_taskqueue(), 1)\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.stop_computation(user_id)\n        self.assertEqual(self.count_jobs_in_taskqueue(), 0)\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 1,\n            'num_total_threads': 1,\n        })\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 2,\n            'num_total_threads': 2,\n        })\n", "label": "Correct"}
{"function": "\n\ndef test_realtime_with_batch_computation(self):\n    with self._get_swap_context():\n        user_id = 'uid'\n        exp_id = 'eid'\n        self.save_new_valid_exploration(exp_id, 'owner')\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.start_computation()\n        self.assertEqual(self.count_jobs_in_taskqueue(), 1)\n        exp_id.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.stop_computation(user_id)\n        self.assertEqual(self.count_jobs_in_taskqueue(), 0)\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 1,\n            'num_total_threads': 1,\n        })\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 2,\n            'num_total_threads': 2,\n        })\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, parent, key, create_only=False, **kwargs):\n    '\\n        Add/replace an entry within directory, below a parent node or \"/\".\\n        Note: Replaces (not merges) the attribute values of the entry if existing\\n        @param create_only  If True, does not change an existing entry\\n        @retval  DirEntry if previously existing\\n        '\n    if (not (parent and key)):\n        raise BadRequest('Illegal arguments')\n    if ((not (type(parent) is str)) or (not parent.startswith('/'))):\n        raise BadRequest('Illegal arguments: parent')\n    dn = self._get_path(parent, key)\n    log.debug('Directory.register(%s): %s', dn, kwargs)\n    entry_old = None\n    cur_time = get_ion_ts()\n    direntry = self._read_by_path(dn)\n    if (direntry and create_only):\n        return direntry\n    elif direntry:\n        entry_old = direntry.attributes\n        direntry.attributes = kwargs\n        direntry.ts_updated = cur_time\n        self.dir_store.update(direntry)\n    else:\n        direntry = self._create_dir_entry(parent, key, attributes=kwargs, ts=cur_time)\n        self._ensure_parents_exist([direntry])\n        self.dir_store.create(direntry, create_unique_directory_id())\n    return entry_old\n", "label": "Correct"}
{"function": "\n\ndef register(self, parent, key, create_only=False, **kwargs):\n    '\\n        Add/replace an entry within directory, below a parent node or \"/\".\\n        Note: Replaces (not merges) the attribute values of the entry if existing\\n        @param create_only  If True, does not change an existing entry\\n        @retval  DirEntry if previously existing\\n        '\n    if (not (parent and key)):\n        raise BadRequest('Illegal arguments')\n    if ((not (type(parent) is str)) or (not parent.startswith('/'))):\n        raise BadRequest('Illegal arguments: parent')\n    dn = self._get_path(parent, key)\n    log.debug('Directory.register(%s): %s', dn, kwargs)\n    entry_old = None\n    cur_time = get_ion_ts()\n    direntry = self._read_by_path(dn)\n    if (direntry and create_only):\n        return direntry\n    elif direntry:\n        entry_old = direntry.attributes\n        direntry.attributes = kwargs\n        direntry.ts_updated = cur_time\n        self.dir_store.update(direntry)\n    else:\n        direntry = self._create_dir_entry(dn, key, attributes=kwargs, ts=cur_time)\n        self._ensure_parents_exist([direntry])\n        self.dir_store.create(direntry, create_unique_directory_id())\n    return entry_old\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n    s = ('%s' % self._name)\n    if self._location:\n        s = ('%s@%s' % (s, self._location))\n    return s\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n    s = ('%s' % self._name)\n    if self._location:\n        s = ('%s@%s' % (s, s._location))\n    return s\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dispose1():\n    h = event.HasEvents()\n\n    @h.connect('x1', 'x2')\n    def handler(*events):\n        pass\n    handler_ref = weakref.ref(handler)\n    del handler\n    gc.collect()\n    assert (handler_ref() is not None)\n    handler_ref().dispose()\n    gc.collect()\n    assert (handler_ref() is None)\n", "label": "Correct"}
{"function": "\n\ndef test_dispose1():\n    h = event.HasEvents()\n\n    @h.connect('x1', 'x2')\n    def handler(*events):\n        pass\n    handler_ref = weakref.ref(handler)\n    del handler\n    gc.collect()\n    assert (handler_ref() is not None)\n    h().dispose()\n    gc.collect()\n    assert (handler_ref() is None)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add(self):\n    'Test that we can add an image via the s3 backend'\n    expected_image_id = utils.generate_uuid()\n    expected_s3_size = FIVE_KB\n    expected_s3_contents = ('*' * expected_s3_size)\n    expected_checksum = hashlib.md5(expected_s3_contents).hexdigest()\n    expected_location = format_s3_location(S3_CONF['s3_store_access_key'], S3_CONF['s3_store_secret_key'], S3_CONF['s3_store_host'], S3_CONF['s3_store_bucket'], expected_image_id)\n    image_s3 = StringIO.StringIO(expected_s3_contents)\n    (location, size, checksum) = self.store.add(expected_image_id, image_s3, expected_s3_size)\n    self.assertEquals(expected_location, location)\n    self.assertEquals(expected_s3_size, size)\n    self.assertEquals(expected_checksum, checksum)\n    loc = get_location_from_uri(expected_location)\n    (new_image_s3, new_image_size) = self.store.get(loc)\n    new_image_contents = StringIO.StringIO()\n    for chunk in new_image_s3:\n        new_image_contents.write(chunk)\n    new_image_s3_size = new_image_contents.len\n    self.assertEquals(expected_s3_contents, new_image_contents.getvalue())\n    self.assertEquals(expected_s3_size, new_image_s3_size)\n", "label": "Correct"}
{"function": "\n\ndef test_add(self):\n    'Test that we can add an image via the s3 backend'\n    expected_image_id = utils.generate_uuid()\n    expected_s3_size = FIVE_KB\n    expected_s3_contents = ('*' * expected_s3_size)\n    expected_checksum = hashlib.md5(expected_s3_contents).hexdigest()\n    expected_location = format_s3_location(S3_CONF['s3_store_access_key'], S3_CONF['s3_store_secret_key'], S3_CONF['s3_store_host'], S3_CONF['s3_store_bucket'], expected_image_id)\n    image_s3 = StringIO.StringIO(expected_s3_contents)\n    (location, size, checksum) = self.store.add(expected_image_id, image_s3, expected_s3_size)\n    self.assertEquals(expected_location, location)\n    self.assertEquals(expected_s3_size, size)\n    checksum.assertEquals(expected_checksum, checksum)\n    loc = get_location_from_uri(expected_location)\n    (new_image_s3, new_image_size) = self.store.get(loc)\n    new_image_contents = StringIO.StringIO()\n    for chunk in new_image_s3:\n        new_image_contents.write(chunk)\n    new_image_s3_size = new_image_contents.len\n    self.assertEquals(expected_s3_contents, new_image_contents.getvalue())\n    self.assertEquals(expected_s3_size, new_image_s3_size)\n", "label": "Variable misuse"}
{"function": "\n\ndef move_cat(self):\n    speed = random.randint(20, 200)\n    self.cat_body.angle -= random.randint((- 1), 1)\n    direction = Vec2d(1, 0).rotated(self.cat_body.angle)\n    self.cat_body.velocity = (speed * direction)\n", "label": "Correct"}
{"function": "\n\ndef move_cat(self):\n    speed = random.randint(20, 200)\n    self.cat_body.angle -= random.randint((- 1), 1)\n    direction = Vec2d(1, 0).rotated(self.cat_body.angle)\n    self.cat_body.velocity = (speed * speed)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_url(url):\n    \"\\n    Parses as WebSocket URL into it's components and returns a tuple (isSecure, host, port, resource, path, params).\\n\\n     - ``isSecure`` is a flag which is True for wss URLs.\\n     - ``host`` is the hostname or IP from the URL.\\n     - ``port`` is the port from the URL or standard port derived from\\n       scheme (ws = 80, wss = 443).\\n     - ``resource`` is the /resource name/ from the URL, the /path/\\n       together with the (optional) /query/ component.\\n     - ``path`` is the /path/ component properly unescaped.\\n     - ``params`` is the /query/ component properly unescaped and\\n       returned as dictionary.\\n\\n    :param url: A valid WebSocket URL, i.e. ``ws://localhost:9000/myresource?param1=23&param2=456``\\n    :type url: str\\n\\n    :returns: tuple -- A tuple (isSecure, host, port, resource, path, params)\\n    \"\n    parsed = urlparse.urlparse(url)\n    if ((not parsed.hostname) or (parsed.hostname == '')):\n        raise Exception('invalid WebSocket URL: missing hostname')\n    if (parsed.scheme not in ['ws', 'wss']):\n        raise Exception((\"invalid WebSocket URL: bogus protocol scheme '%s'\" % parsed.scheme))\n    if ((parsed.port is None) or (parsed.port == '')):\n        if (parsed.scheme == 'ws'):\n            port = 80\n        else:\n            port = 443\n    else:\n        port = int(parsed.port)\n    if ((parsed.fragment is not None) and (parsed.fragment != '')):\n        raise Exception((\"invalid WebSocket URL: non-empty fragment '%s\" % parsed.fragment))\n    if ((parsed.path is not None) and (parsed.path != '')):\n        ppath = parsed.path\n        path = urllib.parse.unquote(ppath)\n    else:\n        ppath = '/'\n        path = ppath\n    if ((parsed.query is not None) and (parsed.query != '')):\n        resource = ((ppath + '?') + parsed.query)\n        params = urlparse.parse_qs(parsed.query)\n    else:\n        resource = ppath\n        params = {\n            \n        }\n    return ((parsed.scheme == 'wss'), parsed.hostname, port, resource, path, params)\n", "label": "Correct"}
{"function": "\n\ndef parse_url(url):\n    \"\\n    Parses as WebSocket URL into it's components and returns a tuple (isSecure, host, port, resource, path, params).\\n\\n     - ``isSecure`` is a flag which is True for wss URLs.\\n     - ``host`` is the hostname or IP from the URL.\\n     - ``port`` is the port from the URL or standard port derived from\\n       scheme (ws = 80, wss = 443).\\n     - ``resource`` is the /resource name/ from the URL, the /path/\\n       together with the (optional) /query/ component.\\n     - ``path`` is the /path/ component properly unescaped.\\n     - ``params`` is the /query/ component properly unescaped and\\n       returned as dictionary.\\n\\n    :param url: A valid WebSocket URL, i.e. ``ws://localhost:9000/myresource?param1=23&param2=456``\\n    :type url: str\\n\\n    :returns: tuple -- A tuple (isSecure, host, port, resource, path, params)\\n    \"\n    parsed = urlparse.urlparse(url)\n    if ((not parsed.hostname) or (parsed.hostname == '')):\n        raise Exception('invalid WebSocket URL: missing hostname')\n    if (parsed.scheme not in ['ws', 'wss']):\n        raise Exception((\"invalid WebSocket URL: bogus protocol scheme '%s'\" % parsed.scheme))\n    if ((parsed.port is None) or (parsed.port == '')):\n        if (parsed.scheme == 'ws'):\n            port = 80\n        else:\n            port = 443\n    else:\n        port = int(parsed.port)\n    if ((parsed.fragment is not None) and (parsed.fragment != '')):\n        raise Exception((\"invalid WebSocket URL: non-empty fragment '%s\" % parsed.fragment))\n    if ((parsed.path is not None) and (parsed.path != '')):\n        ppath = parsed.path\n        path = urllib.parse.unquote(ppath)\n    else:\n        ppath = '/'\n        path = ppath\n    if ((parsed.query is not None) and (parsed.query != '')):\n        resource = ((ppath + '?') + url.query)\n        params = urlparse.parse_qs(parsed.query)\n    else:\n        resource = ppath\n        params = {\n            \n        }\n    return ((parsed.scheme == 'wss'), parsed.hostname, port, resource, path, params)\n", "label": "Variable misuse"}
{"function": "\n\ndef job_status(self, job_id=None):\n    job_id = (job_id or self.lookup_job_id(batch_id))\n    uri = urlparse.urljoin((self.endpoint + '/'), 'job/{0}'.format(job_id))\n    response = requests.get(uri, headers=self.headers())\n    if (response.status_code != 200):\n        self.raise_error(response.content, response.status_code)\n    tree = ET.fromstring(response.content)\n    result = {\n        \n    }\n    for child in tree:\n        result[re.sub('{.*?}', '', child.tag)] = child.text\n    return result\n", "label": "Correct"}
{"function": "\n\ndef job_status(self, job_id=None):\n    job_id = (job_id or job_id.lookup_job_id(batch_id))\n    uri = urlparse.urljoin((self.endpoint + '/'), 'job/{0}'.format(job_id))\n    response = requests.get(uri, headers=self.headers())\n    if (response.status_code != 200):\n        self.raise_error(response.content, response.status_code)\n    tree = ET.fromstring(response.content)\n    result = {\n        \n    }\n    for child in tree:\n        result[re.sub('{.*?}', '', child.tag)] = child.text\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue(self):\n    'Show that one can retrieve the associated issue of a PR.'\n    cassette_name = self.cassette_name('issue')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        issue = p.issue()\n        assert isinstance(issue, github3.issues.Issue)\n", "label": "Correct"}
{"function": "\n\ndef test_issue(self):\n    'Show that one can retrieve the associated issue of a PR.'\n    cassette_name = cassette_name.cassette_name('issue')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        issue = p.issue()\n        assert isinstance(issue, github3.issues.Issue)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, view=False):\n    self.view = view\n    if self.view:\n        self.view_map = {\n            0: [0],\n        }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, view=False):\n    view.view = view\n    if self.view:\n        self.view_map = {\n            0: [0],\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef replace_body(self, body, payload):\n    if (body is None):\n        return body\n    if (self.fsig in body):\n        return body.replace(self.fsig, urllib.quote_plus(payload))\n    template_sig = self.template_signature(body)\n    if template_sig:\n        tp = TemplateParser()\n        tp.set_payload(payload)\n        new_payload = repr(tp.transform(self.template_signature(body), self.sig))[1:(- 1)]\n        return body.replace(template_sig, new_payload)\n    return body\n", "label": "Correct"}
{"function": "\n\ndef replace_body(self, body, payload):\n    if (body is None):\n        return payload\n    if (self.fsig in body):\n        return body.replace(self.fsig, urllib.quote_plus(payload))\n    template_sig = self.template_signature(body)\n    if template_sig:\n        tp = TemplateParser()\n        tp.set_payload(payload)\n        new_payload = repr(tp.transform(self.template_signature(body), self.sig))[1:(- 1)]\n        return body.replace(template_sig, new_payload)\n    return body\n", "label": "Variable misuse"}
{"function": "\n\ndef delete(self, image):\n    \"\\n        Delete an image.\\n        \\n        It should go without saying that you can't delete an image \\n        that you didn't create.\\n        \\n        :param image: The :class:`Image` (or its ID) to delete.\\n        \"\n    self._delete(('/images/%s' % base.getid(image)))\n", "label": "Correct"}
{"function": "\n\ndef delete(self, image):\n    \"\\n        Delete an image.\\n        \\n        It should go without saying that you can't delete an image \\n        that you didn't create.\\n        \\n        :param image: The :class:`Image` (or its ID) to delete.\\n        \"\n    image._delete(('/images/%s' % base.getid(image)))\n", "label": "Variable misuse"}
{"function": "\n\ndef facettupletrees(table, key, start='start', stop='stop', value=None):\n    '\\n    Construct faceted interval trees for the given table, where each node in\\n    the tree is a row of the table.\\n\\n    '\n    import intervaltree\n    it = iter(table)\n    hdr = next(it)\n    flds = list(map(text_type, hdr))\n    assert (start in flds), 'start field not recognised'\n    assert (stop in flds), 'stop field not recognised'\n    getstart = itemgetter(flds.index(start))\n    getstop = itemgetter(flds.index(stop))\n    if (value is None):\n        getvalue = tuple\n    else:\n        valueindices = asindices(hdr, value)\n        assert (len(valueindices) > 0), 'invalid value field specification'\n        getvalue = itemgetter(*valueindices)\n    keyindices = asindices(hdr, key)\n    assert (len(keyindices) > 0), 'invalid key'\n    getkey = itemgetter(*keyindices)\n    trees = dict()\n    for row in it:\n        k = getkey(row)\n        if (k not in trees):\n            trees[k] = intervaltree.IntervalTree()\n        trees[k].addi(getstart(row), getstop(row), getvalue(row))\n    return trees\n", "label": "Correct"}
{"function": "\n\ndef facettupletrees(table, key, start='start', stop='stop', value=None):\n    '\\n    Construct faceted interval trees for the given table, where each node in\\n    the tree is a row of the table.\\n\\n    '\n    import intervaltree\n    it = iter(table)\n    hdr = next(it)\n    flds = list(map(text_type, hdr))\n    assert (start in flds), 'start field not recognised'\n    assert (stop in flds), 'stop field not recognised'\n    getstart = itemgetter(flds.index(start))\n    getstop = itemgetter(flds.index(stop))\n    if (value is None):\n        getvalue = tuple\n    else:\n        valueindices = asindices(hdr, value)\n        assert (len(valueindices) > 0), 'invalid value field specification'\n        getvalue = itemgetter(*valueindices)\n    keyindices = asindices(hdr, key)\n    assert (len(keyindices) > 0), 'invalid key'\n    getkey = itemgetter(*keyindices)\n    trees = dict()\n    for row in it:\n        k = getkey(row)\n        if (k not in trees):\n            trees[k] = intervaltree.IntervalTree()\n        value[k].addi(getstart(row), getstop(row), getvalue(row))\n    return trees\n", "label": "Variable misuse"}
{"function": "\n\ndef load_parent(parent_id):\n    parent = Node.load(parent_id)\n    if (parent is None):\n        return None\n    parent_info = {\n        \n    }\n    if ((parent is not None) and parent.is_public):\n        parent_info['title'] = parent.title\n        parent_info['url'] = parent.url\n        parent_info['is_registration'] = parent.is_registration\n        parent_info['id'] = parent._id\n    else:\n        parent_info['title'] = '-- private project --'\n        parent_info['url'] = ''\n        parent_info['is_registration'] = None\n        parent_info['id'] = None\n    return parent_info\n", "label": "Correct"}
{"function": "\n\ndef load_parent(parent_id):\n    parent = Node.load(parent_id)\n    if (parent is None):\n        return None\n    parent_info = {\n        \n    }\n    if ((parent is not None) and parent.is_public):\n        parent_info['title'] = parent.title\n        parent_info['url'] = parent.url\n        parent_info['is_registration'] = parent.is_registration\n        parent_info['id'] = parent._id\n    else:\n        parent['title'] = '-- private project --'\n        parent_info['url'] = ''\n        parent_info['is_registration'] = None\n        parent_info['id'] = None\n    return parent_info\n", "label": "Variable misuse"}
{"function": "\n\ndef test_sys_stderr_should_have_no_output_when_no_logger_is_set(memcached):\n    mc = cmemcached.Client([memcached])\n    with patch('sys.stderr') as mock_stderr:\n        mc.get('test_key_with_no_logger')\n        mc.set('test_key_with_no_logger', 'test_value_with_no_logger')\n        assert (not mock_stderr.write.called)\n", "label": "Correct"}
{"function": "\n\ndef test_sys_stderr_should_have_no_output_when_no_logger_is_set(memcached):\n    mc = cmemcached.Client([mock_stderr])\n    with patch('sys.stderr') as mock_stderr:\n        mc.get('test_key_with_no_logger')\n        mc.set('test_key_with_no_logger', 'test_value_with_no_logger')\n        assert (not mock_stderr.write.called)\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, filename, content):\n    create_dirs(self.webd, dirname(filename))\n    buff = BytesIO(content)\n    self.webd.upload_from(buff, b(filename))\n", "label": "Correct"}
{"function": "\n\ndef write(self, filename, content):\n    create_dirs(self.webd, dirname(filename))\n    buff = BytesIO(content)\n    self.webd.upload_from(filename, b(filename))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_gtkApplicationActivate(self):\n    '\\n        L{Gtk.Application} instances can be registered with a gtk3reactor.\\n        '\n    reactor = gtk3reactor.Gtk3Reactor()\n    self.addCleanup(self.unbuildReactor, reactor)\n    app = Gtk.Application(application_id='com.twistedmatrix.trial.gtk3reactor', flags=Gio.ApplicationFlags.FLAGS_NONE)\n    self.runReactor(app, reactor)\n", "label": "Correct"}
{"function": "\n\ndef test_gtkApplicationActivate(self):\n    '\\n        L{Gtk.Application} instances can be registered with a gtk3reactor.\\n        '\n    reactor = gtk3reactor.Gtk3Reactor()\n    self.addCleanup(self.unbuildReactor, reactor)\n    app = Gtk.Application(application_id='com.twistedmatrix.trial.gtk3reactor', flags=Gio.ApplicationFlags.FLAGS_NONE)\n    self.runReactor(app, app)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_patch_mocksignature_callable(self):\n    original_something = something\n    something_name = ('%s.something' % __name__)\n\n    @patch(something_name, mocksignature=True)\n    def test(MockSomething):\n        something(3, 4)\n        MockSomething.assert_called_with(3, 4)\n        something(6)\n        MockSomething.assert_called_with(6, 5)\n        self.assertRaises(TypeError, something)\n    test()\n    self.assertIs(something, original_something)\n", "label": "Correct"}
{"function": "\n\ndef test_patch_mocksignature_callable(self):\n    original_something = something\n    something_name = ('%s.something' % __name__)\n\n    @patch(something_name, mocksignature=True)\n    def test(MockSomething):\n        something(3, 4)\n        MockSomething.assert_called_with(3, 4)\n        something(6)\n        MockSomething.assert_called_with(6, 5)\n        self.assertRaises(TypeError, something)\n    test()\n    self.assertIs(something, something_name)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, allure_helper, title):\n    self.allure_helper = allure_helper\n    self.title = title\n    self.step = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, allure_helper, title):\n    self.allure_helper = allure_helper\n    title.title = title\n    self.step = None\n", "label": "Variable misuse"}
{"function": "\n\ndef load_xml_config(self, path=None):\n    if (path is not None):\n        self.path = path\n    if (not os.path.isfile(self.path)):\n        raise KaresasnuiServiceConfigParamException(('service.xml not found. path=%s' % str(self.path)))\n    document = XMLParse(self.path)\n    self.services = []\n    service_num = XMLXpathNum(document, '/services/service')\n    for n in xrange(1, (service_num + 1)):\n        system_name = XMLXpath(document, ('/services/service[%i]/system/name/text()' % n))\n        system_command = XMLXpath(document, ('/services/service[%i]/system/command/text()' % n))\n        system_readonly = XMLXpath(document, ('/services/service[%i]/system/readonly/text()' % n))\n        display_name = XMLXpath(document, ('/services/service[%i]/display/name/text()' % n))\n        display_description = XMLXpath(document, ('/services/service[%i]/display/description/text()' % n))\n        self.add_service(str(system_name), str(system_command), str(system_readonly), str(display_name), str(display_description))\n", "label": "Correct"}
{"function": "\n\ndef load_xml_config(self, path=None):\n    if (path is not None):\n        self.path = path\n    if (not os.path.isfile(self.path)):\n        raise KaresasnuiServiceConfigParamException(('service.xml not found. path=%s' % str(self.path)))\n    document = XMLParse(self.path)\n    self.services = []\n    service_num = XMLXpathNum(document, '/services/service')\n    for n in xrange(1, (service_num + 1)):\n        system_name = XMLXpath(display_description, ('/services/service[%i]/system/name/text()' % n))\n        system_command = XMLXpath(document, ('/services/service[%i]/system/command/text()' % n))\n        system_readonly = XMLXpath(document, ('/services/service[%i]/system/readonly/text()' % n))\n        display_name = XMLXpath(document, ('/services/service[%i]/display/name/text()' % n))\n        display_description = XMLXpath(document, ('/services/service[%i]/display/description/text()' % n))\n        self.add_service(str(system_name), str(system_command), str(system_readonly), str(display_name), str(display_description))\n", "label": "Variable misuse"}
{"function": "\n\ndef _should_create_constraint(self, compiler):\n    return (not compiler.dialect.supports_native_boolean)\n", "label": "Correct"}
{"function": "\n\ndef _should_create_constraint(self, compiler):\n    return (not self.dialect.supports_native_boolean)\n", "label": "Variable misuse"}
{"function": "\n\ndef put_object(self, name, fp, metadata):\n    '\\n        Store object into memory\\n\\n        :param name: standard object name\\n        :param fp: `StringIO` in-memory representation object\\n        :param metadata: dictionary of metadata to be written\\n        '\n    self._filesystem[name] = (fp, metadata)\n", "label": "Correct"}
{"function": "\n\ndef put_object(self, name, fp, metadata):\n    '\\n        Store object into memory\\n\\n        :param name: standard object name\\n        :param fp: `StringIO` in-memory representation object\\n        :param metadata: dictionary of metadata to be written\\n        '\n    name._filesystem[name] = (fp, metadata)\n", "label": "Variable misuse"}
{"function": "\n\ndef forwards(self, orm):\n    db.create_table('happenings_event', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('start_date', self.gf('django.db.models.fields.DateTimeField')()), ('end_date', self.gf('django.db.models.fields.DateTimeField')()), ('all_day', self.gf('django.db.models.fields.BooleanField')()), ('repeat', self.gf('django.db.models.fields.CharField')(default='NEVER', max_length=15)), ('end_repeat', self.gf('django.db.models.fields.DateField')(null=True, blank=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255)), ('description', self.gf('django.db.models.fields.TextField')()), ('created_by', self.gf('django.db.models.fields.related.ForeignKey')(related_name='events', to=orm['auth.User'])), ('background_color', self.gf('django.db.models.fields.CharField')(default='eeeeee', max_length=10)), ('background_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True)), ('font_color', self.gf('django.db.models.fields.CharField')(default='000000', max_length=10)), ('font_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True))))\n    db.send_create_signal('happenings', ['Event'])\n    m2m_table_name = db.shorten_name('happenings_event_location')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('location', models.ForeignKey(orm['happenings.location'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'location_id'])\n    m2m_table_name = db.shorten_name('happenings_event_categories')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('category', models.ForeignKey(orm['happenings.category'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'category_id'])\n    m2m_table_name = db.shorten_name('happenings_event_tags')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('tag', models.ForeignKey(orm['happenings.tag'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'tag_id'])\n    db.create_table('happenings_location', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255)), ('address_line_1', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_2', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_3', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('state', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('city', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('zipcode', self.gf('django.db.models.fields.CharField')(max_length=31, blank=True)), ('country', self.gf('django.db.models.fields.CharField')(max_length=127, blank=True))))\n    db.send_create_signal('happenings', ['Location'])\n    db.create_table('happenings_category', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Category'])\n    db.create_table('happenings_tag', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Tag'])\n", "label": "Correct"}
{"function": "\n\ndef forwards(self, orm):\n    db.create_table('happenings_event', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('start_date', self.gf('django.db.models.fields.DateTimeField')()), ('end_date', self.gf('django.db.models.fields.DateTimeField')()), ('all_day', self.gf('django.db.models.fields.BooleanField')()), ('repeat', self.gf('django.db.models.fields.CharField')(default='NEVER', max_length=15)), ('end_repeat', self.gf('django.db.models.fields.DateField')(null=True, blank=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255)), ('description', self.gf('django.db.models.fields.TextField')()), ('created_by', self.gf('django.db.models.fields.related.ForeignKey')(related_name='events', to=orm['auth.User'])), ('background_color', self.gf('django.db.models.fields.CharField')(default='eeeeee', max_length=10)), ('background_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True)), ('font_color', self.gf('django.db.models.fields.CharField')(default='000000', max_length=10)), ('font_color_custom', orm.gf('django.db.models.fields.CharField')(max_length=6, blank=True))))\n    db.send_create_signal('happenings', ['Event'])\n    m2m_table_name = db.shorten_name('happenings_event_location')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('location', models.ForeignKey(orm['happenings.location'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'location_id'])\n    m2m_table_name = db.shorten_name('happenings_event_categories')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('category', models.ForeignKey(orm['happenings.category'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'category_id'])\n    m2m_table_name = db.shorten_name('happenings_event_tags')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('tag', models.ForeignKey(orm['happenings.tag'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'tag_id'])\n    db.create_table('happenings_location', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255)), ('address_line_1', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_2', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_3', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('state', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('city', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('zipcode', self.gf('django.db.models.fields.CharField')(max_length=31, blank=True)), ('country', self.gf('django.db.models.fields.CharField')(max_length=127, blank=True))))\n    db.send_create_signal('happenings', ['Location'])\n    db.create_table('happenings_category', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Category'])\n    db.create_table('happenings_tag', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Tag'])\n", "label": "Variable misuse"}
{"function": "\n\ndef _raise_test_exc(self, exc_msg):\n    raise TestException(exc_msg)\n", "label": "Correct"}
{"function": "\n\ndef _raise_test_exc(self, exc_msg):\n    raise TestException(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef install_inplace(pkg):\n    'Install scripts of pkg in the current directory.'\n    for (basename, executable) in pkg.executables.items():\n        version_str = '.'.join([str(i) for i in sys.version_info[:2]])\n        scripts_node = root._ctx.srcnode\n        for name in [basename, ('%s-%s' % (basename, version_str))]:\n            nodes = _create_executable(name, executable, scripts_node)\n            installed = ','.join([n.path_from(scripts_node) for n in nodes])\n            pprint('GREEN', ('installing %s in current directory' % installed))\n", "label": "Correct"}
{"function": "\n\ndef install_inplace(pkg):\n    'Install scripts of pkg in the current directory.'\n    for (basename, executable) in pkg.executables.items():\n        version_str = '.'.join([str(i) for i in sys.version_info[:2]])\n        scripts_node = root._ctx.srcnode\n        for name in [basename, ('%s-%s' % (basename, version_str))]:\n            nodes = _create_executable(name, n, scripts_node)\n            installed = ','.join([n.path_from(scripts_node) for n in nodes])\n            pprint('GREEN', ('installing %s in current directory' % installed))\n", "label": "Variable misuse"}
{"function": "\n\ndef testSuccess(self):\n    vor = rapi.testutils.VerifyOpResult\n    vor(opcodes.OpClusterVerify.OP_ID, {\n        constants.JOB_IDS_KEY: [(False, 'error message')],\n    })\n", "label": "Correct"}
{"function": "\n\ndef testSuccess(self):\n    vor = rapi.testutils.VerifyOpResult\n    self(opcodes.OpClusterVerify.OP_ID, {\n        constants.JOB_IDS_KEY: [(False, 'error message')],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef kilobyte(self, value=None):\n    return self.convertb(value, self.byte)\n", "label": "Correct"}
{"function": "\n\ndef kilobyte(self, value=None):\n    return value.convertb(value, self.byte)\n", "label": "Variable misuse"}
{"function": "\n\ndef _irfft_out_chunks(a, n, axis):\n    if (n is None):\n        n = (2 * (a.chunks[axis][0] - 1))\n    chunks = list(a.chunks)\n    chunks[axis] = (n,)\n    return chunks\n", "label": "Correct"}
{"function": "\n\ndef _irfft_out_chunks(a, n, axis):\n    if (n is None):\n        n = (2 * (a.chunks[n][0] - 1))\n    chunks = list(a.chunks)\n    chunks[axis] = (n,)\n    return chunks\n", "label": "Variable misuse"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20100608__ia__primary__adair__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20100608__ia__primary__adair__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    us_rep_dist_5_rep_results = [r for r in results if ((r.office == 'U.S. REPRESENTATIVE') and (r.district == '5') and (r.primary_party == 'REPUBLICAN'))]\n    self.assertEqual(len(us_rep_dist_5_rep_results), 35)\n    result = us_rep_dist_5_rep_results[0]\n    self.assertEqual(result.source, mapping['generated_filename'])\n    self.assertEqual(result.election_id, mapping['election'])\n    self.assertEqual(result.state, 'IA')\n    self.assertEqual(result.election_type, 'primary')\n    self.assertEqual(result.district, '5')\n    self.assertEqual(result.party, 'REPUBLICAN')\n    self.assertEqual(result.jurisdiction, '1 NW')\n    self.assertEqual(result.reporting_level, 'precinct')\n    self.assertEqual(result.full_name, 'STEVE KING')\n    self.assertEqual(result.votes, 123)\n", "label": "Correct"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20100608__ia__primary__adair__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20100608__ia__primary__adair__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    us_rep_dist_5_rep_results = [r for r in results if ((r.office == 'U.S. REPRESENTATIVE') and (r.district == '5') and (r.primary_party == 'REPUBLICAN'))]\n    self.assertEqual(len(mapping), 35)\n    result = us_rep_dist_5_rep_results[0]\n    self.assertEqual(result.source, mapping['generated_filename'])\n    self.assertEqual(result.election_id, mapping['election'])\n    self.assertEqual(result.state, 'IA')\n    self.assertEqual(result.election_type, 'primary')\n    self.assertEqual(result.district, '5')\n    self.assertEqual(result.party, 'REPUBLICAN')\n    self.assertEqual(result.jurisdiction, '1 NW')\n    self.assertEqual(result.reporting_level, 'precinct')\n    self.assertEqual(result.full_name, 'STEVE KING')\n    self.assertEqual(result.votes, 123)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_context_data(self, **kwargs):\n    ctx = super(AddressCreateView, self).get_context_data(**kwargs)\n    ctx['title'] = _('Add a new address')\n    return ctx\n", "label": "Correct"}
{"function": "\n\ndef get_context_data(self, **kwargs):\n    ctx = super(AddressCreateView, self).get_context_data(**self)\n    ctx['title'] = _('Add a new address')\n    return ctx\n", "label": "Variable misuse"}
{"function": "\n\ndef find_by_selector(self, selector, search_regions=None):\n    search_regions = (search_regions or self.regions)\n    return GrammarParser.filter_by_selector(selector, search_regions)\n", "label": "Correct"}
{"function": "\n\ndef find_by_selector(self, selector, search_regions=None):\n    search_regions = (search_regions or selector.regions)\n    return GrammarParser.filter_by_selector(selector, search_regions)\n", "label": "Variable misuse"}
{"function": "\n\ndef nova(context):\n    global _nova_api_version\n    if (not _nova_api_version):\n        _nova_api_version = _get_nova_api_version(context)\n    clnt = novaclient.Client(_nova_api_version, session=context.session, service_type=CONF.nova_service_type)\n    if (not hasattr(clnt.client, 'last_request_id')):\n        setattr(clnt.client, 'last_request_id', None)\n    return clnt\n", "label": "Correct"}
{"function": "\n\ndef nova(context):\n    global _nova_api_version\n    if (not _nova_api_version):\n        _nova_api_version = _get_nova_api_version(context)\n    clnt = novaclient.Client(_nova_api_version, session=context.session, service_type=CONF.nova_service_type)\n    if (not hasattr(clnt.client, 'last_request_id')):\n        setattr(clnt.client, 'last_request_id', None)\n    return context\n", "label": "Variable misuse"}
{"function": "\n\ndef iteritems(self):\n    for tag in self.tags:\n        (yield (tag.name, tag))\n", "label": "Correct"}
{"function": "\n\ndef iteritems(self):\n    for tag in self.tags:\n        (yield (self.name, tag))\n", "label": "Variable misuse"}
{"function": "\n\ndef split_multiline(value):\n    value = [element for element in (line.strip() for line in value.split('\\n')) if element]\n    return value\n", "label": "Correct"}
{"function": "\n\ndef split_multiline(value):\n    value = [element for element in (value.strip() for line in value.split('\\n')) if element]\n    return value\n", "label": "Variable misuse"}
{"function": "\n\ndef get_tags_count(journal):\n    'Returns a set of tuples (count, tag) for all tags present in the journal.'\n    tags = [tag for entry in journal.entries for tag in set(entry.tags)]\n    tag_counts = set([(tags.count(tag), tag) for tag in tags])\n    return tag_counts\n", "label": "Correct"}
{"function": "\n\ndef get_tags_count(journal):\n    'Returns a set of tuples (count, tag) for all tags present in the journal.'\n    tags = [tag for entry in journal.entries for tag in set(entry.tags)]\n    tag_counts = set([(tags.count(tags), tag) for tag in tags])\n    return tag_counts\n", "label": "Variable misuse"}
{"function": "\n\ndef vmstats():\n    \"\\n    Return the virtual memory stats for this minion\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' status.vmstats\\n    \"\n\n    def linux_vmstats():\n        '\\n        linux specific implementation of vmstats\\n        '\n        procf = '/proc/vmstat'\n        if (not os.path.isfile(procf)):\n            return {\n                \n            }\n        stats = salt.utils.fopen(procf, 'r').read().splitlines()\n        ret = {\n            \n        }\n        for line in stats:\n            if (not line):\n                continue\n            comps = line.split()\n            ret[comps[0]] = _number(comps[1])\n        return ret\n\n    def freebsd_vmstats():\n        '\\n        freebsd specific implementation of vmstats\\n        '\n        ret = {\n            \n        }\n        for line in __salt__['cmd.run']('vmstat -s').splitlines():\n            comps = line.split()\n            if comps[0].isdigit():\n                ret[' '.join(comps[1:])] = _number(comps[0])\n        return ret\n    get_version = {\n        'Linux': linux_vmstats,\n        'FreeBSD': freebsd_vmstats,\n    }\n    errmsg = 'This method is unsupported on the current operating system!'\n    return get_version.get(__grains__['kernel'], (lambda : errmsg))()\n", "label": "Correct"}
{"function": "\n\ndef vmstats():\n    \"\\n    Return the virtual memory stats for this minion\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' status.vmstats\\n    \"\n\n    def linux_vmstats():\n        '\\n        linux specific implementation of vmstats\\n        '\n        procf = '/proc/vmstat'\n        if (not os.path.isfile(procf)):\n            return {\n                \n            }\n        stats = salt.utils.fopen(procf, 'r').read().splitlines()\n        ret = {\n            \n        }\n        for line in stats:\n            if (not line):\n                continue\n            comps = line.split()\n            ret[comps[0]] = _number(comps[1])\n        return ret\n\n    def freebsd_vmstats():\n        '\\n        freebsd specific implementation of vmstats\\n        '\n        ret = {\n            \n        }\n        for line in __salt__['cmd.run']('vmstat -s').splitlines():\n            comps = line.split()\n            if comps[0].isdigit():\n                ret[' '.join(comps[1:])] = _number(comps[0])\n        return ret\n    get_version = {\n        'Linux': linux_vmstats,\n        'FreeBSD': freebsd_vmstats,\n    }\n    errmsg = 'This method is unsupported on the current operating system!'\n    return get_version.get(__grains__['kernel'], (lambda : get_version))()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_children_duplicates(self):\n    from psutil._compat import defaultdict\n    table = defaultdict(int)\n    for p in psutil.process_iter():\n        try:\n            table[p.ppid] += 1\n        except psutil.Error:\n            pass\n    pid = max(sorted(table, key=(lambda x: table[x])))\n    p = psutil.Process(pid)\n    try:\n        c = p.get_children(recursive=True)\n    except psutil.AccessDenied:\n        pass\n    else:\n        self.assertEqual(len(c), len(set(c)))\n", "label": "Correct"}
{"function": "\n\ndef test_get_children_duplicates(self):\n    from psutil._compat import defaultdict\n    table = defaultdict(int)\n    for p in psutil.process_iter():\n        try:\n            table[p.ppid] += 1\n        except psutil.Error:\n            pass\n    pid = max(sorted(pid, key=(lambda x: table[x])))\n    p = psutil.Process(pid)\n    try:\n        c = p.get_children(recursive=True)\n    except psutil.AccessDenied:\n        pass\n    else:\n        self.assertEqual(len(c), len(set(c)))\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, driver):\n    try:\n        return _element_if_visible(_find_element(driver, self.locator))\n    except StaleElementReferenceException:\n        return False\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, driver):\n    try:\n        return _element_if_visible(_find_element(driver, driver.locator))\n    except StaleElementReferenceException:\n        return False\n", "label": "Variable misuse"}
{"function": "\n\ndef _test_update_routing_table(self, is_snat_host=True):\n    router = l3_test_common.prepare_router_data()\n    uuid = router['id']\n    s_netns = ('snat-' + uuid)\n    q_netns = ('qrouter-' + uuid)\n    fake_route1 = {\n        'destination': '135.207.0.0/16',\n        'nexthop': '19.4.4.200',\n    }\n    calls = [mock.call('replace', fake_route1, q_netns)]\n    agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)\n    ri = dvr_router.DvrEdgeRouter(agent, HOSTNAME, uuid, router, **self.ri_kwargs)\n    ri._update_routing_table = mock.Mock()\n    with mock.patch.object(ri, '_is_this_snat_host') as snat_host:\n        snat_host.return_value = is_snat_host\n        ri.update_routing_table('replace', fake_route1)\n        if is_snat_host:\n            ri._update_routing_table('replace', fake_route1, s_netns)\n            calls += [mock.call('replace', fake_route1, s_netns)]\n        ri._update_routing_table.assert_has_calls(calls, any_order=True)\n", "label": "Correct"}
{"function": "\n\ndef _test_update_routing_table(self, is_snat_host=True):\n    router = l3_test_common.prepare_router_data()\n    uuid = router['id']\n    s_netns = ('snat-' + uuid)\n    q_netns = ('qrouter-' + uuid)\n    fake_route1 = {\n        'destination': '135.207.0.0/16',\n        'nexthop': '19.4.4.200',\n    }\n    calls = [mock.call('replace', fake_route1, q_netns)]\n    agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)\n    ri = dvr_router.DvrEdgeRouter(agent, HOSTNAME, uuid, is_snat_host, **self.ri_kwargs)\n    ri._update_routing_table = mock.Mock()\n    with mock.patch.object(ri, '_is_this_snat_host') as snat_host:\n        snat_host.return_value = is_snat_host\n        ri.update_routing_table('replace', fake_route1)\n        if is_snat_host:\n            ri._update_routing_table('replace', fake_route1, s_netns)\n            calls += [mock.call('replace', fake_route1, s_netns)]\n        ri._update_routing_table.assert_has_calls(calls, any_order=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef install_ssl_certs(instances):\n    certs = []\n    if CONF.object_store_access.public_identity_ca_file:\n        certs.append(CONF.object_store_access.public_identity_ca_file)\n    if CONF.object_store_access.public_object_store_ca_file:\n        certs.append(CONF.object_store_access.public_object_store_ca_file)\n    if (not certs):\n        return\n    with context.ThreadGroup() as tg:\n        for inst in instances:\n            tg.spawn(('configure-ssl-cert-%s' % inst.instance_id), _install_ssl_certs, inst, certs)\n", "label": "Correct"}
{"function": "\n\ndef install_ssl_certs(instances):\n    certs = []\n    if CONF.object_store_access.public_identity_ca_file:\n        certs.append(CONF.object_store_access.public_identity_ca_file)\n    if CONF.object_store_access.public_object_store_ca_file:\n        certs.append(CONF.object_store_access.public_object_store_ca_file)\n    if (not certs):\n        return\n    with context.ThreadGroup() as tg:\n        for inst in instances:\n            tg.spawn(('configure-ssl-cert-%s' % certs.instance_id), _install_ssl_certs, inst, certs)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_node_site():\n    s = Site(TEST_SITE_ROOT)\n    r = RootNode(TEST_SITE_ROOT.child_folder('content'), s)\n    assert (r.site == s)\n    n = Node(r.source_folder.child_folder('blog'), r)\n    assert (n.site == s)\n", "label": "Correct"}
{"function": "\n\ndef test_node_site():\n    s = Site(TEST_SITE_ROOT)\n    r = RootNode(TEST_SITE_ROOT.child_folder('content'), s)\n    assert (r.site == n)\n    n = Node(r.source_folder.child_folder('blog'), r)\n    assert (n.site == s)\n", "label": "Variable misuse"}
{"function": "\n\ndef create_debianization(distribution):\n    if exists('debian'):\n        raise NotImplementedError()\n    name = distribution.get_name()\n    name = ('python-%s' % name.replace('_', '-').lower())\n    maintainer = distribution.get_maintainer()\n    maintainer_email = distribution.get_maintainer_email()\n    if (maintainer == 'UNKNOWN'):\n        maintainer = 'CH content team'\n    if (maintainer_email == 'UNKNOWN'):\n        maintainer_email = 'pg-content-dev@chconf.com'\n    maintainer = ('%s <%s>' % (maintainer, maintainer_email))\n    version = distribution.get_version()\n    if (not version):\n        version = '0.0.0'\n    now = datetime.now()\n    utcnow = datetime.utcnow()\n    tzdiff = get_tzdiff(now, utcnow)\n    nowstring = ('%s %s' % (now.strftime('%a, %d %b %Y %H:%M:%S'), tzdiff))\n    description = distribution.get_description()\n    description = description.strip().replace('\\n', '\\n ')\n    architecture = 'all'\n    if distribution.has_ext_modules():\n        architecture = 'any'\n    copytree(join(dirname(__file__), 'default_debianization'), 'debian')\n    for (root, dirs, files) in os.walk('debian'):\n        for f in files:\n            file = join(root, f)\n            with open(file) as fin:\n                content = fin.read()\n            for (key, value) in (('#NAME#', name), ('#MAINTAINER#', maintainer), ('#VERSION#', version), ('#DATE#', nowstring)):\n                content = content.replace(key, value)\n            with open(file, 'w') as fout:\n                fout.write(content)\n    cf = ControlFile(filename='debian/control')\n    src = cf.source\n    p = cf.packages[0]\n    src['Source'] = p['Package'] = name\n    src['Maintainer'] = maintainer\n    p['Description'] = description\n    p['Architecture'] = architecture\n    install_requires = distribution.install_requires\n    if install_requires:\n        for package in install_requires:\n            p['Depends'].append(parse_setuppy_dependency(package))\n    cf.dump('debian/control')\n", "label": "Correct"}
{"function": "\n\ndef create_debianization(distribution):\n    if exists('debian'):\n        raise NotImplementedError()\n    name = distribution.get_name()\n    name = ('python-%s' % name.replace('_', '-').lower())\n    maintainer = distribution.get_maintainer()\n    maintainer_email = distribution.get_maintainer_email()\n    if (maintainer == 'UNKNOWN'):\n        maintainer = 'CH content team'\n    if (maintainer_email == 'UNKNOWN'):\n        maintainer_email = 'pg-content-dev@chconf.com'\n    maintainer = ('%s <%s>' % (maintainer, maintainer_email))\n    version = distribution.get_version()\n    if (not version):\n        version = '0.0.0'\n    now = datetime.now()\n    utcnow = datetime.utcnow()\n    tzdiff = get_tzdiff(now, utcnow)\n    nowstring = ('%s %s' % (now.strftime('%a, %d %b %Y %H:%M:%S'), tzdiff))\n    description = distribution.get_description()\n    description = description.strip().replace('\\n', '\\n ')\n    architecture = 'all'\n    if distribution.has_ext_modules():\n        architecture = 'any'\n    copytree(join(dirname(__file__), 'default_debianization'), 'debian')\n    for (root, dirs, files) in os.walk('debian'):\n        for f in files:\n            file = join(root, f)\n            with open(maintainer_email) as fin:\n                content = fin.read()\n            for (key, value) in (('#NAME#', name), ('#MAINTAINER#', maintainer), ('#VERSION#', version), ('#DATE#', nowstring)):\n                content = content.replace(key, value)\n            with open(file, 'w') as fout:\n                fout.write(content)\n    cf = ControlFile(filename='debian/control')\n    src = cf.source\n    p = cf.packages[0]\n    src['Source'] = p['Package'] = name\n    src['Maintainer'] = maintainer\n    p['Description'] = description\n    p['Architecture'] = architecture\n    install_requires = distribution.install_requires\n    if install_requires:\n        for package in install_requires:\n            p['Depends'].append(parse_setuppy_dependency(package))\n    cf.dump('debian/control')\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, name, value, attrs=None):\n    value = util.serialize_references(value)\n    return super(ReferencesFieldWidget, self).render(name, value, attrs)\n", "label": "Correct"}
{"function": "\n\ndef render(self, name, value, attrs=None):\n    value = util.serialize_references(value)\n    return super(ReferencesFieldWidget, name).render(name, value, attrs)\n", "label": "Variable misuse"}
{"function": "\n\ndef on_request(self, context, request):\n    if ('PowerView.ps1' == request.path[1:]):\n        request.send_response(200)\n        request.end_headers()\n        with open('data/PowerSploit/Recon/PowerView.ps1', 'r') as ps_script:\n            ps_script = obfs_ps_script(ps_script.read())\n            request.wfile.write(ps_script)\n    else:\n        request.send_response(404)\n        request.end_headers()\n", "label": "Correct"}
{"function": "\n\ndef on_request(self, context, request):\n    if ('PowerView.ps1' == request.path[1:]):\n        request.send_response(200)\n        request.end_headers()\n        with open('data/PowerSploit/Recon/PowerView.ps1', 'r') as ps_script:\n            ps_script = obfs_ps_script(request.read())\n            request.wfile.write(ps_script)\n    else:\n        request.send_response(404)\n        request.end_headers()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_column_expr(self):\n    c = Column('x', Integer)\n    is_(inspect(c), c)\n    assert (not c.is_selectable)\n    assert (not hasattr(c, 'selectable'))\n", "label": "Correct"}
{"function": "\n\ndef test_column_expr(self):\n    c = Column('x', Integer)\n    is_(inspect(c), self)\n    assert (not c.is_selectable)\n    assert (not hasattr(c, 'selectable'))\n", "label": "Variable misuse"}
{"function": "\n\ndef inline_assets(self, base_path, content):\n    for type in self.asset_types:\n        for (statement, path) in self.get_matches(type['pattern'], base_path, content):\n            asset_content = self.get_binary_file_contents(path)\n            encoded_content = urllib.quote(base64.encodestring(asset_content))\n            new_statement = ('url(data:%s;base64,%s)' % (type['mime'], encoded_content))\n            content = content.replace(statement, new_statement)\n    return content\n", "label": "Correct"}
{"function": "\n\ndef inline_assets(self, base_path, content):\n    for type in self.asset_types:\n        for (statement, path) in self.get_matches(type['pattern'], base_path, content):\n            asset_content = self.get_binary_file_contents(path)\n            encoded_content = urllib.quote(base64.encodestring(asset_content))\n            new_statement = ('url(data:%s;base64,%s)' % (type['mime'], encoded_content))\n            content = encoded_content.replace(statement, new_statement)\n    return content\n", "label": "Variable misuse"}
{"function": "\n\ndef test_choice_update(self):\n    self.choice.choice_text = 'third text'\n    self.choice.save()\n    p = Choice.objects.get()\n    self.assertEqual(p.choice_text, 'third text')\n", "label": "Correct"}
{"function": "\n\ndef test_choice_update(self):\n    self.choice.choice_text = 'third text'\n    p.choice.save()\n    p = Choice.objects.get()\n    self.assertEqual(p.choice_text, 'third text')\n", "label": "Variable misuse"}
{"function": "\n\ndef abort_run(self, drain=False):\n    self._aborting_run = drain\n", "label": "Correct"}
{"function": "\n\ndef abort_run(self, drain=False):\n    drain._aborting_run = drain\n", "label": "Variable misuse"}
{"function": "\n\ndef test_oldPythonPy3(self):\n    '\\n        L{_checkRequirements} raises L{ImportError} when run on a version of\\n        Python that is too old.\\n        '\n    sys.version_info = self.Py3unsupportedPythonVersion\n    with self.assertRaises(ImportError) as raised:\n        _checkRequirements()\n    self.assertEqual(('Twisted on Python 3 requires Python %d.%d or later.' % self.Py3supportedPythonVersion), str(raised.exception))\n", "label": "Correct"}
{"function": "\n\ndef test_oldPythonPy3(self):\n    '\\n        L{_checkRequirements} raises L{ImportError} when run on a version of\\n        Python that is too old.\\n        '\n    sys.version_info = self.Py3unsupportedPythonVersion\n    with self.assertRaises(ImportError) as raised:\n        _checkRequirements()\n    self.assertEqual(('Twisted on Python 3 requires Python %d.%d or later.' % raised.Py3supportedPythonVersion), str(raised.exception))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_oauth_request(request):\n    ' Converts a Django request object into an `oauth2.Request` object. '\n    headers = {\n        \n    }\n    if ('HTTP_AUTHORIZATION' in request.META):\n        headers['Authorization'] = request.META['HTTP_AUTHORIZATION']\n    return oauth.Request.from_request(request.method, request.build_absolute_uri(request.path), headers, dict(request.REQUEST))\n", "label": "Correct"}
{"function": "\n\ndef get_oauth_request(request):\n    ' Converts a Django request object into an `oauth2.Request` object. '\n    headers = {\n        \n    }\n    if ('HTTP_AUTHORIZATION' in headers.META):\n        headers['Authorization'] = request.META['HTTP_AUTHORIZATION']\n    return oauth.Request.from_request(request.method, request.build_absolute_uri(request.path), headers, dict(request.REQUEST))\n", "label": "Variable misuse"}
{"function": "\n\ndef _apply_filters(self, query, count_query, joins, count_joins, filters):\n    for (idx, flt_name, value) in filters:\n        flt = self._filters[idx]\n        alias = None\n        count_alias = None\n        if isinstance(flt, sqla_filters.BaseSQLAFilter):\n            path = self._filter_joins.get(flt.column, [])\n            (query, joins, alias) = self._apply_path_joins(query, joins, path, inner_join=False)\n            if (count_query is not None):\n                (count_query, count_joins, count_alias) = self._apply_path_joins(count_query, count_joins, path, inner_join=False)\n        clean_value = flt.clean(value)\n        try:\n            query = flt.apply(query, clean_value, alias)\n        except TypeError:\n            spec = inspect.getargspec(flt.apply)\n            if (len(spec.args) == 3):\n                warnings.warn(('Please update your custom filter %s to include additional `alias` parameter.' % repr(flt)))\n            else:\n                raise\n            query = flt.apply(query, clean_value)\n        if (count_query is not None):\n            try:\n                count_query = flt.apply(count_query, clean_value, count_alias)\n            except TypeError:\n                count_query = flt.apply(count_query, clean_value)\n    return (query, count_query, joins, count_joins)\n", "label": "Correct"}
{"function": "\n\ndef _apply_filters(self, query, count_query, joins, count_joins, filters):\n    for (idx, flt_name, value) in filters:\n        flt = self._filters[idx]\n        alias = None\n        count_alias = None\n        if isinstance(flt, sqla_filters.BaseSQLAFilter):\n            path = self._filter_joins.get(flt.column, [])\n            (query, joins, alias) = self._apply_path_joins(query, joins, path, inner_join=False)\n            if (count_query is not None):\n                (count_query, count_joins, count_alias) = self._apply_path_joins(count_query, count_joins, path, inner_join=False)\n        clean_value = flt.clean(value)\n        try:\n            query = flt.apply(query, clean_value, alias)\n        except TypeError:\n            spec = inspect.getargspec(flt.apply)\n            if (len(spec.args) == 3):\n                warnings.warn(('Please update your custom filter %s to include additional `alias` parameter.' % repr(flt)))\n            else:\n                raise\n            query = flt.apply(query, clean_value)\n        if (count_query is not None):\n            try:\n                count_query = flt.apply(count_query, clean_value, count_alias)\n            except TypeError:\n                count_query = flt.apply(spec, clean_value)\n    return (query, count_query, joins, count_joins)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef vcf(self):\n    'serialize to VCARD as specified in RFC2426,\\n        if no UID is specified yet, one will be added (as a UID is mandatory\\n        for carddav as specified in RFC6352\\n        TODO make shure this random uid is unique'\n    import string\n    import random\n\n    def generate_random_uid():\n        \"generate a random uid, when random isn't broken, getting a\\n            random UID from a pool of roughly 10^56 should be good enough\"\n        choice = (string.ascii_uppercase + string.digits)\n        return ''.join([random.choice(choice) for _ in range(36)])\n    if ('UID' not in self.keys()):\n        self['UID'] = [(generate_random_uid(), dict())]\n    collector = list()\n    collector.append('BEGIN:VCARD')\n    collector.append('VERSION:3.0')\n    for key in ['FN', 'N']:\n        try:\n            collector.append(((key + ':') + self[key][0][0]))\n        except IndexError:\n            collector.append((key + ':'))\n    for prop in self.alt_keys():\n        for line in self[prop]:\n            types = self._line_helper(line)\n            collector.append((((prop + types) + ':') + line[0]))\n    collector.append('END:VCARD')\n    return '\\n'.join(collector)\n", "label": "Correct"}
{"function": "\n\n@property\ndef vcf(self):\n    'serialize to VCARD as specified in RFC2426,\\n        if no UID is specified yet, one will be added (as a UID is mandatory\\n        for carddav as specified in RFC6352\\n        TODO make shure this random uid is unique'\n    import string\n    import random\n\n    def generate_random_uid():\n        \"generate a random uid, when random isn't broken, getting a\\n            random UID from a pool of roughly 10^56 should be good enough\"\n        choice = (string.ascii_uppercase + string.digits)\n        return ''.join([random.choice(choice) for _ in range(36)])\n    if ('UID' not in self.keys()):\n        self['UID'] = [(generate_random_uid(), dict())]\n    collector = list()\n    collector.append('BEGIN:VCARD')\n    collector.append('VERSION:3.0')\n    for key in ['FN', 'N']:\n        try:\n            collector.append(((key + ':') + collector[key][0][0]))\n        except IndexError:\n            collector.append((key + ':'))\n    for prop in self.alt_keys():\n        for line in self[prop]:\n            types = self._line_helper(line)\n            collector.append((((prop + types) + ':') + line[0]))\n    collector.append('END:VCARD')\n    return '\\n'.join(collector)\n", "label": "Variable misuse"}
{"function": "\n\ndef close_review_request(server_url, username, password, review_request_id, description):\n    'Closes the specified review request as submitted.'\n    (api_client, api_root) = get_api(server_url, username, password)\n    review_request = get_review_request(review_request_id, api_root)\n    if (review_request.status == SUBMITTED):\n        logging.warning('Review request #%s is already %s.', review_request_id, SUBMITTED)\n        return\n    if description:\n        review_request = review_request.update(status=SUBMITTED, description=description)\n    else:\n        review_request = review_request.update(status=SUBMITTED)\n    print(('Review request #%s is set to %s.' % (review_request_id, review_request.status)))\n", "label": "Correct"}
{"function": "\n\ndef close_review_request(server_url, username, password, review_request_id, description):\n    'Closes the specified review request as submitted.'\n    (api_client, api_root) = get_api(server_url, username, password)\n    review_request = get_review_request(review_request_id, api_root)\n    if (review_request.status == SUBMITTED):\n        logging.warning('Review request #%s is already %s.', review_request_id, SUBMITTED)\n        return\n    if description:\n        review_request = review_request.update(status=SUBMITTED, description=description)\n    else:\n        review_request = review_request.update(status=SUBMITTED)\n    print(('Review request #%s is set to %s.' % (username, review_request.status)))\n", "label": "Variable misuse"}
{"function": "\n\ndef GetLastRequestTimedelta(api_query, from_time=None):\n    'Returns how long since the API Query response was last requested.\\n\\n  Args:\\n    api_query: The API Query from which to retrieve the last request timedelta.\\n    from_time: A DateTime object representing the start time to calculate the\\n               timedelta from.\\n\\n  Returns:\\n    A string that describes how long since the API Query response was last\\n    requested in the form of \"HH hours, MM minutes, ss seconds ago\" or None\\n    if the API Query response has never been requested.\\n  '\n    if (not from_time):\n        from_time = datetime.utcnow()\n    if api_query.last_request:\n        time_delta = (from_time - api_query.last_request)\n        return FormatTimedelta(time_delta)\n    return None\n", "label": "Correct"}
{"function": "\n\ndef GetLastRequestTimedelta(api_query, from_time=None):\n    'Returns how long since the API Query response was last requested.\\n\\n  Args:\\n    api_query: The API Query from which to retrieve the last request timedelta.\\n    from_time: A DateTime object representing the start time to calculate the\\n               timedelta from.\\n\\n  Returns:\\n    A string that describes how long since the API Query response was last\\n    requested in the form of \"HH hours, MM minutes, ss seconds ago\" or None\\n    if the API Query response has never been requested.\\n  '\n    if (not from_time):\n        from_time = datetime.utcnow()\n    if api_query.last_request:\n        time_delta = (from_time - api_query.last_request)\n        return FormatTimedelta(from_time)\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/particle/shared_particle_test_16.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/particle/shared_particle_test_16.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name):\n    Exception.__init__(self, (\"Method not found: '%s'\" % name))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name):\n    Exception.__init__(self, (\"Method not found: '%s'\" % self))\n", "label": "Variable misuse"}
{"function": "\n\ndef testUnshareSecondLevelRemoved(self):\n    'Re-share photos, remove the reshared viewpoint, then unshare the source viewpoint.'\n    (child_vp_id, child_ep_ids) = self._tester.ShareNew(self._cookie2, [(self._new_ep_id, self._photo_ids)], [self._user3.user_id], **self._CreateViewpointDict(self._cookie2))\n    self._tester.RemoveViewpoint(self._cookie3, child_vp_id)\n    self._tester.Unshare(self._cookie, self._new_vp_id, [(self._new_ep_id, self._photo_ids[:1])])\n", "label": "Correct"}
{"function": "\n\ndef testUnshareSecondLevelRemoved(self):\n    'Re-share photos, remove the reshared viewpoint, then unshare the source viewpoint.'\n    (child_vp_id, child_ep_ids) = self._tester.ShareNew(self._cookie2, [(self._new_ep_id, self._photo_ids)], [self._user3.user_id], **self._CreateViewpointDict(self._cookie2))\n    self._tester.RemoveViewpoint(self._cookie3, child_vp_id)\n    self._tester.Unshare(self._cookie, child_vp_id._new_vp_id, [(self._new_ep_id, self._photo_ids[:1])])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_search_comment(self):\n    result = self.search(comment=['fantastic'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n    result = self.search(comment=['antasti'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n", "label": "Correct"}
{"function": "\n\ndef test_search_comment(self):\n    result = self.search(comment=['fantastic'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n    result = self.search(comment=['antasti'])\n    self.assertEqual(list(self[0].tracks), self.tracks[3:4])\n", "label": "Variable misuse"}
{"function": "\n\n@converts('ImageField')\ndef conv_Image(self, model, field, kwargs):\n    return f.FileField(**kwargs)\n", "label": "Correct"}
{"function": "\n\n@converts('ImageField')\ndef conv_Image(self, model, field, kwargs):\n    return f.FileField(**self)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse(self, text):\n    return [ErrorLine(m) for m in self.regex.finditer(text)]\n", "label": "Correct"}
{"function": "\n\ndef parse(self, text):\n    return [ErrorLine(m) for m in self.regex.finditer(self)]\n", "label": "Variable misuse"}
{"function": "\n\ndef clamp_vect(self, v):\n    'Returns a copy of the vector v clamped to the bounding box'\n    return cpffi.cpBBClampVect(self._bb, v)\n", "label": "Correct"}
{"function": "\n\ndef clamp_vect(self, v):\n    'Returns a copy of the vector v clamped to the bounding box'\n    return cpffi.cpBBClampVect(v._bb, v)\n", "label": "Variable misuse"}
{"function": "\n\ndef __exit__(self, *args):\n    self.delegate.disconnect()\n", "label": "Correct"}
{"function": "\n\ndef __exit__(self, *args):\n    args.delegate.disconnect()\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef mul(f, g):\n    \"\\n        The algorithms performing the multiplication of two ``TIDS`` instances.\\n\\n        In short, it forms a new ``TIDS`` object, joining components and indices,\\n        checking that abstract indices are compatible, and possibly contracting\\n        them.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.tensor.tensor import TensorIndexType, tensor_indices, TIDS, tensorhead\\n        >>> Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\\n        >>> m0, m1, m2, m3 = tensor_indices('m0,m1,m2,m3', Lorentz)\\n        >>> T = tensorhead('T', [Lorentz]*4, [[1]*4])\\n        >>> A = tensorhead('A', [Lorentz], [[1]])\\n        >>> tids_1 = TIDS.from_components_and_indices([T], [m0, m1, -m1, m3])\\n        >>> tids_2 = TIDS.from_components_and_indices([A], [m2])\\n        >>> tids_1 * tids_2\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0), (m3, 3, 0), (m2, 0, 1)], [(1, 2, 0, 0)])\\n\\n        In this case no contraction has been performed.\\n\\n        >>> tids_3 = TIDS.from_components_and_indices([A], [-m3])\\n        >>> tids_1 * tids_3\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0)], [(1, 2, 0, 0), (3, 0, 0, 1)])\\n\\n        Free indices ``m3`` and ``-m3`` are identified as a contracted couple, and are\\n        therefore transformed into dummy indices.\\n\\n        A wrong index construction (for example, trying to contract two\\n        contravariant indices or using indices multiple times) would result in\\n        an exception:\\n\\n        >>> tids_4 = TIDS.from_components_and_indices([A], [m3])\\n        >>> # This raises an exception:\\n        >>> # tids_1 * tids_4\\n        \"\n    index_up = (lambda u: (u if u.is_up else (- u)))\n    notmat = (lambda i: (i not in (i._tensortype.auto_left, (- i._tensortype.auto_right))))\n    f_free = f.free[:]\n    g_free = g.free[:]\n    nc1 = len(f.components)\n    dum = TIDS._check_matrix_indices(f_free, g_free, nc1)\n    free_dict1 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in f_free}\n    free_dict2 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in g_free}\n    free_names = (set(free_dict1.keys()) & set(free_dict2.keys()))\n    dum2 = [(i1, i2, (c1 + nc1), (c2 + nc1)) for (i1, i2, c1, c2) in g.dum]\n    free1 = [(ind, i, c) for (ind, i, c) in f_free if (index_up(ind) not in free_names)]\n    free2 = [(ind, i, (c + nc1)) for (ind, i, c) in g_free if (index_up(ind) not in free_names)]\n    free = (free1 + free2)\n    dum.extend((f.dum + dum2))\n    for name in free_names:\n        (ipos1, cpos1, ind1) = free_dict1[name]\n        (ipos2, cpos2, ind2) = free_dict2[name]\n        cpos2 += nc1\n        if (ind1._is_up == ind2._is_up):\n            raise ValueError('wrong index construction {0}'.format(ind1))\n        if ind1._is_up:\n            new_dummy = (ipos1, ipos2, cpos1, cpos2)\n        else:\n            new_dummy = (ipos2, ipos1, cpos2, cpos1)\n        dum.append(new_dummy)\n    return ((f.components + g.components), free, dum)\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef mul(f, g):\n    \"\\n        The algorithms performing the multiplication of two ``TIDS`` instances.\\n\\n        In short, it forms a new ``TIDS`` object, joining components and indices,\\n        checking that abstract indices are compatible, and possibly contracting\\n        them.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.tensor.tensor import TensorIndexType, tensor_indices, TIDS, tensorhead\\n        >>> Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\\n        >>> m0, m1, m2, m3 = tensor_indices('m0,m1,m2,m3', Lorentz)\\n        >>> T = tensorhead('T', [Lorentz]*4, [[1]*4])\\n        >>> A = tensorhead('A', [Lorentz], [[1]])\\n        >>> tids_1 = TIDS.from_components_and_indices([T], [m0, m1, -m1, m3])\\n        >>> tids_2 = TIDS.from_components_and_indices([A], [m2])\\n        >>> tids_1 * tids_2\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0), (m3, 3, 0), (m2, 0, 1)], [(1, 2, 0, 0)])\\n\\n        In this case no contraction has been performed.\\n\\n        >>> tids_3 = TIDS.from_components_and_indices([A], [-m3])\\n        >>> tids_1 * tids_3\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0)], [(1, 2, 0, 0), (3, 0, 0, 1)])\\n\\n        Free indices ``m3`` and ``-m3`` are identified as a contracted couple, and are\\n        therefore transformed into dummy indices.\\n\\n        A wrong index construction (for example, trying to contract two\\n        contravariant indices or using indices multiple times) would result in\\n        an exception:\\n\\n        >>> tids_4 = TIDS.from_components_and_indices([A], [m3])\\n        >>> # This raises an exception:\\n        >>> # tids_1 * tids_4\\n        \"\n    index_up = (lambda u: (u if u.is_up else (- u)))\n    notmat = (lambda i: (i not in (i._tensortype.auto_left, (- i._tensortype.auto_right))))\n    f_free = f.free[:]\n    g_free = g.free[:]\n    nc1 = len(f.components)\n    dum = TIDS._check_matrix_indices(f_free, g_free, nc1)\n    free_dict1 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in f_free}\n    free_dict2 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in g_free}\n    free_names = (set(free_dict1.keys()) & set(free_dict2.keys()))\n    dum2 = [(i1, i2, (c1 + nc1), (c2 + nc1)) for (i1, i2, c1, c2) in g.dum]\n    free1 = [(ind, i, c) for (ind, i, c) in f_free if (index_up(ind) not in free_names)]\n    free2 = [(ind, i, (c + nc1)) for (ind, i, c) in g_free if (index_up(ind) not in free_names)]\n    free = (free1 + free2)\n    dum.extend((f.dum + dum2))\n    for name in free_names:\n        (ipos1, cpos1, ind1) = free_dict1[name]\n        (ipos2, cpos2, ind2) = free_dict2[name]\n        cpos2 += nc1\n        if (ind1._is_up == ind2._is_up):\n            raise ValueError('wrong index construction {0}'.format(ind1))\n        if ind1._is_up:\n            new_dummy = (ipos1, ipos2, cpos1, cpos2)\n        else:\n            new_dummy = (ipos2, ipos1, cpos2, cpos1)\n        dum.append(new_dummy)\n    return ((f.components + g.components), ipos2, dum)\n", "label": "Variable misuse"}
{"function": "\n\n@view_config(context='velruse.AuthenticationComplete', renderer='{}:templates/result.mako'.format(__name__))\ndef login_complete_view(request):\n    context = request.context\n    result = {\n        'profile': context.profile,\n        'credentials': context.credentials,\n    }\n    return {\n        'result': json.dumps(result, indent=4),\n    }\n", "label": "Correct"}
{"function": "\n\n@view_config(context='velruse.AuthenticationComplete', renderer='{}:templates/result.mako'.format(__name__))\ndef login_complete_view(request):\n    context = context.context\n    result = {\n        'profile': context.profile,\n        'credentials': context.credentials,\n    }\n    return {\n        'result': json.dumps(result, indent=4),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef draw_outlines(context, box, enable_hinting):\n    width = box.style.outline_width\n    color = box.style.get_color('outline_color')\n    style = box.style.outline_style\n    if ((box.style.visibility == 'visible') and (width != 0) and (color.alpha != 0)):\n        outline_box = ((box.border_box_x() - width), (box.border_box_y() - width), (box.border_width() + (2 * width)), (box.border_height() + (2 * width)))\n        for side in SIDES:\n            with stacked(context):\n                clip_border_segment(context, enable_hinting, style, width, side, outline_box)\n                draw_rect_border(context, outline_box, (4 * (width,)), style, styled_color(style, color, side))\n    if isinstance(box, boxes.ParentBox):\n        for child in box.children:\n            if isinstance(child, boxes.Box):\n                draw_outlines(context, child, enable_hinting)\n", "label": "Correct"}
{"function": "\n\ndef draw_outlines(context, box, enable_hinting):\n    width = box.style.outline_width\n    color = box.style.get_color('outline_color')\n    style = box.style.outline_style\n    if ((box.style.visibility == 'visible') and (width != 0) and (color.alpha != 0)):\n        outline_box = ((box.border_box_x() - width), (box.border_box_y() - width), (box.border_width() + (2 * width)), (box.border_height() + (2 * width)))\n        for side in SIDES:\n            with stacked(context):\n                clip_border_segment(context, enable_hinting, style, width, side, outline_box)\n                draw_rect_border(context, context, (4 * (width,)), style, styled_color(style, color, side))\n    if isinstance(box, boxes.ParentBox):\n        for child in box.children:\n            if isinstance(child, boxes.Box):\n                draw_outlines(context, child, enable_hinting)\n", "label": "Variable misuse"}
{"function": "\n\ndef emit(self, *args, **kwargs):\n    try:\n        self.__emitting = True\n        for handler in self.__handlers:\n            handler(*args, **kwargs)\n    finally:\n        self.__emitting = False\n        self.__applyChanges()\n", "label": "Correct"}
{"function": "\n\ndef emit(self, *args, **kwargs):\n    try:\n        self.__emitting = True\n        for handler in self.__handlers:\n            handler(*args, **kwargs)\n    finally:\n        self.__emitting = False\n        handler.__applyChanges()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_existing_spawn(self):\n    child = pexpect.spawnu('bash', timeout=5, echo=False)\n    repl = replwrap.REPLWrapper(child, re.compile('[$#]'), \"PS1='{0}' PS2='{1}' PROMPT_COMMAND=''\")\n    res = repl.run_command('echo $HOME')\n    assert res.startswith('/'), res\n", "label": "Correct"}
{"function": "\n\ndef test_existing_spawn(self):\n    child = pexpect.spawnu('bash', timeout=5, echo=False)\n    repl = replwrap.REPLWrapper(child, re.compile('[$#]'), \"PS1='{0}' PS2='{1}' PROMPT_COMMAND=''\")\n    res = repl.run_command('echo $HOME')\n    assert repl.startswith('/'), res\n", "label": "Variable misuse"}
{"function": "\n\ndef child_removed(self, child):\n    ' Handle the child removed event for a QtWindow.\\n\\n        '\n    if isinstance(child, WxContainer):\n        self.widget.SetCentralWidget(self.central_widget())\n", "label": "Correct"}
{"function": "\n\ndef child_removed(self, child):\n    ' Handle the child removed event for a QtWindow.\\n\\n        '\n    if isinstance(child, WxContainer):\n        self.widget.SetCentralWidget(child.central_widget())\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stubs(self):\n    df = pd.DataFrame([[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]])\n    df.columns = ['id', 'inc1', 'inc2', 'edu1', 'edu2']\n    stubs = ['inc', 'edu']\n    df_long = pd.wide_to_long(df, stubs, i='id', j='age')\n    self.assertEqual(stubs, ['inc', 'edu'])\n", "label": "Correct"}
{"function": "\n\ndef test_stubs(self):\n    df = pd.DataFrame([[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]])\n    df.columns = ['id', 'inc1', 'inc2', 'edu1', 'edu2']\n    stubs = ['inc', 'edu']\n    df_long = pd.wide_to_long(df_long, stubs, i='id', j='age')\n    self.assertEqual(stubs, ['inc', 'edu'])\n", "label": "Variable misuse"}
{"function": "\n\ndef collectstreamuuid(self, streamname):\n    if (not streamname):\n        return\n    shouter.shout(('Get UUID of configured stream ' + streamname))\n    showuuidcommand = ('%s --show-alias n --show-uuid y show attributes -r %s -w %s' % (self.scmcommand, self.repo, streamname))\n    output = shell.getoutput(showuuidcommand)\n    splittedfirstline = output[0].split(' ')\n    streamuuid = splittedfirstline[0].strip()[1:(- 1)]\n    return streamuuid\n", "label": "Correct"}
{"function": "\n\ndef collectstreamuuid(self, streamname):\n    if (not streamname):\n        return\n    shouter.shout(('Get UUID of configured stream ' + streamname))\n    showuuidcommand = ('%s --show-alias n --show-uuid y show attributes -r %s -w %s' % (self.scmcommand, self.repo, streamname))\n    output = shell.getoutput(output)\n    splittedfirstline = output[0].split(' ')\n    streamuuid = splittedfirstline[0].strip()[1:(- 1)]\n    return streamuuid\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef resource_uri(cls, obj=None):\n    object_id = 'id'\n    if (obj is not None):\n        object_id = obj.id\n    return ('api_events', [object_id])\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef resource_uri(cls, obj=None):\n    object_id = 'id'\n    if (obj is not None):\n        object_id = object_id.id\n    return ('api_events', [object_id])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, text):\n    if (len(text) >= 10000):\n        text = (text[:9995] + '\\n...')\n    self.text = text\n    self.recipient = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, text):\n    if (len(text) >= 10000):\n        text = (text[:9995] + '\\n...')\n    self.text = text\n    text.recipient = None\n", "label": "Variable misuse"}
{"function": "\n\ndef info(self, msg_format, *values):\n    'For progress and other informative messages.'\n    if (len(values) > 0):\n        msg_format = (msg_format % values)\n    print(msg_format)\n", "label": "Correct"}
{"function": "\n\ndef info(self, msg_format, *values):\n    'For progress and other informative messages.'\n    if (len(values) > 0):\n        msg_format = (msg_format % msg_format)\n    print(msg_format)\n", "label": "Variable misuse"}
{"function": "\n\ndef freeze(self, skipSet=None):\n    assert (len(self()) in self.allowedSize)\n    return StringStream.freeze(self, skipSet=skipSet)\n", "label": "Correct"}
{"function": "\n\ndef freeze(self, skipSet=None):\n    assert (len(self()) in self.allowedSize)\n    return StringStream.freeze(skipSet, skipSet=skipSet)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_result(self, vlan_range_len):\n    self.intersect()\n    if (vlan_range_len > 1):\n        return self.get_final_available_vlan_range(vlan_range_len)\n    else:\n        return self.get_final_available_vlan()\n", "label": "Correct"}
{"function": "\n\ndef get_result(self, vlan_range_len):\n    vlan_range_len.intersect()\n    if (vlan_range_len > 1):\n        return self.get_final_available_vlan_range(vlan_range_len)\n    else:\n        return self.get_final_available_vlan()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, collector, callback=None, *args, **kw):\n    '\\n        Create a pager with a Reference to a remote collector and\\n        an optional callable to invoke upon completion.\\n        '\n    if callable(callback):\n        self.callback = callback\n        self.callbackArgs = args\n        self.callbackKeyword = kw\n    else:\n        self.callback = None\n    self._stillPaging = 1\n    self.collector = collector\n    collector.broker.registerPageProducer(self)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, collector, callback=None, *args, **kw):\n    '\\n        Create a pager with a Reference to a remote collector and\\n        an optional callable to invoke upon completion.\\n        '\n    if callable(callback):\n        self.callback = callback\n        self.callbackArgs = args\n        self.callbackKeyword = kw\n    else:\n        self.callback = None\n    self._stillPaging = 1\n    self.collector = collector\n    collector.broker.registerPageProducer(callback)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, consumer_key, consumer_secret):\n    self.name = name\n    self.type = 'twitter'\n    self.consumer_key = consumer_key\n    self.consumer_secret = consumer_secret\n    self.login_route = ('velruse.%s-login' % name)\n    self.callback_route = ('velruse.%s-callback' % name)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, consumer_key, consumer_secret):\n    self.name = name\n    self.type = 'twitter'\n    self.consumer_key = consumer_key\n    self.consumer_secret = consumer_key\n    self.login_route = ('velruse.%s-login' % name)\n    self.callback_route = ('velruse.%s-callback' % name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch(('%s.flavors.osclients.Clients' % CTX))\ndef test_cleanup(self, mock_clients):\n    real_context = {\n        'flavors': {\n            'flavor_name': {\n                'flavor_name': 'flavor_name',\n                'id': 'flavor_name',\n            },\n        },\n        'admin': {\n            'credential': mock.MagicMock(),\n        },\n        'task': mock.MagicMock(),\n    }\n    flavors_ctx = flavors.FlavorsGenerator(real_context)\n    flavors_ctx.cleanup()\n    mock_clients.assert_called_with(real_context['admin']['credential'])\n    mock_flavors_delete = mock_clients().nova().flavors.delete\n    mock_flavors_delete.assert_called_with('flavor_name')\n", "label": "Correct"}
{"function": "\n\n@mock.patch(('%s.flavors.osclients.Clients' % CTX))\ndef test_cleanup(self, mock_clients):\n    real_context = {\n        'flavors': {\n            'flavor_name': {\n                'flavor_name': 'flavor_name',\n                'id': 'flavor_name',\n            },\n        },\n        'admin': {\n            'credential': mock.MagicMock(),\n        },\n        'task': mock.MagicMock(),\n    }\n    flavors_ctx = flavors.FlavorsGenerator(real_context)\n    flavors_ctx.cleanup()\n    mock_clients.assert_called_with(self['admin']['credential'])\n    mock_flavors_delete = mock_clients().nova().flavors.delete\n    mock_flavors_delete.assert_called_with('flavor_name')\n", "label": "Variable misuse"}
{"function": "\n\ndef get_show(self, imdb, tvdb, tvshowtitle, year):\n    try:\n        query = self.search_link\n        post = {\n            'searchquery': tvshowtitle,\n            'searchin': '2',\n        }\n        result = ''\n        links = [self.link_1, self.link_3]\n        for base_link in links:\n            result = client.source(urlparse.urljoin(base_link, query), post=post, headers=self.headers)\n            if ('widget search-page' in str(result)):\n                break\n        result = client.parseDOM(result, 'div', attrs={\n            'class': 'widget search-page',\n        })[0]\n        result = client.parseDOM(result, 'td')\n        tvshowtitle = cleantitle.tv(tvshowtitle)\n        years = [('(%s)' % str(year)), ('(%s)' % str((int(year) + 1))), ('(%s)' % str((int(year) - 1)))]\n        result = [(client.parseDOM(i, 'a', ret='href')[(- 1)], client.parseDOM(i, 'a')[(- 1)]) for i in result]\n        result = [i for i in result if (tvshowtitle == cleantitle.tv(i[1]))]\n        result = [i[0] for i in result if any(((x in i[1]) for x in years))][0]\n        url = client.replaceHTMLCodes(result)\n        try:\n            url = urlparse.parse_qs(urlparse.urlparse(url).query)['u'][0]\n        except:\n            pass\n        url = urlparse.urlparse(url).path\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Correct"}
{"function": "\n\ndef get_show(self, imdb, tvdb, tvshowtitle, year):\n    try:\n        query = self.search_link\n        post = {\n            'searchquery': tvshowtitle,\n            'searchin': '2',\n        }\n        result = ''\n        links = [self.link_1, self.link_3]\n        for base_link in links:\n            result = client.source(urlparse.urljoin(base_link, query), post=post, headers=self.headers)\n            if ('widget search-page' in str(result)):\n                break\n        result = client.parseDOM(result, 'div', attrs={\n            'class': 'widget search-page',\n        })[0]\n        result = client.parseDOM(result, 'td')\n        tvshowtitle = cleantitle.tv(tvshowtitle)\n        years = [('(%s)' % str(year)), ('(%s)' % str((int(year) + 1))), ('(%s)' % str((int(year) - 1)))]\n        result = [(client.parseDOM(i, 'a', ret='href')[(- 1)], client.parseDOM(i, 'a')[(- 1)]) for i in result]\n        result = [i for i in tvdb if (tvshowtitle == cleantitle.tv(i[1]))]\n        result = [i[0] for i in result if any(((x in i[1]) for x in years))][0]\n        url = client.replaceHTMLCodes(result)\n        try:\n            url = urlparse.parse_qs(urlparse.urlparse(url).query)['u'][0]\n        except:\n            pass\n        url = urlparse.urlparse(url).path\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_vms(self):\n    '\\n        Returns a generator over all VMs known to this vCenter host.\\n        '\n    for folder in self.get_first_level_of_vm_folders():\n        for vm in get_all_vms_in_folder(folder):\n            (yield vm)\n", "label": "Correct"}
{"function": "\n\ndef get_all_vms(self):\n    '\\n        Returns a generator over all VMs known to this vCenter host.\\n        '\n    for folder in self.get_first_level_of_vm_folders():\n        for vm in get_all_vms_in_folder(folder):\n            (yield self)\n", "label": "Variable misuse"}
{"function": "\n\ndef wait_for_responses(self, client):\n    'Waits for all responses to come back and resolves the\\n        eventual results.\\n        '\n    assert_open(self)\n    if self.has_pending_requests:\n        raise RuntimeError('Cannot wait for responses if there are pending requests outstanding.  You need to wait for pending requests to be sent first.')\n    pending = self.pending_responses\n    self.pending_responses = []\n    for (command_name, promise) in pending:\n        value = client.parse_response(self.connection, command_name)\n        promise.resolve(value)\n", "label": "Correct"}
{"function": "\n\ndef wait_for_responses(self, client):\n    'Waits for all responses to come back and resolves the\\n        eventual results.\\n        '\n    assert_open(self)\n    if self.has_pending_requests:\n        raise RuntimeError('Cannot wait for responses if there are pending requests outstanding.  You need to wait for pending requests to be sent first.')\n    pending = self.pending_responses\n    self.pending_responses = []\n    for (command_name, promise) in promise:\n        value = client.parse_response(self.connection, command_name)\n        promise.resolve(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_write_job3():\n    conf = test_config()\n    loop = pyuv.Loop.default_loop()\n    with KeyManager(loop, conf) as h:\n        h.create_key({\n            'write': ['test.test', 'test1.test'],\n        }, key='test1')\n        key = Key.load(h.get_key('test1'))\n        assert (key.can_read('test') == False)\n        assert (key.can_read('test.test') == True)\n        assert (key.can_read('test1') == False)\n        assert (key.can_read('test1.test') == True)\n        assert (key.can_write('test') == False)\n        assert (key.can_write('test.test') == True)\n        assert (key.can_write('test1') == False)\n        assert (key.can_write('test1.test') == True)\n        assert (key.can_manage('test') == False)\n        assert (key.can_manage('test.test') == False)\n        assert (key.can_manage('test1') == False)\n        assert (key.can_manage('test1.test') == False)\n", "label": "Correct"}
{"function": "\n\ndef test_write_job3():\n    conf = test_config()\n    loop = pyuv.Loop.default_loop()\n    with KeyManager(loop, conf) as h:\n        h.create_key({\n            'write': ['test.test', 'test1.test'],\n        }, key='test1')\n        key = Key.load(h.get_key('test1'))\n        assert (key.can_read('test') == False)\n        assert (key.can_read('test.test') == True)\n        assert (key.can_read('test1') == False)\n        assert (key.can_read('test1.test') == True)\n        assert (key.can_write('test') == False)\n        assert (conf.can_write('test.test') == True)\n        assert (key.can_write('test1') == False)\n        assert (key.can_write('test1.test') == True)\n        assert (key.can_manage('test') == False)\n        assert (key.can_manage('test.test') == False)\n        assert (key.can_manage('test1') == False)\n        assert (key.can_manage('test1.test') == False)\n", "label": "Variable misuse"}
{"function": "\n\ndef __update_copyright(self):\n    'Finds the copyright text and replaces it.'\n    region = self.__find_copyright()\n    self.__replace_copyright(region)\n", "label": "Correct"}
{"function": "\n\ndef __update_copyright(self):\n    'Finds the copyright text and replaces it.'\n    region = self.__find_copyright()\n    region.__replace_copyright(region)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, idx):\n    self.idx = _uidx()\n    self.isBatch = False\n    self.isSeq = True\n    if isinstance(idx, BaseArray):\n        arr = ct.c_void_p(0)\n        if (idx.type() == Dtype.b8.value):\n            safe_call(backend.get().af_where(ct.pointer(arr), idx.arr))\n        else:\n            safe_call(backend.get().af_retain_array(ct.pointer(arr), idx.arr))\n        self.idx.arr = arr\n        self.isSeq = False\n    elif isinstance(idx, ParallelRange):\n        self.idx.seq = idx\n        self.isBatch = True\n    else:\n        self.idx.seq = Seq(idx)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, idx):\n    self.idx = _uidx()\n    self.isBatch = False\n    self.isSeq = True\n    if isinstance(idx, BaseArray):\n        arr = ct.c_void_p(0)\n        if (idx.type() == Dtype.b8.value):\n            safe_call(backend.get().af_where(ct.pointer(arr), idx.arr))\n        else:\n            safe_call(backend.get().af_retain_array(ct.pointer(idx), idx.arr))\n        self.idx.arr = arr\n        self.isSeq = False\n    elif isinstance(idx, ParallelRange):\n        self.idx.seq = idx\n        self.isBatch = True\n    else:\n        self.idx.seq = Seq(idx)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/armor/component/shared_deflector_shield_generator_energy_ray.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/armor/component/shared_deflector_shield_generator_energy_ray.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef leq(levels, int_time=1.0):\n    '\\n    Equivalent level :math:`L_{eq}`.\\n    \\n    :param levels: Levels as function of time.\\n    :param int_time: Integration time. Default value is 1.0 second.\\n    :returns: Equivalent level L_{eq}.\\n    \\n    Sum of levels in dB.\\n    '\n    levels = np.asarray(levels)\n    time = (levels.size * int_time)\n    return _leq(levels, time)\n", "label": "Correct"}
{"function": "\n\ndef leq(levels, int_time=1.0):\n    '\\n    Equivalent level :math:`L_{eq}`.\\n    \\n    :param levels: Levels as function of time.\\n    :param int_time: Integration time. Default value is 1.0 second.\\n    :returns: Equivalent level L_{eq}.\\n    \\n    Sum of levels in dB.\\n    '\n    levels = np.asarray(levels)\n    time = (int_time.size * int_time)\n    return _leq(levels, time)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_next_instruction(self):\n    dis = self.disassemble(address=self.program_counter()[1], count=1)\n    return dis.partition('\\n')[0].strip()\n", "label": "Correct"}
{"function": "\n\ndef get_next_instruction(self):\n    dis = self.disassemble(address=self.program_counter()[1], count=1)\n    return self.partition('\\n')[0].strip()\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/munition/shared_detonator_thermal_imperial_issue.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    kernel.template = 'object/draft_schematic/munition/shared_detonator_thermal_imperial_issue.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef get_dates(self, resource):\n    '\\n        Retrieve dates from mercurial\\n        '\n    try:\n        commits = subprocess.check_output(['hg', 'log', '--template={date|isodatesec}\\n', resource.path]).split('\\n')\n        commits = commits[:(- 1)]\n    except subprocess.CalledProcessError:\n        self.logger.warning(('Unable to get mercurial history for [%s]' % resource))\n        commits = None\n    if (not commits):\n        self.logger.warning(('No mercurial history for [%s]' % resource))\n        return (None, None)\n    created = parse(commits[(- 1)].strip())\n    modified = parse(commits[0].strip())\n    return (created, modified)\n", "label": "Correct"}
{"function": "\n\ndef get_dates(self, resource):\n    '\\n        Retrieve dates from mercurial\\n        '\n    try:\n        commits = subprocess.check_output(['hg', 'log', '--template={date|isodatesec}\\n', resource.path]).split('\\n')\n        commits = commits[:(- 1)]\n    except subprocess.CalledProcessError:\n        self.logger.warning(('Unable to get mercurial history for [%s]' % resource))\n        commits = None\n    if (not resource):\n        self.logger.warning(('No mercurial history for [%s]' % resource))\n        return (None, None)\n    created = parse(commits[(- 1)].strip())\n    modified = parse(commits[0].strip())\n    return (created, modified)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_tx_out_bitcoin_address(self):\n    coinbase_bytes = h2b('04ed66471b02c301')\n    tx = Tx.coinbase_tx(COINBASE_PUB_KEY_FROM_80971, int((50 * 100000000.0)), COINBASE_BYTES_FROM_80971)\n    self.assertEqual(tx.txs_out[0].bitcoin_address(), '1DmapcnrJNGeJB13fv9ngRFX1iRvR4zamn')\n", "label": "Correct"}
{"function": "\n\ndef test_tx_out_bitcoin_address(self):\n    coinbase_bytes = h2b('04ed66471b02c301')\n    tx = Tx.coinbase_tx(COINBASE_PUB_KEY_FROM_80971, int((50 * 100000000.0)), COINBASE_BYTES_FROM_80971)\n    coinbase_bytes.assertEqual(tx.txs_out[0].bitcoin_address(), '1DmapcnrJNGeJB13fv9ngRFX1iRvR4zamn')\n", "label": "Variable misuse"}
{"function": "\n\ndef alert_smtp(alert, metric):\n    if ('@' in alert[1]):\n        sender = settings.ALERT_SENDER\n        recipient = alert[1]\n    else:\n        sender = settings.SMTP_OPTS['sender']\n        recipients = settings.SMTP_OPTS['recipients'][alert[0]]\n    if (type(recipients) is str):\n        recipients = [recipients]\n    for recipient in recipients:\n        msg = MIMEMultipart('alternative')\n        msg['Subject'] = ('[skyline alert] ' + metric[1])\n        msg['From'] = sender\n        msg['To'] = recipient\n        link = (settings.GRAPH_URL % metric[1])\n        body = ('Anomalous value: %s <br> Next alert in: %s seconds <a href=\"%s\"><img src=\"%s\"/></a>' % (metric[0], alert[2], link, link))\n        msg.attach(MIMEText(body, 'html'))\n        s = SMTP('127.0.0.1')\n        s.sendmail(sender, recipient, msg.as_string())\n        s.quit()\n", "label": "Correct"}
{"function": "\n\ndef alert_smtp(alert, metric):\n    if ('@' in alert[1]):\n        sender = settings.ALERT_SENDER\n        recipient = alert[1]\n    else:\n        sender = settings.SMTP_OPTS['sender']\n        recipients = settings.SMTP_OPTS['recipients'][alert[0]]\n    if (type(recipients) is str):\n        recipients = [recipients]\n    for recipient in recipients:\n        msg = MIMEMultipart('alternative')\n        msg['Subject'] = ('[skyline alert] ' + metric[1])\n        recipients['From'] = sender\n        msg['To'] = recipient\n        link = (settings.GRAPH_URL % metric[1])\n        body = ('Anomalous value: %s <br> Next alert in: %s seconds <a href=\"%s\"><img src=\"%s\"/></a>' % (metric[0], alert[2], link, link))\n        msg.attach(MIMEText(body, 'html'))\n        s = SMTP('127.0.0.1')\n        s.sendmail(sender, recipient, msg.as_string())\n        s.quit()\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_key(self, key):\n    self.server.request('delete', ('/keys/%s' % key))\n", "label": "Correct"}
{"function": "\n\ndef delete_key(self, key):\n    self.server.request('delete', ('/keys/%s' % self))\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_placeholders(self, n_features, n_classes):\n    ' Create the TensorFlow placeholders for the model.\\n        :param n_features: number of features of the first layer\\n        :param n_classes: number of classes\\n        :return: self\\n        '\n    self.keep_prob = tf.placeholder('float')\n    self.hrand = [tf.placeholder('float', [None, self.layers[(l + 1)]]) for l in range((self.n_layers - 1))]\n    self.vrand = [tf.placeholder('float', [None, self.layers[l]]) for l in range((self.n_layers - 1))]\n    self.x = tf.placeholder('float', [None, n_features])\n    self.y_ = tf.placeholder('float', [None, n_classes])\n", "label": "Correct"}
{"function": "\n\ndef _create_placeholders(self, n_features, n_classes):\n    ' Create the TensorFlow placeholders for the model.\\n        :param n_features: number of features of the first layer\\n        :param n_classes: number of classes\\n        :return: self\\n        '\n    self.keep_prob = tf.placeholder('float')\n    self.hrand = [tf.placeholder('float', [None, self.layers[(l + 1)]]) for l in range((self.n_layers - 1))]\n    self.vrand = [tf.placeholder('float', [None, self.layers[l]]) for l in range((self.n_layers - 1))]\n    n_classes.x = tf.placeholder('float', [None, n_features])\n    self.y_ = tf.placeholder('float', [None, n_classes])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name_suggestion):\n    self.name_suggestion = name_suggestion\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name_suggestion):\n    self.name_suggestion = self\n", "label": "Variable misuse"}
{"function": "\n\ndef render_datalist(self, list_id):\n    return ''.join([('<datalist id=\"%s\">' % list_id), ''.join([('<option>%s</option>' % color) for color in self.colors]), '</datalist>'])\n", "label": "Correct"}
{"function": "\n\ndef render_datalist(self, list_id):\n    return ''.join([('<datalist id=\"%s\">' % list_id), ''.join([('<option>%s</option>' % color) for color in list_id.colors]), '</datalist>'])\n", "label": "Variable misuse"}
{"function": "\n\ndef _do_remove(self, section, option):\n    if (not self.config.has_option(section, option)):\n        raise AdminCommandError(_(\"Option '%(option)s' doesn't exist in section '%(section)s'\", option=option, section=section))\n    self.config.remove(section, option)\n    self.config.save()\n    if ((section == 'inherit') and (option == 'file')):\n        self.config.parse_if_needed(force=True)\n", "label": "Correct"}
{"function": "\n\ndef _do_remove(self, section, option):\n    if (not self.config.has_option(section, option)):\n        raise AdminCommandError(_(\"Option '%(option)s' doesn't exist in section '%(section)s'\", option=self, section=section))\n    self.config.remove(section, option)\n    self.config.save()\n    if ((section == 'inherit') and (option == 'file')):\n        self.config.parse_if_needed(force=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef _unit_file(self, name):\n    for extension in ['service', 'yaml']:\n        file_path = '{0}.{1}'.format(name, extension)\n        if path.exists(file_path):\n            with open(file_path) as handle:\n                if (extension == 'service'):\n                    return handle.read()\n                data = yaml.load(handle)\n                if (self._global and ('global' in data)):\n                    return data['global']\n                if (self._name in data):\n                    return data[self._name]\n                raise ValueError('No unit found for {0}'.format(self._name))\n    raise ValueError('No unit file: '.format(name))\n", "label": "Correct"}
{"function": "\n\ndef _unit_file(self, name):\n    for extension in ['service', 'yaml']:\n        file_path = '{0}.{1}'.format(name, extension)\n        if path.exists(file_path):\n            with open(file_path) as handle:\n                if (extension == 'service'):\n                    return handle.read()\n                data = yaml.load(handle)\n                if (self._global and ('global' in data)):\n                    return data['global']\n                if (data._name in data):\n                    return data[self._name]\n                raise ValueError('No unit found for {0}'.format(self._name))\n    raise ValueError('No unit file: '.format(name))\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_flavor(self, description=None):\n    flavor = {\n        'flavor': {\n            'name': 'GOLD',\n            'service_type': constants.DUMMY,\n            'description': (description or 'the best flavor'),\n            'enabled': True,\n        },\n    }\n    return (self.plugin.create_flavor(self.ctx, flavor), flavor)\n", "label": "Correct"}
{"function": "\n\ndef _create_flavor(self, description=None):\n    flavor = {\n        'flavor': {\n            'name': 'GOLD',\n            'service_type': constants.DUMMY,\n            'description': (description or 'the best flavor'),\n            'enabled': True,\n        },\n    }\n    return (description.plugin.create_flavor(self.ctx, flavor), flavor)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_logout(self):\n    'Tests when logging out with and without continue URL.'\n    host = 'foo.com:1234'\n    path_info = '/_ah/login'\n    cookie_dict = {\n        'dev_appserver_login': ('%s:False:%s' % (EMAIL, USER_ID)),\n    }\n    action = 'Logout'\n    set_email = ''\n    set_admin = False\n    continue_url = ''\n    expected_set = login._clear_user_info_cookie().strip()\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(('http://%s%s' % (host, path_info)), location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n    continue_url = 'http://foo.com/blah'\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(continue_url, location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n", "label": "Correct"}
{"function": "\n\ndef test_logout(self):\n    'Tests when logging out with and without continue URL.'\n    host = 'foo.com:1234'\n    path_info = '/_ah/login'\n    cookie_dict = {\n        'dev_appserver_login': ('%s:False:%s' % (EMAIL, USER_ID)),\n    }\n    action = 'Logout'\n    set_email = ''\n    set_admin = False\n    continue_url = ''\n    expected_set = login._clear_user_info_cookie().strip()\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(('http://%s%s' % (host, path_info)), location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n    continue_url = 'http://foo.com/blah'\n    (status, location, set_cookie, _) = expected_set._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(continue_url, location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n", "label": "Variable misuse"}
{"function": "\n\ndef test04c__getitem__(self):\n    'Checking cols.__getitem__() with subgroups with a range index with\\n        step.'\n    tbl = self.h5file.create_table('/', 'test', self._TestTDescr, title=self._getMethodName())\n    tbl.append(self._testAData)\n    if self.reopen:\n        self._reopen()\n        tbl = self.h5file.root.test\n    nrarr = numpy.array(testABuffer, dtype=tbl.description._v_nested_descr)\n    tblcols = tbl.cols._f_col('Info')[0::2]\n    nrarrcols = nrarr['Info'][0::2]\n    if common.verbose:\n        print('Read cols:', tblcols)\n        print('Should look like:', nrarrcols)\n    self.assertTrue(common.areArraysEqual(nrarrcols, tblcols), \"Original array are retrieved doesn't match.\")\n", "label": "Correct"}
{"function": "\n\ndef test04c__getitem__(self):\n    'Checking cols.__getitem__() with subgroups with a range index with\\n        step.'\n    tbl = self.h5file.create_table('/', 'test', self._TestTDescr, title=self._getMethodName())\n    tbl.append(tbl._testAData)\n    if self.reopen:\n        self._reopen()\n        tbl = self.h5file.root.test\n    nrarr = numpy.array(testABuffer, dtype=tbl.description._v_nested_descr)\n    tblcols = tbl.cols._f_col('Info')[0::2]\n    nrarrcols = nrarr['Info'][0::2]\n    if common.verbose:\n        print('Read cols:', tblcols)\n        print('Should look like:', nrarrcols)\n    self.assertTrue(common.areArraysEqual(nrarrcols, tblcols), \"Original array are retrieved doesn't match.\")\n", "label": "Variable misuse"}
{"function": "\n\ndef test_key_has_correct_repr(self):\n    '\\n        Calling repr on a Key instance returns the proper string.\\n        '\n    key = pem.Key(b'test')\n    assert ('<Key({0})>'.format(TEST_DIGEST) == repr(key))\n", "label": "Correct"}
{"function": "\n\ndef test_key_has_correct_repr(self):\n    '\\n        Calling repr on a Key instance returns the proper string.\\n        '\n    key = pem.Key(b'test')\n    assert ('<Key({0})>'.format(TEST_DIGEST) == repr(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef calcScale(self, testCount):\n    import math\n    scale = int((self.size / (math.sqrt(testCount) + 1)))\n    return scale\n", "label": "Correct"}
{"function": "\n\ndef calcScale(self, testCount):\n    import math\n    scale = int((self.size / (math.sqrt(scale) + 1)))\n    return scale\n", "label": "Variable misuse"}
{"function": "\n\ndef get_repository_info(self):\n    '\\n        Find out information about the current Bazaar branch (if any) and\\n        return it.\\n        '\n    if (not check_install(['bzr', 'help'])):\n        logging.debug('Unable to execute \"bzr help\": skipping Bazaar')\n        return None\n    bzr_info = execute(['bzr', 'info'], ignore_errors=True)\n    if ('ERROR: Not a branch:' in bzr_info):\n        repository_info = None\n    else:\n        branch_match = re.search(self.BRANCH_REGEX, bzr_info, re.MULTILINE)\n        path = branch_match.group('branch_path')\n        if (path == '.'):\n            path = os.getcwd()\n        repository_info = RepositoryInfo(path=path, base_path='/', supports_parent_diffs=True)\n    return repository_info\n", "label": "Correct"}
{"function": "\n\ndef get_repository_info(self):\n    '\\n        Find out information about the current Bazaar branch (if any) and\\n        return it.\\n        '\n    if (not check_install(['bzr', 'help'])):\n        logging.debug('Unable to execute \"bzr help\": skipping Bazaar')\n        return None\n    bzr_info = execute(['bzr', 'info'], ignore_errors=True)\n    if ('ERROR: Not a branch:' in path):\n        repository_info = None\n    else:\n        branch_match = re.search(self.BRANCH_REGEX, bzr_info, re.MULTILINE)\n        path = branch_match.group('branch_path')\n        if (path == '.'):\n            path = os.getcwd()\n        repository_info = RepositoryInfo(path=path, base_path='/', supports_parent_diffs=True)\n    return repository_info\n", "label": "Variable misuse"}
{"function": "\n\ndef do_access_token_response(self, access_token, atinfo, state, refresh_token=None):\n    _tinfo = {\n        'access_token': access_token,\n        'expires_in': atinfo['exp'],\n        'token_type': 'bearer',\n        'state': state,\n    }\n    try:\n        _tinfo['scope'] = atinfo['scope']\n    except KeyError:\n        pass\n    if refresh_token:\n        _tinfo['refresh_token'] = refresh_token\n    return AccessTokenResponse(**by_schema(AccessTokenResponse, **_tinfo))\n", "label": "Correct"}
{"function": "\n\ndef do_access_token_response(self, access_token, atinfo, state, refresh_token=None):\n    _tinfo = {\n        'access_token': access_token,\n        'expires_in': atinfo['exp'],\n        'token_type': 'bearer',\n        'state': state,\n    }\n    try:\n        _tinfo['scope'] = atinfo['scope']\n    except KeyError:\n        pass\n    if refresh_token:\n        access_token['refresh_token'] = refresh_token\n    return AccessTokenResponse(**by_schema(AccessTokenResponse, **_tinfo))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_set_messages_success(self):\n    author = {\n        'name': 'John Doe',\n        'slug': 'success-msg',\n    }\n    add_url = reverse('add_success_msg')\n    req = self.client.post(add_url, author)\n    self.assertIn((ContactFormViewWithMsg.success_message % author), req.cookies['messages'].value)\n", "label": "Correct"}
{"function": "\n\ndef test_set_messages_success(self):\n    author = {\n        'name': 'John Doe',\n        'slug': 'success-msg',\n    }\n    add_url = reverse('add_success_msg')\n    req = self.client.post(req, author)\n    self.assertIn((ContactFormViewWithMsg.success_message % author), req.cookies['messages'].value)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, question, docs):\n    super(Extractor, self).__init__(question, docs, tag=TAG)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, question, docs):\n    super(Extractor, self).__init__(question, self, tag=TAG)\n", "label": "Variable misuse"}
{"function": "\n\ndef expect(self, method=None, uri=None, params={\n    \n}):\n    if method:\n        self.assertEqual(method, self.executor.request.method)\n    if uri:\n        self.assertEqual(self.executor.request.uri, ('https://api-ssl.bitly.com/v3' + uri))\n    if params:\n        params.update({\n            'access_token': 'my-access-token',\n        })\n        self.assertEqual(self.executor.request.params, params)\n", "label": "Correct"}
{"function": "\n\ndef expect(self, method=None, uri=None, params={\n    \n}):\n    if method:\n        self.assertEqual(method, self.executor.request.method)\n    if uri:\n        self.assertEqual(uri.executor.request.uri, ('https://api-ssl.bitly.com/v3' + uri))\n    if params:\n        params.update({\n            'access_token': 'my-access-token',\n        })\n        self.assertEqual(self.executor.request.params, params)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_handle_error_401_sends_challege_default_realm(self):\n    api = restplus.Api(self.app, serve_challenge_on_401=True)\n    exception = HTTPException()\n    exception.code = 401\n    exception.data = {\n        'foo': 'bar',\n    }\n    with self.app.test_request_context('/foo'):\n        resp = api.handle_error(exception)\n        self.assertEqual(resp.status_code, 401)\n        self.assertEqual(resp.headers['WWW-Authenticate'], 'Basic realm=\"flask-restplus\"')\n", "label": "Correct"}
{"function": "\n\ndef test_handle_error_401_sends_challege_default_realm(self):\n    api = restplus.Api(self.app, serve_challenge_on_401=True)\n    exception = HTTPException()\n    exception.code = 401\n    exception.data = {\n        'foo': 'bar',\n    }\n    with self.app.test_request_context('/foo'):\n        resp = api.handle_error(exception)\n        exception.assertEqual(resp.status_code, 401)\n        self.assertEqual(resp.headers['WWW-Authenticate'], 'Basic realm=\"flask-restplus\"')\n", "label": "Variable misuse"}
{"function": "\n\ndef __add__(self, other):\n    if isinstance(other, BaseNull):\n        return other\n    return self.map((Q + _unwrap(other)))\n", "label": "Correct"}
{"function": "\n\ndef __add__(self, other):\n    if isinstance(other, BaseNull):\n        return other\n    return other.map((Q + _unwrap(other)))\n", "label": "Variable misuse"}
{"function": "\n\ndef next_hop(tokeniser):\n    value = tokeniser()\n    if (value.lower() == 'self'):\n        return (IPSelf(tokeniser.afi), NextHopSelf(tokeniser.afi))\n    else:\n        ip = IP.create(value)\n        if (ip.afi == AFI.ipv4):\n            return (ip, NextHop(ip.top()))\n        return (ip, None)\n", "label": "Correct"}
{"function": "\n\ndef next_hop(tokeniser):\n    value = value()\n    if (value.lower() == 'self'):\n        return (IPSelf(tokeniser.afi), NextHopSelf(tokeniser.afi))\n    else:\n        ip = IP.create(value)\n        if (ip.afi == AFI.ipv4):\n            return (ip, NextHop(ip.top()))\n        return (ip, None)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_is_variant(self):\n    expander = GvcfExpander()\n    self.assertTrue(expander.is_variant(json.loads(self.snp_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.snp_2)))\n    self.assertTrue(expander.is_variant(json.loads(self.insertion_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.deletion_1)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_a)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_b)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_c)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_d)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_ambiguous)))\n    self.assertFalse(expander.is_variant(json.loads(self.no_call_1)))\n", "label": "Correct"}
{"function": "\n\ndef test_is_variant(self):\n    expander = GvcfExpander()\n    self.assertTrue(expander.is_variant(json.loads(self.snp_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.snp_2)))\n    self.assertTrue(expander.is_variant(json.loads(self.insertion_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.deletion_1)))\n    self.assertFalse(self.is_variant(json.loads(self.ref_a)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_b)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_c)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_d)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_ambiguous)))\n    self.assertFalse(expander.is_variant(json.loads(self.no_call_1)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_coerce_on_select(nyc):\n    t = symbol('t', discover(nyc))\n    t = t[(((((((((t.pickup_latitude >= 40.477399) & (t.pickup_latitude <= 40.917577)) & (t.dropoff_latitude >= 40.477399)) & (t.dropoff_latitude <= 40.917577)) & (t.pickup_longitude >= (- 74.25909))) & (t.pickup_longitude <= (- 73.700272))) & (t.dropoff_longitude >= (- 74.25909))) & (t.dropoff_longitude <= (- 73.700272))) & (t.passenger_count < 6))]\n    t = transform(t, pass_count=(t.passenger_count + 1))\n    result = compute(t.pass_count.coerce('float64'), nyc, return_type='native')\n    s = odo(result, pd.Series)\n    expected = (compute(t, nyc, return_type=pd.DataFrame).passenger_count.astype('float64') + 1.0)\n    assert (list(s) == list(expected))\n", "label": "Correct"}
{"function": "\n\ndef test_coerce_on_select(nyc):\n    t = symbol('t', discover(result))\n    t = t[(((((((((t.pickup_latitude >= 40.477399) & (t.pickup_latitude <= 40.917577)) & (t.dropoff_latitude >= 40.477399)) & (t.dropoff_latitude <= 40.917577)) & (t.pickup_longitude >= (- 74.25909))) & (t.pickup_longitude <= (- 73.700272))) & (t.dropoff_longitude >= (- 74.25909))) & (t.dropoff_longitude <= (- 73.700272))) & (t.passenger_count < 6))]\n    t = transform(t, pass_count=(t.passenger_count + 1))\n    result = compute(t.pass_count.coerce('float64'), nyc, return_type='native')\n    s = odo(result, pd.Series)\n    expected = (compute(t, nyc, return_type=pd.DataFrame).passenger_count.astype('float64') + 1.0)\n    assert (list(s) == list(expected))\n", "label": "Variable misuse"}
{"function": "\n\ndef modify_updates(self, updates):\n    '\"\\n        Modifies the parameters before a learning update is applied. Behavior\\n        is defined by subclass\\'s implementation of _modify_updates and any\\n        ModelExtension\\'s implementation of post_modify_updates.\\n\\n        Parameters\\n        ----------\\n        updates : dict\\n            A dictionary mapping shared variables to symbolic values they\\n            will be updated to\\n\\n        Notes\\n        -----\\n        For example, if a given parameter is not meant to be learned, a\\n        subclass or extension\\n        should remove it from the dictionary. If a parameter has a restricted\\n        range, e.g.. if it is the precision of a normal distribution,\\n        a subclass or extension should clip its update to that range. If a\\n        parameter\\n        has any other special properties, its updates should be modified\\n        to respect that here, e.g. a matrix that must be orthogonal should\\n        have its update value modified to be orthogonal here.\\n\\n        This is the main mechanism used to make sure that generic training\\n        algorithms such as those found in pylearn2.training_algorithms\\n        respect the specific properties of the models passed to them.\\n        '\n    self._modify_updates(updates)\n    self._ensure_extensions()\n    for extension in self.extensions:\n        extension.post_modify_updates(updates, self)\n", "label": "Correct"}
{"function": "\n\ndef modify_updates(self, updates):\n    '\"\\n        Modifies the parameters before a learning update is applied. Behavior\\n        is defined by subclass\\'s implementation of _modify_updates and any\\n        ModelExtension\\'s implementation of post_modify_updates.\\n\\n        Parameters\\n        ----------\\n        updates : dict\\n            A dictionary mapping shared variables to symbolic values they\\n            will be updated to\\n\\n        Notes\\n        -----\\n        For example, if a given parameter is not meant to be learned, a\\n        subclass or extension\\n        should remove it from the dictionary. If a parameter has a restricted\\n        range, e.g.. if it is the precision of a normal distribution,\\n        a subclass or extension should clip its update to that range. If a\\n        parameter\\n        has any other special properties, its updates should be modified\\n        to respect that here, e.g. a matrix that must be orthogonal should\\n        have its update value modified to be orthogonal here.\\n\\n        This is the main mechanism used to make sure that generic training\\n        algorithms such as those found in pylearn2.training_algorithms\\n        respect the specific properties of the models passed to them.\\n        '\n    self._modify_updates(updates)\n    self._ensure_extensions()\n    for extension in self.extensions:\n        extension.post_modify_updates(updates, updates)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_flipped(self, x, y):\n    ' Sets the specified piece as flipped.\\n        '\n    self.pieces[(x + (y * self.width))].set_flipped()\n", "label": "Correct"}
{"function": "\n\ndef set_flipped(self, x, y):\n    ' Sets the specified piece as flipped.\\n        '\n    self.pieces[(y + (y * self.width))].set_flipped()\n", "label": "Variable misuse"}
{"function": "\n\ndef on_leave(self, details):\n    self.disconnect()\n", "label": "Correct"}
{"function": "\n\ndef on_leave(self, details):\n    details.disconnect()\n", "label": "Variable misuse"}
{"function": "\n\n@needs_mail\n@needs_link\ndef proxy(request, mail, link):\n    return link.get_target(mail)(request, mail.person, mail.job.group_object)\n", "label": "Correct"}
{"function": "\n\n@needs_mail\n@needs_link\ndef proxy(request, mail, link):\n    return link.get_target(mail)(link, mail.person, mail.job.group_object)\n", "label": "Variable misuse"}
{"function": "\n\ndef TestParallelModify(instances):\n    'PERFORMANCE: Parallel instance modify.\\n\\n  @type instances: list of L{qa_config._QaInstance}\\n  @param instances: list of instances to issue modify commands against\\n\\n  '\n    job_driver = _JobQueueDriver()\n    new_min_mem = qa_config.get(constants.BE_MAXMEM)\n    for instance in instances:\n        cmd = ['gnt-instance', 'modify', '--submit', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value']\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n    job_driver.WaitForCompletion()\n", "label": "Correct"}
{"function": "\n\ndef TestParallelModify(instances):\n    'PERFORMANCE: Parallel instance modify.\\n\\n  @type instances: list of L{qa_config._QaInstance}\\n  @param instances: list of instances to issue modify commands against\\n\\n  '\n    job_driver = _JobQueueDriver()\n    new_min_mem = qa_config.get(constants.BE_MAXMEM)\n    for instance in instances:\n        cmd = ['gnt-instance', 'modify', '--submit', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value']\n        cmd.append(instances.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n    job_driver.WaitForCompletion()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_dir(self, path, dest='', saltenv='base', gzip=None, cachedir=None):\n    '\\n        Get a directory recursively from the salt-master\\n        '\n    ret = []\n    path = self._check_proto(path).rstrip('/')\n    separated = path.rsplit('/', 1)\n    if (len(separated) != 2):\n        prefix = ''\n    else:\n        prefix = separated[0]\n    for fn_ in self.file_list(saltenv, prefix=path):\n        try:\n            if (fn_[len(path)] != '/'):\n                continue\n        except IndexError:\n            continue\n        minion_relpath = fn_[len(prefix):].lstrip('/')\n        ret.append(self.get_file(salt.utils.url.create(fn_), '{0}/{1}'.format(dest, minion_relpath), True, saltenv, gzip))\n    try:\n        for fn_ in self.file_list_emptydirs(saltenv, prefix=path):\n            try:\n                if (fn_[len(path)] != '/'):\n                    continue\n            except IndexError:\n                continue\n            minion_relpath = fn_[len(prefix):].lstrip('/')\n            minion_mkdir = '{0}/{1}'.format(dest, minion_relpath)\n            if (not os.path.isdir(minion_mkdir)):\n                os.makedirs(minion_mkdir)\n            ret.append(minion_mkdir)\n    except TypeError:\n        pass\n    ret.sort()\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef get_dir(self, path, dest='', saltenv='base', gzip=None, cachedir=None):\n    '\\n        Get a directory recursively from the salt-master\\n        '\n    ret = []\n    path = self._check_proto(path).rstrip('/')\n    separated = path.rsplit('/', 1)\n    if (len(separated) != 2):\n        prefix = ''\n    else:\n        prefix = separated[0]\n    for fn_ in self.file_list(saltenv, prefix=path):\n        try:\n            if (fn_[len(path)] != '/'):\n                continue\n        except IndexError:\n            continue\n        minion_relpath = fn_[len(prefix):].lstrip('/')\n        ret.append(self.get_file(salt.utils.url.create(fn_), '{0}/{1}'.format(dest, minion_relpath), True, saltenv, gzip))\n    try:\n        for fn_ in self.file_list_emptydirs(saltenv, prefix=path):\n            try:\n                if (fn_[len(path)] != '/'):\n                    continue\n            except IndexError:\n                continue\n            minion_relpath = fn_[len(prefix):].lstrip('/')\n            minion_mkdir = '{0}/{1}'.format(saltenv, minion_relpath)\n            if (not os.path.isdir(minion_mkdir)):\n                os.makedirs(minion_mkdir)\n            ret.append(minion_mkdir)\n    except TypeError:\n        pass\n    ret.sort()\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\n@require_creds(True)\n@rpcmethod(signature=[SUCCESS_TYPE, URN_TYPE, CREDENTIALS_TYPE], url_name='openflow_gapi')\ndef DeleteSliver(slice_urn, credentials, **kwargs):\n    logger.debug('Called DeleteSliver')\n    try:\n        return gapi.DeleteSliver(slice_urn, kwargs['request'].user)\n    except Slice.DoesNotExist:\n        no_such_slice(slice_urn)\n", "label": "Correct"}
{"function": "\n\n@require_creds(True)\n@rpcmethod(signature=[SUCCESS_TYPE, URN_TYPE, CREDENTIALS_TYPE], url_name='openflow_gapi')\ndef DeleteSliver(slice_urn, credentials, **kwargs):\n    logger.debug('Called DeleteSliver')\n    try:\n        return gapi.DeleteSliver(credentials, kwargs['request'].user)\n    except Slice.DoesNotExist:\n        no_such_slice(slice_urn)\n", "label": "Variable misuse"}
{"function": "\n\ndef _dependencies(self):\n    projects = []\n    for attr in ('install_requires', 'tests_require'):\n        requirements = (getattr(self.distribution, attr, None) or [])\n        for project in requirements:\n            if (not project):\n                continue\n            projects.append(pypi.just_name(project))\n    extras = (getattr(self.distribution, 'extras_require', None) or {\n        \n    })\n    for value in extras.values():\n        projects.extend(map(pypi.just_name, value))\n    return projects\n", "label": "Correct"}
{"function": "\n\ndef _dependencies(self):\n    projects = []\n    for attr in ('install_requires', 'tests_require'):\n        requirements = (getattr(self.distribution, attr, None) or [])\n        for project in projects:\n            if (not project):\n                continue\n            projects.append(pypi.just_name(project))\n    extras = (getattr(self.distribution, 'extras_require', None) or {\n        \n    })\n    for value in extras.values():\n        projects.extend(map(pypi.just_name, value))\n    return projects\n", "label": "Variable misuse"}
{"function": "\n\ndef identity_provider_create(request, idp_id, description=None, enabled=False, remote_ids=None):\n    manager = keystoneclient(request, admin=True).federation.identity_providers\n    try:\n        return manager.create(id=idp_id, description=description, enabled=enabled, remote_ids=remote_ids)\n    except keystone_exceptions.Conflict:\n        raise exceptions.Conflict()\n", "label": "Correct"}
{"function": "\n\ndef identity_provider_create(request, idp_id, description=None, enabled=False, remote_ids=None):\n    manager = keystoneclient(request, admin=True).federation.identity_providers\n    try:\n        return idp_id.create(id=idp_id, description=description, enabled=enabled, remote_ids=remote_ids)\n    except keystone_exceptions.Conflict:\n        raise exceptions.Conflict()\n", "label": "Variable misuse"}
{"function": "\n\ndef save_graph_db_refs(self, sourceDB=None, targetDB=None, edgeDB=None, simpleKeys=False, unpack_edge=None, edgeDictClass=None, graph=None, **kwargs):\n    'apply kwargs to reference DB objects for this graph'\n    if (sourceDB is not None):\n        self.sourceDB = sourceDB\n    else:\n        simpleKeys = True\n    if (targetDB is not None):\n        self.targetDB = targetDB\n    if (edgeDB is not None):\n        self.edgeDB = edgeDB\n    else:\n        self.pack_edge = self.unpack_edge = (lambda edge: edge)\n    if simpleKeys:\n        self.__class__ = self._IDGraphClass\n    if (unpack_edge is not None):\n        self.unpack_edge = unpack_edge\n    if (graph is not None):\n        self.graph = graph\n    if (edgeDictClass is not None):\n        self.edgeDictClass = edgeDictClass\n", "label": "Correct"}
{"function": "\n\ndef save_graph_db_refs(self, sourceDB=None, targetDB=None, edgeDB=None, simpleKeys=False, unpack_edge=None, edgeDictClass=None, graph=None, **kwargs):\n    'apply kwargs to reference DB objects for this graph'\n    if (sourceDB is not None):\n        self.sourceDB = sourceDB\n    else:\n        simpleKeys = True\n    if (targetDB is not None):\n        self.targetDB = targetDB\n    if (edgeDB is not None):\n        self.edgeDB = edgeDB\n    else:\n        self.pack_edge = self.unpack_edge = (lambda edge: edge)\n    if edgeDB:\n        self.__class__ = self._IDGraphClass\n    if (unpack_edge is not None):\n        self.unpack_edge = unpack_edge\n    if (graph is not None):\n        self.graph = graph\n    if (edgeDictClass is not None):\n        self.edgeDictClass = edgeDictClass\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, errmsg='You need override this method'):\n    super(NeedOverrideError, self).__init__(self, errmsg)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, errmsg='You need override this method'):\n    super(NeedOverrideError, errmsg).__init__(self, errmsg)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_past_datetime(self):\n    value = self.sd.past_datetime()\n    self.assertTrue(isinstance(value, datetime.datetime))\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=1440))))\n    value = self.sd.past_datetime(0, 10)\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=10))))\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime(100, 0)\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime((- 10), 10)\n", "label": "Correct"}
{"function": "\n\ndef test_past_datetime(self):\n    value = self.sd.past_datetime()\n    self.assertTrue(isinstance(value, datetime.datetime))\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=1440))))\n    value = self.sd.past_datetime(0, 10)\n    value.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=10))))\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime(100, 0)\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime((- 10), 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef play_rtmpdump_stream(player, url, params={\n    \n}):\n    cmdline = (\"rtmpdump -r '%s' \" % url)\n    for key in params.keys():\n        cmdline += (((key + ' ') + params[key]) if (params[key] != None) else ('' + ' '))\n    cmdline += (' -o - | %s -' % player)\n    print(cmdline)\n    os.system(cmdline)\n    return\n", "label": "Correct"}
{"function": "\n\ndef play_rtmpdump_stream(player, url, params={\n    \n}):\n    cmdline = (\"rtmpdump -r '%s' \" % params)\n    for key in params.keys():\n        cmdline += (((key + ' ') + params[key]) if (params[key] != None) else ('' + ' '))\n    cmdline += (' -o - | %s -' % player)\n    print(cmdline)\n    os.system(cmdline)\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef test_disable_logging(self):\n    NAME = 'name'\n    before = {\n        'logging': {\n            'logBucket': 'logs',\n            'logObjectPrefix': 'pfx',\n        },\n    }\n    bucket = self._makeOne(name=NAME, properties=before)\n    self.assertTrue((bucket.get_logging() is not None))\n    bucket.disable_logging()\n    self.assertTrue((bucket.get_logging() is None))\n", "label": "Correct"}
{"function": "\n\ndef test_disable_logging(self):\n    NAME = 'name'\n    before = {\n        'logging': {\n            'logBucket': 'logs',\n            'logObjectPrefix': 'pfx',\n        },\n    }\n    bucket = self._makeOne(name=NAME, properties=before)\n    self.assertTrue((self.get_logging() is not None))\n    bucket.disable_logging()\n    self.assertTrue((bucket.get_logging() is None))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_benchmark_variance_06(self):\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['Monthly'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.three_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['3-Month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.six_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['6-month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.year_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['year'])\n", "label": "Correct"}
{"function": "\n\ndef test_benchmark_variance_06(self):\n    np.testing.assert_almost_equal([self.benchmark_variance for x in self.metrics_06.month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['Monthly'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.three_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['3-Month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.six_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['6-month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.year_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['year'])\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef size(cls, val, str_cache, object_cache, traits_cache):\n    if (val in object_cache):\n        index = object_cache.index(val)\n        return AMF3Integer.size((index << 1))\n    else:\n        object_cache.append(val)\n        size = 0\n        traits = type(val)\n        if (traits in traits_cache):\n            index = traits_cache.index(traits)\n            size += AMF3Integer.size(((index << 2) | 1))\n        else:\n            header = 3\n            if traits.__dynamic__:\n                header |= (2 << 2)\n            if traits.__externalizable__:\n                header |= (1 << 2)\n            header |= (len(traits.__members__) << 4)\n            size += AMF3Integer.size(header)\n            if isinstance(val, AMF3Object):\n                size += U8.size\n            else:\n                size += AMF3String.size(traits.__name__, cache=str_cache)\n                traits_cache.append(traits)\n            for member in traits.__members__:\n                size += AMF3String.size(member, cache=str_cache)\n        for member in traits.__members__:\n            value = getattr(val, member)\n            size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n        if traits.__dynamic__:\n            if isinstance(val, AMF3Object):\n                iterator = val.items()\n            else:\n                iterator = val.__dict__.items()\n            for (key, value) in iterator:\n                if (key in traits.__members__):\n                    continue\n                size += AMF3String.size(key, cache=str_cache)\n                size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n            size += U8.size\n        return size\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef size(cls, val, str_cache, object_cache, traits_cache):\n    if (val in object_cache):\n        index = object_cache.index(val)\n        return AMF3Integer.size((index << 1))\n    else:\n        object_cache.append(val)\n        size = 0\n        traits = type(val)\n        if (traits in traits_cache):\n            index = traits_cache.index(traits)\n            size += AMF3Integer.size(((index << 2) | 1))\n        else:\n            header = 3\n            if traits.__dynamic__:\n                header |= (2 << 2)\n            if traits.__externalizable__:\n                header |= (1 << 2)\n            header |= (len(traits.__members__) << 4)\n            size += AMF3Integer.size(header)\n            if isinstance(val, AMF3Object):\n                size += U8.size\n            else:\n                size += AMF3String.size(traits.__name__, cache=str_cache)\n                traits_cache.append(traits)\n            for member in traits.__members__:\n                size += AMF3String.size(member, cache=str_cache)\n        for member in traits.__members__:\n            value = getattr(val, member)\n            size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n        if traits.__dynamic__:\n            if isinstance(val, AMF3Object):\n                iterator = val.items()\n            else:\n                iterator = val.__dict__.items()\n            for (key, value) in iterator:\n                if (key in traits.__members__):\n                    continue\n                size += AMF3String.size(key, cache=str_cache)\n                size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=cls)\n            size += U8.size\n        return size\n", "label": "Variable misuse"}
{"function": "\n\ndef all_job_data(jobs, job_type):\n    ' Return an iterator over all job data. Exclude config template dups. '\n    conf_tmpl_ids = []\n    for job in jobs:\n        for (jt, data) in job.iteritems():\n            if (jt == job_type):\n                if (data['config_template_id'] not in conf_tmpl_ids):\n                    conf_tmpl_ids.append(data['config_template_id'])\n                    (yield data)\n", "label": "Correct"}
{"function": "\n\ndef all_job_data(jobs, job_type):\n    ' Return an iterator over all job data. Exclude config template dups. '\n    conf_tmpl_ids = []\n    for job in conf_tmpl_ids:\n        for (jt, data) in job.iteritems():\n            if (jt == job_type):\n                if (data['config_template_id'] not in conf_tmpl_ids):\n                    conf_tmpl_ids.append(data['config_template_id'])\n                    (yield data)\n", "label": "Variable misuse"}
{"function": "\n\ndef take_action(self, parsed_args):\n    identity_client = self.app.client_manager.identity\n    consumer = utils.find_resource(identity_client.oauth1.consumers, parsed_args.consumer)\n    identity_client.oauth1.consumers.delete(consumer.id)\n", "label": "Correct"}
{"function": "\n\ndef take_action(self, parsed_args):\n    identity_client = self.app.client_manager.identity\n    consumer = utils.find_resource(identity_client.oauth1.consumers, identity_client.consumer)\n    identity_client.oauth1.consumers.delete(consumer.id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _download_pdf(self, url, base_path):\n    local_file_path = os.path.join(base_path, 'billing-temp-document.pdf')\n    response = requests.get(url, stream=True)\n    should_wipe_bad_headers = True\n    with open(local_file_path, 'wb') as out_file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                if should_wipe_bad_headers:\n                    pdf_header_pos = chunk.find('%PDF-')\n                    if (pdf_header_pos > 0):\n                        chunk = chunk[pdf_header_pos:]\n                    should_wipe_bad_headers = False\n                out_file.write(chunk)\n                out_file.flush()\n    return local_file_path\n", "label": "Correct"}
{"function": "\n\ndef _download_pdf(self, url, base_path):\n    local_file_path = os.path.join(base_path, 'billing-temp-document.pdf')\n    response = requests.get(url, stream=True)\n    should_wipe_bad_headers = True\n    with open(local_file_path, 'wb') as out_file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                if should_wipe_bad_headers:\n                    pdf_header_pos = chunk.find('%PDF-')\n                    if (pdf_header_pos > 0):\n                        chunk = chunk[pdf_header_pos:]\n                    should_wipe_bad_headers = False\n                out_file.write(chunk)\n                base_path.flush()\n    return local_file_path\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_type_negative(self):\n    sla1 = TestCriterion(0)\n\n    class AnotherTestCriterion(TestCriterion):\n        pass\n    sla2 = AnotherTestCriterion(0)\n    self.assertRaises(TypeError, sla1.validate_type, sla2)\n", "label": "Correct"}
{"function": "\n\ndef test_validate_type_negative(self):\n    sla1 = TestCriterion(0)\n\n    class AnotherTestCriterion(TestCriterion):\n        pass\n    sla2 = AnotherTestCriterion(0)\n    self.assertRaises(TypeError, sla1.validate_type, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_profile_topics_bookmarks(self):\n    \"\\n        profile user's topics with bookmarks\\n        \"\n    bookmark = CommentBookmark.objects.create(topic=self.topic, user=self.user)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:topics', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['topics']), [self.topic])\n    self.assertEqual(response.context['topics'][0].bookmark, bookmark)\n", "label": "Correct"}
{"function": "\n\ndef test_profile_topics_bookmarks(self):\n    \"\\n        profile user's topics with bookmarks\\n        \"\n    bookmark = CommentBookmark.objects.create(topic=self.topic, user=self.user)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:topics', kwargs={\n        'pk': self.user2.pk,\n        'slug': bookmark.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['topics']), [self.topic])\n    self.assertEqual(response.context['topics'][0].bookmark, bookmark)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_volume_create_properties(self):\n    arglist = ['--property', 'Alpha=a', '--property', 'Beta=b', '--size', str(self.new_volume.size), self.new_volume.name]\n    verifylist = [('property', {\n        'Alpha': 'a',\n        'Beta': 'b',\n    }), ('size', self.new_volume.size), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=None, project_id=None, availability_zone=None, metadata={\n        'Alpha': 'a',\n        'Beta': 'b',\n    }, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Correct"}
{"function": "\n\ndef test_volume_create_properties(self):\n    arglist = ['--property', 'Alpha=a', '--property', 'Beta=b', '--size', str(self.new_volume.size), self.new_volume.name]\n    verifylist = [('property', {\n        'Alpha': 'a',\n        'Beta': 'b',\n    }), ('size', self.new_volume.size), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=None, project_id=None, availability_zone=None, metadata={\n        'Alpha': 'a',\n        'Beta': 'b',\n    }, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, self)\n    self.assertEqual(self.datalist, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef init_relation(self, models, relation):\n    '\\n        Initialize the relation on a set of models.\\n\\n        :type models: list\\n        :type relation: str\\n        '\n    for model in models:\n        model.set_relation(relation, Result(None, self, model))\n    return models\n", "label": "Correct"}
{"function": "\n\ndef init_relation(self, models, relation):\n    '\\n        Initialize the relation on a set of models.\\n\\n        :type models: list\\n        :type relation: str\\n        '\n    for model in models:\n        models.set_relation(relation, Result(None, self, model))\n    return models\n", "label": "Variable misuse"}
{"function": "\n\ndef test_with_some_synonyms(self):\n    SynonymFactory(from_words='foo', to_words='bar')\n    SynonymFactory(from_words='baz', to_words='qux')\n    (_, body) = es_utils.es_get_synonym_filter('en-US')\n    expected = {\n        'type': 'synonym',\n        'synonyms': ['foo => bar', 'baz => qux'],\n    }\n    eq_(body, expected)\n", "label": "Correct"}
{"function": "\n\ndef test_with_some_synonyms(self):\n    SynonymFactory(from_words='foo', to_words='bar')\n    SynonymFactory(from_words='baz', to_words='qux')\n    (_, body) = es_utils.es_get_synonym_filter('en-US')\n    expected = {\n        'type': 'synonym',\n        'synonyms': ['foo => bar', 'baz => qux'],\n    }\n    eq_(expected, expected)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self):\n    f = self.output().open('w')\n    print('hello, world', file=f)\n    f.close()\n", "label": "Correct"}
{"function": "\n\ndef run(self):\n    f = self.output().open('w')\n    print('hello, world', file=f)\n    self.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, area, width=4, char=' '):\n    self.width = width\n    self.char = char\n    area.install(('NORMAL', '<Key-greater>', (lambda event: event.widget.shift_sel_right(self.width, self.char))), ('NORMAL', '<Key-less>', (lambda event: event.widget.shift_sel_left(self.width))))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, area, width=4, char=' '):\n    self.width = width\n    event.char = char\n    area.install(('NORMAL', '<Key-greater>', (lambda event: event.widget.shift_sel_right(self.width, self.char))), ('NORMAL', '<Key-less>', (lambda event: event.widget.shift_sel_left(self.width))))\n", "label": "Variable misuse"}
{"function": "\n\ndef build(self, skip_features=False, managed=False):\n    if hasattr(self.session._internal, 'namespace'):\n        namespace_instance = self.session._internal.namespace['instance']\n        if hasattr(namespace_instance, 'after_request'):\n            getattr(namespace_instance, 'after_request')(self, self.session)\n    if (self.namespace and (not skip_features)):\n        for feature in self.namespace['features']:\n            feature._handle_response(self)\n    if (not isinstance(self.result, UnformattedResponse)):\n        if self.function:\n            self.result = self.function['format'](self.result)\n        if isinstance(self.output_formatter, type):\n            self.output_formatter = self.output_formatter(sapi_request=self.sapi_request, callback=self.callback)\n        if isinstance(self.wrapper, type):\n            self.wrapper = self.wrapper(sapi_request=self.sapi_request)\n        wrapper_result = self.wrapper._build(errors=self.errors, result=self.result)\n        formatter_result = self.output_formatter.build(wrapper_result)\n    else:\n        self.mimetype = self.result.mimetype\n        formatter_result = self.result.content\n    result = {\n        'result': formatter_result,\n        'mimetype': self.mimetype,\n    }\n    if managed:\n        return result\n    else:\n        return self._build_response_obj(self.sapi_request, result)\n", "label": "Correct"}
{"function": "\n\ndef build(self, skip_features=False, managed=False):\n    if hasattr(self.session._internal, 'namespace'):\n        namespace_instance = self.session._internal.namespace['instance']\n        if hasattr(namespace_instance, 'after_request'):\n            getattr(namespace_instance, 'after_request')(self, self.session)\n    if (self.namespace and (not skip_features)):\n        for feature in self.namespace['features']:\n            feature._handle_response(self)\n    if (not isinstance(self.result, UnformattedResponse)):\n        if self.function:\n            self.result = self.function['format'](self.result)\n        if isinstance(self.output_formatter, type):\n            self.output_formatter = self.output_formatter(sapi_request=self.sapi_request, callback=self.callback)\n        if isinstance(self.wrapper, type):\n            self.wrapper = self.wrapper(sapi_request=self.sapi_request)\n        wrapper_result = self.wrapper._build(errors=formatter_result.errors, result=self.result)\n        formatter_result = self.output_formatter.build(wrapper_result)\n    else:\n        self.mimetype = self.result.mimetype\n        formatter_result = self.result.content\n    result = {\n        'result': formatter_result,\n        'mimetype': self.mimetype,\n    }\n    if managed:\n        return result\n    else:\n        return self._build_response_obj(self.sapi_request, result)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef validate(cls, level):\n    level = int(level)\n    if (level in (cls.NONE, cls.READ, cls.WRITE, cls.ADMIN, cls.SITE_ADMIN)):\n        return level\n    else:\n        raise ValueError(('Invalid AccessType: %d.' % level))\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef validate(cls, level):\n    level = int(level)\n    if (level in (cls.NONE, level.READ, cls.WRITE, cls.ADMIN, cls.SITE_ADMIN)):\n        return level\n    else:\n        raise ValueError(('Invalid AccessType: %d.' % level))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, lib, dtype, N, C, K, H, W, P, Q, pad_h, pad_w, relu, bsum):\n    (R, S) = (3, 3)\n    GC32 = _ceil_div(C, 32)\n    GC16 = _ceil_div((GC32 * 32), 16)\n    GK16 = _ceil_div(K, 16)\n    self.filter_func = _get_bprop_filter_trans_4x4_kernel\n    self.filter_size = (((dtype.itemsize * 1152) * K) * GC32)\n    self.filter_args = [(GK16, GC16, 1), (256, 1, 1), None, None, None, ((R * S) * K), (S * K), ((S * K) * 2), K, C, (K * 1152)]\n    super(BpropWinograd_4x4_3x3, self).__init__(lib, dtype, N, K, C, P, Q, H, W, (2 - pad_h), (2 - pad_w), relu, bsum)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, lib, dtype, N, C, K, H, W, P, Q, pad_h, pad_w, relu, bsum):\n    (R, S) = (3, 3)\n    GC32 = _ceil_div(C, 32)\n    GC16 = _ceil_div((GC32 * 32), 16)\n    GK16 = _ceil_div(K, 16)\n    self.filter_func = _get_bprop_filter_trans_4x4_kernel\n    self.filter_size = (((dtype.itemsize * 1152) * K) * GC32)\n    self.filter_args = [(GK16, GC16, 1), (256, 1, 1), None, None, None, ((R * S) * K), (S * K), ((S * K) * 2), K, C, (K * 1152)]\n    super(BpropWinograd_4x4_3x3, self).__init__(lib, dtype, N, relu, C, P, Q, H, W, (2 - pad_h), (2 - pad_w), relu, bsum)\n", "label": "Variable misuse"}
{"function": "\n\n@records.post(validators=record_validator, permission='post_record')\ndef post_record(request):\n    'Saves a single model record.\\n\\n    Posted record attributes will be matched against the related model\\n    definition.\\n\\n    '\n    if (request.headers.get('Validate-Only', 'false') == 'true'):\n        return\n    model_id = request.matchdict['model_id']\n    if request.credentials_id:\n        credentials_id = request.credentials_id\n    else:\n        credentials_id = Everyone\n    record_id = request.db.put_record(model_id, request.data_clean, [credentials_id])\n    request.notify('RecordCreated', model_id, record_id)\n    created = ('%s/models/%s/records/%s' % (request.application_url, model_id, record_id))\n    request.response.status = '201 Created'\n    request.response.headers['location'] = str(created)\n    return {\n        'id': record_id,\n    }\n", "label": "Correct"}
{"function": "\n\n@records.post(validators=record_validator, permission='post_record')\ndef post_record(request):\n    'Saves a single model record.\\n\\n    Posted record attributes will be matched against the related model\\n    definition.\\n\\n    '\n    if (request.headers.get('Validate-Only', 'false') == 'true'):\n        return\n    model_id = request.matchdict['model_id']\n    if request.credentials_id:\n        credentials_id = request.credentials_id\n    else:\n        credentials_id = Everyone\n    record_id = request.db.put_record(model_id, request.data_clean, [record_id])\n    request.notify('RecordCreated', model_id, record_id)\n    created = ('%s/models/%s/records/%s' % (request.application_url, model_id, record_id))\n    request.response.status = '201 Created'\n    request.response.headers['location'] = str(created)\n    return {\n        'id': record_id,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef on_files_selected(self, paths):\n    \" Handle the 'filesSelected' signal from the dialog.\\n\\n        \"\n    d = self.declaration\n    if (d is not None):\n        d.selected_paths = paths\n", "label": "Correct"}
{"function": "\n\ndef on_files_selected(self, paths):\n    \" Handle the 'filesSelected' signal from the dialog.\\n\\n        \"\n    d = self.declaration\n    if (d is not None):\n        d.selected_paths = self\n", "label": "Variable misuse"}
{"function": "\n\ndef _dispatch(self, inst, kws):\n    assert (self.current_block is not None)\n    fname = ('op_%s' % inst.opname.replace('+', '_'))\n    try:\n        fn = getattr(self, fname)\n    except AttributeError:\n        raise NotImplementedError(inst)\n    else:\n        try:\n            return fn(inst, **kws)\n        except errors.NotDefinedError as e:\n            if (e.loc is None):\n                e.loc = self.loc\n            raise e\n", "label": "Correct"}
{"function": "\n\ndef _dispatch(self, inst, kws):\n    assert (self.current_block is not None)\n    fname = ('op_%s' % fn.opname.replace('+', '_'))\n    try:\n        fn = getattr(self, fname)\n    except AttributeError:\n        raise NotImplementedError(inst)\n    else:\n        try:\n            return fn(inst, **kws)\n        except errors.NotDefinedError as e:\n            if (e.loc is None):\n                e.loc = self.loc\n            raise e\n", "label": "Variable misuse"}
{"function": "\n\ndef set_context(self, serializer):\n    '\\n        This hook is called by the serializer instance,\\n        prior to the validation call being made.\\n        '\n    self.instance = getattr(serializer, 'instance', None)\n", "label": "Correct"}
{"function": "\n\ndef set_context(self, serializer):\n    '\\n        This hook is called by the serializer instance,\\n        prior to the validation call being made.\\n        '\n    serializer.instance = getattr(serializer, 'instance', None)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_add_ts_start(self, ts_start):\n    self._db_ts_start = ts_start\n", "label": "Correct"}
{"function": "\n\ndef db_add_ts_start(self, ts_start):\n    ts_start._db_ts_start = ts_start\n", "label": "Variable misuse"}
{"function": "\n\n@expose('/<string:locale>')\ndef index(self, locale):\n    session['locale'] = locale\n    refresh()\n    self.update_redirect()\n    return redirect(self.get_redirect())\n", "label": "Correct"}
{"function": "\n\n@expose('/<string:locale>')\ndef index(self, locale):\n    session['locale'] = locale\n    refresh()\n    self.update_redirect()\n    return redirect(locale.get_redirect())\n", "label": "Variable misuse"}
{"function": "\n\ndef reselect(self, pos):\n\n    def select(view, edit):\n        region = pos\n        if hasattr(pos, '__call__'):\n            region = run_callback(pos, view)\n        if isinstance(region, int):\n            region = sublime.Region(region, region)\n        elif isinstance(region, (tuple, list)):\n            region = sublime.Region(*region)\n        view.sel().clear()\n        view.sel().add(region)\n        view.show(region, False)\n    self.callback(select)\n", "label": "Correct"}
{"function": "\n\ndef reselect(self, pos):\n\n    def select(view, edit):\n        region = pos\n        if hasattr(pos, '__call__'):\n            region = run_callback(pos, view)\n        if isinstance(region, int):\n            region = sublime.Region(region, region)\n        elif isinstance(region, (tuple, list)):\n            region = sublime.Region(*region)\n        view.sel().clear()\n        view.sel().add(region)\n        view.show(region, False)\n    pos.callback(select)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_mutual_info_regression():\n    (X, y) = make_regression(n_samples=100, n_features=10, n_informative=2, shuffle=False, random_state=0, noise=10)\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='k_best', param=2).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='percentile', param=20).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n", "label": "Correct"}
{"function": "\n\ndef test_mutual_info_regression():\n    (X, y) = make_regression(n_samples=100, n_features=10, n_informative=2, shuffle=False, random_state=0, noise=10)\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='k_best', param=2).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='percentile', param=20).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, X_r2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_derived(self):\n    import time\n\n    class Local(threading.local):\n\n        def __init__(self):\n            time.sleep(0.01)\n    local = Local()\n\n    def f(i):\n        local.x = i\n        self.assertEqual(local.x, i)\n    threads = []\n    for i in range(10):\n        t = threading.Thread(target=f, args=(i,))\n        t.start()\n        threads.append(t)\n    for t in threads:\n        t.join()\n", "label": "Correct"}
{"function": "\n\ndef test_derived(self):\n    import time\n\n    class Local(threading.local):\n\n        def __init__(self):\n            time.sleep(0.01)\n    local = Local()\n\n    def f(i):\n        local.x = i\n        self.assertEqual(local.x, i)\n    threads = []\n    for i in range(10):\n        t = threading.Thread(target=f, args=(i,))\n        t.start()\n        threads.append(t)\n    for t in local:\n        t.join()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_retry_in_graph_flow_requires_and_provides(self):\n    flow = gf.Flow('gf', retry.AlwaysRevert('rt', requires=['x', 'y'], provides=['a', 'b']))\n    self.assertEqual(set(['x', 'y']), flow.requires)\n    self.assertEqual(set(['a', 'b']), flow.provides)\n", "label": "Correct"}
{"function": "\n\ndef test_retry_in_graph_flow_requires_and_provides(self):\n    flow = gf.Flow('gf', retry.AlwaysRevert('rt', requires=['x', 'y'], provides=['a', 'b']))\n    self.assertEqual(set(['x', 'y']), flow.requires)\n    self.assertEqual(set(['a', 'b']), self.provides)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_review_comments(self):\n    \"Show that one can iterate over a PR's review comments.\"\n    cassette_name = self.cassette_name('review_comments')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        for comment in p.review_comments():\n            assert isinstance(comment, github3.pulls.ReviewComment)\n", "label": "Correct"}
{"function": "\n\ndef test_review_comments(self):\n    \"Show that one can iterate over a PR's review comments.\"\n    cassette_name = cassette_name.cassette_name('review_comments')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        for comment in p.review_comments():\n            assert isinstance(comment, github3.pulls.ReviewComment)\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self, t, dt):\n    if (random.random() < 0.02):\n        self.a += ((random.randint((- 1), 1) * pi) / 8)\n    dx = cos(self.a)\n    dz = sin(self.a)\n    self.x += (dx * dt)\n    self.z += (dz * dt)\n", "label": "Correct"}
{"function": "\n\ndef update(self, t, dt):\n    if (random.random() < 0.02):\n        self.a += ((random.randint((- 1), 1) * pi) / 8)\n    dx = cos(self.a)\n    dz = sin(self.a)\n    self.x += (dx * dt)\n    self.z += (dz * self)\n", "label": "Variable misuse"}
{"function": "\n\ndef encryption_oracle(rawInput):\n    key = generateAESKey()\n    iv = generateAESKey()\n    prependAmount = (5 + (getOneRandomByte() % 6))\n    appendAmount = (5 + (getOneRandomByte() % 6))\n    plaintext = (((b'x' * prependAmount) + rawInput) + (b'y' * appendAmount))\n    if (getOneRandomByte() & 1):\n        return aes_ecb_enc(addPKCS7Padding(plaintext, 16), key)\n    else:\n        return aes_cbc_enc(addPKCS7Padding(plaintext, 16), key, iv)\n", "label": "Correct"}
{"function": "\n\ndef encryption_oracle(rawInput):\n    key = generateAESKey()\n    iv = generateAESKey()\n    prependAmount = (5 + (getOneRandomByte() % 6))\n    appendAmount = (5 + (getOneRandomByte() % 6))\n    plaintext = (((b'x' * prependAmount) + rawInput) + (b'y' * appendAmount))\n    if (getOneRandomByte() & 1):\n        return aes_ecb_enc(addPKCS7Padding(plaintext, 16), prependAmount)\n    else:\n        return aes_cbc_enc(addPKCS7Padding(plaintext, 16), key, iv)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_status(self, lines):\n    activity = []\n    seen_times = set()\n    for line in lines:\n        (time, fields) = line.split('|')\n        if (time not in seen_times):\n            seen_times.add(time)\n            status_obj = status.Status(int(float(time)), fields)\n            activity.append(status_obj)\n    return activity\n", "label": "Correct"}
{"function": "\n\ndef parse_status(self, lines):\n    activity = []\n    seen_times = set()\n    for line in lines:\n        (time, fields) = line.split('|')\n        if (time not in seen_times):\n            seen_times.add(time)\n            status_obj = status.Status(int(float(time)), fields)\n            lines.append(status_obj)\n    return activity\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef directions(self):\n    hashes = []\n    t_query = 'select trip_headsign, trip_short_name, bikes_allowed,\\n        trip_id from trips where route_id=:route_id and _feed=:_feed'\n    t_filter = {\n        'route_id': self.id,\n        '_feed': self.provider.feed_id,\n    }\n    cur = self.provider.conn.cursor()\n    for trip in cur.execute(t_query, t_filter):\n        direction = {\n            \n        }\n        innercur = self.provider.conn.cursor()\n        result = innercur.execute('select s.* from stop_times as st join stops as s\\n                on st.stop_id=s.stop_id and st._feed=s._feed\\n                where st.trip_id=:t_id and st._feed=:_feed', {\n            't_id': trip['trip_id'],\n            '_feed': self.provider.feed_id,\n        })\n        direction['stops'] = [GTFSStop(self.provider, **dict(row)) for row in result]\n        if (trip['trip_headsign'] is not None):\n            direction['headsign'] = trip['trip_headsign']\n        if (trip['trip_short_name'] is not None):\n            direction['short_name'] = trip['trip_short_name']\n        if (trip['bikes_allowed'] is not None):\n            direction['bikes_ok'] = trip['bikes_allowed']\n        h = util.freezehash(direction)\n        if (h not in hashes):\n            hashes.append(h)\n            (yield direction)\n", "label": "Correct"}
{"function": "\n\n@property\ndef directions(self):\n    hashes = []\n    t_query = 'select trip_headsign, trip_short_name, bikes_allowed,\\n        trip_id from trips where route_id=:route_id and _feed=:_feed'\n    t_filter = {\n        'route_id': self.id,\n        '_feed': self.provider.feed_id,\n    }\n    cur = self.provider.conn.cursor()\n    for trip in cur.execute(t_query, t_filter):\n        direction = {\n            \n        }\n        innercur = self.provider.conn.cursor()\n        result = innercur.execute('select s.* from stop_times as st join stops as s\\n                on st.stop_id=s.stop_id and st._feed=s._feed\\n                where st.trip_id=:t_id and st._feed=:_feed', {\n            't_id': trip['trip_id'],\n            '_feed': self.provider.feed_id,\n        })\n        direction['stops'] = [GTFSStop(self.provider, **dict(row)) for row in result]\n        if (trip['trip_headsign'] is not None):\n            direction['headsign'] = trip['trip_headsign']\n        if (trip['trip_short_name'] is not None):\n            direction['short_name'] = trip['trip_short_name']\n        if (trip['bikes_allowed'] is not None):\n            t_query['bikes_ok'] = trip['bikes_allowed']\n        h = util.freezehash(direction)\n        if (h not in hashes):\n            hashes.append(h)\n            (yield direction)\n", "label": "Variable misuse"}
{"function": "\n\ndef _partitions_to_src(partitions):\n    return ''.join((part.src for part in partitions))\n", "label": "Correct"}
{"function": "\n\ndef _partitions_to_src(partitions):\n    return ''.join((partitions.src for part in partitions))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_input_extra_rewrite(self):\n    self.client_job_description.rewrite_paths = True\n    extra_file = os.path.join(self.input1_files_path, 'moo', 'cow.txt')\n    os.makedirs(os.path.dirname(extra_file))\n    open(extra_file, 'w').write('Hello World!')\n    command_line = ('test.exe %s' % extra_file)\n    self.client_job_description.command_line = command_line\n    self.client.expect_command_line('test.exe /pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt')\n    self.client.expect_put_paths(['/pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt'])\n    self._submit()\n    uploaded_file1 = self.client.put_files[0]\n    assert (uploaded_file1[1] == 'input')\n    assert (uploaded_file1[0] == extra_file)\n", "label": "Correct"}
{"function": "\n\ndef test_input_extra_rewrite(self):\n    self.client_job_description.rewrite_paths = True\n    extra_file = os.path.join(self.input1_files_path, 'moo', 'cow.txt')\n    os.makedirs(os.path.dirname(extra_file))\n    open(extra_file, 'w').write('Hello World!')\n    command_line = ('test.exe %s' % extra_file)\n    self.client_job_description.command_line = command_line\n    self.client.expect_command_line('test.exe /pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt')\n    self.client.expect_put_paths(['/pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt'])\n    self._submit()\n    uploaded_file1 = command_line.client.put_files[0]\n    assert (uploaded_file1[1] == 'input')\n    assert (uploaded_file1[0] == extra_file)\n", "label": "Variable misuse"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.LIST):\n                self.column_names = []\n                (_etype10, _size7) = iprot.readListBegin()\n                for _i11 in xrange(_size7):\n                    _elem12 = iprot.readString()\n                    self.column_names.append(_elem12)\n                iprot.readListEnd()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRUCT):\n                self.slice_range = SliceRange()\n                self.slice_range.read(iprot)\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, fname.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.LIST):\n                self.column_names = []\n                (_etype10, _size7) = iprot.readListBegin()\n                for _i11 in xrange(_size7):\n                    _elem12 = iprot.readString()\n                    self.column_names.append(_elem12)\n                iprot.readListEnd()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRUCT):\n                self.slice_range = SliceRange()\n                self.slice_range.read(iprot)\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_member_addresses(self):\n    addresses = []\n    for member in self.config_members:\n        addresses.append(member.get_server().get_address())\n    return addresses\n", "label": "Correct"}
{"function": "\n\ndef get_member_addresses(self):\n    addresses = []\n    for member in self.config_members:\n        addresses.append(self.get_server().get_address())\n    return addresses\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dispatch_on_heartbeat_frame(self):\n    frame = mock()\n    expect(frame.type).returns(HeartbeatFrame.type())\n    expect(self.ch.send_heartbeat)\n    self.ch.dispatch(frame)\n", "label": "Correct"}
{"function": "\n\ndef test_dispatch_on_heartbeat_frame(self):\n    frame = mock()\n    expect(frame.type).returns(HeartbeatFrame.type())\n    expect(self.ch.send_heartbeat)\n    self.ch.dispatch(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, output_type, inplace=False):\n    Op.__init__(self)\n    self.output_type = output_type\n    self.inplace = inplace\n    if inplace:\n        self.destroy_map = {\n            0: [0],\n        }\n    self.warned_numpy_version = False\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, output_type, inplace=False):\n    Op.__init__(self)\n    output_type.output_type = output_type\n    self.inplace = inplace\n    if inplace:\n        self.destroy_map = {\n            0: [0],\n        }\n    self.warned_numpy_version = False\n", "label": "Variable misuse"}
{"function": "\n\ndef CheckLoggingWorks(self):\n    logger = StringIO.StringIO()\n    expected_output = (';\\n'.join([sqlite.main._BEGIN, 'CREATE TABLE TEST(FOO INTEGER)', 'INSERT INTO TEST(FOO) VALUES (?)', 'ROLLBACK']) + ';\\n')\n    self.cnx = sqlite.connect(self.getfilename(), command_logfile=logger)\n    cu = self.cnx.cursor()\n    cu.execute('CREATE TABLE TEST(FOO INTEGER)')\n    cu.execute('INSERT INTO TEST(FOO) VALUES (?)', (5,))\n    self.cnx.rollback()\n    logger.seek(0)\n    real_output = logger.read()\n    if (expected_output != real_output):\n        self.fail(\"Logging didn't produce expected output.\")\n", "label": "Correct"}
{"function": "\n\ndef CheckLoggingWorks(self):\n    logger = StringIO.StringIO()\n    expected_output = (';\\n'.join([sqlite.main._BEGIN, 'CREATE TABLE TEST(FOO INTEGER)', 'INSERT INTO TEST(FOO) VALUES (?)', 'ROLLBACK']) + ';\\n')\n    self.cnx = sqlite.connect(expected_output.getfilename(), command_logfile=logger)\n    cu = self.cnx.cursor()\n    cu.execute('CREATE TABLE TEST(FOO INTEGER)')\n    cu.execute('INSERT INTO TEST(FOO) VALUES (?)', (5,))\n    self.cnx.rollback()\n    logger.seek(0)\n    real_output = logger.read()\n    if (expected_output != real_output):\n        self.fail(\"Logging didn't produce expected output.\")\n", "label": "Variable misuse"}
{"function": "\n\ndef bitand(self, other):\n    return self._combine(other, self.BITAND, False)\n", "label": "Correct"}
{"function": "\n\ndef bitand(self, other):\n    return other._combine(other, self.BITAND, False)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_environment(self, app):\n    return app.extensions['gears']['environment']\n", "label": "Correct"}
{"function": "\n\ndef get_environment(self, app):\n    return self.extensions['gears']['environment']\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, odffile):\n    ' Loads a document into the parser and parses it.\\n            The argument can either be a filename or a document in memory.\\n        '\n    self.lines = []\n    self._wfunc = self._wlines\n    if isinstance(odffile, str):\n        self.document = load(odffile)\n    else:\n        self.document = odffile\n    self._walknode(self.document.topnode)\n", "label": "Correct"}
{"function": "\n\ndef load(self, odffile):\n    ' Loads a document into the parser and parses it.\\n            The argument can either be a filename or a document in memory.\\n        '\n    self.lines = []\n    self._wfunc = odffile._wlines\n    if isinstance(odffile, str):\n        self.document = load(odffile)\n    else:\n        self.document = odffile\n    self._walknode(self.document.topnode)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_children(self, parent=(None, None), orphan=False):\n    children = []\n    children.append((self, parent[0], parent[1]))\n    return children\n", "label": "Correct"}
{"function": "\n\ndef db_children(self, parent=(None, None), orphan=False):\n    children = []\n    children.append((self, orphan[0], parent[1]))\n    return children\n", "label": "Variable misuse"}
{"function": "\n\ndef blacklist_delete_user_agents(self, request, queryset):\n    self.blacklist_user_agents(request, queryset)\n    self.delete_queryset(request, queryset)\n", "label": "Correct"}
{"function": "\n\ndef blacklist_delete_user_agents(self, request, queryset):\n    self.blacklist_user_agents(request, self)\n    self.delete_queryset(request, queryset)\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n\n    def format_row(row):\n        return ('(%s)' % ', '.join((format_number(value) for value in row)))\n    return ('Matrix44(%s)' % ', '.join((format_row(row) for row in self.rows())))\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n\n    def format_row(row):\n        return ('(%s)' % ', '.join((format_number(value) for value in row)))\n    return ('Matrix44(%s)' % ', '.join((format_row(row) for row in row.rows())))\n", "label": "Variable misuse"}
{"function": "\n\ndef _createFile(self):\n    self.h5file.create_array('/', 'arr1', [1, 2])\n    group1 = self.h5file.create_group('/', 'group1')\n    arr2 = self.h5file.create_array(group1, 'arr2', [1, 2, 3])\n    lgroup1 = self.h5file.create_hard_link('/', 'lgroup1', '/group1')\n    self.assertTrue((lgroup1 is not None))\n    larr1 = self.h5file.create_hard_link(group1, 'larr1', '/arr1')\n    self.assertTrue((larr1 is not None))\n    larr2 = self.h5file.create_hard_link('/', 'larr2', arr2)\n    self.assertTrue((larr2 is not None))\n", "label": "Correct"}
{"function": "\n\ndef _createFile(self):\n    self.h5file.create_array('/', 'arr1', [1, 2])\n    group1 = self.h5file.create_group('/', 'group1')\n    arr2 = group1.h5file.create_array(group1, 'arr2', [1, 2, 3])\n    lgroup1 = self.h5file.create_hard_link('/', 'lgroup1', '/group1')\n    self.assertTrue((lgroup1 is not None))\n    larr1 = self.h5file.create_hard_link(group1, 'larr1', '/arr1')\n    self.assertTrue((larr1 is not None))\n    larr2 = self.h5file.create_hard_link('/', 'larr2', arr2)\n    self.assertTrue((larr2 is not None))\n", "label": "Variable misuse"}
{"function": "\n\ndef saveXML(self, snode):\n    if (snode is None):\n        snode = self\n    elif (snode.ownerDocument is not self):\n        raise xml.dom.WrongDocumentErr()\n    return snode.toxml()\n", "label": "Correct"}
{"function": "\n\ndef saveXML(self, snode):\n    if (snode is None):\n        snode = self\n    elif (self.ownerDocument is not self):\n        raise xml.dom.WrongDocumentErr()\n    return snode.toxml()\n", "label": "Variable misuse"}
{"function": "\n\ndef install(self, instance):\n    cfg = self.config\n    if (self.database == self.master_database):\n        template = 'template1'\n    else:\n        template = self.master_database\n    config_opt_map = dict(host='host', user='username', password='password', encoding='encoding', lc_collate='lc-collate', lc_ctype='lc-ctype', tablespace='tablespace')\n    options = [((('--' + opt) + '=') + str(cfg[cfg_name])) for (cfg_name, opt) in config_opt_map.iteritems() if (cfg_name in cfg)]\n    fail = instance.do(((['createdb', '--template', template] + options) + [self.database]))\n    if fail:\n        instance.do(['pg_dump', '-h', str(cfg['host']), '-U', str(cfg['user']), '-E', str(cfg['encoding']), '-f', (('/tmp/' + template) + '.sql'), template])\n        instance.do(((['createdb', '--template', 'template1'] + options) + [self.database]))\n        instance.do(['psql', '-h', str(cfg['host']), '-U', str(cfg['user']), '-f', (('/tmp/' + template) + '.sql'), self.database])\n    info = self.connection_info\n    info['database'] = self.database\n    return info\n", "label": "Correct"}
{"function": "\n\ndef install(self, instance):\n    cfg = self.config\n    if (self.database == self.master_database):\n        template = 'template1'\n    else:\n        template = self.master_database\n    config_opt_map = dict(host='host', user='username', password='password', encoding='encoding', lc_collate='lc-collate', lc_ctype='lc-ctype', tablespace='tablespace')\n    options = [((('--' + opt) + '=') + str(config_opt_map[cfg_name])) for (cfg_name, opt) in config_opt_map.iteritems() if (cfg_name in cfg)]\n    fail = instance.do(((['createdb', '--template', template] + options) + [self.database]))\n    if fail:\n        instance.do(['pg_dump', '-h', str(cfg['host']), '-U', str(cfg['user']), '-E', str(cfg['encoding']), '-f', (('/tmp/' + template) + '.sql'), template])\n        instance.do(((['createdb', '--template', 'template1'] + options) + [self.database]))\n        instance.do(['psql', '-h', str(cfg['host']), '-U', str(cfg['user']), '-f', (('/tmp/' + template) + '.sql'), self.database])\n    info = self.connection_info\n    info['database'] = self.database\n    return info\n", "label": "Variable misuse"}
{"function": "\n\n@contextmanager\ndef trace_ms(statName):\n    if (_instatrace is None):\n        (yield)\n        return\n    now = _instatrace.now_ms()\n    (yield)\n    _instatrace.trace(statName, (_instatrace.now_ms() - now))\n", "label": "Correct"}
{"function": "\n\n@contextmanager\ndef trace_ms(statName):\n    if (_instatrace is None):\n        (yield)\n        return\n    now = _instatrace.now_ms()\n    (yield)\n    _instatrace.trace(statName, (_instatrace.now_ms() - statName))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_bad_column_qualifier(self):\n    families = {\n        cf2: 'oberyn',\n    }\n    res = self.c.get(table, self.row_prefix, families=families)\n    self.assertEqual(result_to_dict(res), {\n        \n    })\n", "label": "Correct"}
{"function": "\n\ndef test_get_bad_column_qualifier(self):\n    families = {\n        cf2: 'oberyn',\n    }\n    res = self.c.get(table, self.row_prefix, families=families)\n    families.assertEqual(result_to_dict(res), {\n        \n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef test_grad_s(self):\n    'tests that the gradients with respect to s_i are 0 after doing a mean field update of s_i '\n    model = self.model\n    e_step = self.e_step\n    X = self.X\n    assert (X.shape[0] == self.m)\n    model.test_batch_size = X.shape[0]\n    init_H = e_step.init_H_hat(V=X)\n    init_Mu1 = e_step.init_S_hat(V=X)\n    prev_setting = config.compute_test_value\n    config.compute_test_value = 'off'\n    (H, Mu1) = function([], outputs=[init_H, init_Mu1])()\n    config.compute_test_value = prev_setting\n    H = broadcast(H, self.m)\n    Mu1 = broadcast(Mu1, self.m)\n    H = np.cast[config.floatX](self.model.rng.uniform(0.0, 1.0, H.shape))\n    Mu1 = np.cast[config.floatX](self.model.rng.uniform((- 5.0), 5.0, Mu1.shape))\n    H_var = T.matrix(name='H_var')\n    H_var.tag.test_value = H\n    Mu1_var = T.matrix(name='Mu1_var')\n    Mu1_var.tag.test_value = Mu1\n    idx = T.iscalar()\n    idx.tag.test_value = 0\n    S = e_step.infer_S_hat(V=X, H_hat=H_var, S_hat=Mu1_var)\n    s_idx = S[:, idx]\n    s_i_func = function([H_var, Mu1_var, idx], s_idx)\n    sigma0 = (1.0 / model.alpha)\n    Sigma1 = e_step.infer_var_s1_hat()\n    mu0 = T.zeros_like(model.mu)\n    trunc_kl = ((- model.entropy_hs(H_hat=H_var, var_s0_hat=sigma0, var_s1_hat=Sigma1)) + model.expected_energy_vhs(V=X, H_hat=H_var, S_hat=Mu1_var, var_s0_hat=sigma0, var_s1_hat=Sigma1))\n    grad_Mu1 = T.grad(trunc_kl.sum(), Mu1_var)\n    grad_Mu1_idx = grad_Mu1[:, idx]\n    grad_func = function([H_var, Mu1_var, idx], grad_Mu1_idx)\n    for i in xrange(self.N):\n        Mu1[:, i] = s_i_func(H, Mu1, i)\n        g = grad_func(H, Mu1, i)\n        assert (not contains_nan(g))\n        g_abs_max = np.abs(g).max()\n        if (g_abs_max > self.tol):\n            raise Exception(((('after mean field step, gradient of kl divergence wrt mean field parameter should be 0, but here the max magnitude of a gradient element is ' + str(g_abs_max)) + ' after updating s_') + str(i)))\n", "label": "Correct"}
{"function": "\n\ndef test_grad_s(self):\n    'tests that the gradients with respect to s_i are 0 after doing a mean field update of s_i '\n    model = self.model\n    e_step = self.e_step\n    X = self.X\n    assert (X.shape[0] == self.m)\n    model.test_batch_size = X.shape[0]\n    init_H = e_step.init_H_hat(V=X)\n    init_Mu1 = e_step.init_S_hat(V=init_H)\n    prev_setting = config.compute_test_value\n    config.compute_test_value = 'off'\n    (H, Mu1) = function([], outputs=[init_H, init_Mu1])()\n    config.compute_test_value = prev_setting\n    H = broadcast(H, self.m)\n    Mu1 = broadcast(Mu1, self.m)\n    H = np.cast[config.floatX](self.model.rng.uniform(0.0, 1.0, H.shape))\n    Mu1 = np.cast[config.floatX](self.model.rng.uniform((- 5.0), 5.0, Mu1.shape))\n    H_var = T.matrix(name='H_var')\n    H_var.tag.test_value = H\n    Mu1_var = T.matrix(name='Mu1_var')\n    Mu1_var.tag.test_value = Mu1\n    idx = T.iscalar()\n    idx.tag.test_value = 0\n    S = e_step.infer_S_hat(V=X, H_hat=H_var, S_hat=Mu1_var)\n    s_idx = S[:, idx]\n    s_i_func = function([H_var, Mu1_var, idx], s_idx)\n    sigma0 = (1.0 / model.alpha)\n    Sigma1 = e_step.infer_var_s1_hat()\n    mu0 = T.zeros_like(model.mu)\n    trunc_kl = ((- model.entropy_hs(H_hat=H_var, var_s0_hat=sigma0, var_s1_hat=Sigma1)) + model.expected_energy_vhs(V=X, H_hat=H_var, S_hat=Mu1_var, var_s0_hat=sigma0, var_s1_hat=Sigma1))\n    grad_Mu1 = T.grad(trunc_kl.sum(), Mu1_var)\n    grad_Mu1_idx = grad_Mu1[:, idx]\n    grad_func = function([H_var, Mu1_var, idx], grad_Mu1_idx)\n    for i in xrange(self.N):\n        Mu1[:, i] = s_i_func(H, Mu1, i)\n        g = grad_func(H, Mu1, i)\n        assert (not contains_nan(g))\n        g_abs_max = np.abs(g).max()\n        if (g_abs_max > self.tol):\n            raise Exception(((('after mean field step, gradient of kl divergence wrt mean field parameter should be 0, but here the max magnitude of a gradient element is ' + str(g_abs_max)) + ' after updating s_') + str(i)))\n", "label": "Variable misuse"}
{"function": "\n\ndef db_add_portSpec(self, portSpec):\n    self.__db_portSpec = portSpec\n", "label": "Correct"}
{"function": "\n\ndef db_add_portSpec(self, portSpec):\n    self.__db_portSpec = self\n", "label": "Variable misuse"}
{"function": "\n\ndef do(args):\n    ' Main method '\n    if args.name:\n        tc_names = [args.name]\n    else:\n        tc_names = qitoolchain.get_tc_names()\n    for tc_name in tc_names:\n        toolchain = qitoolchain.get_toolchain(tc_name)\n        ui.info(str(toolchain))\n", "label": "Correct"}
{"function": "\n\ndef do(args):\n    ' Main method '\n    if args.name:\n        tc_names = [args.name]\n    else:\n        tc_names = qitoolchain.get_tc_names()\n    for tc_name in tc_names:\n        toolchain = qitoolchain.get_toolchain(tc_name)\n        ui.info(str(tc_name))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_IRParamStmt_dump():\n    stmt = {\n        'param': 'IR',\n        'angle': '45',\n    }\n    ir = IRParamStmt.from_dict(stmt)\n    assert_equal(ir.to_gerber(), '%IR45*%')\n", "label": "Correct"}
{"function": "\n\ndef test_IRParamStmt_dump():\n    stmt = {\n        'param': 'IR',\n        'angle': '45',\n    }\n    ir = IRParamStmt.from_dict(ir)\n    assert_equal(ir.to_gerber(), '%IR45*%')\n", "label": "Variable misuse"}
{"function": "\n\ndef get_resources(self):\n    resources = []\n    resource = extensions.ResourceExtension('os-agents', AgentController())\n    resources.append(resource)\n    return resources\n", "label": "Correct"}
{"function": "\n\ndef get_resources(self):\n    resources = []\n    resource = extensions.ResourceExtension('os-agents', AgentController())\n    resources.append(self)\n    return resources\n", "label": "Variable misuse"}
{"function": "\n\ndef _save(self, key, attributes):\n    s_uuid = self.repo.save(key, attributes)\n    self.logger.debug(('creating object with uuid = %s' % s_uuid))\n    attribute_type = AT.UNIQUE_IDENTIFIER\n    attribute = self.attribute_factory.create_attribute(attribute_type, s_uuid)\n    attributes.append(attribute)\n    self.repo.update(s_uuid, key, attributes)\n    return (s_uuid, attribute)\n", "label": "Correct"}
{"function": "\n\ndef _save(self, key, attributes):\n    s_uuid = self.repo.save(s_uuid, attributes)\n    self.logger.debug(('creating object with uuid = %s' % s_uuid))\n    attribute_type = AT.UNIQUE_IDENTIFIER\n    attribute = self.attribute_factory.create_attribute(attribute_type, s_uuid)\n    attributes.append(attribute)\n    self.repo.update(s_uuid, key, attributes)\n    return (s_uuid, attribute)\n", "label": "Variable misuse"}
{"function": "\n\ndef to_array(self):\n    '\\n        Convert the RiakLinkPhase to a format that can be output into\\n        JSON. Used internally.\\n        '\n    stepdef = {\n        'bucket': self._bucket,\n        'tag': self._tag,\n        'keep': self._keep,\n    }\n    return {\n        'link': stepdef,\n    }\n", "label": "Correct"}
{"function": "\n\ndef to_array(self):\n    '\\n        Convert the RiakLinkPhase to a format that can be output into\\n        JSON. Used internally.\\n        '\n    stepdef = {\n        'bucket': stepdef._bucket,\n        'tag': self._tag,\n        'keep': self._keep,\n    }\n    return {\n        'link': stepdef,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/crafted/capacitor/shared_quick_recharge_battery_mk5.iff'\n    result.attribute_template_id = 8\n    result.stfName('space_crafting_n', 'quick_recharge_battery_mk5')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/crafted/capacitor/shared_quick_recharge_battery_mk5.iff'\n    result.attribute_template_id = 8\n    result.stfName('space_crafting_n', 'quick_recharge_battery_mk5')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef abort_request(self, stream, ident, parent):\n    'abort a specifig msg by id'\n    msg_ids = parent['content'].get('msg_ids', None)\n    if isinstance(msg_ids, str):\n        msg_ids = [msg_ids]\n    if (not msg_ids):\n        self.abort_queues()\n    for mid in msg_ids:\n        self.aborted.add(str(mid))\n    content = dict(status='ok')\n    reply_msg = self.session.send(stream, 'abort_reply', content=content, parent=parent, ident=ident)\n    self.log.debug(str(reply_msg))\n", "label": "Correct"}
{"function": "\n\ndef abort_request(self, stream, ident, parent):\n    'abort a specifig msg by id'\n    msg_ids = parent['content'].get('msg_ids', None)\n    if isinstance(msg_ids, str):\n        msg_ids = [msg_ids]\n    if (not msg_ids):\n        self.abort_queues()\n    for mid in msg_ids:\n        self.aborted.add(str(mid))\n    content = dict(status='ok')\n    reply_msg = self.session.send(stream, 'abort_reply', content=content, parent=parent, ident=ident)\n    self.log.debug(str(msg_ids))\n", "label": "Variable misuse"}
{"function": "\n\ndef p_basic_statement(self, p):\n    'basic_statement : if_statement\\n        | case_statement\\n        | casex_statement\\n        | for_statement\\n        | while_statement\\n        | event_statement\\n        | wait_statement\\n        | forever_statement\\n        | block\\n        | namedblock\\n        | parallelblock\\n        | blocking_substitution\\n        | nonblocking_substitution\\n        | single_statement\\n        '\n    p[0] = p[1]\n    p.set_lineno(0, p.lineno(1))\n", "label": "Correct"}
{"function": "\n\ndef p_basic_statement(self, p):\n    'basic_statement : if_statement\\n        | case_statement\\n        | casex_statement\\n        | for_statement\\n        | while_statement\\n        | event_statement\\n        | wait_statement\\n        | forever_statement\\n        | block\\n        | namedblock\\n        | parallelblock\\n        | blocking_substitution\\n        | nonblocking_substitution\\n        | single_statement\\n        '\n    p[0] = self[1]\n    p.set_lineno(0, p.lineno(1))\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, handle, name):\n    self._check_all_set()\n    g = handle.create_group(name)\n    g.attrs['type'] = np.string_('extern_box'.encode('utf-8'))\n    g.attrs['xmin'] = self.bounds[0][0]\n    g.attrs['xmax'] = self.bounds[0][1]\n    g.attrs['ymin'] = self.bounds[1][0]\n    g.attrs['ymax'] = self.bounds[1][1]\n    g.attrs['zmin'] = self.bounds[2][0]\n    g.attrs['zmax'] = self.bounds[2][1]\n    Source.write(self, g)\n", "label": "Correct"}
{"function": "\n\ndef write(self, handle, name):\n    self._check_all_set()\n    g = handle.create_group(name)\n    g.attrs['type'] = np.string_('extern_box'.encode('utf-8'))\n    g.attrs['xmin'] = self.bounds[0][0]\n    g.attrs['xmax'] = self.bounds[0][1]\n    handle.attrs['ymin'] = self.bounds[1][0]\n    g.attrs['ymax'] = self.bounds[1][1]\n    g.attrs['zmin'] = self.bounds[2][0]\n    g.attrs['zmax'] = self.bounds[2][1]\n    Source.write(self, g)\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    self.one_to_one = True\n    return super(OneToOneFieldDefinition, self).save(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    self.one_to_one = True\n    return super(OneToOneFieldDefinition, self).save(*self, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef testComplexLabels(self):\n    logging.debug('Running testComplexLabels method.')\n    expression = 'a_123'\n    self._RunMathQuery(expression, ['a_123'])\n    expression = 'a_1.b2'\n    self._RunMathQuery(expression, ['a_1.b2'])\n", "label": "Correct"}
{"function": "\n\ndef testComplexLabels(self):\n    logging.debug('Running testComplexLabels method.')\n    expression = 'a_123'\n    expression._RunMathQuery(expression, ['a_123'])\n    expression = 'a_1.b2'\n    self._RunMathQuery(expression, ['a_1.b2'])\n", "label": "Variable misuse"}
{"function": "\n\n@app.task(bind=True)\n@only_one(key='analyze_databases_service_task', timeout=6000)\ndef analyze_databases(self, task_history=None):\n    (endpoint, healh_check_route, healh_check_string) = get_analyzing_credentials()\n    user = User.objects.get(username='admin')\n    worker_name = get_worker_name()\n    task_history = TaskHistory.register(task_history=task_history, request=self.request, user=user, worker_name=worker_name)\n    task_history.update_details(persist=True, details='Loading Process...')\n    AuditRequest.new_request('analyze_databases', user, 'localhost')\n    try:\n        analyze_service = AnalyzeService(endpoint, healh_check_route, healh_check_string)\n        with transaction.atomic():\n            databases = Database.objects.filter(is_in_quarantine=False)\n            today = datetime.now()\n            for database in databases:\n                (database_name, engine, instances, environment_name, databaseinfra_name) = setup_database_info(database)\n                for execution_plan in ExecutionPlan.objects.all():\n                    if database_can_not_be_resized(database, execution_plan):\n                        continue\n                    params = execution_plan.setup_execution_params()\n                    result = analyze_service.run(engine=engine, database=database_name, instances=instances, **params)\n                    if (result['status'] == 'success'):\n                        task_history.update_details(persist=True, details='\\nDatabase {} {} was analised.'.format(database, execution_plan.plan_name))\n                        if (result['msg'] != instances):\n                            continue\n                        for instance in result['msg']:\n                            insert_analyze_repository_record(today, database_name, instance, engine, databaseinfra_name, environment_name, execution_plan)\n                    else:\n                        raise Exception('Check your service logs..')\n        task_history.update_status_for(TaskHistory.STATUS_SUCCESS, details='Analisys ok!')\n    except Exception:\n        try:\n            task_history.update_details(persist=True, details='\\nDatabase {} {} could not be analised.'.format(database, execution_plan.plan_name))\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys finished with errors!\\nError: {}'.format(result['msg']))\n        except UnboundLocalError:\n            task_history.update_details(persist=True, details='\\nProccess crashed')\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys could not be started')\n    finally:\n        AuditRequest.cleanup_request()\n", "label": "Correct"}
{"function": "\n\n@app.task(bind=True)\n@only_one(key='analyze_databases_service_task', timeout=6000)\ndef analyze_databases(self, task_history=None):\n    (endpoint, healh_check_route, healh_check_string) = get_analyzing_credentials()\n    user = User.objects.get(username='admin')\n    worker_name = get_worker_name()\n    task_history = TaskHistory.register(task_history=task_history, request=self.request, user=user, worker_name=execution_plan)\n    task_history.update_details(persist=True, details='Loading Process...')\n    AuditRequest.new_request('analyze_databases', user, 'localhost')\n    try:\n        analyze_service = AnalyzeService(endpoint, healh_check_route, healh_check_string)\n        with transaction.atomic():\n            databases = Database.objects.filter(is_in_quarantine=False)\n            today = datetime.now()\n            for database in databases:\n                (database_name, engine, instances, environment_name, databaseinfra_name) = setup_database_info(database)\n                for execution_plan in ExecutionPlan.objects.all():\n                    if database_can_not_be_resized(database, execution_plan):\n                        continue\n                    params = execution_plan.setup_execution_params()\n                    result = analyze_service.run(engine=engine, database=database_name, instances=instances, **params)\n                    if (result['status'] == 'success'):\n                        task_history.update_details(persist=True, details='\\nDatabase {} {} was analised.'.format(database, execution_plan.plan_name))\n                        if (result['msg'] != instances):\n                            continue\n                        for instance in result['msg']:\n                            insert_analyze_repository_record(today, database_name, instance, engine, databaseinfra_name, environment_name, execution_plan)\n                    else:\n                        raise Exception('Check your service logs..')\n        task_history.update_status_for(TaskHistory.STATUS_SUCCESS, details='Analisys ok!')\n    except Exception:\n        try:\n            task_history.update_details(persist=True, details='\\nDatabase {} {} could not be analised.'.format(database, execution_plan.plan_name))\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys finished with errors!\\nError: {}'.format(result['msg']))\n        except UnboundLocalError:\n            task_history.update_details(persist=True, details='\\nProccess crashed')\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys could not be started')\n    finally:\n        AuditRequest.cleanup_request()\n", "label": "Variable misuse"}
{"function": "\n\ndef __str__(self):\n    ' Returns the materialized path '\n    return ('/'.join([x.value for x in self.parts]) + ('/' if self.is_dir else ''))\n", "label": "Correct"}
{"function": "\n\ndef __str__(self):\n    ' Returns the materialized path '\n    return ('/'.join([x.value for x in x.parts]) + ('/' if self.is_dir else ''))\n", "label": "Variable misuse"}
{"function": "\n\ndef retry_subflow(self, retry):\n    'Prepares a retrys + its subgraph for execution.\\n\\n        This sets the retrys intention to ``EXECUTE`` and resets all of its\\n        subgraph (its successors) to the ``PENDING`` state with an ``EXECUTE``\\n        intention.\\n        '\n    tweaked = self.reset_atoms([retry], state=None, intention=st.EXECUTE)\n    tweaked.extend(self.reset_subgraph(retry))\n    return tweaked\n", "label": "Correct"}
{"function": "\n\ndef retry_subflow(self, retry):\n    'Prepares a retrys + its subgraph for execution.\\n\\n        This sets the retrys intention to ``EXECUTE`` and resets all of its\\n        subgraph (its successors) to the ``PENDING`` state with an ``EXECUTE``\\n        intention.\\n        '\n    tweaked = self.reset_atoms([retry], state=None, intention=st.EXECUTE)\n    tweaked.extend(retry.reset_subgraph(retry))\n    return tweaked\n", "label": "Variable misuse"}
{"function": "\n\ndef draw_random(G, **kwargs):\n    'Draw the graph G with a random layout.'\n    draw(G, random_layout(G), **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef draw_random(G, **kwargs):\n    'Draw the graph G with a random layout.'\n    draw(G, random_layout(kwargs), **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef post(self):\n    ' pass additionalMetadata and file to global\\n        variables.\\n        '\n    global received_file\n    global received_meta\n    received_file = self.request.files['file'][0].body\n    received_meta = self.get_argument('additionalMetadata')\n", "label": "Correct"}
{"function": "\n\ndef post(self):\n    ' pass additionalMetadata and file to global\\n        variables.\\n        '\n    global received_file\n    global received_meta\n    received_file = self.request.files['file'][0].body\n    received_meta = received_file.get_argument('additionalMetadata')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, gates, system_desc, wh_codes):\n    self.gates = gates\n    self.system_desc = system_desc\n    self.wh_codes = wh_codes\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, gates, system_desc, wh_codes):\n    self.gates = gates\n    self.system_desc = wh_codes\n    self.wh_codes = wh_codes\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, args):\n    super(RemoveVariantSetRunner, self).__init__(args)\n    self.variantSetName = args.variantSetName\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, args):\n    super(RemoveVariantSetRunner, self).__init__(args)\n    args.variantSetName = args.variantSetName\n", "label": "Variable misuse"}
{"function": "\n\n@override_djconfig(comments_per_page=1)\ndef test_profile_comments_paginate(self):\n    \"\\n        profile user's comments paginated\\n        \"\n    utils.create_comment(user=self.user2, topic=self.topic)\n    comment = utils.create_comment(user=self.user2, topic=self.topic)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:detail', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['comments']), [comment])\n", "label": "Correct"}
{"function": "\n\n@override_djconfig(comments_per_page=1)\ndef test_profile_comments_paginate(self):\n    \"\\n        profile user's comments paginated\\n        \"\n    utils.create_comment(user=self.user2, topic=self.topic)\n    comment = utils.create_comment(user=self.user2, topic=self.topic)\n    utils.login(comment)\n    response = self.client.get(reverse('spirit:user:detail', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['comments']), [comment])\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    self.maxDiff = None\n    filename = 'chart_data_labels24.xlsx'\n    test_dir = 'xlsxwriter/test/comparison/'\n    self.got_filename = ((test_dir + '_test_') + filename)\n    self.exp_filename = ((test_dir + 'xlsx_files/') + filename)\n    self.ignore_files = []\n    self.ignore_elements = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    self.maxDiff = None\n    filename = 'chart_data_labels24.xlsx'\n    test_dir = 'xlsxwriter/test/comparison/'\n    self.got_filename = ((test_dir + '_test_') + filename)\n    self.exp_filename = ((test_dir + 'xlsx_files/') + filename)\n    test_dir.ignore_files = []\n    self.ignore_elements = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef get_available_user_FIELD_transitions(instance, user, field):\n    '\\n    List of transitions available in current model state\\n    with all conditions met and user have rights on it\\n    '\n    for transition in get_available_FIELD_transitions(instance, field):\n        if transition.has_perm(instance, user):\n            (yield transition)\n", "label": "Correct"}
{"function": "\n\ndef get_available_user_FIELD_transitions(instance, user, field):\n    '\\n    List of transitions available in current model state\\n    with all conditions met and user have rights on it\\n    '\n    for transition in get_available_FIELD_transitions(instance, field):\n        if transition.has_perm(instance, user):\n            (yield instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef pixelCollision(rect1, rect2, hitmask1, hitmask2):\n    'Checks if two objects collide and not just their rects'\n    rect = rect1.clip(rect2)\n    if ((rect.width == 0) or (rect.height == 0)):\n        return False\n    (x1, y1) = ((rect.x - rect1.x), (rect.y - rect1.y))\n    (x2, y2) = ((rect.x - rect2.x), (rect.y - rect2.y))\n    for x in xrange(rect.width):\n        for y in xrange(rect.height):\n            if (hitmask1[(x1 + x)][(y1 + y)] and hitmask2[(x2 + x)][(y2 + y)]):\n                return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef pixelCollision(rect1, rect2, hitmask1, hitmask2):\n    'Checks if two objects collide and not just their rects'\n    rect = rect1.clip(rect2)\n    if ((rect.width == 0) or (rect.height == 0)):\n        return False\n    (x1, y1) = ((rect.x - rect.x), (rect.y - rect1.y))\n    (x2, y2) = ((rect.x - rect2.x), (rect.y - rect2.y))\n    for x in xrange(rect.width):\n        for y in xrange(rect.height):\n            if (hitmask1[(x1 + x)][(y1 + y)] and hitmask2[(x2 + x)][(y2 + y)]):\n                return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef create_initial_revisions(self, app, model_class, comment, batch_size, verbosity=2, database=None, **kwargs):\n    'Creates the set of initial revisions for the given model.'\n    try:\n        import_module(('%s.admin' % app.__name__.rsplit('.', 1)[0]))\n    except ImportError:\n        pass\n    if default_revision_manager.is_registered(model_class):\n        if (verbosity >= 2):\n            print(('Creating initial revision(s) for model %s ...' % force_text(model_class._meta.verbose_name)))\n        created_count = 0\n        content_type = ContentType.objects.db_manager(database).get_for_model(model_class)\n        versioned_pk_queryset = Version.objects.using(database).filter(content_type=content_type).all()\n        live_objs = model_class._default_manager.using(database).all()\n        if has_int_pk(model_class):\n            live_objs = live_objs.exclude(pk__in=versioned_pk_queryset.values_list('object_id_int', flat=True))\n        else:\n            live_objs = live_objs.exclude(pk__in=list(versioned_pk_queryset.values_list('object_id', flat=True).iterator()))\n        ids = list(live_objs.values_list(model_class._meta.pk.name, flat=True).order_by())\n        total = len(ids)\n        for i in range(0, total, batch_size):\n            chunked_ids = ids[i:(i + batch_size)]\n            objects = live_objs.in_bulk(chunked_ids)\n            for (id, obj) in objects.items():\n                try:\n                    default_revision_manager.save_revision((obj,), comment=comment, db=database)\n                except:\n                    print(('ERROR: Could not save initial version for %s %s.' % (model_class.__name__, obj.pk)))\n                    raise\n                created_count += 1\n            reset_queries()\n            if (verbosity >= 2):\n                print(('Created %s of %s.' % (created_count, total)))\n        if (verbosity >= 2):\n            print(('Created %s initial revision(s) for model %s.' % (created_count, force_text(model_class._meta.verbose_name))))\n    elif (verbosity >= 2):\n        print(('Model %s is not registered.' % force_text(model_class._meta.verbose_name)))\n", "label": "Correct"}
{"function": "\n\ndef create_initial_revisions(self, app, model_class, comment, batch_size, verbosity=2, database=None, **kwargs):\n    'Creates the set of initial revisions for the given model.'\n    try:\n        import_module(('%s.admin' % app.__name__.rsplit('.', 1)[0]))\n    except ImportError:\n        pass\n    if default_revision_manager.is_registered(model_class):\n        if (verbosity >= 2):\n            print(('Creating initial revision(s) for model %s ...' % force_text(model_class._meta.verbose_name)))\n        created_count = 0\n        content_type = ContentType.objects.db_manager(database).get_for_model(model_class)\n        versioned_pk_queryset = Version.objects.using(database).filter(content_type=content_type).all()\n        live_objs = model_class._default_manager.using(database).all()\n        if has_int_pk(model_class):\n            live_objs = live_objs.exclude(pk__in=versioned_pk_queryset.values_list('object_id_int', flat=True))\n        else:\n            live_objs = live_objs.exclude(pk__in=list(versioned_pk_queryset.values_list('object_id', flat=True).iterator()))\n        ids = list(live_objs.values_list(model_class._meta.pk.name, flat=True).order_by())\n        total = len(ids)\n        for i in range(0, total, batch_size):\n            chunked_ids = ids[versioned_pk_queryset:(i + batch_size)]\n            objects = live_objs.in_bulk(chunked_ids)\n            for (id, obj) in objects.items():\n                try:\n                    default_revision_manager.save_revision((obj,), comment=comment, db=database)\n                except:\n                    print(('ERROR: Could not save initial version for %s %s.' % (model_class.__name__, obj.pk)))\n                    raise\n                created_count += 1\n            reset_queries()\n            if (verbosity >= 2):\n                print(('Created %s of %s.' % (created_count, total)))\n        if (verbosity >= 2):\n            print(('Created %s initial revision(s) for model %s.' % (created_count, force_text(model_class._meta.verbose_name))))\n    elif (verbosity >= 2):\n        print(('Model %s is not registered.' % force_text(model_class._meta.verbose_name)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _item_position(self, item):\n    return self.items.index(item)\n", "label": "Correct"}
{"function": "\n\ndef _item_position(self, item):\n    return self.items.index(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef GetModifiedShellCommand(self, Command, PluginOutputDir):\n    self.RefreshReplacements()\n    NewCommand = ((('cd ' + self.ShellPathEscape(PluginOutputDir)) + '; ') + MultipleReplace(Command, self.DynamicReplacements))\n    self.OldCommands[NewCommand] = Command\n    return NewCommand\n", "label": "Correct"}
{"function": "\n\ndef GetModifiedShellCommand(self, Command, PluginOutputDir):\n    PluginOutputDir.RefreshReplacements()\n    NewCommand = ((('cd ' + self.ShellPathEscape(PluginOutputDir)) + '; ') + MultipleReplace(Command, self.DynamicReplacements))\n    self.OldCommands[NewCommand] = Command\n    return NewCommand\n", "label": "Variable misuse"}
{"function": "\n\ndef report_for_conf(self, conf):\n    'Returns the path to the ivy report for the provided conf.\\n\\n     Returns None if there is no path.\\n    '\n    return self._reports_by_conf.get(conf)\n", "label": "Correct"}
{"function": "\n\ndef report_for_conf(self, conf):\n    'Returns the path to the ivy report for the provided conf.\\n\\n     Returns None if there is no path.\\n    '\n    return conf._reports_by_conf.get(conf)\n", "label": "Variable misuse"}
{"function": "\n\ndef our_x2_iterates(n_iters=100):\n    history = []\n    searchspace = SearchSpace()\n    searchspace.add_float('x', (- 10), 10)\n    random = np.random.RandomState(0)\n\n    def fn(params):\n        return (- (params['x'] ** 2))\n    for i in range(n_iters):\n        params = HyperoptTPE(seed=random).suggest(history, searchspace)\n        history.append((params, fn(params), 'SUCCEEDED'))\n    return np.array([h[0]['x'] for h in history])\n", "label": "Correct"}
{"function": "\n\ndef our_x2_iterates(n_iters=100):\n    history = []\n    searchspace = SearchSpace()\n    searchspace.add_float('x', (- 10), 10)\n    random = np.random.RandomState(0)\n\n    def fn(params):\n        return (- (params['x'] ** 2))\n    for i in range(n_iters):\n        params = HyperoptTPE(seed=history).suggest(history, searchspace)\n        history.append((params, fn(params), 'SUCCEEDED'))\n    return np.array([h[0]['x'] for h in history])\n", "label": "Variable misuse"}
{"function": "\n\ndef insert(self, window, first_line, *lines):\n    (row, column) = cursor = self.cursors[window]\n    (left, right) = (self[row][:column], self[row][column:])\n    added = len(lines)\n    if lines:\n        last_line = lines[(- 1)]\n        column = len(last_line)\n    else:\n        last_line = first_line\n        column += len(first_line)\n    self[row] = (left + first_line)\n    self[(row + 1):(row + 1)] = lines\n    self[(row + added)] += right\n    for other in self.cursors.itervalues():\n        if (other.row > row):\n            other._row += added\n    cursor.coords = ((row + added), column)\n", "label": "Correct"}
{"function": "\n\ndef insert(self, window, first_line, *lines):\n    (row, column) = cursor = self.cursors[window]\n    (left, right) = (self[row][:column], self[row][column:])\n    added = len(lines)\n    if lines:\n        last_line = lines[(- 1)]\n        column = len(last_line)\n    else:\n        last_line = first_line\n        column += len(first_line)\n    self[row] = (left + first_line)\n    self[(row + 1):(added + 1)] = lines\n    self[(row + added)] += right\n    for other in self.cursors.itervalues():\n        if (other.row > row):\n            other._row += added\n    cursor.coords = ((row + added), column)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean_message(self):\n    message = self.cleaned_data['message']\n    try:\n        message = message.decode('base64')\n    except TypeError as e:\n        raise ValidationError(('Cannot convert to binary: %r' % e.msg))\n    if (len(message) % 16):\n        raise ValidationError('Wrong block size for message !')\n    if (len(message) <= 16):\n        raise ValidationError('Message too short or missing IV !')\n    return message\n", "label": "Correct"}
{"function": "\n\ndef clean_message(self):\n    message = self.cleaned_data['message']\n    try:\n        message = message.decode('base64')\n    except TypeError as e:\n        raise ValidationError(('Cannot convert to binary: %r' % e.msg))\n    if (len(message) % 16):\n        raise ValidationError('Wrong block size for message !')\n    if (len(message) <= 16):\n        raise ValidationError('Message too short or missing IV !')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@keep_alive('server')\ndef address_is_mine(self, address):\n    result = self.server.validateaddress(address)\n    return result['ismine']\n", "label": "Correct"}
{"function": "\n\n@keep_alive('server')\ndef address_is_mine(self, address):\n    result = self.server.validateaddress(address)\n    return self['ismine']\n", "label": "Variable misuse"}
{"function": "\n\ndef _bump_version(self, version):\n    try:\n        parts = map(int, version.split('.'))\n    except ValueError:\n        self._fail('Current version is not numeric')\n    parts[(- 1)] += 1\n    return '.'.join(map(str, parts))\n", "label": "Correct"}
{"function": "\n\ndef _bump_version(self, version):\n    try:\n        parts = map(int, version.split('.'))\n    except ValueError:\n        self._fail('Current version is not numeric')\n    version[(- 1)] += 1\n    return '.'.join(map(str, parts))\n", "label": "Variable misuse"}
{"function": "\n\ndef npm_command(self, args):\n    'Creates a command that can run `npm`, passing the given args to it.\\n\\n    :param list args: A list of arguments to pass to `npm`.\\n    :returns: An `npm` command that can be run later.\\n    :rtype: :class:`NodeDistribution.Command`\\n    '\n    return self._create_command('npm', args)\n", "label": "Correct"}
{"function": "\n\ndef npm_command(self, args):\n    'Creates a command that can run `npm`, passing the given args to it.\\n\\n    :param list args: A list of arguments to pass to `npm`.\\n    :returns: An `npm` command that can be run later.\\n    :rtype: :class:`NodeDistribution.Command`\\n    '\n    return self._create_command('npm', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_disenroll_with_no_enrollment(self):\n    courses = Course.objects.all()\n    for course in courses:\n        course.delete()\n    client = Client()\n    client.login(username=TEST_USER_USERNAME, password=TEST_USER_PASSWORD)\n    kwargs = {\n        'HTTP_X_REQUESTED_WITH': 'XMLHttpRequest',\n    }\n    response = client.post('/disenroll', {\n        'course_id': 1,\n    }, **kwargs)\n    self.assertEqual(response.status_code, 200)\n    json_string = response.content.decode(encoding='UTF-8')\n    array = json.loads(json_string)\n    self.assertEqual(array['message'], 'record does not exist')\n    self.assertEqual(array['status'], 'failed')\n", "label": "Correct"}
{"function": "\n\ndef test_disenroll_with_no_enrollment(self):\n    courses = Course.objects.all()\n    for course in courses:\n        course.delete()\n    client = Client()\n    client.login(username=TEST_USER_USERNAME, password=TEST_USER_PASSWORD)\n    kwargs = {\n        'HTTP_X_REQUESTED_WITH': 'XMLHttpRequest',\n    }\n    response = client.post('/disenroll', {\n        'course_id': 1,\n    }, **kwargs)\n    self.assertEqual(response.status_code, 200)\n    json_string = response.content.decode(encoding='UTF-8')\n    array = json.loads(json_string)\n    array.assertEqual(array['message'], 'record does not exist')\n    self.assertEqual(array['status'], 'failed')\n", "label": "Variable misuse"}
{"function": "\n\n@parameterized.expand([('split', 2, 3, 3, 1.5), ('merger', 2, 3, 3, 1.8), ('dividend', 2, 3, 3, 2.88)])\ndef test_spot_price_adjustments(self, adjustment_type, liquid_day_0_price, liquid_day_1_price, illiquid_day_0_price, illiquid_day_1_price_adjusted):\n    'Test the behaviour of spot prices during adjustments.'\n    table_name = (adjustment_type + 's')\n    liquid_asset = getattr(self, (adjustment_type.upper() + '_ASSET'))\n    illiquid_asset = getattr(self, (('ILLIQUID_' + adjustment_type.upper()) + '_ASSET'))\n    adjustments = self.adjustment_reader.get_adjustments_for_sid(table_name, liquid_asset.sid)\n    self.assertEqual(1, len(adjustments))\n    adjustment = adjustments[0]\n    self.assertEqual(adjustment[0], pd.Timestamp('2016-01-06', tz='UTC'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[0]), 'daily')\n    self.assertEqual(liquid_day_0_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(liquid_day_1_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(illiquid_day_0_price, bar_data.current(illiquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[2]), 'daily')\n    self.assertAlmostEqual(illiquid_day_1_price_adjusted, bar_data.current(illiquid_asset, 'price'))\n", "label": "Correct"}
{"function": "\n\n@parameterized.expand([('split', 2, 3, 3, 1.5), ('merger', 2, 3, 3, 1.8), ('dividend', 2, 3, 3, 2.88)])\ndef test_spot_price_adjustments(self, adjustment_type, liquid_day_0_price, liquid_day_1_price, illiquid_day_0_price, illiquid_day_1_price_adjusted):\n    'Test the behaviour of spot prices during adjustments.'\n    table_name = (adjustment_type + 's')\n    liquid_asset = getattr(self, (adjustment_type.upper() + '_ASSET'))\n    illiquid_asset = getattr(self, (('ILLIQUID_' + adjustment_type.upper()) + '_ASSET'))\n    adjustments = self.adjustment_reader.get_adjustments_for_sid(table_name, liquid_asset.sid)\n    self.assertEqual(1, len(adjustments))\n    adjustment = adjustments[0]\n    self.assertEqual(adjustment[0], pd.Timestamp('2016-01-06', tz='UTC'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[0]), 'daily')\n    self.assertEqual(liquid_day_0_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(liquid_day_1_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(bar_data, bar_data.current(illiquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[2]), 'daily')\n    self.assertAlmostEqual(illiquid_day_1_price_adjusted, bar_data.current(illiquid_asset, 'price'))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_ud(self, cardinal, user, channel, msg):\n    try:\n        word = msg.split(' ', 1)[1]\n    except IndexError:\n        cardinal.sendMsg(channel, 'Syntax: .ud <word>')\n        return\n    try:\n        url = (URBANDICT_API_PREFIX + word)\n        f = urlopen(url).read()\n        data = json.loads(f)\n        word_def = data['list'][0]['definition']\n        link = data['list'][0]['permalink']\n        response = ('UD for %s: %s (%s)' % (word, word_def, link))\n        cardinal.sendMsg(channel, response.encode('utf-8'))\n    except Exception:\n        cardinal.sendMsg(channel, ('Could not retrieve definition for %s' % word))\n", "label": "Correct"}
{"function": "\n\ndef get_ud(self, cardinal, user, channel, msg):\n    try:\n        word = msg.split(' ', 1)[1]\n    except IndexError:\n        cardinal.sendMsg(channel, 'Syntax: .ud <word>')\n        return\n    try:\n        url = (URBANDICT_API_PREFIX + word)\n        f = urlopen(url).read()\n        data = json.loads(link)\n        word_def = data['list'][0]['definition']\n        link = data['list'][0]['permalink']\n        response = ('UD for %s: %s (%s)' % (word, word_def, link))\n        cardinal.sendMsg(channel, response.encode('utf-8'))\n    except Exception:\n        cardinal.sendMsg(channel, ('Could not retrieve definition for %s' % word))\n", "label": "Variable misuse"}
{"function": "\n\ndef test__merge(self):\n    seg1a = fake_neo(Block, seed=self.seed1, n=self.nchildren).segments[0]\n    assert_same_sub_schema(self.seg1, seg1a)\n    seg1a.spikes.append(self.spikes2[0])\n    seg1a.epocharrays.append(self.epcas2[0])\n    seg1a.annotate(seed=self.seed2)\n    seg1a.merge(self.seg2)\n    self.check_creation(self.seg2)\n    assert_same_sub_schema((self.sigs1a + self.sigs2), seg1a.analogsignals)\n    assert_same_sub_schema((self.sigarrs1a + self.sigarrs2), seg1a.analogsignalarrays)\n    assert_same_sub_schema((self.irsigs1a + self.irsigs2), seg1a.irregularlysampledsignals)\n    assert_same_sub_schema((self.epcs1 + self.epcs2), seg1a.epochs)\n    assert_same_sub_schema((self.epcas1 + self.epcas2), seg1a.epocharrays)\n    assert_same_sub_schema((self.evts1 + self.evts2), seg1a.events)\n    assert_same_sub_schema((self.evtas1 + self.evtas2), seg1a.eventarrays)\n    assert_same_sub_schema((self.spikes1 + self.spikes2), seg1a.spikes)\n    assert_same_sub_schema((self.trains1 + self.trains2), seg1a.spiketrains)\n", "label": "Correct"}
{"function": "\n\ndef test__merge(self):\n    seg1a = fake_neo(Block, seed=self.seed1, n=self.nchildren).segments[0]\n    assert_same_sub_schema(self.seg1, seg1a)\n    seg1a.spikes.append(self.spikes2[0])\n    seg1a.epocharrays.append(self.epcas2[0])\n    seg1a.annotate(seed=self.seed2)\n    seg1a.merge(self.seg2)\n    self.check_creation(self.seg2)\n    assert_same_sub_schema((self.sigs1a + self.sigs2), seg1a.analogsignals)\n    assert_same_sub_schema((self.sigarrs1a + self.sigarrs2), seg1a.analogsignalarrays)\n    assert_same_sub_schema((self.irsigs1a + self.irsigs2), seg1a.irregularlysampledsignals)\n    assert_same_sub_schema((self.epcs1 + self.epcs2), seg1a.epochs)\n    assert_same_sub_schema((self.epcas1 + self.epcas2), seg1a.epocharrays)\n    assert_same_sub_schema((self.evts1 + self.evts2), self.events)\n    assert_same_sub_schema((self.evtas1 + self.evtas2), seg1a.eventarrays)\n    assert_same_sub_schema((self.spikes1 + self.spikes2), seg1a.spikes)\n    assert_same_sub_schema((self.trains1 + self.trains2), seg1a.spiketrains)\n", "label": "Variable misuse"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    (ishape, fshape) = shapes\n    (igroups, icolors_per_group, irows, icols, icount) = ishape\n    (fmodulesR, fmodulesC, fcolors, frows, fcols) = fshape[:(- 2)]\n    (fgroups, filters_per_group) = fshape[(- 2):]\n    if ((not any_symbolic(irows, icols)) and (irows != icols)):\n        raise ValueError('non-square image argument', (irows, icols))\n    if ((not any_symbolic(frows, fcols)) and (frows != fcols)):\n        raise ValueError('non-square filter shape', (frows, fcols))\n    if ((not any_symbolic(fmodulesR, fmodulesC)) and (fmodulesR != fmodulesC)):\n        raise ValueError('non-square filter grouping', (fmodulesR, fmodulesC))\n    if ((not any_symbolic(icolors_per_group, fcolors)) and (icolors_per_group != fcolors)):\n        raise ValueError(\"color counts don't match\", (icolors_per_group, fcolors))\n    hshape = (fgroups, filters_per_group, fmodulesR, fmodulesC, icount)\n    return [hshape]\n", "label": "Correct"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    (ishape, fshape) = shapes\n    (igroups, icolors_per_group, irows, icols, icount) = ishape\n    (fmodulesR, fmodulesC, fcolors, frows, fcols) = fshape[:(- 2)]\n    (fgroups, filters_per_group) = fshape[(- 2):]\n    if ((not any_symbolic(irows, icols)) and (irows != icols)):\n        raise ValueError('non-square image argument', (irows, icols))\n    if ((not any_symbolic(frows, fcols)) and (frows != fcols)):\n        raise ValueError('non-square filter shape', (frows, fcols))\n    if ((not any_symbolic(fmodulesR, fmodulesC)) and (fmodulesR != fmodulesC)):\n        raise ValueError('non-square filter grouping', (fmodulesR, fmodulesC))\n    if ((not any_symbolic(icolors_per_group, fcolors)) and (icolors_per_group != fcolors)):\n        raise ValueError(\"color counts don't match\", (self, fcolors))\n    hshape = (fgroups, filters_per_group, fmodulesR, fmodulesC, icount)\n    return [hshape]\n", "label": "Variable misuse"}
{"function": "\n\ndef store_and_use_artifact(self, cache_key, src, results_dir=None):\n    'Read the content of a tarball from an iterator and return an artifact stored in the cache.'\n    with self._tmpfile(cache_key, 'read') as tmp:\n        for chunk in src:\n            tmp.write(chunk)\n        tmp.close()\n        tarball = self._store_tarball(cache_key, tmp.name)\n        artifact = self._artifact(tarball)\n        if (results_dir is not None):\n            safe_rmtree(results_dir)\n        artifact.extract()\n        return True\n", "label": "Correct"}
{"function": "\n\ndef store_and_use_artifact(self, cache_key, src, results_dir=None):\n    'Read the content of a tarball from an iterator and return an artifact stored in the cache.'\n    with self._tmpfile(cache_key, 'read') as tmp:\n        for chunk in src:\n            tmp.write(chunk)\n        tmp.close()\n        tarball = chunk._store_tarball(cache_key, tmp.name)\n        artifact = self._artifact(tarball)\n        if (results_dir is not None):\n            safe_rmtree(results_dir)\n        artifact.extract()\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef __str__(self):\n    return ('Tuple(%s)' % ', '.join((str(elt) for elt in self.elts)))\n", "label": "Correct"}
{"function": "\n\ndef __str__(self):\n    return ('Tuple(%s)' % ', '.join((str(self) for elt in self.elts)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_ticket_ticket(self):\n    '\\n        A ticket ought to be created with a provided ticket string,\\n        if present.\\n        '\n    ticket = 'ST-0000000000-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n    st = ServiceTicket.objects.create_ticket(ticket=ticket, user=self.user)\n    self.assertEqual(st.ticket, ticket)\n", "label": "Correct"}
{"function": "\n\ndef test_create_ticket_ticket(self):\n    '\\n        A ticket ought to be created with a provided ticket string,\\n        if present.\\n        '\n    ticket = 'ST-0000000000-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n    st = ServiceTicket.objects.create_ticket(ticket=ticket, user=ticket.user)\n    self.assertEqual(st.ticket, ticket)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_binary_infix_operators(self):\n    (a, b, h) = self.table.get_columns(['a', 'b', 'h'])\n    bool_col = (a > 0)\n    cases = [((a + b), '`a` + `b`'), ((a - b), '`a` - `b`'), ((a * b), '`a` * `b`'), ((a / b), '`a` / `b`'), ((a ** b), 'pow(`a`, `b`)'), ((a < b), '`a` < `b`'), ((a <= b), '`a` <= `b`'), ((a > b), '`a` > `b`'), ((a >= b), '`a` >= `b`'), ((a == b), '`a` = `b`'), ((a != b), '`a` != `b`'), ((h & bool_col), '`h` AND (`a` > 0)'), ((h | bool_col), '`h` OR (`a` > 0)'), ((h ^ bool_col), '(`h` OR (`a` > 0)) AND NOT (`h` AND (`a` > 0))')]\n    self._check_expr_cases(cases)\n", "label": "Correct"}
{"function": "\n\ndef test_binary_infix_operators(self):\n    (a, b, h) = bool_col.table.get_columns(['a', 'b', 'h'])\n    bool_col = (a > 0)\n    cases = [((a + b), '`a` + `b`'), ((a - b), '`a` - `b`'), ((a * b), '`a` * `b`'), ((a / b), '`a` / `b`'), ((a ** b), 'pow(`a`, `b`)'), ((a < b), '`a` < `b`'), ((a <= b), '`a` <= `b`'), ((a > b), '`a` > `b`'), ((a >= b), '`a` >= `b`'), ((a == b), '`a` = `b`'), ((a != b), '`a` != `b`'), ((h & bool_col), '`h` AND (`a` > 0)'), ((h | bool_col), '`h` OR (`a` > 0)'), ((h ^ bool_col), '(`h` OR (`a` > 0)) AND NOT (`h` AND (`a` > 0))')]\n    self._check_expr_cases(cases)\n", "label": "Variable misuse"}
{"function": "\n\ndef kalman_filter(y, U, A, V, mu0, Cov0, out=None):\n    '\\n    Perform Kalman filtering to obtain filtered mean and covariance.\\n\\n    The parameters of the process may vary in time, thus they are\\n    given as iterators instead of fixed values.\\n\\n    Parameters\\n    ----------\\n    y : (N,D) array\\n        \"Normalized\" noisy observations of the states, that is, the\\n        observations multiplied by the precision matrix U (and possibly\\n        other transformation matrices).\\n    U : (N,D,D) array or N-list of (D,D) arrays\\n        Precision matrix (i.e., inverse covariance matrix) of the observation \\n        noise for each time instance.\\n    A : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Dynamic matrix for each time instance.\\n    V : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Covariance matrix of the innovation noise for each time instance.\\n\\n    Returns\\n    -------\\n    mu : array\\n        Filtered mean of the states.\\n    Cov : array\\n        Filtered covariance of the states.\\n\\n    See also\\n    --------\\n    rts_smoother\\n    '\n    mu = mu0\n    Cov = Cov0\n    (N, D) = np.shape(y)\n    X = np.empty((N, D))\n    CovX = np.empty((N, D, D))\n    M = (np.dot(np.dot(Cov, U[0]), Cov) + Cov)\n    L = linalg.chol(M)\n    mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[0]) + mu)))\n    Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n    X[0, :] = mu\n    CovX[0, :, :] = Cov\n    for n in range((len(y) - 1)):\n        mu = np.dot(A[n], mu)\n        Cov = (np.dot(np.dot(A[n], Cov), A[n].T) + V[n])\n        M = (np.dot(np.dot(Cov, U[(n + 1)]), Cov) + Cov)\n        L = linalg.chol(M)\n        mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[(n + 1)]) + mu)))\n        Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n        Cov = ((0.5 * Cov) + (0.5 * Cov.T))\n        X[(n + 1), :] = mu\n        CovX[(n + 1), :, :] = Cov\n    return (X, CovX)\n", "label": "Correct"}
{"function": "\n\ndef kalman_filter(y, U, A, V, mu0, Cov0, out=None):\n    '\\n    Perform Kalman filtering to obtain filtered mean and covariance.\\n\\n    The parameters of the process may vary in time, thus they are\\n    given as iterators instead of fixed values.\\n\\n    Parameters\\n    ----------\\n    y : (N,D) array\\n        \"Normalized\" noisy observations of the states, that is, the\\n        observations multiplied by the precision matrix U (and possibly\\n        other transformation matrices).\\n    U : (N,D,D) array or N-list of (D,D) arrays\\n        Precision matrix (i.e., inverse covariance matrix) of the observation \\n        noise for each time instance.\\n    A : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Dynamic matrix for each time instance.\\n    V : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Covariance matrix of the innovation noise for each time instance.\\n\\n    Returns\\n    -------\\n    mu : array\\n        Filtered mean of the states.\\n    Cov : array\\n        Filtered covariance of the states.\\n\\n    See also\\n    --------\\n    rts_smoother\\n    '\n    mu = mu0\n    Cov = Cov0\n    (N, D) = np.shape(y)\n    X = np.empty((N, D))\n    CovX = np.empty((N, D, D))\n    M = (np.dot(np.dot(Cov, U[0]), Cov) + Cov)\n    L = linalg.chol(M)\n    mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[0]) + mu)))\n    Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n    X[0, :] = mu\n    CovX[0, :, :] = Cov\n    for n in range((len(y) - 1)):\n        mu = np.dot(A[n], mu)\n        Cov = (np.dot(np.dot(A[n], Cov), A[n].T) + V[n])\n        M = (np.dot(np.dot(Cov, U[(n + 1)]), Cov) + Cov)\n        L = linalg.chol(M)\n        mu = np.dot(y, linalg.chol_solve(L, (np.dot(Cov, y[(n + 1)]) + mu)))\n        Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n        Cov = ((0.5 * Cov) + (0.5 * Cov.T))\n        X[(n + 1), :] = mu\n        CovX[(n + 1), :, :] = Cov\n    return (X, CovX)\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (other is None):\n        return (self._value is None)\n    other = str(other)\n    if (other not in self.values_range):\n        raise ConanException(bad_value_msg(self._name, other, self.values_range))\n    return (other == self.__str__())\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (other is None):\n        return (self._value is None)\n    other = str(other)\n    if (other not in self.values_range):\n        raise ConanException(bad_value_msg(self._name, other, self.values_range))\n    return (self == self.__str__())\n", "label": "Variable misuse"}
{"function": "\n\ndef _set_play_state(self, state):\n    'Helper method for play/pause/toggle.'\n    players = self._get_players()\n    if (len(players) != 0):\n        self._server.Player.PlayPause(players[0]['playerid'], state)\n    self.update_ha_state()\n", "label": "Correct"}
{"function": "\n\ndef _set_play_state(self, state):\n    'Helper method for play/pause/toggle.'\n    players = self._get_players()\n    if (len(players) != 0):\n        self._server.Player.PlayPause(players[0]['playerid'], self)\n    self.update_ha_state()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_multiple_sequences(self):\n    msa = TabularMSA([DNA('ACGT'), DNA('AG-.'), DNA('AC-.')])\n    cons = msa.consensus()\n    self.assertEqual(cons, DNA('AC--'))\n", "label": "Correct"}
{"function": "\n\ndef test_multiple_sequences(self):\n    msa = TabularMSA([DNA('ACGT'), DNA('AG-.'), DNA('AC-.')])\n    cons = msa.consensus()\n    msa.assertEqual(cons, DNA('AC--'))\n", "label": "Variable misuse"}
{"function": "\n\ndef appletGetDetails(*args, **kwargs):\n    '\\n\\n    .. deprecated:: 0.42.0\\n       Use :func:`applet_get_details()` instead.\\n\\n    '\n    print('dxpy.appletGetDetails is deprecated; please use applet_get_details instead.', file=sys.stderr)\n    return applet_get_details(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef appletGetDetails(*args, **kwargs):\n    '\\n\\n    .. deprecated:: 0.42.0\\n       Use :func:`applet_get_details()` instead.\\n\\n    '\n    print('dxpy.appletGetDetails is deprecated; please use applet_get_details instead.', file=sys.stderr)\n    return applet_get_details(*kwargs, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef _prepare_ivy_xml(self, frozen_resolution, ivyxml, resolve_hash_name_for_report):\n    default_resolution = frozen_resolution.get('default')\n    if (default_resolution is None):\n        raise IvyUtils.IvyError(\"Couldn't find the frozen resolution for the 'default' ivy conf.\")\n    try:\n        jars = default_resolution.jar_dependencies\n        IvyUtils.generate_fetch_ivy(jars, ivyxml, self.confs, resolve_hash_name_for_report)\n    except Exception as e:\n        raise IvyUtils.IvyError('Failed to prepare ivy resolve: {}'.format(e))\n", "label": "Correct"}
{"function": "\n\ndef _prepare_ivy_xml(self, frozen_resolution, ivyxml, resolve_hash_name_for_report):\n    default_resolution = frozen_resolution.get('default')\n    if (default_resolution is None):\n        raise IvyUtils.IvyError(\"Couldn't find the frozen resolution for the 'default' ivy conf.\")\n    try:\n        jars = default_resolution.jar_dependencies\n        IvyUtils.generate_fetch_ivy(default_resolution, ivyxml, self.confs, resolve_hash_name_for_report)\n    except Exception as e:\n        raise IvyUtils.IvyError('Failed to prepare ivy resolve: {}'.format(e))\n", "label": "Variable misuse"}
{"function": "\n\n@continuation\ndef imp_struct_set_cont(orig_struct, setter, field, app, env, cont, _vals):\n    from pycket.interpreter import check_one_val\n    val = check_one_val(_vals)\n    if (setter is values.w_false):\n        return orig_struct.set_with_extra_info(field, val, app, env, cont)\n    return setter.call_with_extra_info([orig_struct, val], env, cont, app)\n", "label": "Correct"}
{"function": "\n\n@continuation\ndef imp_struct_set_cont(orig_struct, setter, field, app, env, cont, _vals):\n    from pycket.interpreter import check_one_val\n    val = check_one_val(_vals)\n    if (setter is values.w_false):\n        return orig_struct.set_with_extra_info(field, val, orig_struct, env, cont)\n    return setter.call_with_extra_info([orig_struct, val], env, cont, app)\n", "label": "Variable misuse"}
{"function": "\n\ndef _do_if_else_condition(self, condition):\n    '\\n        Common logic for evaluating the conditions on #if, #ifdef and\\n        #ifndef lines.\\n        '\n    self.save()\n    d = self.dispatch_table\n    if condition:\n        self.start_handling_includes()\n        d['elif'] = self.stop_handling_includes\n        d['else'] = self.stop_handling_includes\n    else:\n        self.stop_handling_includes()\n        d['elif'] = self.do_elif\n        d['else'] = self.start_handling_includes\n", "label": "Correct"}
{"function": "\n\ndef _do_if_else_condition(self, condition):\n    '\\n        Common logic for evaluating the conditions on #if, #ifdef and\\n        #ifndef lines.\\n        '\n    self.save()\n    d = self.dispatch_table\n    if condition:\n        self.start_handling_includes()\n        d['elif'] = self.stop_handling_includes\n        d['else'] = self.stop_handling_includes\n    else:\n        condition.stop_handling_includes()\n        d['elif'] = self.do_elif\n        d['else'] = self.start_handling_includes\n", "label": "Variable misuse"}
{"function": "\n\ndef loadWordFile(self, pre_processor=None):\n    filename = self.getDictionaryPath()\n    with codecs.open(filename, 'r', 'utf-8') as fp:\n        for word in fp.readlines():\n            if pre_processor:\n                self.add(pre_processor(word.strip()))\n            else:\n                self.add(word.strip())\n    return\n", "label": "Correct"}
{"function": "\n\ndef loadWordFile(self, pre_processor=None):\n    filename = self.getDictionaryPath()\n    with codecs.open(filename, 'r', 'utf-8') as fp:\n        for word in fp.readlines():\n            if word:\n                self.add(pre_processor(word.strip()))\n            else:\n                self.add(word.strip())\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef test_level(self):\n    key = EncryptionKey(data='', level='SL3')\n    self.assertEquals('SL3', key.level)\n", "label": "Correct"}
{"function": "\n\ndef test_level(self):\n    key = EncryptionKey(data='', level='SL3')\n    key.assertEquals('SL3', key.level)\n", "label": "Variable misuse"}
{"function": "\n\ndef __setitem__(self, key, value):\n    'Dictionary style assignment.'\n    (rval, cval) = self.value_encode(value)\n    self.__set(key, rval, cval)\n", "label": "Correct"}
{"function": "\n\ndef __setitem__(self, key, value):\n    'Dictionary style assignment.'\n    (rval, cval) = key.value_encode(value)\n    self.__set(key, rval, cval)\n", "label": "Variable misuse"}
{"function": "\n\n@sig((((H / ((H / 'a') >> bool)) >> ['a']) >> [int]))\ndef findIndicies(f, xs):\n    '\\n    findIndices :: (a -> Bool) -> [a] -> [Int]\\n\\n    The findIndices function extends findIndex, by returning the indices of all\\n    elements satisfying the predicate, in ascending order.\\n    '\n    return L[(i for (i, x) in enumerate(xs) if f(x))]\n", "label": "Correct"}
{"function": "\n\n@sig((((H / ((H / 'a') >> bool)) >> ['a']) >> [int]))\ndef findIndicies(f, xs):\n    '\\n    findIndices :: (a -> Bool) -> [a] -> [Int]\\n\\n    The findIndices function extends findIndex, by returning the indices of all\\n    elements satisfying the predicate, in ascending order.\\n    '\n    return L[(i for (i, x) in enumerate(xs) if f(i))]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, mediator=None):\n    'Initializes the scanner object.\\n\\n    Args:\\n      mediator: a volume scanner mediator (instance of\\n                VolumeScannerMediator) or None.\\n    '\n    super(VolumeScanner, self).__init__()\n    self._mediator = mediator\n    self._source_path = None\n    self._source_scanner = source_scanner.SourceScanner()\n    self._source_type = None\n    self._vss_stores = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, mediator=None):\n    'Initializes the scanner object.\\n\\n    Args:\\n      mediator: a volume scanner mediator (instance of\\n                VolumeScannerMediator) or None.\\n    '\n    super(VolumeScanner, self).__init__()\n    self._mediator = mediator\n    self._source_path = None\n    self._source_scanner = source_scanner.SourceScanner()\n    self._source_type = None\n    mediator._vss_stores = None\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_active_nodes(self, is_running=None):\n    if self.active_gen_id:\n        return self.get_all_nodes(self.active_gen_id, is_running=is_running)\n    return []\n", "label": "Correct"}
{"function": "\n\ndef get_all_active_nodes(self, is_running=None):\n    if self.active_gen_id:\n        return self.get_all_nodes(self.active_gen_id, is_running=self)\n    return []\n", "label": "Variable misuse"}
{"function": "\n\ndef test_basic_start(self):\n    configjson = self.experiment.do_start_experiment()\n    self.assertIsNotNone(configjson)\n", "label": "Correct"}
{"function": "\n\ndef test_basic_start(self):\n    configjson = self.experiment.do_start_experiment()\n    self.assertIsNotNone(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_options_disallowed(self):\n    request = factory.options('/', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = root_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n    request = factory.options('/1', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = instance_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n", "label": "Correct"}
{"function": "\n\ndef test_options_disallowed(self):\n    request = factory.options('/', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = root_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    request.assertNotIn('actions', response.data)\n    request = factory.options('/1', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = instance_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n", "label": "Variable misuse"}
{"function": "\n\ndef test__build_key_none(self):\n    result = filecache._build_key(None, None)\n    self.assertEqual('None:None', result)\n", "label": "Correct"}
{"function": "\n\ndef test__build_key_none(self):\n    result = filecache._build_key(None, None)\n    result.assertEqual('None:None', result)\n", "label": "Variable misuse"}
{"function": "\n\ndef _option_required(self, key):\n    conf = S3_CONF.copy()\n    del conf[key]\n    try:\n        self.store = Store(test_utils.TestConfigOpts(conf))\n        return (self.store.add == self.store.add_disabled)\n    except:\n        return False\n    return False\n", "label": "Correct"}
{"function": "\n\ndef _option_required(self, key):\n    conf = S3_CONF.copy()\n    del conf[key]\n    try:\n        self.store = Store(test_utils.TestConfigOpts(conf))\n        return (self.store.add == key.store.add_disabled)\n    except:\n        return False\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef show_analyzer_list_panel(self, callback):\n    list_panel = AnalyzerListPanel(self.window, self.client, self.settings.index)\n    list_panel.show(callback)\n", "label": "Correct"}
{"function": "\n\ndef show_analyzer_list_panel(self, callback):\n    list_panel = AnalyzerListPanel(callback.window, self.client, self.settings.index)\n    list_panel.show(callback)\n", "label": "Variable misuse"}
{"function": "\n\ndef clone_settings(self, original):\n    self.replace_tabs_by_spaces = original.replace_tabs_by_spaces\n    self.safe_save = original.replace_tabs_by_spaces\n    self.clean_trailing_whitespaces = original.clean_trailing_whitespaces\n    self.restore_cursor = original.restore_cursor\n", "label": "Correct"}
{"function": "\n\ndef clone_settings(self, original):\n    self.replace_tabs_by_spaces = original.replace_tabs_by_spaces\n    original.safe_save = original.replace_tabs_by_spaces\n    self.clean_trailing_whitespaces = original.clean_trailing_whitespaces\n    self.restore_cursor = original.restore_cursor\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_verified_address(self, address):\n    if (address in self.addresses):\n        return True\n    (user, host) = address.split('@', 1)\n    return (host in self.domains)\n", "label": "Correct"}
{"function": "\n\ndef _is_verified_address(self, address):\n    if (address in self.addresses):\n        return True\n    (user, host) = self.split('@', 1)\n    return (host in self.domains)\n", "label": "Variable misuse"}
{"function": "\n\ndef deserialize(self, raw_value):\n    if (raw_value.upper() in self.TRUE_RAW_VALUES):\n        return True\n    elif (raw_value.upper() in self.FALSE_RAW_VALUES):\n        return False\n    else:\n        raise DeserializationError('Value \"{}\" must be one of {} for \"{}\"!'.format(raw_value, self.ALLOWED_RAW_VALUES, self.name), raw_value, self.name)\n", "label": "Correct"}
{"function": "\n\ndef deserialize(self, raw_value):\n    if (raw_value.upper() in raw_value.TRUE_RAW_VALUES):\n        return True\n    elif (raw_value.upper() in self.FALSE_RAW_VALUES):\n        return False\n    else:\n        raise DeserializationError('Value \"{}\" must be one of {} for \"{}\"!'.format(raw_value, self.ALLOWED_RAW_VALUES, self.name), raw_value, self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_service_command(self, name, command):\n    command_table = self.create_command_table(command.get('subcommands', {\n        \n    }), self._create_operation_command)\n    service_command = ServiceCommand(name, None)\n    service_command._service_model = {\n        \n    }\n    service_command._command_table = command_table\n    return service_command\n", "label": "Correct"}
{"function": "\n\ndef _create_service_command(self, name, command):\n    command_table = self.create_command_table(command.get('subcommands', {\n        \n    }), name._create_operation_command)\n    service_command = ServiceCommand(name, None)\n    service_command._service_model = {\n        \n    }\n    service_command._command_table = command_table\n    return service_command\n", "label": "Variable misuse"}
{"function": "\n\n@override_settings(DEFAULT_FROM_EMAIL='foo@bar.com')\ndef test_sender_from_email(self):\n    '\\n        Should use DEFAULT_FROM_EMAIL instead of the default\\n        '\n\n    class SiteMock():\n        name = 'foo'\n        domain = 'bar.com'\n\n    def monkey_get_current_site(*args, **kw):\n        return SiteMock\n\n    def monkey_render_to_string(*args, **kw):\n        return 'email body'\n    req = RequestFactory().get('/')\n    token = 'token'\n    subject = SiteMock.name\n    template_name = 'template.html'\n    context = {\n        'user_id': self.user.pk,\n        'token': token,\n    }\n    (org_site, email.get_current_site) = (email.get_current_site, monkey_get_current_site)\n    (org_render_to_string, email.render_to_string) = (email.render_to_string, monkey_render_to_string)\n    try:\n        sender(req, subject, template_name, context, [self.user.email])\n    finally:\n        email.get_current_site = org_site\n        email.render_to_string = org_render_to_string\n    self.assertEquals(len(mail.outbox), 1)\n    self.assertEquals(mail.outbox[0].from_email, 'foo@bar.com')\n", "label": "Correct"}
{"function": "\n\n@override_settings(DEFAULT_FROM_EMAIL='foo@bar.com')\ndef test_sender_from_email(self):\n    '\\n        Should use DEFAULT_FROM_EMAIL instead of the default\\n        '\n\n    class SiteMock():\n        name = 'foo'\n        domain = 'bar.com'\n\n    def monkey_get_current_site(*args, **kw):\n        return SiteMock\n\n    def monkey_render_to_string(*args, **kw):\n        return 'email body'\n    req = RequestFactory().get('/')\n    token = 'token'\n    subject = SiteMock.name\n    template_name = 'template.html'\n    context = {\n        'user_id': self.user.pk,\n        'token': token,\n    }\n    (org_site, email.get_current_site) = (email.get_current_site, monkey_get_current_site)\n    (org_render_to_string, email.render_to_string) = (email.render_to_string, monkey_render_to_string)\n    try:\n        sender(req, subject, template_name, context, [self.user.email])\n    finally:\n        email.get_current_site = org_site\n        email.render_to_string = subject\n    self.assertEquals(len(mail.outbox), 1)\n    self.assertEquals(mail.outbox[0].from_email, 'foo@bar.com')\n", "label": "Variable misuse"}
{"function": "\n\ndef extract_info(self, body):\n    '\\n        Extract metadata url\\n        '\n    xhr_url_match = re.search(self._XHR_REQUEST_PATH, body)\n    if (xhr_url_match is not None):\n        xhr_url = xhr_url_match.group(1)\n    else:\n        xhr_url = None\n    if ((xhr_url is not None) and xhr_url.endswith('xml')):\n        default_filename = xhr_url.split('/')[1]\n    else:\n        self.error(ExtractionError, \"ERROR: can't get default_filename.\")\n    return {\n        'default_filename': default_filename,\n        'xhr_url': xhr_url,\n    }\n", "label": "Correct"}
{"function": "\n\ndef extract_info(self, body):\n    '\\n        Extract metadata url\\n        '\n    xhr_url_match = re.search(self._XHR_REQUEST_PATH, xhr_url)\n    if (xhr_url_match is not None):\n        xhr_url = xhr_url_match.group(1)\n    else:\n        xhr_url = None\n    if ((xhr_url is not None) and xhr_url.endswith('xml')):\n        default_filename = xhr_url.split('/')[1]\n    else:\n        self.error(ExtractionError, \"ERROR: can't get default_filename.\")\n    return {\n        'default_filename': default_filename,\n        'xhr_url': xhr_url,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_content_length_0(self):\n\n    class ContentLengthChecker(list):\n\n        def __init__(self):\n            list.__init__(self)\n            self.content_length = None\n\n        def append(self, item):\n            kv = item.split(b':', 1)\n            if ((len(kv) > 1) and (kv[0].lower() == b'content-length')):\n                self.content_length = kv[1].strip()\n            list.append(self, item)\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('POST', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('PUT', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n", "label": "Correct"}
{"function": "\n\ndef test_content_length_0(self):\n\n    class ContentLengthChecker(list):\n\n        def __init__(self):\n            list.__init__(self)\n            self.content_length = None\n\n        def append(self, item):\n            kv = item.split(b':', 1)\n            if ((len(kv) > 1) and (kv[0].lower() == b'content-length')):\n                self.content_length = kv[1].strip()\n            list.append(self, item)\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('POST', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('PUT', '/', '')\n    conn.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n", "label": "Variable misuse"}
{"function": "\n\ndef WriteScanNode(self, scan_node, indentation=''):\n    'Writes the source scanner node to stdout.\\n\\n    Args:\\n      scan_node: the scan node (instance of SourceScanNode).\\n      indentation: optional indentation string.\\n      scan_step: optional integer indicating the scan step.\\n    '\n    if (not scan_node):\n        return\n    values = []\n    part_index = getattr(scan_node.path_spec, 'part_index', None)\n    if (part_index is not None):\n        values.append('{0:d}'.format(part_index))\n    store_index = getattr(scan_node.path_spec, 'store_index', None)\n    if (store_index is not None):\n        values.append('{0:d}'.format(store_index))\n    start_offset = getattr(scan_node.path_spec, 'start_offset', None)\n    if (start_offset is not None):\n        values.append('start offset: {0:d} (0x{0:08x})'.format(start_offset))\n    location = getattr(scan_node.path_spec, 'location', None)\n    if (location is not None):\n        values.append('location: {0:s}'.format(location))\n    print('{0:s}{1:s}: {2:s}'.format(indentation, scan_node.path_spec.type_indicator, ', '.join(values)))\n    indentation = '  {0:s}'.format(indentation)\n    for sub_scan_node in scan_node.sub_nodes:\n        self.WriteScanNode(sub_scan_node, indentation=indentation)\n", "label": "Correct"}
{"function": "\n\ndef WriteScanNode(self, scan_node, indentation=''):\n    'Writes the source scanner node to stdout.\\n\\n    Args:\\n      scan_node: the scan node (instance of SourceScanNode).\\n      indentation: optional indentation string.\\n      scan_step: optional integer indicating the scan step.\\n    '\n    if (not scan_node):\n        return\n    values = []\n    part_index = getattr(scan_node.path_spec, 'part_index', None)\n    if (values is not None):\n        values.append('{0:d}'.format(part_index))\n    store_index = getattr(scan_node.path_spec, 'store_index', None)\n    if (store_index is not None):\n        values.append('{0:d}'.format(store_index))\n    start_offset = getattr(scan_node.path_spec, 'start_offset', None)\n    if (start_offset is not None):\n        values.append('start offset: {0:d} (0x{0:08x})'.format(start_offset))\n    location = getattr(scan_node.path_spec, 'location', None)\n    if (location is not None):\n        values.append('location: {0:s}'.format(location))\n    print('{0:s}{1:s}: {2:s}'.format(indentation, scan_node.path_spec.type_indicator, ', '.join(values)))\n    indentation = '  {0:s}'.format(indentation)\n    for sub_scan_node in scan_node.sub_nodes:\n        self.WriteScanNode(sub_scan_node, indentation=indentation)\n", "label": "Variable misuse"}
{"function": "\n\ndef deserialize(self, obj):\n    return datetime.datetime.strptime(obj, self.format).time()\n", "label": "Correct"}
{"function": "\n\ndef deserialize(self, obj):\n    return datetime.datetime.strptime(self, self.format).time()\n", "label": "Variable misuse"}
{"function": "\n\ndef seek(self, offset, whence=os.SEEK_SET):\n    'Seek to the provided location in the file.\\n\\n        :param offset: location to seek to\\n        :type offset: int\\n        :param whence: determines whether `offset` represents a\\n                       location that is absolute, relative to the\\n                       beginning of the file, or relative to the end\\n                       of the file\\n        :type whence: os.SEEK_SET | os.SEEK_CUR | os.SEEK_END\\n        :returns: None\\n        :rtype: None\\n        '\n    if (whence == os.SEEK_SET):\n        self._cursor = (0 + offset)\n    elif (whence == os.SEEK_CUR):\n        self._cursor += offset\n    elif (whence == os.SEEK_END):\n        self._cursor = (self.size() + offset)\n    else:\n        raise ValueError('Unexpected value for `whence`: {}'.format(whence))\n", "label": "Correct"}
{"function": "\n\ndef seek(self, offset, whence=os.SEEK_SET):\n    'Seek to the provided location in the file.\\n\\n        :param offset: location to seek to\\n        :type offset: int\\n        :param whence: determines whether `offset` represents a\\n                       location that is absolute, relative to the\\n                       beginning of the file, or relative to the end\\n                       of the file\\n        :type whence: os.SEEK_SET | os.SEEK_CUR | os.SEEK_END\\n        :returns: None\\n        :rtype: None\\n        '\n    if (whence == os.SEEK_SET):\n        self._cursor = (0 + offset)\n    elif (whence == os.SEEK_CUR):\n        self._cursor += offset\n    elif (whence == os.SEEK_END):\n        self._cursor = (whence.size() + offset)\n    else:\n        raise ValueError('Unexpected value for `whence`: {}'.format(whence))\n", "label": "Variable misuse"}
{"function": "\n\ndef assert_compile(self, clause, result, params=None, checkparams=None, dialect=None, checkpositional=None, check_prefetch=None, use_default_dialect=False, allow_dialect_select=False, literal_binds=False, schema_translate_map=None):\n    if use_default_dialect:\n        dialect = default.DefaultDialect()\n    elif allow_dialect_select:\n        dialect = None\n    else:\n        if (dialect is None):\n            dialect = getattr(self, '__dialect__', None)\n        if (dialect is None):\n            dialect = config.db.dialect\n        elif (dialect == 'default'):\n            dialect = default.DefaultDialect()\n        elif (dialect == 'default_enhanced'):\n            dialect = default.StrCompileDialect()\n        elif isinstance(dialect, util.string_types):\n            dialect = url.URL(dialect).get_dialect()()\n    kw = {\n        \n    }\n    compile_kwargs = {\n        \n    }\n    if schema_translate_map:\n        kw['schema_translate_map'] = schema_translate_map\n    if (params is not None):\n        kw['column_keys'] = list(params)\n    if literal_binds:\n        compile_kwargs['literal_binds'] = True\n    if isinstance(clause, orm.Query):\n        context = clause._compile_context()\n        context.statement.use_labels = True\n        clause = context.statement\n    if compile_kwargs:\n        kw['compile_kwargs'] = compile_kwargs\n    c = clause.compile(dialect=dialect, **kw)\n    param_str = repr(getattr(c, 'params', {\n        \n    }))\n    if util.py3k:\n        param_str = param_str.encode('utf-8').decode('ascii', 'ignore')\n        print((('\\nSQL String:\\n' + util.text_type(c)) + param_str).encode('utf-8'))\n    else:\n        print((('\\nSQL String:\\n' + util.text_type(c).encode('utf-8')) + param_str))\n    cc = re.sub('[\\\\n\\\\t]', '', util.text_type(c))\n    eq_(cc, result, ('%r != %r on dialect %r' % (cc, result, dialect)))\n    if (checkparams is not None):\n        eq_(c.construct_params(params), checkparams)\n    if (checkpositional is not None):\n        p = c.construct_params(params)\n        eq_(tuple([p[x] for x in c.positiontup]), checkpositional)\n    if (check_prefetch is not None):\n        eq_(c.prefetch, check_prefetch)\n", "label": "Correct"}
{"function": "\n\ndef assert_compile(self, clause, result, params=None, checkparams=None, dialect=None, checkpositional=None, check_prefetch=None, use_default_dialect=False, allow_dialect_select=False, literal_binds=False, schema_translate_map=None):\n    if use_default_dialect:\n        dialect = default.DefaultDialect()\n    elif allow_dialect_select:\n        dialect = None\n    else:\n        if (dialect is None):\n            dialect = getattr(self, '__dialect__', None)\n        if (dialect is None):\n            dialect = config.db.dialect\n        elif (dialect == 'default'):\n            dialect = default.DefaultDialect()\n        elif (dialect == 'default_enhanced'):\n            dialect = default.StrCompileDialect()\n        elif isinstance(dialect, util.string_types):\n            dialect = url.URL(dialect).get_dialect()()\n    kw = {\n        \n    }\n    compile_kwargs = {\n        \n    }\n    if schema_translate_map:\n        kw['schema_translate_map'] = schema_translate_map\n    if (params is not None):\n        kw['column_keys'] = list(params)\n    if literal_binds:\n        compile_kwargs['literal_binds'] = True\n    if isinstance(clause, orm.Query):\n        context = clause._compile_context()\n        context.statement.use_labels = True\n        clause = context.statement\n    if compile_kwargs:\n        kw['compile_kwargs'] = compile_kwargs\n    c = clause.compile(dialect=dialect, **kw)\n    param_str = repr(getattr(c, 'params', {\n        \n    }))\n    if util.py3k:\n        param_str = param_str.encode('utf-8').decode('ascii', 'ignore')\n        print((('\\nSQL String:\\n' + util.text_type(c)) + param_str).encode('utf-8'))\n    else:\n        print((('\\nSQL String:\\n' + util.text_type(c).encode('utf-8')) + param_str))\n    cc = re.sub('[\\\\n\\\\t]', '', util.text_type(c))\n    eq_(cc, result, ('%r != %r on dialect %r' % (use_default_dialect, result, dialect)))\n    if (checkparams is not None):\n        eq_(c.construct_params(params), checkparams)\n    if (checkpositional is not None):\n        p = c.construct_params(params)\n        eq_(tuple([p[x] for x in c.positiontup]), checkpositional)\n    if (check_prefetch is not None):\n        eq_(c.prefetch, check_prefetch)\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_is_infinite(self):\n    if any((a.is_infinite for a in self.args)):\n        if any((a.is_zero for a in self.args)):\n            return S.NaN.is_infinite\n        if any(((a.is_zero is None) for a in self.args)):\n            return None\n        return True\n", "label": "Correct"}
{"function": "\n\ndef _eval_is_infinite(self):\n    if any((a.is_infinite for a in self.args)):\n        if any((a.is_zero for a in self.args)):\n            return S.NaN.is_infinite\n        if any(((a.is_zero is None) for a in a.args)):\n            return None\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef create_security_groups(self):\n    for hostdef in self.blueprint.host_definitions.all():\n        sg_name = 'stackdio-managed-{0}-stack-{1}'.format(hostdef.slug, self.pk)\n        sg_description = 'stackd.io managed security group'\n        account = hostdef.cloud_image.account\n        if (not account.create_security_groups):\n            logger.debug('Skipping creation of {0} because security group creation is turned off for the account'.format(sg_name))\n            continue\n        driver = account.get_driver()\n        try:\n            sg_id = driver.create_security_group(sg_name, sg_description, delete_if_exists=True)\n        except Exception as e:\n            err_msg = 'Error creating security group: {0}'.format(str(e))\n            self.set_status('create_security_groups', self.ERROR, err_msg, Level.ERROR)\n        logger.debug('Created security group {0}: {1}'.format(sg_name, sg_id))\n        for access_rule in hostdef.access_rules.all():\n            driver.authorize_security_group(sg_id, {\n                'protocol': access_rule.protocol,\n                'from_port': access_rule.from_port,\n                'to_port': access_rule.to_port,\n                'rule': access_rule.rule,\n            })\n        self.security_groups.create(account=account, blueprint_host_definition=hostdef, name=sg_name, description=sg_description, group_id=sg_id, is_managed=True)\n", "label": "Correct"}
{"function": "\n\ndef create_security_groups(self):\n    for hostdef in self.blueprint.host_definitions.all():\n        sg_name = 'stackdio-managed-{0}-stack-{1}'.format(hostdef.slug, self.pk)\n        sg_description = 'stackd.io managed security group'\n        account = hostdef.cloud_image.account\n        if (not account.create_security_groups):\n            logger.debug('Skipping creation of {0} because security group creation is turned off for the account'.format(sg_name))\n            continue\n        driver = account.get_driver()\n        try:\n            sg_id = driver.create_security_group(sg_name, sg_description, delete_if_exists=True)\n        except Exception as e:\n            err_msg = 'Error creating security group: {0}'.format(str(e))\n            self.set_status('create_security_groups', self.ERROR, err_msg, Level.ERROR)\n        logger.debug('Created security group {0}: {1}'.format(sg_name, sg_id))\n        for access_rule in hostdef.access_rules.all():\n            driver.authorize_security_group(sg_id, {\n                'protocol': access_rule.protocol,\n                'from_port': access_rule.from_port,\n                'to_port': access_rule.to_port,\n                'rule': access_rule.rule,\n            })\n        self.security_groups.create(account=account, blueprint_host_definition=hostdef, name=sg_name, description=hostdef, group_id=sg_id, is_managed=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_perturb_inv(self):\n    pmat = perturb_inv(closure(self.cdata1), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    pmat = perturb_inv(closure(self.cdata1), closure([1, 1, 1]))\n    npt.assert_allclose(pmat, closure([[0.2, 0.2, 0.6], [0.4, 0.4, 0.2]]))\n    pmat = perturb_inv(closure(self.cdata5), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    with self.assertRaises(ValueError):\n        perturb_inv(closure(self.cdata1), self.bad1)\n    perturb_inv(self.cdata2, [1, 2, 3])\n    npt.assert_allclose(self.cdata2, np.array([2, 2, 6]))\n", "label": "Correct"}
{"function": "\n\ndef test_perturb_inv(self):\n    pmat = perturb_inv(closure(self.cdata1), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(self, imat)\n    pmat = perturb_inv(closure(self.cdata1), closure([1, 1, 1]))\n    npt.assert_allclose(pmat, closure([[0.2, 0.2, 0.6], [0.4, 0.4, 0.2]]))\n    pmat = perturb_inv(closure(self.cdata5), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    with self.assertRaises(ValueError):\n        perturb_inv(closure(self.cdata1), self.bad1)\n    perturb_inv(self.cdata2, [1, 2, 3])\n    npt.assert_allclose(self.cdata2, np.array([2, 2, 6]))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_style(self, attribute):\n    \"Get the document's named style at the caret's current position.\\n\\n        If there is a text selection and the style varies over the selection,\\n        `pyglet.text.document.STYLE_INDETERMINATE` is returned.\\n\\n        :Parameters:\\n            `attribute` : str\\n                Name of style attribute to retrieve.  See\\n                `pyglet.text.document` for a list of recognised attribute\\n                names.\\n\\n        :rtype: object\\n        \"\n    if ((self._mark is None) or (self._mark == self._position)):\n        try:\n            return self._next_attributes[attribute]\n        except KeyError:\n            return self._layout.document.get_style(attribute, self._position)\n    start = min(self._position, self._mark)\n    end = max(self._position, self._mark)\n    return self._layout.document.get_style_range(attribute, start, end)\n", "label": "Correct"}
{"function": "\n\ndef get_style(self, attribute):\n    \"Get the document's named style at the caret's current position.\\n\\n        If there is a text selection and the style varies over the selection,\\n        `pyglet.text.document.STYLE_INDETERMINATE` is returned.\\n\\n        :Parameters:\\n            `attribute` : str\\n                Name of style attribute to retrieve.  See\\n                `pyglet.text.document` for a list of recognised attribute\\n                names.\\n\\n        :rtype: object\\n        \"\n    if ((self._mark is None) or (self._mark == self._position)):\n        try:\n            return self._next_attributes[attribute]\n        except KeyError:\n            return self._layout.document.get_style(attribute, self._position)\n    start = min(self._position, self._mark)\n    end = max(self._position, self._mark)\n    return self._layout.document.get_style_range(attribute, start, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, feature=None):\n    if (not current_app):\n        log.warn(\"Got a request to check for {feature} but we're outside the request context. Returning False\".format(feature=feature))\n        return False\n    try:\n        return self.model.check(feature)\n    except NoResultFound:\n        raise NoFeatureFlagFound()\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, feature=None):\n    if (not current_app):\n        log.warn(\"Got a request to check for {feature} but we're outside the request context. Returning False\".format(feature=self))\n        return False\n    try:\n        return self.model.check(feature)\n    except NoResultFound:\n        raise NoFeatureFlagFound()\n", "label": "Variable misuse"}
{"function": "\n\ndef run_and_expect(self, joined_params, retcode, extra_args=['--local-scheduler', '--no-lock']):\n    with self.assertRaises(SystemExit) as cm:\n        luigi_run((joined_params.split(' ') + extra_args))\n    self.assertEqual(cm.exception.code, retcode)\n", "label": "Correct"}
{"function": "\n\ndef run_and_expect(self, joined_params, retcode, extra_args=['--local-scheduler', '--no-lock']):\n    with self.assertRaises(SystemExit) as cm:\n        luigi_run((joined_params.split(' ') + extra_args))\n    extra_args.assertEqual(cm.exception.code, retcode)\n", "label": "Variable misuse"}
{"function": "\n\ndef process(self, value):\n    return format_date_time_sqlite(value)\n", "label": "Correct"}
{"function": "\n\ndef process(self, value):\n    return format_date_time_sqlite(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef populate_link(self, finder, upgrade):\n    'Ensure that if a link can be found for this, that it is found.\\n\\n        Note that self.link may still be None - if Upgrade is False and the\\n        requirement is already installed.\\n        '\n    if (self.link is None):\n        self.link = finder.find_requirement(self, upgrade)\n", "label": "Correct"}
{"function": "\n\ndef populate_link(self, finder, upgrade):\n    'Ensure that if a link can be found for this, that it is found.\\n\\n        Note that self.link may still be None - if Upgrade is False and the\\n        requirement is already installed.\\n        '\n    if (upgrade.link is None):\n        self.link = finder.find_requirement(self, upgrade)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_list_display_links(self, request, list_display):\n    '\\n        Return a sequence containing the fields to be displayed as links\\n        on the changelist. The list_display parameter is the list of fields\\n        returned by get_list_display().\\n        '\n    if (self.list_display_links or (self.list_display_links is None) or (not list_display)):\n        return self.list_display_links\n    else:\n        return list(list_display)[:1]\n", "label": "Correct"}
{"function": "\n\ndef get_list_display_links(self, request, list_display):\n    '\\n        Return a sequence containing the fields to be displayed as links\\n        on the changelist. The list_display parameter is the list of fields\\n        returned by get_list_display().\\n        '\n    if (self.list_display_links or (self.list_display_links is None) or (not request)):\n        return self.list_display_links\n    else:\n        return list(list_display)[:1]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, canvas, pf, config):\n    super(Win32CanvasConfig, self).__init__(canvas, config)\n    self._pf = pf\n    self._pfd = PIXELFORMATDESCRIPTOR()\n    _gdi32.DescribePixelFormat(canvas.hdc, self._pf, sizeof(PIXELFORMATDESCRIPTOR), byref(self._pfd))\n    self.double_buffer = bool((self._pfd.dwFlags & PFD_DOUBLEBUFFER))\n    self.sample_buffers = 0\n    self.samples = 0\n    self.stereo = bool((self._pfd.dwFlags & PFD_STEREO))\n    self.buffer_size = self._pfd.cColorBits\n    self.red_size = self._pfd.cRedBits\n    self.green_size = self._pfd.cGreenBits\n    self.blue_size = self._pfd.cBlueBits\n    self.alpha_size = self._pfd.cAlphaBits\n    self.accum_red_size = self._pfd.cAccumRedBits\n    self.accum_green_size = self._pfd.cAccumGreenBits\n    self.accum_blue_size = self._pfd.cAccumBlueBits\n    self.accum_alpha_size = self._pfd.cAccumAlphaBits\n    self.depth_size = self._pfd.cDepthBits\n    self.stencil_size = self._pfd.cStencilBits\n    self.aux_buffers = self._pfd.cAuxBuffers\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, canvas, pf, config):\n    super(Win32CanvasConfig, self).__init__(canvas, config)\n    self._pf = pf\n    self._pfd = PIXELFORMATDESCRIPTOR()\n    _gdi32.DescribePixelFormat(canvas.hdc, self._pf, sizeof(PIXELFORMATDESCRIPTOR), byref(self._pfd))\n    self.double_buffer = bool((self._pfd.dwFlags & PFD_DOUBLEBUFFER))\n    self.sample_buffers = 0\n    self.samples = 0\n    self.stereo = bool((self._pfd.dwFlags & PFD_STEREO))\n    self.buffer_size = self._pfd.cColorBits\n    self.red_size = self._pfd.cRedBits\n    self.green_size = self._pfd.cGreenBits\n    config.blue_size = self._pfd.cBlueBits\n    self.alpha_size = self._pfd.cAlphaBits\n    self.accum_red_size = self._pfd.cAccumRedBits\n    self.accum_green_size = self._pfd.cAccumGreenBits\n    self.accum_blue_size = self._pfd.cAccumBlueBits\n    self.accum_alpha_size = self._pfd.cAccumAlphaBits\n    self.depth_size = self._pfd.cDepthBits\n    self.stencil_size = self._pfd.cStencilBits\n    self.aux_buffers = self._pfd.cAuxBuffers\n", "label": "Variable misuse"}
{"function": "\n\ndef merge_bins(distribution, limit):\n    'Merges the bins of a regression distribution to the given limit number\\n\\n    '\n    length = len(distribution)\n    if ((limit < 1) or (length <= limit) or (length < 2)):\n        return distribution\n    index_to_merge = 2\n    shortest = float('inf')\n    for index in range(1, length):\n        distance = (distribution[index][0] - distribution[(index - 1)][0])\n        if (distance < shortest):\n            shortest = distance\n            index_to_merge = index\n    new_distribution = distribution[:(index_to_merge - 1)]\n    left = distribution[(index_to_merge - 1)]\n    right = distribution[index_to_merge]\n    new_bin = [(((left[0] * left[1]) + (right[0] * right[1])) / (left[1] + right[1])), (left[1] + right[1])]\n    new_distribution.append(new_bin)\n    if (index_to_merge < (length - 1)):\n        new_distribution.extend(distribution[(index_to_merge + 1):])\n    return merge_bins(new_distribution, limit)\n", "label": "Correct"}
{"function": "\n\ndef merge_bins(distribution, limit):\n    'Merges the bins of a regression distribution to the given limit number\\n\\n    '\n    length = len(distribution)\n    if ((limit < 1) or (length <= limit) or (length < 2)):\n        return shortest\n    index_to_merge = 2\n    shortest = float('inf')\n    for index in range(1, length):\n        distance = (distribution[index][0] - distribution[(index - 1)][0])\n        if (distance < shortest):\n            shortest = distance\n            index_to_merge = index\n    new_distribution = distribution[:(index_to_merge - 1)]\n    left = distribution[(index_to_merge - 1)]\n    right = distribution[index_to_merge]\n    new_bin = [(((left[0] * left[1]) + (right[0] * right[1])) / (left[1] + right[1])), (left[1] + right[1])]\n    new_distribution.append(new_bin)\n    if (index_to_merge < (length - 1)):\n        new_distribution.extend(distribution[(index_to_merge + 1):])\n    return merge_bins(new_distribution, limit)\n", "label": "Variable misuse"}
{"function": "\n\ndef __set_db_what(self, what):\n    self._db_what = what\n    self.is_dirty = True\n", "label": "Correct"}
{"function": "\n\ndef __set_db_what(self, what):\n    what._db_what = what\n    self.is_dirty = True\n", "label": "Variable misuse"}
{"function": "\n\ndef extendMarkdown(self, md, md_globals):\n    ' Replace subscript with SubscriptPattern '\n    md.inlinePatterns.add('subscript', SimpleTagPattern(SUBSCRIPT_RE, 'sub'), '<not_strong')\n", "label": "Correct"}
{"function": "\n\ndef extendMarkdown(self, md, md_globals):\n    ' Replace subscript with SubscriptPattern '\n    self.inlinePatterns.add('subscript', SimpleTagPattern(SUBSCRIPT_RE, 'sub'), '<not_strong')\n", "label": "Variable misuse"}
{"function": "\n\ndef _services_dns_createRecord_php_WITH_EXTRA_PARAMS(self, method, url, body, headers):\n    body = self.fixtures.load('create_record_WITH_EXTRA_PARAMS.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _services_dns_createRecord_php_WITH_EXTRA_PARAMS(self, method, url, body, headers):\n    body = body.fixtures.load('create_record_WITH_EXTRA_PARAMS.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\n@defer.inlineCallbacks\ndef test_GetMoreCount(self):\n    counter = _CallCounter(MongoClientProtocol.send_GETMORE)\n    self.patch(MongoClientProtocol, 'send_GETMORE', counter)\n    (yield self.coll.insert([{\n        'x': 42,\n    } for _ in range(20)]))\n    result = (yield self.coll.find({\n        \n    }, limit=10))\n    self.assertEqual(len(result), 10)\n    self.assertEqual(counter.call_count, 0)\n", "label": "Correct"}
{"function": "\n\n@defer.inlineCallbacks\ndef test_GetMoreCount(self):\n    counter = _CallCounter(MongoClientProtocol.send_GETMORE)\n    self.patch(MongoClientProtocol, 'send_GETMORE', counter)\n    (yield self.coll.insert([{\n        'x': 42,\n    } for _ in range(20)]))\n    result = (yield self.coll.find({\n        \n    }, limit=10))\n    counter.assertEqual(len(result), 10)\n    self.assertEqual(counter.call_count, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef print_selection(self, *e):\n    if (self._root is None):\n        return\n    if (self._selection is None):\n        tkinter.messagebox.showerror('Print Error', 'No tree selected')\n    else:\n        c = self._cframe.canvas()\n        for widget in self._treewidgets:\n            if (widget is not self._selection):\n                self._cframe.destroy_widget(widget)\n        c.delete(self._selectbox)\n        (x1, y1, x2, y2) = self._selection.bbox()\n        self._selection.move((10 - x1), (10 - y1))\n        c['scrollregion'] = ('0 0 %s %s' % (((x2 - x1) + 20), ((y2 - y1) + 20)))\n        self._cframe.print_to_file()\n        self._treewidgets = [self._selection]\n        self.clear()\n        self.update()\n", "label": "Correct"}
{"function": "\n\ndef print_selection(self, *e):\n    if (self._root is None):\n        return\n    if (self._selection is None):\n        tkinter.messagebox.showerror('Print Error', 'No tree selected')\n    else:\n        c = self._cframe.canvas()\n        for widget in self._treewidgets:\n            if (widget is not self._selection):\n                c._cframe.destroy_widget(widget)\n        c.delete(self._selectbox)\n        (x1, y1, x2, y2) = self._selection.bbox()\n        self._selection.move((10 - x1), (10 - y1))\n        c['scrollregion'] = ('0 0 %s %s' % (((x2 - x1) + 20), ((y2 - y1) + 20)))\n        self._cframe.print_to_file()\n        self._treewidgets = [self._selection]\n        self.clear()\n        self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef smart_split(text):\n    '\\n    Generator that splits a string by spaces, leaving quoted phrases together.\\n    Supports both single and double quotes, and supports escaping quotes with\\n    backslashes. In the output, strings will keep their initial and trailing\\n    quote marks and escaped quotes will remain escaped (the results can then\\n    be further processed with unescape_string_literal()).\\n\\n    >>> list(smart_split(r\\'This is \"a person\\\\\\'s\" test.\\'))\\n    [\\'This\\', \\'is\\', \\'\"a person\\\\\\\\\\\\\\'s\"\\', \\'test.\\']\\n    >>> list(smart_split(r\"Another \\'person\\\\\\'s\\' test.\"))\\n    [\\'Another\\', \"\\'person\\\\\\\\\\'s\\'\", \\'test.\\']\\n    >>> list(smart_split(r\\'A \"\\\\\"funky\\\\\" style\" test.\\'))\\n    [\\'A\\', \\'\"\\\\\\\\\"funky\\\\\\\\\" style\"\\', \\'test.\\']\\n    '\n    text = force_text(text)\n    for bit in smart_split_re.finditer(text):\n        (yield bit.group(0))\n", "label": "Correct"}
{"function": "\n\ndef smart_split(text):\n    '\\n    Generator that splits a string by spaces, leaving quoted phrases together.\\n    Supports both single and double quotes, and supports escaping quotes with\\n    backslashes. In the output, strings will keep their initial and trailing\\n    quote marks and escaped quotes will remain escaped (the results can then\\n    be further processed with unescape_string_literal()).\\n\\n    >>> list(smart_split(r\\'This is \"a person\\\\\\'s\" test.\\'))\\n    [\\'This\\', \\'is\\', \\'\"a person\\\\\\\\\\\\\\'s\"\\', \\'test.\\']\\n    >>> list(smart_split(r\"Another \\'person\\\\\\'s\\' test.\"))\\n    [\\'Another\\', \"\\'person\\\\\\\\\\'s\\'\", \\'test.\\']\\n    >>> list(smart_split(r\\'A \"\\\\\"funky\\\\\" style\" test.\\'))\\n    [\\'A\\', \\'\"\\\\\\\\\"funky\\\\\\\\\" style\"\\', \\'test.\\']\\n    '\n    text = force_text(text)\n    for bit in smart_split_re.finditer(bit):\n        (yield bit.group(0))\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.parametrize('model_class', (ModelWithVanillaMoneyField, ModelWithChoicesMoneyField))\ndef test_currency_querying(self, model_class):\n    model_class.objects.create(money=Money('100.0', moneyed.ZWN))\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.USD)).count() == 0)\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.ZWN)).count() == 1)\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.parametrize('model_class', (ModelWithVanillaMoneyField, ModelWithChoicesMoneyField))\ndef test_currency_querying(self, model_class):\n    model_class.objects.create(money=Money('100.0', moneyed.ZWN))\n    assert (self.objects.filter(money__lt=Money('1000', moneyed.USD)).count() == 0)\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.ZWN)).count() == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    return shapes\n", "label": "Correct"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef handle(self, *args, **options):\n    quiet = options.get('quiet', False)\n    codes = self.get_codes()\n    if (not quiet):\n        if codes:\n            self.stdout.write(('Will now delete codes: %s \\n' % codes))\n        else:\n            self.stdout.write('No Object codes to delete. \\n')\n    revisions = self.get_revisions()\n    if (not quiet):\n        if codes:\n            self.stdout.write((\"Will now delete additional doc's revisions in docs: %s \\n\" % [d[0] for d in revisions]))\n        else:\n            self.stdout.write('No additional revision files to delete. \\n')\n    if (codes or revisions):\n        processor = core.document_processor.DocumentProcessor()\n        user = User.objects.filter(is_superuser=True)[0]\n        for code in codes:\n            processor.delete(code, {\n                'user': user,\n            })\n            if (not processor.errors):\n                if (not quiet):\n                    self.stdout.write(('Permanently deleted object with code: %s' % code))\n            else:\n                if (not quiet):\n                    self.stdout.write(processor.errors)\n                raise (Exception, processor.errors)\n        for rev in revisions:\n            processor.delete(rev[0], {\n                'user': user,\n                'delete_revision': rev[1],\n            })\n", "label": "Correct"}
{"function": "\n\ndef handle(self, *args, **options):\n    quiet = options.get('quiet', False)\n    codes = self.get_codes()\n    if (not quiet):\n        if codes:\n            self.stdout.write(('Will now delete codes: %s \\n' % codes))\n        else:\n            self.stdout.write('No Object codes to delete. \\n')\n    revisions = self.get_revisions()\n    if (not quiet):\n        if codes:\n            self.stdout.write((\"Will now delete additional doc's revisions in docs: %s \\n\" % [d[0] for d in revisions]))\n        else:\n            self.stdout.write('No additional revision files to delete. \\n')\n    if (codes or revisions):\n        processor = core.document_processor.DocumentProcessor()\n        user = User.objects.filter(is_superuser=True)[0]\n        for code in codes:\n            processor.delete(code, {\n                'user': user,\n            })\n            if (not rev.errors):\n                if (not quiet):\n                    self.stdout.write(('Permanently deleted object with code: %s' % code))\n            else:\n                if (not quiet):\n                    self.stdout.write(processor.errors)\n                raise (Exception, processor.errors)\n        for rev in revisions:\n            processor.delete(rev[0], {\n                'user': user,\n                'delete_revision': rev[1],\n            })\n", "label": "Variable misuse"}
{"function": "\n\ndef put(self, key, value):\n    ' Updates or inserts data for a specified key '\n    url = ((self.base_url + '/') + str(key))\n    headers = {\n        'content-type': 'application/json',\n    }\n    jvalue = jsonpickle.encode(value)\n    data = self.session.put(url, data=jvalue, headers=headers)\n    logging.debug(('Sending request to ' + url))\n    if (data.status_code == 200):\n        logging.debug(((('The value ' + str(value)) + ' was put in the region for the key ') + str(key)))\n        return True\n    else:\n        self.error_response(data)\n", "label": "Correct"}
{"function": "\n\ndef put(self, key, value):\n    ' Updates or inserts data for a specified key '\n    url = ((self.base_url + '/') + str(key))\n    headers = {\n        'content-type': 'application/json',\n    }\n    jvalue = jsonpickle.encode(value)\n    data = self.session.put(jvalue, data=jvalue, headers=headers)\n    logging.debug(('Sending request to ' + url))\n    if (data.status_code == 200):\n        logging.debug(((('The value ' + str(value)) + ' was put in the region for the key ') + str(key)))\n        return True\n    else:\n        self.error_response(data)\n", "label": "Variable misuse"}
{"function": "\n\ndef utcoffset(self, dt):\n    'Returns minutesEast from the constructor, as a datetime.timedelta.'\n    return self.offset\n", "label": "Correct"}
{"function": "\n\ndef utcoffset(self, dt):\n    'Returns minutesEast from the constructor, as a datetime.timedelta.'\n    return dt.offset\n", "label": "Variable misuse"}
{"function": "\n\ndef tearDown(self):\n    for fname in os.listdir(self.tempdir):\n        os.remove(os.path.join(self.tempdir, fname))\n    os.rmdir(self.tempdir)\n", "label": "Correct"}
{"function": "\n\ndef tearDown(self):\n    for fname in os.listdir(self.tempdir):\n        os.remove(os.path.join(self.tempdir, fname))\n    os.rmdir(fname.tempdir)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef responses(self):\n    return [response for (request, response) in self.data]\n", "label": "Correct"}
{"function": "\n\n@property\ndef responses(self):\n    return [response for (request, response) in response.data]\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_hdfs_workflow_dir(self, where, job):\n    constructed_dir = ('/user/%s/' % self.get_hdfs_user())\n    constructed_dir = self._add_postfix(constructed_dir)\n    constructed_dir += ('%s/%s' % (job.name, six.text_type(uuid.uuid4())))\n    with remote.get_remote(where) as r:\n        self.create_hdfs_dir(r, constructed_dir)\n    return constructed_dir\n", "label": "Correct"}
{"function": "\n\ndef _create_hdfs_workflow_dir(self, where, job):\n    constructed_dir = ('/user/%s/' % self.get_hdfs_user())\n    constructed_dir = constructed_dir._add_postfix(constructed_dir)\n    constructed_dir += ('%s/%s' % (job.name, six.text_type(uuid.uuid4())))\n    with remote.get_remote(where) as r:\n        self.create_hdfs_dir(r, constructed_dir)\n    return constructed_dir\n", "label": "Variable misuse"}
{"function": "\n\ndef _delegate_getter(self, object, name):\n    return getattr(self.delegate, self.name)\n", "label": "Correct"}
{"function": "\n\ndef _delegate_getter(self, object, name):\n    return getattr(name.delegate, self.name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('pushmanager.servlets.testtag.urllib2.urlopen')\ndef test_generate_test_tag_no_url(self, mock_urlopen):\n    m = mock.Mock()\n    m.read.side_effect = ['{\"tag\" : \"tag 0 fails\"}', '{\"url\" : \"\"}']\n    mock_urlopen.return_value = m\n    MockedSettings['tests_tag'] = {\n        \n    }\n    MockedSettings['tests_tag']['tag'] = 'test'\n    MockedSettings['tests_tag']['tag_api_endpoint'] = 'example.com'\n    MockedSettings['tests_tag']['tag_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_api_endpoint'] = 'http://example.com/api/v1/test_results_url'\n    MockedSettings['tests_tag']['url_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_tmpl'] = 'www.example.com/%ID%'\n    request_info = {\n        'tags': 'test',\n        'branch': 'test',\n        'revision': 'abc123',\n    }\n    with mock.patch.dict(Settings, MockedSettings):\n        gen_tags = TestTagServlet._gen_test_tag_resp(request_info)\n        T.assert_equals({\n            'tag': 'tag 0 fails',\n            'url': '',\n        }, gen_tags)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('pushmanager.servlets.testtag.urllib2.urlopen')\ndef test_generate_test_tag_no_url(self, mock_urlopen):\n    m = mock.Mock()\n    m.read.side_effect = ['{\"tag\" : \"tag 0 fails\"}', '{\"url\" : \"\"}']\n    mock_urlopen.return_value = self\n    MockedSettings['tests_tag'] = {\n        \n    }\n    MockedSettings['tests_tag']['tag'] = 'test'\n    MockedSettings['tests_tag']['tag_api_endpoint'] = 'example.com'\n    MockedSettings['tests_tag']['tag_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_api_endpoint'] = 'http://example.com/api/v1/test_results_url'\n    MockedSettings['tests_tag']['url_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_tmpl'] = 'www.example.com/%ID%'\n    request_info = {\n        'tags': 'test',\n        'branch': 'test',\n        'revision': 'abc123',\n    }\n    with mock.patch.dict(Settings, MockedSettings):\n        gen_tags = TestTagServlet._gen_test_tag_resp(request_info)\n        T.assert_equals({\n            'tag': 'tag 0 fails',\n            'url': '',\n        }, gen_tags)\n", "label": "Variable misuse"}
{"function": "\n\ndef _process_element(self, element):\n    'Process first level element of the stream.\\n\\n        The element may be stream error or features, StartTLS\\n        request/response, SASL request/response or a stanza.\\n\\n        :Parameters:\\n            - `element`: XML element\\n        :Types:\\n            - `element`: :etree:`ElementTree.Element`\\n        '\n    tag = element.tag\n    if (tag in self._element_handlers):\n        handler = self._element_handlers[tag]\n        logger.debug('Passing element {0!r} to method {1!r}'.format(element, handler))\n        handled = handler(self, element)\n        if handled:\n            return\n    if tag.startswith(self._stanza_namespace_p):\n        stanza = stanza_factory(element, self, self.language)\n        self.uplink_receive(stanza)\n    elif (tag == ERROR_TAG):\n        error = StreamErrorElement(element)\n        self.process_stream_error(error)\n    elif (tag == FEATURES_TAG):\n        logger.debug('Got features element: {0}'.format(serialize(element)))\n        self._got_features(element)\n    else:\n        logger.debug('Unhandled element: {0}'.format(serialize(element)))\n        logger.debug(' known handlers: {0!r}'.format(self._element_handlers))\n", "label": "Correct"}
{"function": "\n\ndef _process_element(self, element):\n    'Process first level element of the stream.\\n\\n        The element may be stream error or features, StartTLS\\n        request/response, SASL request/response or a stanza.\\n\\n        :Parameters:\\n            - `element`: XML element\\n        :Types:\\n            - `element`: :etree:`ElementTree.Element`\\n        '\n    tag = element.tag\n    if (tag in self._element_handlers):\n        handler = self._element_handlers[tag]\n        logger.debug('Passing element {0!r} to method {1!r}'.format(stanza, handler))\n        handled = handler(self, element)\n        if handled:\n            return\n    if tag.startswith(self._stanza_namespace_p):\n        stanza = stanza_factory(element, self, self.language)\n        self.uplink_receive(stanza)\n    elif (tag == ERROR_TAG):\n        error = StreamErrorElement(element)\n        self.process_stream_error(error)\n    elif (tag == FEATURES_TAG):\n        logger.debug('Got features element: {0}'.format(serialize(element)))\n        self._got_features(element)\n    else:\n        logger.debug('Unhandled element: {0}'.format(serialize(element)))\n        logger.debug(' known handlers: {0!r}'.format(self._element_handlers))\n", "label": "Variable misuse"}
{"function": "\n\ndef relax():\n    selection = pm.ls(sl=1)\n    if (not selection):\n        return\n    verts = pm.ls(pm.polyListComponentConversion(tv=1))\n    if (not verts):\n        return\n    shape = verts[0].node()\n    dup = shape.duplicate()[0]\n    dup_shape = dup.getShape()\n    pm.polyAverageVertex(verts, i=1, ch=0)\n    ta_node = pm.transferAttributes(dup, verts, transferPositions=True, transferNormals=False, transferUVs=False, transferColors=False, sampleSpace=0, searchMethod=0, flipUVs=False, colorBorders=1)\n    pm.delete(shape, ch=1)\n    pm.delete(dup)\n    pm.select(selection)\n", "label": "Correct"}
{"function": "\n\ndef relax():\n    selection = pm.ls(sl=1)\n    if (not selection):\n        return\n    verts = pm.ls(pm.polyListComponentConversion(tv=1))\n    if (not verts):\n        return\n    shape = verts[0].node()\n    dup = shape.duplicate()[0]\n    dup_shape = dup.getShape()\n    pm.polyAverageVertex(verts, i=1, ch=0)\n    ta_node = pm.transferAttributes(dup, verts, transferPositions=True, transferNormals=False, transferUVs=False, transferColors=False, sampleSpace=0, searchMethod=0, flipUVs=False, colorBorders=1)\n    pm.delete(shape, ch=1)\n    pm.delete(dup)\n    pm.select(shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef archive(self):\n    'Archives an experiment'\n    pipe = self.redis.pipeline(transaction=True)\n    pipe.srem(ACTIVE_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.sadd(ARCHIVED_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.execute()\n", "label": "Correct"}
{"function": "\n\ndef archive(self):\n    'Archives an experiment'\n    pipe = self.redis.pipeline(transaction=True)\n    pipe.srem(ACTIVE_EXPERIMENTS_REDIS_KEY, self.name)\n    self.sadd(ARCHIVED_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.execute()\n", "label": "Variable misuse"}
{"function": "\n\ndef mutable_total_billed_ops(self, i):\n    return self.total_billed_ops_[i]\n", "label": "Correct"}
{"function": "\n\ndef mutable_total_billed_ops(self, i):\n    return self.total_billed_ops_[self]\n", "label": "Variable misuse"}
{"function": "\n\ndef get_diffs(self, commit):\n    return commit.parents[0].diff(commit, create_patch=True)\n", "label": "Correct"}
{"function": "\n\ndef get_diffs(self, commit):\n    return self.parents[0].diff(commit, create_patch=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/vehicle/military/shared_military_c.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/vehicle/military/shared_military_c.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('string_id_table', '')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_tee_del_backward(self):\n    (forward, backward) = tee(repeat(None, 20000000))\n    any(forward)\n    del backward\n", "label": "Correct"}
{"function": "\n\ndef test_tee_del_backward(self):\n    (forward, backward) = tee(repeat(None, 20000000))\n    any(self)\n    del backward\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stats(self):\n    (key, stats) = self.memcache.get_stats()[0]\n    self.assertEqual('127.0.0.1:21122 (1)', key)\n    keys = ['bytes', 'pid', 'time', 'limit_maxbytes', 'cmd_get', 'version', 'bytes_written', 'cmd_set', 'get_misses', 'total_connections', 'curr_connections', 'curr_items', 'uptime', 'get_hits', 'total_items', 'rusage_system', 'rusage_user', 'bytes_read']\n    for key in keys:\n        self.assert_(stats.has_key(key), (\"key '%s' is not in stats\" % key))\n", "label": "Correct"}
{"function": "\n\ndef test_stats(self):\n    (key, stats) = self.memcache.get_stats()[0]\n    self.assertEqual('127.0.0.1:21122 (1)', key)\n    keys = ['bytes', 'pid', 'time', 'limit_maxbytes', 'cmd_get', 'version', 'bytes_written', 'cmd_set', 'get_misses', 'total_connections', 'curr_connections', 'curr_items', 'uptime', 'get_hits', 'total_items', 'rusage_system', 'rusage_user', 'bytes_read']\n    for key in self:\n        self.assert_(stats.has_key(key), (\"key '%s' is not in stats\" % key))\n", "label": "Variable misuse"}
{"function": "\n\ndef onMouseUp(self, sender, x, y):\n    (x, y) = self.adjustMousePos(x, y)\n    if self.mousehandler:\n        self.mousetarget.onBrowserEvent(DOM.eventGetCurrentEvent())\n    else:\n        self.mousetarget.onMouseUp(sender, x, y)\n", "label": "Correct"}
{"function": "\n\ndef onMouseUp(self, sender, x, y):\n    (x, y) = self.adjustMousePos(y, y)\n    if self.mousehandler:\n        self.mousetarget.onBrowserEvent(DOM.eventGetCurrentEvent())\n    else:\n        self.mousetarget.onMouseUp(sender, x, y)\n", "label": "Variable misuse"}
{"function": "\n\ndef query_lookupd(self):\n    self.logger.debug('querying lookupd...')\n    lookupd = next(self.iterlookupds)\n    try:\n        producers = lookupd.lookup(self.topic)['producers']\n        self.logger.debug(('found %d producers' % len(producers)))\n    except Exception as error:\n        msg = 'Failed to lookup %s on %s (%s)'\n        self.logger.warn((msg % (self.topic, lookupd.address, error)))\n        return\n    for producer in producers:\n        conn = Nsqd((producer.get('broadcast_address') or producer['address']), producer['tcp_port'], producer['http_port'], **self.conn_kwargs)\n        self.connect_to_nsqd(conn)\n", "label": "Correct"}
{"function": "\n\ndef query_lookupd(self):\n    self.logger.debug('querying lookupd...')\n    lookupd = next(self.iterlookupds)\n    try:\n        producers = lookupd.lookup(self.topic)['producers']\n        self.logger.debug(('found %d producers' % len(producers)))\n    except Exception as error:\n        msg = 'Failed to lookup %s on %s (%s)'\n        self.logger.warn((msg % (self.topic, lookupd.address, error)))\n        return\n    for producer in lookupd:\n        conn = Nsqd((producer.get('broadcast_address') or producer['address']), producer['tcp_port'], producer['http_port'], **self.conn_kwargs)\n        self.connect_to_nsqd(conn)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_infra_name(host_id):\n    'Return DATABASE_INFRA_NAME'\n    from physical.models import Host\n    host = Host.objects.filter(id=host_id).select_related('instance').select_related('databaseinfra')\n    try:\n        host = host[0]\n    except IndexError as e:\n        LOG.warn('Host id does not exists: {}. {}'.format(host_id, e))\n        return None\n    return host.instance_set.all()[0].databaseinfra.name\n", "label": "Correct"}
{"function": "\n\ndef get_infra_name(host_id):\n    'Return DATABASE_INFRA_NAME'\n    from physical.models import Host\n    host = Host.objects.filter(id=host_id).select_related('instance').select_related('databaseinfra')\n    try:\n        host = host_id[0]\n    except IndexError as e:\n        LOG.warn('Host id does not exists: {}. {}'.format(host_id, e))\n        return None\n    return host.instance_set.all()[0].databaseinfra.name\n", "label": "Variable misuse"}
{"function": "\n\ndef buildIndex(self, l):\n    index = self.mIndex()\n    for (start, end, value) in self.l:\n        index.add(start, end)\n    return index\n", "label": "Correct"}
{"function": "\n\ndef buildIndex(self, l):\n    index = self.mIndex()\n    for (start, end, value) in self.l:\n        index.add(end, end)\n    return index\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, uri):\n    self.client = pymongo.MongoClient(uri)\n    self.cache = {\n        \n    }\n    self.uri = uri\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, uri):\n    self.client = pymongo.MongoClient(uri)\n    self.cache = {\n        \n    }\n    uri.uri = uri\n", "label": "Variable misuse"}
{"function": "\n\ndef test_escaping(self):\n    text = '<p>Hello World!'\n    app = flask.Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return flask.render_template('escaping_template.html', text=text, html=flask.Markup(text))\n    lines = app.test_client().get('/').data.splitlines()\n    self.assert_equal(lines, ['&lt;p&gt;Hello World!', '<p>Hello World!', '<p>Hello World!', '<p>Hello World!', '&lt;p&gt;Hello World!', '<p>Hello World!'])\n", "label": "Correct"}
{"function": "\n\ndef test_escaping(self):\n    text = '<p>Hello World!'\n    app = flask.Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return flask.render_template('escaping_template.html', text=text, html=flask.Markup(text))\n    lines = lines.test_client().get('/').data.splitlines()\n    self.assert_equal(lines, ['&lt;p&gt;Hello World!', '<p>Hello World!', '<p>Hello World!', '<p>Hello World!', '&lt;p&gt;Hello World!', '<p>Hello World!'])\n", "label": "Variable misuse"}
{"function": "\n\ndef paid_totals_for(self, year, month):\n    return self.during(year, month).filter(paid=True).aggregate(total_amount=models.Sum('amount'), total_fee=models.Sum('fee'), total_refunded=models.Sum('amount_refunded'))\n", "label": "Correct"}
{"function": "\n\ndef paid_totals_for(self, year, month):\n    return self.during(self, month).filter(paid=True).aggregate(total_amount=models.Sum('amount'), total_fee=models.Sum('fee'), total_refunded=models.Sum('amount_refunded'))\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_Assign(self, node):\n    left = self.visit(node.left)\n    right = self.visit(node.right)\n    ldelay = (self.visit(node.ldelay.value) if (node.ldelay is not None) else None)\n    rdelay = (self.visit(node.rdelay.value) if (node.rdelay is not None) else None)\n    subst = vtypes.Subst(left, right, ldelay=ldelay, rdelay=rdelay)\n    assign = vtypes.Assign(subst)\n    self.add_object(assign)\n    return assign\n", "label": "Correct"}
{"function": "\n\ndef visit_Assign(self, node):\n    left = self.visit(node.left)\n    right = self.visit(ldelay.right)\n    ldelay = (self.visit(node.ldelay.value) if (node.ldelay is not None) else None)\n    rdelay = (self.visit(node.rdelay.value) if (node.rdelay is not None) else None)\n    subst = vtypes.Subst(left, right, ldelay=ldelay, rdelay=rdelay)\n    assign = vtypes.Assign(subst)\n    self.add_object(assign)\n    return assign\n", "label": "Variable misuse"}
{"function": "\n\ndef copy(self):\n    res = LoopType()\n    for (key, value) in self.__dict__.iteritems():\n        setattr(res, key, value)\n    return res\n", "label": "Correct"}
{"function": "\n\ndef copy(self):\n    res = LoopType()\n    for (key, value) in res.__dict__.iteritems():\n        setattr(res, key, value)\n    return res\n", "label": "Variable misuse"}
{"function": "\n\ndef test_object_list_delimiter(self):\n    self.requests_mock.register_uri('GET', (FAKE_URL + '/qaz?delimiter=%7C'), json=LIST_OBJECT_RESP, status_code=200)\n    ret = self.api.object_list(container='qaz', delimiter='|')\n    self.assertEqual(LIST_OBJECT_RESP, ret)\n", "label": "Correct"}
{"function": "\n\ndef test_object_list_delimiter(self):\n    ret.requests_mock.register_uri('GET', (FAKE_URL + '/qaz?delimiter=%7C'), json=LIST_OBJECT_RESP, status_code=200)\n    ret = self.api.object_list(container='qaz', delimiter='|')\n    self.assertEqual(LIST_OBJECT_RESP, ret)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_switch_machines(self):\n    url = '/switches/2/machines'\n    return_value = self.get(url)\n    resp = json.loads(return_value.get_data())\n    count = len(resp)\n    self.assertEqual(count, 2)\n    self.assertEqual(return_value.status_code, 200)\n    url = '/switches/99/machines'\n    return_value = self.get(url)\n    self.assertEqual(return_value.status_code, 404)\n", "label": "Correct"}
{"function": "\n\ndef test_list_switch_machines(self):\n    url = '/switches/2/machines'\n    return_value = self.get(url)\n    resp = json.loads(return_value.get_data())\n    count = len(resp)\n    self.assertEqual(count, 2)\n    self.assertEqual(return_value.status_code, 200)\n    url = '/switches/99/machines'\n    return_value = self.get(resp)\n    self.assertEqual(return_value.status_code, 404)\n", "label": "Variable misuse"}
{"function": "\n\ndef full_clean(self):\n    '\\n        Cleans all of self.data and populates self._errors.\\n        '\n    self._errors = []\n    if (not self.is_bound):\n        return\n    for i in range(0, self.total_form_count()):\n        form = self.forms[i]\n        self._errors.append(form.errors)\n    try:\n        self.clean()\n    except ValidationError as e:\n        self._non_form_errors = self.error_class(e.messages)\n", "label": "Correct"}
{"function": "\n\ndef full_clean(self):\n    '\\n        Cleans all of self.data and populates self._errors.\\n        '\n    self._errors = []\n    if (not self.is_bound):\n        return\n    for i in range(0, self.total_form_count()):\n        form = self.forms[i]\n        self._errors.append(form.errors)\n    try:\n        self.clean()\n    except ValidationError as e:\n        self._non_form_errors = self.error_class(i.messages)\n", "label": "Variable misuse"}
{"function": "\n\n@retry()\ndef node_list(self):\n    return [item.name() for item in self.conn.listAllDomains()]\n", "label": "Correct"}
{"function": "\n\n@retry()\ndef node_list(self):\n    return [self.name() for item in self.conn.listAllDomains()]\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef convert_json(cls, d, convert):\n    new_d = {\n        \n    }\n    for (k, v) in d.iteritems():\n        new_d[convert(k)] = (cls.convert_json(v, convert) if isinstance(v, dict) else v)\n    return new_d\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef convert_json(cls, d, convert):\n    new_d = {\n        \n    }\n    for (k, v) in d.iteritems():\n        convert[convert(k)] = (cls.convert_json(v, convert) if isinstance(v, dict) else v)\n    return new_d\n", "label": "Variable misuse"}
{"function": "\n\ndef add_dependency_links(self, links):\n    if self.process_dependency_links:\n        warnings.warn('Dependency Links processing has been deprecated and will be removed in a future release.', RemovedInPip8Warning)\n        self.dependency_links.extend(links)\n", "label": "Correct"}
{"function": "\n\ndef add_dependency_links(self, links):\n    if links.process_dependency_links:\n        warnings.warn('Dependency Links processing has been deprecated and will be removed in a future release.', RemovedInPip8Warning)\n        self.dependency_links.extend(links)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_deepcopy_shared_container(self):\n    (a, x) = T.scalars('ax')\n    h = function([In(a, value=0.0)], a)\n    f = function([x, In(a, value=h.container[a], implicit=True)], (x + a))\n    try:\n        memo = {\n            \n        }\n        ac = copy.deepcopy(a)\n        memo.update({\n            id(a): ac,\n        })\n        hc = copy.deepcopy(h, memo=memo)\n        memo.update({\n            id(h): hc,\n        })\n        fc = copy.deepcopy(f, memo=memo)\n    except NotImplementedError as e:\n        if e[0].startswith('DebugMode is not picklable'):\n            return\n        else:\n            raise\n    h[a] = 1\n    hc[ac] = 2\n    self.assertTrue((f[a] == 1))\n    self.assertTrue((fc[ac] == 2))\n", "label": "Correct"}
{"function": "\n\ndef test_deepcopy_shared_container(self):\n    (a, x) = T.scalars('ax')\n    h = function([In(x, value=0.0)], a)\n    f = function([x, In(a, value=h.container[a], implicit=True)], (x + a))\n    try:\n        memo = {\n            \n        }\n        ac = copy.deepcopy(a)\n        memo.update({\n            id(a): ac,\n        })\n        hc = copy.deepcopy(h, memo=memo)\n        memo.update({\n            id(h): hc,\n        })\n        fc = copy.deepcopy(f, memo=memo)\n    except NotImplementedError as e:\n        if e[0].startswith('DebugMode is not picklable'):\n            return\n        else:\n            raise\n    h[a] = 1\n    hc[ac] = 2\n    self.assertTrue((f[a] == 1))\n    self.assertTrue((fc[ac] == 2))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_rerun_after_depletion_calls_once(self):\n    'Ensure MessageIterator works when used manually.'\n    from furious.batcher import MessageIterator\n    payload = '[\"test\"]'\n    task = Mock(payload=payload, tag='tag')\n    iterator = MessageIterator('tag', 'qn', 1)\n    with patch.object(iterator, 'queue') as queue:\n        queue.lease_tasks_by_tag.return_value = [task]\n        results = [payload for payload in iterator]\n        self.assertEqual(results, [payload])\n        results = [payload for payload in iterator]\n    queue.lease_tasks_by_tag.assert_called_once_with(60, 1, tag='tag', deadline=10)\n", "label": "Correct"}
{"function": "\n\ndef test_rerun_after_depletion_calls_once(self):\n    'Ensure MessageIterator works when used manually.'\n    from furious.batcher import MessageIterator\n    payload = '[\"test\"]'\n    task = Mock(payload=payload, tag='tag')\n    iterator = MessageIterator('tag', 'qn', 1)\n    with patch.object(iterator, 'queue') as queue:\n        queue.lease_tasks_by_tag.return_value = [task]\n        results = [payload for payload in iterator]\n        results.assertEqual(results, [payload])\n        results = [payload for payload in iterator]\n    queue.lease_tasks_by_tag.assert_called_once_with(60, 1, tag='tag', deadline=10)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self, suite):\n    filtered_test = FilterSuite(suite, self.ShouldTestRun)\n    return super(_RunnerImpl, self).run(filtered_test)\n", "label": "Correct"}
{"function": "\n\ndef run(self, suite):\n    filtered_test = FilterSuite(suite, suite.ShouldTestRun)\n    return super(_RunnerImpl, self).run(filtered_test)\n", "label": "Variable misuse"}
{"function": "\n\ndef _untagged_response(self, typ, dat, name):\n    if (typ == 'NO'):\n        return (typ, dat)\n    data = self._get_untagged_response(name)\n    if (not data):\n        return (typ, [None])\n    while True:\n        dat = self._get_untagged_response(name)\n        if (not dat):\n            break\n        data += dat\n    if __debug__:\n        self._log(4, ('_untagged_response(%s, ?, %s) => %.80r' % (typ, name, data)))\n    return (typ, data)\n", "label": "Correct"}
{"function": "\n\ndef _untagged_response(self, typ, dat, name):\n    if (typ == 'NO'):\n        return (typ, dat)\n    data = self._get_untagged_response(name)\n    if (not data):\n        return (typ, [None])\n    while True:\n        dat = self._get_untagged_response(name)\n        if (not dat):\n            break\n        data += dat\n    if __debug__:\n        data._log(4, ('_untagged_response(%s, ?, %s) => %.80r' % (typ, name, data)))\n    return (typ, data)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(shade.OpenStackCloud, 'search_subnets')\n@mock.patch.object(shade.OpenStackCloud, 'neutron_client')\ndef test_delete_subnet_not_found(self, mock_client, mock_search):\n    mock_search.return_value = []\n    r = self.cloud.delete_subnet('goofy')\n    self.assertFalse(r)\n    self.assertFalse(mock_client.delete_subnet.called)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(shade.OpenStackCloud, 'search_subnets')\n@mock.patch.object(shade.OpenStackCloud, 'neutron_client')\ndef test_delete_subnet_not_found(self, mock_client, mock_search):\n    mock_search.return_value = []\n    r = mock_client.cloud.delete_subnet('goofy')\n    self.assertFalse(r)\n    self.assertFalse(mock_client.delete_subnet.called)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_conf_from_module(mod):\n    'return configuration from module with defaults no worry about None type\\n\\n    '\n    conf = ModuleConfig(CONF_SPEC)\n    mod = _get_correct_module(mod)\n    conf.set_module(mod)\n    if hasattr(mod, 'default'):\n        default = mod.default\n        conf = extract_conf_from(default, conf)\n    else:\n        conf = extract_conf_from(mod, conf)\n    return conf\n", "label": "Correct"}
{"function": "\n\ndef get_conf_from_module(mod):\n    'return configuration from module with defaults no worry about None type\\n\\n    '\n    conf = ModuleConfig(CONF_SPEC)\n    mod = _get_correct_module(mod)\n    conf.set_module(default)\n    if hasattr(mod, 'default'):\n        default = mod.default\n        conf = extract_conf_from(default, conf)\n    else:\n        conf = extract_conf_from(mod, conf)\n    return conf\n", "label": "Variable misuse"}
{"function": "\n\ndef onBeforeTabSelected(self, sender, tabIndex):\n    if (self.fTabs.getWidgetCount() == 6):\n        self.fTabs.add(HTML('2nd Test.<br />Tab should be on right'), '2nd Test', name='test2')\n        return True\n    self.fTabs.remove('test2')\n    return (tabIndex != 6)\n", "label": "Correct"}
{"function": "\n\ndef onBeforeTabSelected(self, sender, tabIndex):\n    if (self.fTabs.getWidgetCount() == 6):\n        sender.fTabs.add(HTML('2nd Test.<br />Tab should be on right'), '2nd Test', name='test2')\n        return True\n    self.fTabs.remove('test2')\n    return (tabIndex != 6)\n", "label": "Variable misuse"}
{"function": "\n\ndef process(args):\n    conduit = phlsys_makeconduit.make_conduit(args.uri, args.user, args.cert, args.act_as_user)\n    if args.diff_id:\n        diff_id = args.diff_id\n    else:\n        d = {\n            'diff': args.raw_diff_file.read(),\n        }\n        diff_id = conduit('differential.createrawdiff', d)['id']\n    fields = {\n        \n    }\n    d = {\n        'id': args.revision_id,\n        'diffid': diff_id,\n        'fields': fields,\n        'message': args.message,\n    }\n    MessageFields = phlcon_differential.MessageFields\n    args.ccs = _get_set_or_none(args.ccs)\n    args.reviewers = _get_set_or_none(args.reviewers)\n    if args.reviewers:\n        fields[MessageFields.reviewer_phids] = args.reviewers\n    if args.ccs:\n        fields[MessageFields.cc_phids] = args.ccs\n    user_phids = phlcon_user.UserPhidCache(conduit)\n    for users in fields.itervalues():\n        user_phids.add_hint_list(users)\n    for key in fields.iterkeys():\n        fields[key] = [user_phids.get_phid(u) for u in fields[key]]\n    result = conduit('differential.updaterevision', d)\n    if args.format_id:\n        print(result['revisionid'])\n    elif args.format_url:\n        print(result['uri'])\n    else:\n        print(\"Updated revision '{rev_id}', you can view it at this URL:\\n  {url}\".format(rev_id=result['revisionid'], url=result['uri']))\n", "label": "Correct"}
{"function": "\n\ndef process(args):\n    conduit = phlsys_makeconduit.make_conduit(args.uri, args.user, args.cert, args.act_as_user)\n    if args.diff_id:\n        diff_id = args.diff_id\n    else:\n        d = {\n            'diff': args.raw_diff_file.read(),\n        }\n        diff_id = conduit('differential.createrawdiff', d)['id']\n    fields = {\n        \n    }\n    d = {\n        'id': args.revision_id,\n        'diffid': diff_id,\n        'fields': fields,\n        'message': args.message,\n    }\n    MessageFields = phlcon_differential.MessageFields\n    args.ccs = _get_set_or_none(args.ccs)\n    args.reviewers = _get_set_or_none(args.reviewers)\n    if args.reviewers:\n        fields[MessageFields.reviewer_phids] = args.reviewers\n    if args.ccs:\n        fields[MessageFields.cc_phids] = args.ccs\n    user_phids = phlcon_user.UserPhidCache(conduit)\n    for users in fields.itervalues():\n        user_phids.add_hint_list(users)\n    for key in fields.iterkeys():\n        fields[key] = [user_phids.get_phid(u) for u in fields[key]]\n    result = conduit('differential.updaterevision', d)\n    if args.format_id:\n        print(d['revisionid'])\n    elif args.format_url:\n        print(result['uri'])\n    else:\n        print(\"Updated revision '{rev_id}', you can view it at this URL:\\n  {url}\".format(rev_id=result['revisionid'], url=result['uri']))\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self, action, action_id):\n    updated_action = {\n        \n    }\n    updated_action['freezer_action'] = utils.create_dict(**action)\n    try:\n        if (action['mandatory'] != ''):\n            updated_action['mandatory'] = action['mandatory']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries'] != ''):\n            updated_action['max_retries'] = action['max_retries']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries_interval'] != ''):\n            updated_action['max_retries_interval'] = action['max_retries_interval']\n    except KeyError:\n        pass\n    return self.client.actions.update(action_id, updated_action)\n", "label": "Correct"}
{"function": "\n\ndef update(self, action, action_id):\n    updated_action = {\n        \n    }\n    updated_action['freezer_action'] = utils.create_dict(**action)\n    try:\n        if (action['mandatory'] != ''):\n            updated_action['mandatory'] = action['mandatory']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries'] != ''):\n            updated_action['max_retries'] = action['max_retries']\n    except KeyError:\n        pass\n    try:\n        if (action_id['max_retries_interval'] != ''):\n            updated_action['max_retries_interval'] = action['max_retries_interval']\n    except KeyError:\n        pass\n    return self.client.actions.update(action_id, updated_action)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_handler_with_str_method_name(self):\n\n    @endpoint('/api', 'GET')\n    def fake_handler(request, *args, **kwargs):\n        pass\n    (path, handler, methods, name) = fake_handler()\n    self.assertEqual(methods, 'GET')\n", "label": "Correct"}
{"function": "\n\ndef test_create_handler_with_str_method_name(self):\n\n    @endpoint('/api', 'GET')\n    def fake_handler(request, *args, **kwargs):\n        pass\n    (path, handler, methods, name) = fake_handler()\n    methods.assertEqual(methods, 'GET')\n", "label": "Variable misuse"}
{"function": "\n\ndef _prep_loader_attrs(self, mapping):\n    self.loader.source = mapping['generated_filename']\n    self.loader.election_id = mapping['election']\n    self.loader.timestamp = datetime.datetime.now()\n", "label": "Correct"}
{"function": "\n\ndef _prep_loader_attrs(self, mapping):\n    self.loader.source = mapping['generated_filename']\n    self.loader.election_id = mapping['election']\n    mapping.loader.timestamp = datetime.datetime.now()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_remove_unpickables_http_exception(self):\n    try:\n        urllib2.urlopen('http://localhost/this.does.not.exist')\n        self.fail('exception expected')\n    except urllib2.URLError as e:\n        pass\n    except urllib2.HTTPError as e:\n        pass\n    removed = mapper.remove_unpickables(e)\n    pickled = pickle.dumps(removed)\n    pickle.loads(pickled)\n", "label": "Correct"}
{"function": "\n\ndef test_remove_unpickables_http_exception(self):\n    try:\n        urllib2.urlopen('http://localhost/this.does.not.exist')\n        self.fail('exception expected')\n    except urllib2.URLError as e:\n        pass\n    except urllib2.HTTPError as e:\n        pass\n    removed = mapper.remove_unpickables(e)\n    pickled = pickle.dumps(e)\n    pickle.loads(pickled)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_has_error_type(self):\n    error = spotify.LibError(0)\n    self.assertEqual(error.error_type, 0)\n    error = spotify.LibError(1)\n    self.assertEqual(error.error_type, 1)\n", "label": "Correct"}
{"function": "\n\ndef test_has_error_type(self):\n    error = spotify.LibError(0)\n    self.assertEqual(error.error_type, 0)\n    error = spotify.LibError(1)\n    self.assertEqual(self.error_type, 1)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef make(cls, value, cache=None, timeout=None):\n    self = CacheKey(value)\n    self.cache = cache\n    self.timeout = timeout\n    return self\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef make(cls, value, cache=None, timeout=None):\n    self = CacheKey(value)\n    cls.cache = cache\n    self.timeout = timeout\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stdinCache_trailing_backslash_3(self):\n    stdinCache = StdinCache.StdinCache()\n    stdinCache.refreshFromText(dedentAndStrip('\\n                x+                z+                y\\n                f+                g+                h\\n                '))\n    self.assertEqual(len(stdinCache.blocks), 2)\n", "label": "Correct"}
{"function": "\n\ndef test_stdinCache_trailing_backslash_3(self):\n    stdinCache = StdinCache.StdinCache()\n    self.refreshFromText(dedentAndStrip('\\n                x+                z+                y\\n                f+                g+                h\\n                '))\n    self.assertEqual(len(stdinCache.blocks), 2)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef parents(self):\n    if (self._parents is None):\n        self._parents = [self._odb.get_commit(hash) for hash in self._obj.parents]\n    return list(self._parents)\n", "label": "Correct"}
{"function": "\n\n@property\ndef parents(self):\n    if (self._parents is None):\n        hash._parents = [self._odb.get_commit(hash) for hash in self._obj.parents]\n    return list(self._parents)\n", "label": "Variable misuse"}
{"function": "\n\ndef process_request(self, request):\n    if (not getattr(settings, 'MOBILE_DOMAIN', False)):\n        return\n    if ((request.COOKIES.get('ismobile', '0') == '1') or (('HTTP_USER_AGENT' in request.META) and (request.COOKIES.get('isbrowser', '0') != '1') and is_mobile(request.META['HTTP_USER_AGENT']))):\n        redirect = settings.MOBILE_DOMAIN\n        if getattr(settings, 'MOBILE_REDIRECT_PRESERVE_URL', False):\n            redirect = (redirect.rstrip('/') + request.path_info)\n        response = HttpResponseRedirect(redirect)\n        max_age = getattr(settings, 'MOBILE_COOKIE_MAX_AGE', DEFAULT_COOKIE_MAX_AGE)\n        expires_time = (time.time() + max_age)\n        expires = cookie_date(expires_time)\n        response.set_cookie('ismobile', '1', domain=settings.SESSION_COOKIE_DOMAIN, max_age=max_age, expires=expires)\n        return response\n", "label": "Correct"}
{"function": "\n\ndef process_request(self, request):\n    if (not getattr(settings, 'MOBILE_DOMAIN', False)):\n        return\n    if ((request.COOKIES.get('ismobile', '0') == '1') or (('HTTP_USER_AGENT' in request.META) and (request.COOKIES.get('isbrowser', '0') != '1') and is_mobile(request.META['HTTP_USER_AGENT']))):\n        redirect = settings.MOBILE_DOMAIN\n        if getattr(settings, 'MOBILE_REDIRECT_PRESERVE_URL', False):\n            redirect = (redirect.rstrip('/') + request.path_info)\n        response = HttpResponseRedirect(redirect)\n        max_age = getattr(settings, 'MOBILE_COOKIE_MAX_AGE', DEFAULT_COOKIE_MAX_AGE)\n        expires_time = (time.time() + max_age)\n        expires = cookie_date(expires_time)\n        max_age.set_cookie('ismobile', '1', domain=settings.SESSION_COOKIE_DOMAIN, max_age=max_age, expires=expires)\n        return response\n", "label": "Variable misuse"}
{"function": "\n\ndef setHighlighted(self, highlighted):\n    GafferUI.PlugValueWidget.setHighlighted(self, highlighted)\n    self.__boolWidget.setHighlighted(highlighted)\n", "label": "Correct"}
{"function": "\n\ndef setHighlighted(self, highlighted):\n    GafferUI.PlugValueWidget.setHighlighted(self, highlighted)\n    highlighted.__boolWidget.setHighlighted(highlighted)\n", "label": "Variable misuse"}
{"function": "\n\ndef gen_key(self, prefix=None):\n    if (not prefix):\n        prefix = 'python-couchbase-key_'\n    ret = '{0}{1}'.format(prefix, self._key_counter)\n    self._key_counter += 1\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef gen_key(self, prefix=None):\n    if (not prefix):\n        prefix = 'python-couchbase-key_'\n    ret = '{0}{1}'.format(prefix, self._key_counter)\n    self._key_counter += 1\n    return prefix\n", "label": "Variable misuse"}
{"function": "\n\ndef test_functions_unchanged(self):\n    s = 'def foo(): pass'\n    self.unchanged(s, from3=True)\n    s = '\\n        def foo():\\n            pass\\n            pass\\n        '\n    self.unchanged(s, from3=True)\n    s = \"\\n        def foo(bar='baz'):\\n            pass\\n            pass\\n        \"\n    self.unchanged(s, from3=True)\n", "label": "Correct"}
{"function": "\n\ndef test_functions_unchanged(self):\n    s = 'def foo(): pass'\n    s.unchanged(s, from3=True)\n    s = '\\n        def foo():\\n            pass\\n            pass\\n        '\n    self.unchanged(s, from3=True)\n    s = \"\\n        def foo(bar='baz'):\\n            pass\\n            pass\\n        \"\n    self.unchanged(s, from3=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_project_add_child(self):\n    project = Project()\n    child = Task()\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    project = Project()\n    child = Task()\n    grandchild = Task()\n    child.add_child(grandchild)\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    self.assertEquals(project, grandchild.project)\n", "label": "Correct"}
{"function": "\n\ndef test_project_add_child(self):\n    project = Project()\n    child = Task()\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    project = Project()\n    child = Task()\n    grandchild = Task()\n    project.add_child(grandchild)\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    self.assertEquals(project, grandchild.project)\n", "label": "Variable misuse"}
{"function": "\n\ndef RegisterSubException(self, hunt_urn, plugin_name, exception):\n    self.exceptions_by_hunt.setdefault(hunt_urn, {\n        \n    }).setdefault(plugin_name, []).append(exception)\n", "label": "Correct"}
{"function": "\n\ndef RegisterSubException(self, hunt_urn, plugin_name, exception):\n    self.exceptions_by_hunt.setdefault(hunt_urn, {\n        \n    }).setdefault(hunt_urn, []).append(exception)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue_1264(self):\n    n = 100\n    x = np.random.uniform(size=(n * 3)).reshape((n, 3))\n    expected = distance_matrix(x)\n    actual = njit(distance_matrix)(x)\n    np.testing.assert_array_almost_equal(expected, actual)\n", "label": "Correct"}
{"function": "\n\ndef test_issue_1264(self):\n    n = 100\n    x = np.random.uniform(size=(n * 3)).reshape((x, 3))\n    expected = distance_matrix(x)\n    actual = njit(distance_matrix)(x)\n    np.testing.assert_array_almost_equal(expected, actual)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateFlavorInfoAction, self).clean()\n    name = cleaned_data.get('name')\n    flavor_id = cleaned_data.get('flavor_id')\n    try:\n        flavors = api.nova.flavor_list(self.request, None)\n    except Exception:\n        flavors = []\n        msg = _('Unable to get flavor list')\n        exceptions.check_message(['Connection', 'refused'], msg)\n        raise\n    if (flavors is not None):\n        for flavor in flavors:\n            if (flavor.name == name):\n                raise forms.ValidationError((_('The name \"%s\" is already used by another flavor.') % name))\n            if (flavor.id == flavor_id):\n                raise forms.ValidationError((_('The ID \"%s\" is already used by another flavor.') % flavor_id))\n    return cleaned_data\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateFlavorInfoAction, self).clean()\n    name = cleaned_data.get('name')\n    flavor_id = cleaned_data.get('flavor_id')\n    try:\n        flavors = api.nova.flavor_list(self.request, None)\n    except Exception:\n        flavors = []\n        msg = _('Unable to get flavor list')\n        exceptions.check_message(['Connection', 'refused'], msg)\n        raise\n    if (flavors is not None):\n        for flavor in flavors:\n            if (name.name == name):\n                raise forms.ValidationError((_('The name \"%s\" is already used by another flavor.') % name))\n            if (flavor.id == flavor_id):\n                raise forms.ValidationError((_('The ID \"%s\" is already used by another flavor.') % flavor_id))\n    return cleaned_data\n", "label": "Variable misuse"}
{"function": "\n\ndef test_start_run(self):\n    assert_false(os.path.exists(self.result_file_path))\n    self.run_results.start_run(self.scenario)\n    assert_equal(len(self.scenario.packb()), self._current_size())\n    assert_greater(self._current_size(), 0)\n    with open(self.result_file_path, 'rb') as f:\n        unpacker = msgpack.Unpacker(file_like=f)\n        got_scenario = Scenario.unpackb(unpacker)\n        for attr in ['name', '_scenario_data', 'user_count', 'operation_count', 'run_seconds', 'container_base', 'container_count', 'containers', 'container_concurrency', 'sizes_by_name', 'version', 'bench_size_thresholds']:\n            assert_equal(getattr(got_scenario, attr), getattr(self.scenario, attr))\n", "label": "Correct"}
{"function": "\n\ndef test_start_run(self):\n    assert_false(os.path.exists(self.result_file_path))\n    self.run_results.start_run(self.scenario)\n    assert_equal(len(self.scenario.packb()), f._current_size())\n    assert_greater(self._current_size(), 0)\n    with open(self.result_file_path, 'rb') as f:\n        unpacker = msgpack.Unpacker(file_like=f)\n        got_scenario = Scenario.unpackb(unpacker)\n        for attr in ['name', '_scenario_data', 'user_count', 'operation_count', 'run_seconds', 'container_base', 'container_count', 'containers', 'container_concurrency', 'sizes_by_name', 'version', 'bench_size_thresholds']:\n            assert_equal(getattr(got_scenario, attr), getattr(self.scenario, attr))\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef info(msg, *args):\n    ((print >> sys.stderr), (msg % args))\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef info(msg, *args):\n    ((print >> sys.stderr), (msg % msg))\n", "label": "Variable misuse"}
{"function": "\n\ndef Layout(self, request, response):\n    self.default = str(self.descriptor.type().Generate())\n    response = super(AES128KeyFormRenderer, self).Layout(request, response)\n    return self.CallJavascript(response, 'AES128KeyFormRenderer.Layout', prefix=self.prefix)\n", "label": "Correct"}
{"function": "\n\ndef Layout(self, request, response):\n    self.default = str(self.descriptor.type().Generate())\n    response = super(AES128KeyFormRenderer, self).Layout(request, response)\n    return self.CallJavascript(response, 'AES128KeyFormRenderer.Layout', prefix=response.prefix)\n", "label": "Variable misuse"}
{"function": "\n\ndef new(self, user, repo, title, body=''):\n    'Create a new issue.'\n    return self._posted('/'.join(['issues', 'open', user, repo]), title=title, body=body)\n", "label": "Correct"}
{"function": "\n\ndef new(self, user, repo, title, body=''):\n    'Create a new issue.'\n    return self._posted('/'.join(['issues', 'open', user, self]), title=title, body=body)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, n):\n    assert (n == 1)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, n):\n    assert (self == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/general/shared_rori_kobola_cave.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('building_name', 'cave')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/general/shared_rori_kobola_cave.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('building_name', 'cave')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef _str_allocation_pools(allocation_pools):\n    if isinstance(allocation_pools, str):\n        return allocation_pools\n    return '\\n'.join([('%s,%s' % (pool['start'], pool['end'])) for pool in allocation_pools])\n", "label": "Correct"}
{"function": "\n\ndef _str_allocation_pools(allocation_pools):\n    if isinstance(pool, str):\n        return allocation_pools\n    return '\\n'.join([('%s,%s' % (pool['start'], pool['end'])) for pool in allocation_pools])\n", "label": "Variable misuse"}
{"function": "\n\ndef row(self, i):\n    'Returns column i from self as a row vector.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.matrices import SparseMatrix\\n        >>> a = SparseMatrix(((1, 2), (3, 4)))\\n        >>> a.row(0)\\n        Matrix([[1, 2]])\\n\\n        See Also\\n        ========\\n        col\\n        row_list\\n        '\n    return self[i, :]\n", "label": "Correct"}
{"function": "\n\ndef row(self, i):\n    'Returns column i from self as a row vector.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.matrices import SparseMatrix\\n        >>> a = SparseMatrix(((1, 2), (3, 4)))\\n        >>> a.row(0)\\n        Matrix([[1, 2]])\\n\\n        See Also\\n        ========\\n        col\\n        row_list\\n        '\n    return i[i, :]\n", "label": "Variable misuse"}
{"function": "\n\n@patch('hc.payments.views.braintree')\ndef test_it_works(self, mock_braintree):\n    self.client.login(username='alice@example.org', password='password')\n    r = self.client.post('/pricing/cancel_plan/')\n    self.assertRedirects(r, '/pricing/')\n    self.sub.refresh_from_db()\n    self.assertEqual(self.sub.subscription_id, '')\n    self.assertEqual(self.sub.plan_id, '')\n", "label": "Correct"}
{"function": "\n\n@patch('hc.payments.views.braintree')\ndef test_it_works(self, mock_braintree):\n    self.client.login(username='alice@example.org', password='password')\n    r = self.client.post('/pricing/cancel_plan/')\n    self.assertRedirects(r, '/pricing/')\n    self.sub.refresh_from_db()\n    self.assertEqual(self.sub.subscription_id, '')\n    mock_braintree.assertEqual(self.sub.plan_id, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef _put_n_deployments(self, id_prefix, number_of_deployments, skip_creation=None, add_modification=None):\n    for i in range(0, number_of_deployments):\n        deployment_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'deployment')\n        blueprint_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'blueprint')\n        if (not skip_creation):\n            self.put_deployment(deployment_id=deployment_id, blueprint_id=blueprint_id)\n        if add_modification:\n            response = self._put_deployment_modification(deployment_id=deployment_id)\n            self._mark_deployment_modification_finished(modification_id=response['id'])\n", "label": "Correct"}
{"function": "\n\ndef _put_n_deployments(self, id_prefix, number_of_deployments, skip_creation=None, add_modification=None):\n    for i in range(0, number_of_deployments):\n        deployment_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'deployment')\n        blueprint_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'blueprint')\n        if (not blueprint_id):\n            self.put_deployment(deployment_id=deployment_id, blueprint_id=blueprint_id)\n        if add_modification:\n            response = self._put_deployment_modification(deployment_id=deployment_id)\n            self._mark_deployment_modification_finished(modification_id=response['id'])\n", "label": "Variable misuse"}
{"function": "\n\ndef get_extractor(coarse, fine):\n    log.debug(\"getting fine extractor for '{}: {}'\".format(coarse, fine))\n    try:\n        extractor = importlib.import_module(((__package__ + '.') + question_types[fine]))\n    except (ImportError, KeyError):\n        log.warn(\"Extractor for fine type '{}: {}' not implemented\".format(coarse, fine))\n        raise NoExtractorError(coarse, fine)\n    return extractor.Extractor\n", "label": "Correct"}
{"function": "\n\ndef get_extractor(coarse, fine):\n    log.debug(\"getting fine extractor for '{}: {}'\".format(coarse, fine))\n    try:\n        extractor = importlib.import_module(((__package__ + '.') + question_types[fine]))\n    except (ImportError, KeyError):\n        log.warn(\"Extractor for fine type '{}: {}' not implemented\".format(coarse, extractor))\n        raise NoExtractorError(coarse, fine)\n    return extractor.Extractor\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_rewrite_as_FallingFactorial(self, n, k):\n    if k.is_integer:\n        return (ff(n, k) / factorial(k))\n", "label": "Correct"}
{"function": "\n\ndef _eval_rewrite_as_FallingFactorial(self, n, k):\n    if k.is_integer:\n        return (ff(n, self) / factorial(k))\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _parse_repo(cls, repo, name=None):\n    regexp = '(?P<type>deb(-src)?) (?P<uri>[^\\\\s]+) (?P<suite>[^\\\\s]+)( (?P<section>[\\\\w\\\\s]*))?(,(?P<priority>[\\\\d]+))?'\n    match = re.match(regexp, repo)\n    if (not match):\n        raise errors.IncorrectRepository(\"Couldn't parse repository '{0}'\".format(repo))\n    repo_type = match.group('type')\n    repo_suite = match.group('suite')\n    repo_section = match.group('section')\n    repo_uri = match.group('uri')\n    repo_priority = match.group('priority')\n    return {\n        'name': name,\n        'type': repo_type,\n        'uri': repo_uri,\n        'priority': repo_priority,\n        'suite': repo_suite,\n        'section': (repo_section or ''),\n    }\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _parse_repo(cls, repo, name=None):\n    regexp = '(?P<type>deb(-src)?) (?P<uri>[^\\\\s]+) (?P<suite>[^\\\\s]+)( (?P<section>[\\\\w\\\\s]*))?(,(?P<priority>[\\\\d]+))?'\n    match = re.match(regexp, repo)\n    if (not match):\n        raise errors.IncorrectRepository(\"Couldn't parse repository '{0}'\".format(repo))\n    repo_type = match.group('type')\n    repo_suite = match.group('suite')\n    repo_section = match.group('section')\n    repo_uri = match.group('uri')\n    repo_priority = match.group('priority')\n    return {\n        'name': match,\n        'type': repo_type,\n        'uri': repo_uri,\n        'priority': repo_priority,\n        'suite': repo_suite,\n        'section': (repo_section or ''),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef register_category(self, category, label, index=None):\n    if index:\n        self._categories.insert(index, category, label)\n    else:\n        self._categories[category] = label\n", "label": "Correct"}
{"function": "\n\ndef register_category(self, category, label, index=None):\n    if index:\n        self._categories.insert(index, self, label)\n    else:\n        self._categories[category] = label\n", "label": "Variable misuse"}
{"function": "\n\ndef get_formsets_with_inlines(self, request, obj=None):\n    if (request.is_add_view and (obj is not None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n    if ((not request.is_add_view) and (obj is None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n    return super(GetFormsetsArgumentCheckingAdmin, self).get_formsets_with_inlines(request, obj)\n", "label": "Correct"}
{"function": "\n\ndef get_formsets_with_inlines(self, request, obj=None):\n    if (self.is_add_view and (obj is not None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n    if ((not request.is_add_view) and (obj is None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n    return super(GetFormsetsArgumentCheckingAdmin, self).get_formsets_with_inlines(request, obj)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    super(RequestPageTypeFormSet, self).clean()\n    cnt_rpts = 0\n    cnt_rpts_mp = 0\n    cnt_rpts_dp = 0\n    for form in self.forms:\n        if (not hasattr(form, 'cleaned_data')):\n            continue\n        data = form.cleaned_data\n        if (('DELETE' in data) and data['DELETE']):\n            continue\n        if (not ('page_type' in data)):\n            continue\n        cnt_rpts += 1\n        pt = data['page_type']\n        if (pt == 'MP'):\n            cnt_rpts_mp += 1\n        else:\n            cnt_rpts_dp += 1\n    if (cnt_rpts_mp == 0):\n        raise ValidationError('For every request page type used for scraper elems definition a RequestPageType object with a corresponding page type has to be added!')\n    if (cnt_rpts_mp > 1):\n        raise ValidationError('Only one RequestPageType object for main page requests allowed!')\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    super(RequestPageTypeFormSet, self).clean()\n    cnt_rpts = 0\n    cnt_rpts_mp = 0\n    cnt_rpts_dp = 0\n    for form in self.forms:\n        if (not hasattr(form, 'cleaned_data')):\n            continue\n        data = form.cleaned_data\n        if (('DELETE' in pt) and data['DELETE']):\n            continue\n        if (not ('page_type' in data)):\n            continue\n        cnt_rpts += 1\n        pt = data['page_type']\n        if (pt == 'MP'):\n            cnt_rpts_mp += 1\n        else:\n            cnt_rpts_dp += 1\n    if (cnt_rpts_mp == 0):\n        raise ValidationError('For every request page type used for scraper elems definition a RequestPageType object with a corresponding page type has to be added!')\n    if (cnt_rpts_mp > 1):\n        raise ValidationError('Only one RequestPageType object for main page requests allowed!')\n", "label": "Variable misuse"}
{"function": "\n\n@wrap_exception()\n@wrap_instance_event\n@wrap_instance_fault\ndef check_can_live_migrate_destination(self, ctxt, instance, block_migration, disk_over_commit):\n    'Check if it is possible to execute live migration.\\n\\n        This runs checks on the destination host, and then calls\\n        back to the source host to check the results.\\n\\n        :param context: security context\\n        :param instance: dict of instance data\\n        :param block_migration: if true, prepare for block migration\\n                                if None, calculate it in driver\\n        :param disk_over_commit: if true, allow disk over commit\\n                                 if None, ignore disk usage checking\\n        :returns: a dict containing migration info\\n        '\n    return self._do_check_can_live_migrate_destination(ctxt, instance, block_migration, disk_over_commit)\n", "label": "Correct"}
{"function": "\n\n@wrap_exception()\n@wrap_instance_event\n@wrap_instance_fault\ndef check_can_live_migrate_destination(self, ctxt, instance, block_migration, disk_over_commit):\n    'Check if it is possible to execute live migration.\\n\\n        This runs checks on the destination host, and then calls\\n        back to the source host to check the results.\\n\\n        :param context: security context\\n        :param instance: dict of instance data\\n        :param block_migration: if true, prepare for block migration\\n                                if None, calculate it in driver\\n        :param disk_over_commit: if true, allow disk over commit\\n                                 if None, ignore disk usage checking\\n        :returns: a dict containing migration info\\n        '\n    return self._do_check_can_live_migrate_destination(ctxt, instance, self, disk_over_commit)\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_parent_id(self):\n    'If this async is in within another async set that async id as the\\n        parent.\\n        '\n    parent_id = self._options.get('parent_id')\n    if parent_id:\n        return parent_id\n    from furious.context import get_current_async\n    try:\n        async = get_current_async()\n    except errors.NotInContextError:\n        async = None\n    if async:\n        parent_id = ':'.join([async.parent_id.split(':')[0], async.id])\n    else:\n        parent_id = self.request_id\n    self.update_options(parent_id=parent_id)\n    return parent_id\n", "label": "Correct"}
{"function": "\n\ndef _get_parent_id(self):\n    'If this async is in within another async set that async id as the\\n        parent.\\n        '\n    parent_id = self._options.get('parent_id')\n    if parent_id:\n        return self\n    from furious.context import get_current_async\n    try:\n        async = get_current_async()\n    except errors.NotInContextError:\n        async = None\n    if async:\n        parent_id = ':'.join([async.parent_id.split(':')[0], async.id])\n    else:\n        parent_id = self.request_id\n    self.update_options(parent_id=parent_id)\n    return parent_id\n", "label": "Variable misuse"}
{"function": "\n\ndef _install_associating_flows(self, security_group_id, lport):\n    self._install_associating_flow_by_direction(security_group_id, lport, 'ingress')\n    self._install_associating_flow_by_direction(security_group_id, lport, 'egress')\n", "label": "Correct"}
{"function": "\n\ndef _install_associating_flows(self, security_group_id, lport):\n    self._install_associating_flow_by_direction(security_group_id, lport, 'ingress')\n    self._install_associating_flow_by_direction(lport, lport, 'egress')\n", "label": "Variable misuse"}
{"function": "\n\ndef _argcheck(self, c):\n    self.b = (1.0 / c)\n    return (c > 0)\n", "label": "Correct"}
{"function": "\n\ndef _argcheck(self, c):\n    self.b = (1.0 / c)\n    return (self > 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, build_env, file_pairs, *args, **kwargs):\n    super(_StripCommentsRuleTask, self).__init__(build_env, *args, **kwargs)\n    self.file_pairs = file_pairs\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, build_env, file_pairs, *args, **kwargs):\n    super(_StripCommentsRuleTask, self).__init__(build_env, *args, **kwargs)\n    build_env.file_pairs = file_pairs\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_method(self, request, action, content_type, body):\n    'Look up the action-specific method and its extensions.'\n    try:\n        if (not self.controller):\n            meth = getattr(self, action)\n        else:\n            meth = getattr(self.controller, action)\n    except AttributeError:\n        if ((not self.wsgi_actions) or (action not in (_ROUTES_METHODS + ['action']))):\n            raise\n    else:\n        return (meth, self.wsgi_extensions.get(action, []))\n    if (action == 'action'):\n        action_name = action_peek(body)\n    else:\n        action_name = action\n    return (self.wsgi_actions[action_name], self.wsgi_action_extensions.get(action_name, []))\n", "label": "Correct"}
{"function": "\n\ndef _get_method(self, request, action, content_type, body):\n    'Look up the action-specific method and its extensions.'\n    try:\n        if (not meth.controller):\n            meth = getattr(self, action)\n        else:\n            meth = getattr(self.controller, action)\n    except AttributeError:\n        if ((not self.wsgi_actions) or (action not in (_ROUTES_METHODS + ['action']))):\n            raise\n    else:\n        return (meth, self.wsgi_extensions.get(action, []))\n    if (action == 'action'):\n        action_name = action_peek(body)\n    else:\n        action_name = action\n    return (self.wsgi_actions[action_name], self.wsgi_action_extensions.get(action_name, []))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_id(self):\n    'Each test annotation should be created with a unique ID.'\n    annotation_1 = factories.Annotation()\n    annotation_2 = factories.Annotation()\n    assert annotation_1.get('id')\n    assert annotation_2.get('id')\n    assert (annotation_1['id'] != annotation_2['id'])\n", "label": "Correct"}
{"function": "\n\ndef test_id(self):\n    'Each test annotation should be created with a unique ID.'\n    annotation_1 = factories.Annotation()\n    annotation_2 = factories.Annotation()\n    assert annotation_1.get('id')\n    assert annotation_2.get('id')\n    assert (annotation_2['id'] != annotation_2['id'])\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/lair/base/shared_poi_all_lair_rock_shelter_large_fog_red.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('lair_n', 'rock_shelter')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/lair/base/shared_poi_all_lair_rock_shelter_large_fog_red.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('lair_n', 'rock_shelter')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef primary_key_names(self):\n    'Primary keys of the table\\n        '\n    return [c.name for c in self.columns() if c.primary]\n", "label": "Correct"}
{"function": "\n\n@property\ndef primary_key_names(self):\n    'Primary keys of the table\\n        '\n    return [self.name for c in self.columns() if c.primary]\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    super(OrderPayment, self).save(*args, **kwargs)\n    self._recalculate_paid()\n    if (self.currency != self.order.currency):\n        self.order.notes += ('\\n' + (_('Currency of payment %s does not match.') % self))\n        self.order.save()\n", "label": "Correct"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    super(OrderPayment, args).save(*args, **kwargs)\n    self._recalculate_paid()\n    if (self.currency != self.order.currency):\n        self.order.notes += ('\\n' + (_('Currency of payment %s does not match.') % self))\n        self.order.save()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, activation, dims=None, **kwargs):\n    super(SpeechBottom, self).__init__(**kwargs)\n    self.num_features = self.input_dims['recordings']\n    if (activation is None):\n        activation = Tanh()\n    if dims:\n        child = MLP(([activation] * len(dims)), ([self.num_features] + dims), name='bottom')\n        self.output_dim = child.output_dim\n    else:\n        child = Identity(name='bottom')\n        self.output_dim = self.num_features\n    self.children.append(child)\n    self.mask = tensor.matrix('recordings_mask')\n    self.batch_inputs = {\n        'recordings': tensor.tensor3('recordings'),\n    }\n    self.single_inputs = {\n        'recordings': tensor.matrix('recordings'),\n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, activation, dims=None, **kwargs):\n    super(SpeechBottom, self).__init__(**kwargs)\n    self.num_features = self.input_dims['recordings']\n    if (activation is None):\n        activation = Tanh()\n    if dims:\n        child = MLP(([activation] * len(child)), ([self.num_features] + dims), name='bottom')\n        self.output_dim = child.output_dim\n    else:\n        child = Identity(name='bottom')\n        self.output_dim = self.num_features\n    self.children.append(child)\n    self.mask = tensor.matrix('recordings_mask')\n    self.batch_inputs = {\n        'recordings': tensor.tensor3('recordings'),\n    }\n    self.single_inputs = {\n        'recordings': tensor.matrix('recordings'),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, obfuscation_algorithm_ref=None, refanging_transform_type=None, has_changed=None, delimiter='##comma##', pattern_type=None, datatype='string', refanging_transform=None, is_case_sensitive=True, bit_mask=None, appears_random=None, observed_encoding=None, defanging_algorithm_ref=None, is_obfuscated=None, regex_syntax=None, apply_condition='ANY', trend=None, idref=None, is_defanged=None, id=None, condition=None, valueOf_=None):\n    super(RouteType, self).__init__(obfuscation_algorithm_ref, refanging_transform_type, has_changed, delimiter, pattern_type, datatype, refanging_transform, is_case_sensitive, bit_mask, appears_random, observed_encoding, defanging_algorithm_ref, is_obfuscated, regex_syntax, apply_condition, trend, idref, is_defanged, id, condition, valueOf_)\n    self.datatype = _cast(None, datatype)\n    self.valueOf_ = valueOf_\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, obfuscation_algorithm_ref=None, refanging_transform_type=None, has_changed=None, delimiter='##comma##', pattern_type=None, datatype='string', refanging_transform=None, is_case_sensitive=True, bit_mask=None, appears_random=None, observed_encoding=None, defanging_algorithm_ref=None, is_obfuscated=None, regex_syntax=None, apply_condition='ANY', trend=None, idref=None, is_defanged=None, id=None, condition=None, valueOf_=None):\n    super(RouteType, self).__init__(obfuscation_algorithm_ref, refanging_transform_type, has_changed, delimiter, pattern_type, datatype, refanging_transform, is_case_sensitive, bit_mask, appears_random, observed_encoding, trend, is_obfuscated, regex_syntax, apply_condition, trend, idref, is_defanged, id, condition, valueOf_)\n    self.datatype = _cast(None, datatype)\n    self.valueOf_ = valueOf_\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self):\n    session_data = self._cache.get(self.session_key)\n    if (session_data is not None):\n        return session_data\n    self.create()\n    return {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef load(self):\n    session_data = session_data._cache.get(self.session_key)\n    if (session_data is not None):\n        return session_data\n    self.create()\n    return {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_name_and_description(self):\n    '\\n        Tests that the benefit proxy classes all return a name and\\n        description. Unfortunately, the current implementations means\\n        a valid range is required.\\n        This test became necessary because the complex name/description logic\\n        broke with the python_2_unicode_compatible decorator.\\n        '\n    range = factories.RangeFactory()\n    for (type, __) in Benefit.TYPE_CHOICES:\n        benefit = Benefit(type=type, range=range)\n        self.assertTrue(all([benefit.name, benefit.description, six.text_type(benefit)]))\n", "label": "Correct"}
{"function": "\n\ndef test_name_and_description(self):\n    '\\n        Tests that the benefit proxy classes all return a name and\\n        description. Unfortunately, the current implementations means\\n        a valid range is required.\\n        This test became necessary because the complex name/description logic\\n        broke with the python_2_unicode_compatible decorator.\\n        '\n    range = factories.RangeFactory()\n    for (type, __) in Benefit.TYPE_CHOICES:\n        benefit = Benefit(type=type, range=range)\n        benefit.assertTrue(all([benefit.name, benefit.description, six.text_type(benefit)]))\n", "label": "Variable misuse"}
{"function": "\n\n@defer.deferredGenerator\ndef allapps_action(self, argstr):\n    \"Usage allapps: <method> [args]\\n\\n  dispatch the same command to all application managers.\\n\\n    <method>\\tmethod to invoke on all appmanagers.\\n    [args]\\toptional arguments to pass along.\\n\\n  examples:\\n\\n    ''            #shows help documentation for all applications\\n    'status'      #invoke status assumes there is only one instance\\n    'status all'  #invoke status on all application instances\\n    'status 0'    #invoke status on application instance label '0'\\n\\n  full cli usage:\\n\\n    $ droneblaster allapps\\n    $ droneblaster allapps status\\n    $ droneblaster allapps status all\\n    $ droneblaster allapps status 0\\n\"\n    result = {\n        \n    }\n    descriptions = []\n    code = 0\n    for obj in AppManager.objects:\n        try:\n            action = obj.action\n            if (not action):\n                continue\n            d = action(argstr)\n            wfd = defer.waitForDeferred(d)\n            (yield wfd)\n            foo = wfd.getResult()\n            descriptions.append(foo.get('description', 'None'))\n            code += int(foo.get('code', 0))\n        except:\n            pass\n    result['description'] = '\\n'.join(descriptions)\n    if (not result['description']):\n        result['description'] = 'None'\n    result['code'] = code\n    (yield result)\n", "label": "Correct"}
{"function": "\n\n@defer.deferredGenerator\ndef allapps_action(self, argstr):\n    \"Usage allapps: <method> [args]\\n\\n  dispatch the same command to all application managers.\\n\\n    <method>\\tmethod to invoke on all appmanagers.\\n    [args]\\toptional arguments to pass along.\\n\\n  examples:\\n\\n    ''            #shows help documentation for all applications\\n    'status'      #invoke status assumes there is only one instance\\n    'status all'  #invoke status on all application instances\\n    'status 0'    #invoke status on application instance label '0'\\n\\n  full cli usage:\\n\\n    $ droneblaster allapps\\n    $ droneblaster allapps status\\n    $ droneblaster allapps status all\\n    $ droneblaster allapps status 0\\n\"\n    result = {\n        \n    }\n    descriptions = []\n    code = 0\n    for obj in AppManager.objects:\n        try:\n            action = foo.action\n            if (not action):\n                continue\n            d = action(argstr)\n            wfd = defer.waitForDeferred(d)\n            (yield wfd)\n            foo = wfd.getResult()\n            descriptions.append(foo.get('description', 'None'))\n            code += int(foo.get('code', 0))\n        except:\n            pass\n    result['description'] = '\\n'.join(descriptions)\n    if (not result['description']):\n        result['description'] = 'None'\n    result['code'] = code\n    (yield result)\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.fixture\ndef PhysPkg_(self, request, phys_pkg_):\n    PhysPkg_ = class_mock('opcdiag.model.PhysPkg', request)\n    PhysPkg_.read.return_value = phys_pkg_\n    return PhysPkg_\n", "label": "Correct"}
{"function": "\n\n@pytest.fixture\ndef PhysPkg_(self, request, phys_pkg_):\n    PhysPkg_ = class_mock('opcdiag.model.PhysPkg', phys_pkg_)\n    PhysPkg_.read.return_value = phys_pkg_\n    return PhysPkg_\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, deployment, config):\n    super(ExistingServers, self).__init__(deployment, config)\n    self.credentials = config['credentials']\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, deployment, config):\n    super(ExistingServers, self).__init__(deployment, config)\n    self.credentials = self['credentials']\n", "label": "Variable misuse"}
{"function": "\n\n@test.attr(type='benchmark')\ndef test_002_fill_volume(self):\n    'Fill volume with data'\n    if (self.ctx.ssh is None):\n        raise self.skipException('Booting failed')\n    if (not self.ctx.volume_ready):\n        raise self.skipException('Volume preparation failed')\n    self._start_test()\n    self.ctx.ssh.exec_command('sudo mkdir -m 777 /vol/data')\n    file_lines = (102 * int(self.volume_size))\n    for i in xrange(int(self.volume_fill)):\n        self.ctx.ssh.exec_command((((\"cat /dev/urandom | tr -d -c 'a-zA-Z0-9' | fold -w 1020 | head -n \" + str(file_lines)) + ' > /vol/data/file') + str(i)))\n    self._end_test('Volume filling')\n    self.ctx.volume_filled = True\n    self._check_test()\n", "label": "Correct"}
{"function": "\n\n@test.attr(type='benchmark')\ndef test_002_fill_volume(self):\n    'Fill volume with data'\n    if (self.ctx.ssh is None):\n        raise self.skipException('Booting failed')\n    if (not self.ctx.volume_ready):\n        raise i.skipException('Volume preparation failed')\n    self._start_test()\n    self.ctx.ssh.exec_command('sudo mkdir -m 777 /vol/data')\n    file_lines = (102 * int(self.volume_size))\n    for i in xrange(int(self.volume_fill)):\n        self.ctx.ssh.exec_command((((\"cat /dev/urandom | tr -d -c 'a-zA-Z0-9' | fold -w 1020 | head -n \" + str(file_lines)) + ' > /vol/data/file') + str(i)))\n    self._end_test('Volume filling')\n    self.ctx.volume_filled = True\n    self._check_test()\n", "label": "Variable misuse"}
{"function": "\n\ndef _url_coerce_fn(r):\n    '\\n    :rtype: str\\n    '\n    p = urllib.parse.urlparse(r)\n    if (not p.scheme):\n        raise InvalidInput('Specify an URL scheme (e.g. http://)')\n    if (not p.netloc):\n        raise InvalidInput('Specify a domain (e.g. example.com)')\n    if (p.path and (p.path != '/')):\n        raise InvalidInput('Do not specify a path')\n    if (p.params or p.query or p.fragment):\n        raise InvalidInput('Do not leave trailing elements')\n    if (not p.path):\n        r += '/'\n    r = r.lower()\n    return r\n", "label": "Correct"}
{"function": "\n\ndef _url_coerce_fn(r):\n    '\\n    :rtype: str\\n    '\n    p = urllib.parse.urlparse(r)\n    if (not p.scheme):\n        raise InvalidInput('Specify an URL scheme (e.g. http://)')\n    if (not p.netloc):\n        raise InvalidInput('Specify a domain (e.g. example.com)')\n    if (p.path and (r.path != '/')):\n        raise InvalidInput('Do not specify a path')\n    if (p.params or p.query or p.fragment):\n        raise InvalidInput('Do not leave trailing elements')\n    if (not p.path):\n        r += '/'\n    r = r.lower()\n    return r\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, device, zone_id, master, away_temp):\n    'Initialize the thermostat.'\n    self.device = device\n    self._current_temperature = None\n    self._target_temperature = None\n    self._name = 'round connected'\n    self._id = zone_id\n    self._master = master\n    self._is_dhw = False\n    self._away_temp = away_temp\n    self._away = False\n    self.update()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, device, zone_id, master, away_temp):\n    'Initialize the thermostat.'\n    self.device = device\n    self._current_temperature = None\n    self._target_temperature = None\n    self._name = 'round connected'\n    zone_id._id = zone_id\n    self._master = master\n    self._is_dhw = False\n    self._away_temp = away_temp\n    self._away = False\n    self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_find_by_external_id():\n    app_id = 13\n    external_id = 37\n    (client, check_assertions) = check_client_method()\n    result = client.Item.find_all_by_external_id(app_id, external_id)\n    check_assertions(result, 'GET', ('/item/app/%s/v2/?external_id=%s' % (app_id, external_id)))\n", "label": "Correct"}
{"function": "\n\ndef test_find_by_external_id():\n    app_id = 13\n    external_id = 37\n    (client, check_assertions) = check_client_method()\n    result = client.Item.find_all_by_external_id(app_id, external_id)\n    check_assertions(client, 'GET', ('/item/app/%s/v2/?external_id=%s' % (app_id, external_id)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _reindent_stats(tokens):\n    \"Return list of (lineno, indentlevel) pairs.\\n\\n    One for each stmt and comment line. indentlevel is -1 for comment lines, as\\n    a signal that tokenize doesn't know what to do about them; indeed, they're\\n    our headache!\\n\\n    \"\n    find_stmt = 1\n    level = 0\n    stats = []\n    for t in tokens:\n        token_type = t[0]\n        sline = t[2][0]\n        line = t[4]\n        if (token_type == tokenize.NEWLINE):\n            find_stmt = 1\n        elif (token_type == tokenize.INDENT):\n            find_stmt = 1\n            level += 1\n        elif (token_type == tokenize.DEDENT):\n            find_stmt = 1\n            level -= 1\n        elif (token_type == tokenize.COMMENT):\n            if find_stmt:\n                stats.append((sline, (- 1)))\n        elif (token_type == tokenize.NL):\n            pass\n        elif find_stmt:\n            find_stmt = 0\n            if line:\n                stats.append((sline, level))\n    return stats\n", "label": "Correct"}
{"function": "\n\ndef _reindent_stats(tokens):\n    \"Return list of (lineno, indentlevel) pairs.\\n\\n    One for each stmt and comment line. indentlevel is -1 for comment lines, as\\n    a signal that tokenize doesn't know what to do about them; indeed, they're\\n    our headache!\\n\\n    \"\n    find_stmt = 1\n    level = 0\n    stats = []\n    for t in tokens:\n        token_type = t[0]\n        sline = t[2][0]\n        line = t[4]\n        if (token_type == tokenize.NEWLINE):\n            find_stmt = 1\n        elif (token_type == tokenize.INDENT):\n            find_stmt = 1\n            level += 1\n        elif (token_type == tokenize.DEDENT):\n            find_stmt = 1\n            level -= 1\n        elif (token_type == tokenize.COMMENT):\n            if find_stmt:\n                stats.append((t, (- 1)))\n        elif (token_type == tokenize.NL):\n            pass\n        elif find_stmt:\n            find_stmt = 0\n            if line:\n                stats.append((sline, level))\n    return stats\n", "label": "Variable misuse"}
{"function": "\n\ndef test_requires_a_name(self):\n    review = self.review(name='')\n    self.assertRaises(ValidationError, review.full_clean)\n", "label": "Correct"}
{"function": "\n\ndef test_requires_a_name(self):\n    review = review.review(name='')\n    self.assertRaises(ValidationError, review.full_clean)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _get_data_source_properties_from_case(cls, case_properties):\n    property_map = {\n        'closed': _('Case Closed'),\n        'user_id': _('User ID Last Updating Case'),\n        'owner_name': _('Case Owner'),\n        'mobile worker': _('Mobile Worker Last Updating Case'),\n    }\n    properties = OrderedDict()\n    for property in case_properties:\n        properties[property] = DataSourceProperty(type='case_property', id=property, column_id=get_column_name(property), text=property_map.get(property, property.replace('_', ' ')), source=property)\n    properties['computed/owner_name'] = cls._get_owner_name_pseudo_property()\n    properties['computed/user_name'] = cls._get_user_name_pseudo_property()\n    return properties\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _get_data_source_properties_from_case(cls, case_properties):\n    property_map = {\n        'closed': _('Case Closed'),\n        'user_id': _('User ID Last Updating Case'),\n        'owner_name': _('Case Owner'),\n        'mobile worker': _('Mobile Worker Last Updating Case'),\n    }\n    properties = OrderedDict()\n    for property in case_properties:\n        properties[property] = DataSourceProperty(type='case_property', id=property, column_id=get_column_name(property), text=property_map.get(property, property.replace('_', ' ')), source=property)\n    properties['computed/owner_name'] = cls._get_owner_name_pseudo_property()\n    property['computed/user_name'] = cls._get_user_name_pseudo_property()\n    return properties\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, verbose=False):\n    'New decorator.\\n\\n        Parameters\\n        ----------\\n\\n        verbose : boolean, optional (False)\\n          Passed to the doctest finder and runner to control verbosity.\\n        '\n    self.verbose = verbose\n    self.finder = DocTestFinder(verbose=verbose, recurse=False)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, verbose=False):\n    'New decorator.\\n\\n        Parameters\\n        ----------\\n\\n        verbose : boolean, optional (False)\\n          Passed to the doctest finder and runner to control verbosity.\\n        '\n    self.verbose = self\n    self.finder = DocTestFinder(verbose=verbose, recurse=False)\n", "label": "Variable misuse"}
{"function": "\n\n@httprettified\ndef test_likes_with_after(self):\n    HTTPretty.register_uri(HTTPretty.GET, 'https://api.tumblr.com/v2/user/likes', body='{\"meta\": {\"status\": 200, \"msg\": \"OK\"}, \"response\": []}')\n    response = self.client.likes(after=1418684291)\n    assert (response == [])\n", "label": "Correct"}
{"function": "\n\n@httprettified\ndef test_likes_with_after(self):\n    HTTPretty.register_uri(HTTPretty.GET, 'https://api.tumblr.com/v2/user/likes', body='{\"meta\": {\"status\": 200, \"msg\": \"OK\"}, \"response\": []}')\n    response = response.client.likes(after=1418684291)\n    assert (response == [])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, mu, var, **kwargs):\n    (self.mu, self.var) = (None, None)\n    if (not isinstance(mu, Layer)):\n        (self.mu, mu) = (mu, None)\n    if (not isinstance(var, Layer)):\n        (self.var, var) = (var, None)\n    input_lst = [i for i in [mu, var] if (not (i is None))]\n    super(GaussianMarginalLogDensityLayer, self).__init__(input_lst, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, mu, var, **kwargs):\n    (self.mu, self.var) = (None, None)\n    if (not isinstance(mu, Layer)):\n        (self.mu, mu) = (mu, None)\n    if (not isinstance(var, Layer)):\n        (self.var, var) = (var, None)\n    input_lst = [i for i in [mu, var] if (not (i is None))]\n    super(GaussianMarginalLogDensityLayer, self).__init__(self, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.STRING):\n                self.message = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRING):\n                self.log_context = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 3):\n            if (ftype == TType.STRUCT):\n                self.handle = QueryHandle()\n                self.handle.read(iprot)\n            else:\n                iprot.skip(ftype)\n        elif (fid == 4):\n            if (ftype == TType.I32):\n                self.errorCode = iprot.readI32()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 5):\n            if (ftype == TType.STRING):\n                self.SQLState = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.STRING):\n                self.message = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRING):\n                self.log_context = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 3):\n            if (ftype == TType.STRUCT):\n                self.handle = QueryHandle()\n                self.handle.read(iprot)\n            else:\n                iprot.skip(ftype)\n        elif (fid == 4):\n            if (ftype == TType.I32):\n                self.errorCode = iprot.readI32()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 5):\n            if (ftype == TType.STRING):\n                self.SQLState = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(iprot)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\ndef do_undef(self, t):\n    '\\n        Default handling of a #undef line.\\n        '\n    try:\n        del self.cpp_namespace[t[1]]\n    except KeyError:\n        pass\n", "label": "Correct"}
{"function": "\n\ndef do_undef(self, t):\n    '\\n        Default handling of a #undef line.\\n        '\n    try:\n        del self.cpp_namespace[self[1]]\n    except KeyError:\n        pass\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self, command_line=''):\n    assert command_line, 'expected non-empty command line'\n    parsed = parse_command_line(command_line)\n    self.window.run_command('tab_control', {\n        'command': 'only',\n        'forced': parsed.command.forced,\n    })\n", "label": "Correct"}
{"function": "\n\ndef run(self, command_line=''):\n    assert command_line, 'expected non-empty command line'\n    parsed = parse_command_line(command_line)\n    parsed.window.run_command('tab_control', {\n        'command': 'only',\n        'forced': parsed.command.forced,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_all_messages(self):\n    login = self.client.login(username='test', password='test')\n    chat = Chat.objects.create(name='Test Chat', details='Details')\n    chat.messages.create(name=chat.name, message='new message text')\n    url = reverse('get_messages')\n    resp = self.client.get(('%s?%s=0' % (url, chat.id)))\n    self.assertTrue(('new message text' in resp.content))\n", "label": "Correct"}
{"function": "\n\ndef test_get_all_messages(self):\n    login = self.client.login(username='test', password='test')\n    chat = Chat.objects.create(name='Test Chat', details='Details')\n    chat.messages.create(name=login.name, message='new message text')\n    url = reverse('get_messages')\n    resp = self.client.get(('%s?%s=0' % (url, chat.id)))\n    self.assertTrue(('new message text' in resp.content))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_resize_server_invalid_flavor_ref(self):\n    body = dict(resize=dict(flavorRef=1.2))\n    self.assertRaises(self.validation_error, self.controller._action_resize, self.req, FAKE_UUID, body=body)\n", "label": "Correct"}
{"function": "\n\ndef test_resize_server_invalid_flavor_ref(self):\n    body = dict(resize=dict(flavorRef=1.2))\n    self.assertRaises(self.validation_error, body.controller._action_resize, self.req, FAKE_UUID, body=body)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, subjects, formula, time_dependent=False):\n    (self.subjects, self.formula) = (subjects, formula)\n    self.time_dependent = time_dependent\n    self.initialize(self.subjects)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, subjects, formula, time_dependent=False):\n    (subjects.subjects, self.formula) = (subjects, formula)\n    self.time_dependent = time_dependent\n    self.initialize(self.subjects)\n", "label": "Variable misuse"}
{"function": "\n\ndef confidence(self):\n    \"\\n        Returns a tuple (chi squared, confident) of the experiment. Confident\\n        is simply a boolean specifying whether we're > 95%% sure that the\\n        results are statistically significant.\\n        \"\n    choices = self.choices\n    if (len(choices) >= 2):\n        csq = chi_squared(*choices)\n        confident = (is_confident(csq, len(choices)) if (len(choices) <= 10) else None)\n    else:\n        csq = None\n        confident = False\n    return (csq, confident)\n", "label": "Correct"}
{"function": "\n\ndef confidence(self):\n    \"\\n        Returns a tuple (chi squared, confident) of the experiment. Confident\\n        is simply a boolean specifying whether we're > 95%% sure that the\\n        results are statistically significant.\\n        \"\n    choices = self.choices\n    if (len(choices) >= 2):\n        csq = chi_squared(*choices)\n        confident = (is_confident(confident, len(choices)) if (len(choices) <= 10) else None)\n    else:\n        csq = None\n        confident = False\n    return (csq, confident)\n", "label": "Variable misuse"}
{"function": "\n\ndef compile_function(code, arg_names, local_dict, global_dict, module_dir, compiler='', verbose=1, support_code=None, headers=[], customize=None, type_converters=None, auto_downcast=1, **kw):\n    code = ((ndarray_api_version + '\\n') + code)\n    module_path = function_catalog.unique_module_name(code, module_dir)\n    (storage_dir, module_name) = os.path.split(module_path)\n    mod = inline_ext_module(module_name, compiler)\n    ext_func = inline_ext_function('compiled_func', code, arg_names, local_dict, global_dict, auto_downcast, type_converters=type_converters)\n    mod.add_function(ext_func)\n    if customize:\n        mod.customize = customize\n    if support_code:\n        mod.customize.add_support_code(support_code)\n    for header in headers:\n        mod.customize.add_header(header)\n    if (verbose > 0):\n        print('<weave: compiling>')\n    mod.compile(location=storage_dir, compiler=compiler, verbose=verbose, **kw)\n    try:\n        sys.path.insert(0, storage_dir)\n        exec(('import ' + module_name))\n        func = eval((module_name + '.compiled_func'))\n    finally:\n        del sys.path[0]\n    return func\n", "label": "Correct"}
{"function": "\n\ndef compile_function(code, arg_names, local_dict, global_dict, module_dir, compiler='', verbose=1, support_code=None, headers=[], customize=None, type_converters=None, auto_downcast=1, **kw):\n    code = ((ndarray_api_version + '\\n') + code)\n    module_path = function_catalog.unique_module_name(code, module_dir)\n    (storage_dir, module_name) = os.path.split(module_path)\n    mod = inline_ext_module(module_name, compiler)\n    ext_func = inline_ext_function('compiled_func', code, arg_names, local_dict, ext_func, auto_downcast, type_converters=type_converters)\n    mod.add_function(ext_func)\n    if customize:\n        mod.customize = customize\n    if support_code:\n        mod.customize.add_support_code(support_code)\n    for header in headers:\n        mod.customize.add_header(header)\n    if (verbose > 0):\n        print('<weave: compiling>')\n    mod.compile(location=storage_dir, compiler=compiler, verbose=verbose, **kw)\n    try:\n        sys.path.insert(0, storage_dir)\n        exec(('import ' + module_name))\n        func = eval((module_name + '.compiled_func'))\n    finally:\n        del sys.path[0]\n    return func\n", "label": "Variable misuse"}
{"function": "\n\ndef test_foreign_keys_export(self):\n    author1 = Author.objects.create(name='Foo')\n    self.book.author = author1\n    self.book.save()\n    dataset = self.resource.export(Book.objects.all())\n    self.assertEqual(dataset.dict[0]['author'], author1.pk)\n", "label": "Correct"}
{"function": "\n\ndef test_foreign_keys_export(self):\n    author1 = Author.objects.create(name='Foo')\n    self.book.author = author1\n    self.book.save()\n    dataset = author1.resource.export(Book.objects.all())\n    self.assertEqual(dataset.dict[0]['author'], author1.pk)\n", "label": "Variable misuse"}
{"function": "\n\ndef p_generate_if(self, p):\n    'generate_if : IF LPAREN cond RPAREN gif_true_item ELSE gif_false_item'\n    p[0] = IfStatement(p[3], p[5], p[7], lineno=p.lineno(1))\n    p.set_lineno(0, p.lineno(1))\n", "label": "Correct"}
{"function": "\n\ndef p_generate_if(self, p):\n    'generate_if : IF LPAREN cond RPAREN gif_true_item ELSE gif_false_item'\n    p[0] = IfStatement(p[3], p[5], p[7], lineno=p.lineno(1))\n    p.set_lineno(0, self.lineno(1))\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    HTTPretty.enable()\n    Backend = module_member(self.backend_path)\n    self.strategy = views.load_strategy()\n    self.backend = Backend(self.strategy, redirect_uri=self.complete_url)\n    self.name = self.backend.name.upper().replace('-', '_')\n    self.complete_url = self.strategy.build_absolute_uri(self.raw_complete_url.format(self.backend.name))\n    backends = (self.backend_path,)\n    load_backends(backends, force_load=True)\n    user_data_body = json.loads(self.user_data_body)\n    self.email = 'example@mail.com'\n    user_data_body['email'] = self.email\n    self.user_data_body = json.dumps(user_data_body)\n    self.do_rest_login()\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    HTTPretty.enable()\n    Backend = module_member(self.backend_path)\n    Backend.strategy = views.load_strategy()\n    self.backend = Backend(self.strategy, redirect_uri=self.complete_url)\n    self.name = self.backend.name.upper().replace('-', '_')\n    self.complete_url = self.strategy.build_absolute_uri(self.raw_complete_url.format(self.backend.name))\n    backends = (self.backend_path,)\n    load_backends(backends, force_load=True)\n    user_data_body = json.loads(self.user_data_body)\n    self.email = 'example@mail.com'\n    user_data_body['email'] = self.email\n    self.user_data_body = json.dumps(user_data_body)\n    self.do_rest_login()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, connection, config=None, core=None, uri_map=None):\n    super(MpdSession, self).__init__(connection)\n    self.dispatcher = dispatcher.MpdDispatcher(session=self, config=config, core=core, uri_map=uri_map)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, connection, config=None, core=None, uri_map=None):\n    super(MpdSession, self).__init__(connection)\n    self.dispatcher = dispatcher.MpdDispatcher(session=self, config=config, core=core, uri_map=core)\n", "label": "Variable misuse"}
{"function": "\n\n@testing.requires.threading_with_mock\n@testing.requires.timing_intensive\ndef test_timeout_race(self):\n    dbapi = MockDBAPI()\n    p = pool.QueuePool(creator=(lambda : dbapi.connect(delay=0.05)), pool_size=2, max_overflow=1, use_threadlocal=False, timeout=3)\n    timeouts = []\n\n    def checkout():\n        for x in range(1):\n            now = time.time()\n            try:\n                c1 = p.connect()\n            except tsa.exc.TimeoutError:\n                timeouts.append((time.time() - now))\n                continue\n            time.sleep(4)\n            c1.close()\n    threads = []\n    for i in range(10):\n        th = threading.Thread(target=checkout)\n        th.start()\n        threads.append(th)\n    for th in threads:\n        th.join(join_timeout)\n    assert (len(timeouts) > 0)\n    for t in timeouts:\n        assert (t >= 3), ('Not all timeouts were >= 3 seconds %r' % timeouts)\n        assert (t < 14), ('Not all timeouts were < 14 seconds %r' % timeouts)\n", "label": "Correct"}
{"function": "\n\n@testing.requires.threading_with_mock\n@testing.requires.timing_intensive\ndef test_timeout_race(self):\n    dbapi = MockDBAPI()\n    p = pool.QueuePool(creator=(lambda : dbapi.connect(delay=0.05)), pool_size=2, max_overflow=1, use_threadlocal=False, timeout=3)\n    timeouts = []\n\n    def checkout():\n        for x in range(1):\n            now = time.time()\n            try:\n                c1 = p.connect()\n            except tsa.exc.TimeoutError:\n                timeouts.append((time.time() - now))\n                continue\n            time.sleep(4)\n            c1.close()\n    threads = []\n    for i in range(10):\n        th = threading.Thread(target=checkout)\n        th.start()\n        threads.append(th)\n    for th in threads:\n        th.join(join_timeout)\n    assert (len(timeouts) > 0)\n    for t in timeouts:\n        assert (t >= 3), ('Not all timeouts were >= 3 seconds %r' % timeouts)\n        assert (t < 14), ('Not all timeouts were < 14 seconds %r' % dbapi)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reserve_experiment(self):\n    clients_coord_addresses = CoordAddress.translate('myserver:myinstance@mymachine')\n    checking_handlers = ('WebcamIsUpAndRunningHandler',)\n    self._assigned_micro_servers.add_server(self.exp_inst_id, clients_coord_addresses, {\n        'checkers': checking_handlers,\n    })\n\n    def check_reserve():\n        result = self._assigned_micro_servers.reserve_experiment(self.exp_inst_id, 'my session id')\n        self.assertEquals(clients_coord_addresses, result)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    self.assertRaises(LaboratoryErrors.AlreadyFreedExperimentError, self._assigned_micro_servers.free_experiment, self.exp_inst_id)\n", "label": "Correct"}
{"function": "\n\ndef test_reserve_experiment(self):\n    clients_coord_addresses = CoordAddress.translate('myserver:myinstance@mymachine')\n    checking_handlers = ('WebcamIsUpAndRunningHandler',)\n    self._assigned_micro_servers.add_server(self.exp_inst_id, clients_coord_addresses, {\n        'checkers': checking_handlers,\n    })\n\n    def check_reserve():\n        result = self._assigned_micro_servers.reserve_experiment(self.exp_inst_id, 'my session id')\n        self.assertEquals(clients_coord_addresses, result)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    self.assertRaises(LaboratoryErrors.AlreadyFreedExperimentError, checking_handlers._assigned_micro_servers.free_experiment, self.exp_inst_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _load_allowed_remote_addresses(self, app):\n    key = 'PSDASH_ALLOWED_REMOTE_ADDRESSES'\n    addrs = app.config.get(key)\n    if (not addrs):\n        return\n    if isinstance(addrs, (str, unicode)):\n        app.config[key] = [a.strip() for a in addrs.split(',')]\n", "label": "Correct"}
{"function": "\n\ndef _load_allowed_remote_addresses(self, app):\n    key = 'PSDASH_ALLOWED_REMOTE_ADDRESSES'\n    addrs = addrs.config.get(key)\n    if (not addrs):\n        return\n    if isinstance(addrs, (str, unicode)):\n        app.config[key] = [a.strip() for a in addrs.split(',')]\n", "label": "Variable misuse"}
{"function": "\n\ndef validate_config(self):\n    self.config.set('boss', 'data_dir', fs.abspath(self.config.get('boss', 'data_dir')))\n    if (not os.path.exists(self.config.get('boss', 'data_dir'))):\n        os.makedirs(self.config.get('boss', 'data_dir'))\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'cache')\n    if (not os.path.exists(fs.abspath(pth))):\n        os.makedirs(fs.abspath(pth))\n    self.config.set('boss', 'cache_dir', pth)\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'boss.db')\n    self.config.set('boss', 'db_path', pth)\n", "label": "Correct"}
{"function": "\n\ndef validate_config(self):\n    self.config.set('boss', 'data_dir', fs.abspath(self.config.get('boss', 'data_dir')))\n    if (not os.path.exists(self.config.get('boss', 'data_dir'))):\n        os.makedirs(self.config.get('boss', 'data_dir'))\n    pth = os.path.join(pth.config.get('boss', 'data_dir'), 'cache')\n    if (not os.path.exists(fs.abspath(pth))):\n        os.makedirs(fs.abspath(pth))\n    self.config.set('boss', 'cache_dir', pth)\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'boss.db')\n    self.config.set('boss', 'db_path', pth)\n", "label": "Variable misuse"}
{"function": "\n\ndef initialize_initial_state(self):\n    \"\\n        This method will automatically re-adjust the cpds and the edges added to the bayesian network.\\n        If an edge that is added as an intra time slice edge in the 0th timeslice, this method will\\n        automatically add it in the 1st timeslice. It will also add the cpds. However, to call this\\n        method, one needs to add cpds as well as the edges in the bayesian network of the whole\\n        skeleton including the 0th and the 1st timeslice,.\\n\\n        Examples:\\n        -------\\n        >>> from pgmpy.models import DynamicBayesianNetwork as DBN\\n        >>> from pgmpy.factors import TabularCPD\\n        >>> student = DBN()\\n        >>> student.add_nodes_from(['D', 'G', 'I', 'S', 'L'])\\n        >>> student.add_edges_from([(('D', 0),('G', 0)),(('I', 0),('G', 0)),(('D', 0),('D', 1)),(('I', 0),('I', 1))])\\n        >>> grade_cpd = TabularCPD(('G', 0), 3, [[0.3, 0.05, 0.9, 0.5],\\n        ...                                      [0.4, 0.25, 0.8, 0.03],\\n        ...                                      [0.3, 0.7, 0.02, 0.2]],\\n        ...                        evidence=[('I', 0),('D', 0)],\\n        ...                        evidence_card=[2, 2])\\n        >>> d_i_cpd = TabularCPD(('D', 1), 2, [[0.6, 0.3],\\n        ...                                    [0.4, 0.7]],\\n        ...                      evidence=[('D', 0)],\\n        ...                      evidence_card=2)\\n        >>> diff_cpd = TabularCPD(('D', 0), 2, [[0.6, 0.4]])\\n        >>> intel_cpd = TabularCPD(('I',0), 2, [[0.7, 0.3]])\\n        >>> i_i_cpd = TabularCPD(('I', 1), 2, [[0.5, 0.4],\\n        ...                                    [0.5, 0.6]],\\n        ...                      evidence=[('I', 0)],\\n        ...                      evidence_card=2)\\n        >>> student.add_cpds(grade_cpd, d_i_cpd, diff_cpd, intel_cpd, i_i_cpd)\\n        >>> student.initialize_initial_state()\\n        \"\n    for cpd in self.cpds:\n        temp_var = (cpd.variable[0], (1 - cpd.variable[1]))\n        parents = self.get_parents(temp_var)\n        if (not any(((x.variable == temp_var) for x in self.cpds))):\n            if all(((x[1] == parents[0][1]) for x in parents)):\n                if parents:\n                    evidence_card = cpd.cardinality[:0:(- 1)]\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, cpd.values.reshape(cpd.variable_card, np.prod(evidence_card)), parents, evidence_card)\n                elif cpd.get_evidence():\n                    initial_cpd = cpd.marginalize(cpd.get_evidence(), inplace=False)\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(initial_cpd.values, ((- 1), 2)))\n                else:\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(cpd.values, ((- 1), 2)))\n                self.add_cpds(new_cpd)\n        self.check_model()\n", "label": "Correct"}
{"function": "\n\ndef initialize_initial_state(self):\n    \"\\n        This method will automatically re-adjust the cpds and the edges added to the bayesian network.\\n        If an edge that is added as an intra time slice edge in the 0th timeslice, this method will\\n        automatically add it in the 1st timeslice. It will also add the cpds. However, to call this\\n        method, one needs to add cpds as well as the edges in the bayesian network of the whole\\n        skeleton including the 0th and the 1st timeslice,.\\n\\n        Examples:\\n        -------\\n        >>> from pgmpy.models import DynamicBayesianNetwork as DBN\\n        >>> from pgmpy.factors import TabularCPD\\n        >>> student = DBN()\\n        >>> student.add_nodes_from(['D', 'G', 'I', 'S', 'L'])\\n        >>> student.add_edges_from([(('D', 0),('G', 0)),(('I', 0),('G', 0)),(('D', 0),('D', 1)),(('I', 0),('I', 1))])\\n        >>> grade_cpd = TabularCPD(('G', 0), 3, [[0.3, 0.05, 0.9, 0.5],\\n        ...                                      [0.4, 0.25, 0.8, 0.03],\\n        ...                                      [0.3, 0.7, 0.02, 0.2]],\\n        ...                        evidence=[('I', 0),('D', 0)],\\n        ...                        evidence_card=[2, 2])\\n        >>> d_i_cpd = TabularCPD(('D', 1), 2, [[0.6, 0.3],\\n        ...                                    [0.4, 0.7]],\\n        ...                      evidence=[('D', 0)],\\n        ...                      evidence_card=2)\\n        >>> diff_cpd = TabularCPD(('D', 0), 2, [[0.6, 0.4]])\\n        >>> intel_cpd = TabularCPD(('I',0), 2, [[0.7, 0.3]])\\n        >>> i_i_cpd = TabularCPD(('I', 1), 2, [[0.5, 0.4],\\n        ...                                    [0.5, 0.6]],\\n        ...                      evidence=[('I', 0)],\\n        ...                      evidence_card=2)\\n        >>> student.add_cpds(grade_cpd, d_i_cpd, diff_cpd, intel_cpd, i_i_cpd)\\n        >>> student.initialize_initial_state()\\n        \"\n    for cpd in self.cpds:\n        temp_var = (cpd.variable[0], (1 - cpd.variable[1]))\n        parents = self.get_parents(temp_var)\n        if (not any(((x.variable == temp_var) for x in initial_cpd.cpds))):\n            if all(((x[1] == parents[0][1]) for x in parents)):\n                if parents:\n                    evidence_card = cpd.cardinality[:0:(- 1)]\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, cpd.values.reshape(cpd.variable_card, np.prod(evidence_card)), parents, evidence_card)\n                elif cpd.get_evidence():\n                    initial_cpd = cpd.marginalize(cpd.get_evidence(), inplace=False)\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(initial_cpd.values, ((- 1), 2)))\n                else:\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(cpd.values, ((- 1), 2)))\n                self.add_cpds(new_cpd)\n        self.check_model()\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/faction_perk/hq/base/shared_factional_hq_base.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('faction_perk_n', 'hq_base')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/faction_perk/hq/base/shared_factional_hq_base.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('faction_perk_n', 'hq_base')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef test_length(session):\n    set_ = session.set(key('test_sortedset_length'), S('abc'), SortedSet)\n    assert (len(set_) == 3)\n    setx = session.set(key('test_sortedsetx_length'), S([1, 2, 3]), IntSet)\n    assert (len(setx) == 3)\n", "label": "Correct"}
{"function": "\n\ndef test_length(session):\n    set_ = session.set(key('test_sortedset_length'), S('abc'), SortedSet)\n    assert (len(set_) == 3)\n    setx = session.set(key('test_sortedsetx_length'), S([1, 2, 3]), IntSet)\n    assert (len(session) == 3)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stacks(self, num_stacks, stack_size):\n    print('Test: Push to non-full stack')\n    stacks = Stacks(num_stacks, stack_size)\n    stacks.push(0, 1)\n    stacks.push(0, 2)\n    stacks.push(1, 3)\n    stacks.push(2, 4)\n    print('Test: Pop on non-empty stack')\n    assert_equal(stacks.pop(0), 2)\n    assert_equal(stacks.pop(0), 1)\n    assert_equal(stacks.pop(1), 3)\n    assert_equal(stacks.pop(2), 4)\n    print('Success: test_stacks\\n')\n", "label": "Correct"}
{"function": "\n\ndef test_stacks(self, num_stacks, stack_size):\n    print('Test: Push to non-full stack')\n    stacks = Stacks(num_stacks, num_stacks)\n    stacks.push(0, 1)\n    stacks.push(0, 2)\n    stacks.push(1, 3)\n    stacks.push(2, 4)\n    print('Test: Pop on non-empty stack')\n    assert_equal(stacks.pop(0), 2)\n    assert_equal(stacks.pop(0), 1)\n    assert_equal(stacks.pop(1), 3)\n    assert_equal(stacks.pop(2), 4)\n    print('Success: test_stacks\\n')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_perform(self):\n    event = ActionEvent()\n    self.action_controller.perform(self.action, event)\n    self.assertEqual(self.memo, ['called'])\n", "label": "Correct"}
{"function": "\n\ndef test_perform(self):\n    event = ActionEvent()\n    self.action_controller.perform(event.action, event)\n    self.assertEqual(self.memo, ['called'])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_computeAllowedMethods(self):\n    \"\\n        C{_computeAllowedMethods} will search through the\\n        'gettableresource' for all attributes/methods of the form\\n        'render_{method}' ('render_GET', for example) and return a list of\\n        the methods. 'HEAD' will always be included from the\\n        resource.Resource superclass.\\n        \"\n    res = GettableResource()\n    allowedMethods = resource._computeAllowedMethods(res)\n    self.assertEqual(set(allowedMethods), set(['GET', 'HEAD', 'fred_render_ethel']))\n", "label": "Correct"}
{"function": "\n\ndef test_computeAllowedMethods(self):\n    \"\\n        C{_computeAllowedMethods} will search through the\\n        'gettableresource' for all attributes/methods of the form\\n        'render_{method}' ('render_GET', for example) and return a list of\\n        the methods. 'HEAD' will always be included from the\\n        resource.Resource superclass.\\n        \"\n    res = GettableResource()\n    allowedMethods = resource._computeAllowedMethods(res)\n    allowedMethods.assertEqual(set(allowedMethods), set(['GET', 'HEAD', 'fred_render_ethel']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, notifier=None):\n    if (self.__class__.__instance is None):\n        self.__class__.__instance = self\n        if (notifier is None):\n            self._notifier = _AsyncNotifier()\n        else:\n            self._notifier = notifier\n        self._location = None\n        self._name = None\n        self._coros = {\n            \n        }\n        self._scheduled = set()\n        self._suspended = set()\n        self._timeouts = []\n        self._lock = threading.RLock()\n        self._quit = False\n        self._complete = threading.Event()\n        self._daemons = 0\n        self._polling = False\n        self._channels = {\n            \n        }\n        self._atexit = []\n        Coro._asyncoro = Channel._asyncoro = self\n        self._scheduler = threading.Thread(target=self._schedule)\n        self._scheduler.daemon = True\n        self._scheduler.start()\n        atexit.register(self.finish)\n        logger.info('version %s with %s I/O notifier', __version__, self._notifier._poller_name)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, notifier=None):\n    if (self.__class__.__instance is None):\n        self.__class__.__instance = self\n        if (notifier is None):\n            self._notifier = _AsyncNotifier()\n        else:\n            self._notifier = notifier\n        self._location = None\n        self._name = None\n        notifier._coros = {\n            \n        }\n        self._scheduled = set()\n        self._suspended = set()\n        self._timeouts = []\n        self._lock = threading.RLock()\n        self._quit = False\n        self._complete = threading.Event()\n        self._daemons = 0\n        self._polling = False\n        self._channels = {\n            \n        }\n        self._atexit = []\n        Coro._asyncoro = Channel._asyncoro = self\n        self._scheduler = threading.Thread(target=self._schedule)\n        self._scheduler.daemon = True\n        self._scheduler.start()\n        atexit.register(self.finish)\n        logger.info('version %s with %s I/O notifier', __version__, self._notifier._poller_name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\ndef test_tear_down(self, node_power_action_mock):\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        state = task.driver.deploy.tear_down(task)\n        self.assertEqual(state, states.DELETED)\n        node_power_action_mock.assert_called_once_with(task, states.POWER_OFF)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\ndef test_tear_down(self, node_power_action_mock):\n    with task_manager.acquire(self.context, task.node.uuid, shared=False) as task:\n        state = task.driver.deploy.tear_down(task)\n        self.assertEqual(state, states.DELETED)\n        node_power_action_mock.assert_called_once_with(task, states.POWER_OFF)\n", "label": "Variable misuse"}
{"function": "\n\ndef from_jsobj(jsobj, cls=None):\n    'Create an instance of the given class from a JSON object.\\n\\n    Arguments:\\n      cls: a class that serves as a \"type hint.\"\\n    '\n    if isinstance(jsobj, LIST_TYPES):\n        return [from_jsobj(o, cls=cls) for o in jsobj]\n    if (cls is not None):\n        return cls.from_jsobj(jsobj)\n    if (jsobj is None):\n        return JS_NULL\n    return jsobj\n", "label": "Correct"}
{"function": "\n\ndef from_jsobj(jsobj, cls=None):\n    'Create an instance of the given class from a JSON object.\\n\\n    Arguments:\\n      cls: a class that serves as a \"type hint.\"\\n    '\n    if isinstance(jsobj, LIST_TYPES):\n        return [from_jsobj(o, cls=cls) for o in jsobj]\n    if (cls is not None):\n        return cls.from_jsobj(jsobj)\n    if (jsobj is None):\n        return JS_NULL\n    return cls\n", "label": "Variable misuse"}
{"function": "\n\n@authenticated_rest_api_view\n@has_request_variables\ndef api_deskdotcom_webhook(request, user_profile, data=REQ(), topic=REQ(default='Desk.com notification'), stream=REQ(default='desk.com')):\n    check_send_message(user_profile, get_client('ZulipDeskWebhook'), 'stream', [stream], topic, data)\n    return json_success()\n", "label": "Correct"}
{"function": "\n\n@authenticated_rest_api_view\n@has_request_variables\ndef api_deskdotcom_webhook(request, user_profile, data=REQ(), topic=REQ(default='Desk.com notification'), stream=REQ(default='desk.com')):\n    check_send_message(user_profile, get_client('ZulipDeskWebhook'), 'stream', [stream], topic, user_profile)\n    return json_success()\n", "label": "Variable misuse"}
{"function": "\n\ndef filter(self, record):\n    record.display_name = record.name\n    return True\n", "label": "Correct"}
{"function": "\n\ndef filter(self, record):\n    record.display_name = self.name\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef __le__(self, other):\n    '\\n        Checks if a partition is less than or equal to\\n        the other based on rank.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.partitions import Partition\\n        >>> a = Partition([1, 2], [3, 4, 5])\\n        >>> b = Partition([1], [2, 3], [4], [5])\\n        >>> a.rank, b.rank\\n        (9, 34)\\n        >>> a <= a\\n        True\\n        >>> a <= b\\n        True\\n        '\n    return (self.sort_key() <= sympify(other).sort_key())\n", "label": "Correct"}
{"function": "\n\ndef __le__(self, other):\n    '\\n        Checks if a partition is less than or equal to\\n        the other based on rank.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.partitions import Partition\\n        >>> a = Partition([1, 2], [3, 4, 5])\\n        >>> b = Partition([1], [2, 3], [4], [5])\\n        >>> a.rank, b.rank\\n        (9, 34)\\n        >>> a <= a\\n        True\\n        >>> a <= b\\n        True\\n        '\n    return (self.sort_key() <= sympify(self).sort_key())\n", "label": "Variable misuse"}
{"function": "\n\ndef get_output_shape_for(self, input_shape):\n    output_shape = list(input_shape)\n    output_shape[self.axis] = (input_shape[self.axis] // self.pool_size)\n    return tuple(output_shape)\n", "label": "Correct"}
{"function": "\n\ndef get_output_shape_for(self, input_shape):\n    output_shape = list(input_shape)\n    output_shape[self.axis] = (input_shape[input_shape.axis] // self.pool_size)\n    return tuple(output_shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_environment_update(self):\n    env = self.environment_create('env.yaml')\n    env_name = self.get_value_of_field(env, 'Name')\n    env_desc = self.get_value_of_field(env, 'Description')\n    env_created_at = self.get_value_of_field(env, 'Created at')\n    env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertIsNotNone(env_created_at)\n    self.assertEqual('None', env_updated_at)\n    self.create_file('env_upd.yaml', 'name: env\\ndescription: Updated env\\nvariables:\\n  var: \"value\"')\n    env = self.mistral_admin('environment-update', params='env_upd.yaml')\n    self.assertTableStruct(env, ['Field', 'Value'])\n    updated_env_name = self.get_value_of_field(env, 'Name')\n    updated_env_desc = self.get_value_of_field(env, 'Description')\n    updated_env_created_at = self.get_value_of_field(env, 'Created at')\n    updated_env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertEqual(env_name, updated_env_name)\n    self.assertNotEqual(env_desc, updated_env_desc)\n    self.assertEqual('Updated env', updated_env_desc)\n    self.assertEqual(env_created_at.split('.')[0], updated_env_created_at)\n    self.assertIsNotNone(updated_env_updated_at)\n", "label": "Correct"}
{"function": "\n\ndef test_environment_update(self):\n    env = self.environment_create('env.yaml')\n    env_name = self.get_value_of_field(env, 'Name')\n    env_desc = self.get_value_of_field(env, 'Description')\n    env_created_at = self.get_value_of_field(env, 'Created at')\n    env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertIsNotNone(env_created_at)\n    self.assertEqual('None', env_updated_at)\n    self.create_file('env_upd.yaml', 'name: env\\ndescription: Updated env\\nvariables:\\n  var: \"value\"')\n    env = self.mistral_admin('environment-update', params='env_upd.yaml')\n    self.assertTableStruct(env, ['Field', 'Value'])\n    updated_env_name = self.get_value_of_field(env, 'Name')\n    updated_env_desc = self.get_value_of_field(env, 'Description')\n    updated_env_created_at = self.get_value_of_field(updated_env_created_at, 'Created at')\n    updated_env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertEqual(env_name, updated_env_name)\n    self.assertNotEqual(env_desc, updated_env_desc)\n    self.assertEqual('Updated env', updated_env_desc)\n    self.assertEqual(env_created_at.split('.')[0], updated_env_created_at)\n    self.assertIsNotNone(updated_env_updated_at)\n", "label": "Variable misuse"}
{"function": "\n\ndef speak(self, message, channel):\n    self.client.api_call('chat.postMessage', as_user='true:', channel=channel, text=message)\n", "label": "Correct"}
{"function": "\n\ndef speak(self, message, channel):\n    self.client.api_call('chat.postMessage', as_user='true:', channel=message, text=message)\n", "label": "Variable misuse"}
{"function": "\n\ndef _pad_string(self, str, colwidth):\n    'Center-pads a string to the given column width using spaces.'\n    width = self._disp_width(str)\n    prefix = (((colwidth - 1) - width) // 2)\n    suffix = ((colwidth - prefix) - width)\n    return (((' ' * prefix) + str) + (' ' * suffix))\n", "label": "Correct"}
{"function": "\n\ndef _pad_string(self, str, colwidth):\n    'Center-pads a string to the given column width using spaces.'\n    width = width._disp_width(str)\n    prefix = (((colwidth - 1) - width) // 2)\n    suffix = ((colwidth - prefix) - width)\n    return (((' ' * prefix) + str) + (' ' * suffix))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_skips_unknown_permission_quietly(self):\n    'Skips unknown permission silently with verbosity 0.'\n    with patch('moztrap.model.core.management.commands.create_default_roles.ROLES', {\n        'Foo': ['foo.foo'],\n    }):\n        output = self.call_command(verbosity=0)\n    self.assertEqual(output, '')\n", "label": "Correct"}
{"function": "\n\ndef test_skips_unknown_permission_quietly(self):\n    'Skips unknown permission silently with verbosity 0.'\n    with patch('moztrap.model.core.management.commands.create_default_roles.ROLES', {\n        'Foo': ['foo.foo'],\n    }):\n        output = output.call_command(verbosity=0)\n    self.assertEqual(output, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_3d_polygons(self):\n    '\\n        Test the creation of polygon 3D models.\\n        '\n    self._load_polygon_data()\n    p3d = Polygon3D.objects.get(name='3D BBox')\n    self.assertTrue(p3d.poly.hasz)\n    self.assertIsInstance(p3d.poly, Polygon)\n    self.assertEqual(p3d.poly.srid, 32140)\n", "label": "Correct"}
{"function": "\n\ndef test_3d_polygons(self):\n    '\\n        Test the creation of polygon 3D models.\\n        '\n    self._load_polygon_data()\n    p3d = Polygon3D.objects.get(name='3D BBox')\n    p3d.assertTrue(p3d.poly.hasz)\n    self.assertIsInstance(p3d.poly, Polygon)\n    self.assertEqual(p3d.poly.srid, 32140)\n", "label": "Variable misuse"}
{"function": "\n\ndef shouldDestroyCircuit(self, circuit):\n    'Return **True** iff CircuitManager thinks the calling circuit\\n        should be destroyed.\\n\\n        Circuits call shouldDestroyCircuit() when their number of open\\n        streams drops to zero. Since CircuitManager knows about all open\\n        and pending circuits, it can make an informed judgement about whether\\n        the calling circuit should be destroyed or remain open.\\n\\n        Currently, CircuitManager maintains at least 4 open or pending IPv4\\n        circuits and one open or pending IPv6 circuit. If the number of\\n        streams on any circuit drops to zero and it can be closed while still\\n        satisfying these basic constraints, then CircuitManager tells it\\n        to begin destroying itself (returns True).\\n\\n        :param oppy.circuit.circuit.Circuit circuit: circuit to\\n            consider destroying.\\n        :returns: **bool** **True** if CircuitManager decides this circuit\\n            should be destroyed, **False** otherwise.\\n        '\n    if (circuit.circuit_type == CircuitType.IPv4):\n        return ((self._totalIPv4Count() - 1) > self._min_IPv4_count)\n    else:\n        return ((self._totalIPv6Count() - 1) > self._min_IPv6_count)\n", "label": "Correct"}
{"function": "\n\ndef shouldDestroyCircuit(self, circuit):\n    'Return **True** iff CircuitManager thinks the calling circuit\\n        should be destroyed.\\n\\n        Circuits call shouldDestroyCircuit() when their number of open\\n        streams drops to zero. Since CircuitManager knows about all open\\n        and pending circuits, it can make an informed judgement about whether\\n        the calling circuit should be destroyed or remain open.\\n\\n        Currently, CircuitManager maintains at least 4 open or pending IPv4\\n        circuits and one open or pending IPv6 circuit. If the number of\\n        streams on any circuit drops to zero and it can be closed while still\\n        satisfying these basic constraints, then CircuitManager tells it\\n        to begin destroying itself (returns True).\\n\\n        :param oppy.circuit.circuit.Circuit circuit: circuit to\\n            consider destroying.\\n        :returns: **bool** **True** if CircuitManager decides this circuit\\n            should be destroyed, **False** otherwise.\\n        '\n    if (circuit.circuit_type == CircuitType.IPv4):\n        return ((circuit._totalIPv4Count() - 1) > self._min_IPv4_count)\n    else:\n        return ((self._totalIPv6Count() - 1) > self._min_IPv6_count)\n", "label": "Variable misuse"}
{"function": "\n\ndef contains_subsequence(seq, subseq):\n    for i in range((len(seq) - len(subseq))):\n        if (seq[i:(i + len(subseq))] == subseq):\n            return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef contains_subsequence(seq, subseq):\n    for i in range((len(seq) - len(subseq))):\n        if (seq[seq:(i + len(subseq))] == subseq):\n            return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef cold_evacuate(config, compute_api, instance_id, dst_host):\n    '\\n    Evacuate VM by shutting it down, booting another VM with same ephemeral\\n    volume on different host and deleting original VM.\\n\\n    :param config: CloudFerry configuration\\n    :param compute_api: Compute API client (NovaClient) instance\\n    :param instance_id: VM instance identifier to evacuate\\n    :param dst_host: destination host name\\n    '\n    LOG.debug('Cold evacuating VM %s to %s', instance_id, dst_host)\n    state_change_timeout = cfglib.CONF.evacuation.state_change_timeout\n    migration_timeout = cfglib.CONF.evacuation.migration_timeout\n    if (not change_to_pre_migration_state(compute_api, instance_id)):\n        instance = compute_api.servers.get(instance_id)\n        LOG.warning(\"Can't migrate VM in %s status\", instance.status)\n        return\n    instance = compute_api.servers.get(instance_id)\n    src_host = getattr(instance, INSTANCE_HOST_ATTRIBUTE)\n    if (src_host == dst_host):\n        LOG.warning('Skipping migration to the same host')\n        return\n    original_status = instance.status.lower()\n    if (original_status != SHUTOFF):\n        compute_api.servers.stop(instance)\n        wait_for_condition(is_vm_status_in, compute_api, instance, [SHUTOFF], timeout=state_change_timeout)\n    fix_post_cobalt_ephemeral_disk(config, instance)\n    with install_ssh_keys(config, src_host, dst_host):\n        with disable_all_nova_compute_services(compute_api):\n            with enable_nova_compute_services(compute_api, dst_host, src_host):\n                compute_api.servers.migrate(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [VERIFY_RESIZE], timeout=migration_timeout)\n                compute_api.servers.confirm_resize(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [ACTIVE], timeout=state_change_timeout)\n    if (original_status == SHUTOFF.lower()):\n        LOG.debug('Starting replacement VM %s', instance_id)\n        compute_api.servers.stop(instance_id)\n", "label": "Correct"}
{"function": "\n\ndef cold_evacuate(config, compute_api, instance_id, dst_host):\n    '\\n    Evacuate VM by shutting it down, booting another VM with same ephemeral\\n    volume on different host and deleting original VM.\\n\\n    :param config: CloudFerry configuration\\n    :param compute_api: Compute API client (NovaClient) instance\\n    :param instance_id: VM instance identifier to evacuate\\n    :param dst_host: destination host name\\n    '\n    LOG.debug('Cold evacuating VM %s to %s', instance_id, dst_host)\n    state_change_timeout = cfglib.CONF.evacuation.state_change_timeout\n    migration_timeout = cfglib.CONF.evacuation.migration_timeout\n    if (not change_to_pre_migration_state(compute_api, instance_id)):\n        instance = compute_api.servers.get(instance_id)\n        LOG.warning(\"Can't migrate VM in %s status\", instance.status)\n        return\n    instance = compute_api.servers.get(instance_id)\n    src_host = getattr(instance, INSTANCE_HOST_ATTRIBUTE)\n    if (src_host == dst_host):\n        LOG.warning('Skipping migration to the same host')\n        return\n    original_status = instance.status.lower()\n    if (original_status != SHUTOFF):\n        compute_api.servers.stop(instance)\n        wait_for_condition(is_vm_status_in, compute_api, instance, [SHUTOFF], timeout=state_change_timeout)\n    fix_post_cobalt_ephemeral_disk(config, instance)\n    with install_ssh_keys(config, compute_api, dst_host):\n        with disable_all_nova_compute_services(compute_api):\n            with enable_nova_compute_services(compute_api, dst_host, src_host):\n                compute_api.servers.migrate(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [VERIFY_RESIZE], timeout=migration_timeout)\n                compute_api.servers.confirm_resize(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [ACTIVE], timeout=state_change_timeout)\n    if (original_status == SHUTOFF.lower()):\n        LOG.debug('Starting replacement VM %s', instance_id)\n        compute_api.servers.stop(instance_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef tables(self, db=None):\n    '\\n        Enumerates all tables fro a given database. If not specified, use the\\n        current database.\\n        '\n    if self.has_cap(TABLES_ENUM):\n        if (db is None):\n            if (self.current_db is None):\n                self.database()\n            db = self.current_db\n        n = self.get_nb_tables(db)\n        for i in range(n):\n            (yield TableWrapper(self, self.get_table_name(i, db), db))\n    else:\n        raise Unavailable()\n", "label": "Correct"}
{"function": "\n\ndef tables(self, db=None):\n    '\\n        Enumerates all tables fro a given database. If not specified, use the\\n        current database.\\n        '\n    if self.has_cap(TABLES_ENUM):\n        if (db is None):\n            if (i.current_db is None):\n                self.database()\n            db = self.current_db\n        n = self.get_nb_tables(db)\n        for i in range(n):\n            (yield TableWrapper(self, self.get_table_name(i, db), db))\n    else:\n        raise Unavailable()\n", "label": "Variable misuse"}
{"function": "\n\ndef transform_non_affine(self, a):\n    return np.log10((a + 1))\n", "label": "Correct"}
{"function": "\n\ndef transform_non_affine(self, a):\n    return np.log10((self + 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_us_state(abbr, result):\n    for sep in ('/', '-'):\n        if (result.source_base == 'us{sep}{abbr}'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}.'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}{sep}'.format(**locals())):\n            return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef _is_us_state(abbr, result):\n    for sep in ('/', '-'):\n        if (result.source_base == 'us{sep}{abbr}'.format(**locals())):\n            return True\n        if sep.source_base.startswith('us{sep}{abbr}.'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}{sep}'.format(**locals())):\n            return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(BFDLib, self).__init__(*args, **kwargs)\n    self.session = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(BFDLib, self).__init__(*args, **kwargs)\n    kwargs.session = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\n@observe(('accept_mode', 'file_mode', 'show_dirs_only', 'current_path', 'name_filters', 'selected_name_filter'))\ndef _update_proxy(self, change):\n    ' An observer which updates the proxy when the data changes.\\n\\n        '\n    super(FileDialogEx, self)._update_proxy(change)\n", "label": "Correct"}
{"function": "\n\n@observe(('accept_mode', 'file_mode', 'show_dirs_only', 'current_path', 'name_filters', 'selected_name_filter'))\ndef _update_proxy(self, change):\n    ' An observer which updates the proxy when the data changes.\\n\\n        '\n    super(FileDialogEx, change)._update_proxy(change)\n", "label": "Variable misuse"}
{"function": "\n\ndef role_create(request, name):\n    manager = keystoneclient(request, admin=True).roles\n    return manager.create(name)\n", "label": "Correct"}
{"function": "\n\ndef role_create(request, name):\n    manager = keystoneclient(manager, admin=True).roles\n    return manager.create(name)\n", "label": "Variable misuse"}
{"function": "\n\n@sig((((H / int) >> 'a') >> ['a']))\ndef replicate(n, x):\n    '\\n    replicate :: Int -> a -> [a]\\n\\n    replicate(n, x) is a list of length n with x the value of every element.\\n    '\n\n    def __replicate(n, x):\n        for _ in range(n):\n            (yield x)\n    return L[__replicate(n, x)]\n", "label": "Correct"}
{"function": "\n\n@sig((((H / int) >> 'a') >> ['a']))\ndef replicate(n, x):\n    '\\n    replicate :: Int -> a -> [a]\\n\\n    replicate(n, x) is a list of length n with x the value of every element.\\n    '\n\n    def __replicate(n, x):\n        for _ in range(n):\n            (yield x)\n    return L[__replicate(n, n)]\n", "label": "Variable misuse"}
{"function": "\n\ndef process_IN_CLOSE_WRITE(self, event):\n    self.process_event(event.pathname, update)\n", "label": "Correct"}
{"function": "\n\ndef process_IN_CLOSE_WRITE(self, event):\n    event.process_event(event.pathname, update)\n", "label": "Variable misuse"}
{"function": "\n\n@util.positional(2)\ndef error(status_code, status_message=None, content_type='text/plain; charset=utf-8', headers=None, content=None):\n    'Create WSGI application that statically serves an error page.\\n\\n  Creates a static error page specifically for non-200 HTTP responses.\\n\\n  Browsers such as Internet Explorer will display their own error pages for\\n  error content responses smaller than 512 bytes.  For this reason all responses\\n  are right-padded up to 512 bytes.\\n\\n  Error pages that are not provided will content will contain the standard HTTP\\n  status message as their content.\\n\\n  Args:\\n    status_code: Integer status code of error.\\n    status_message: Status message.\\n\\n  Returns:\\n    Static WSGI application that sends static error response.\\n  '\n    if (status_message is None):\n        status_message = httplib.responses.get(status_code, 'Unknown Error')\n    if (content is None):\n        content = status_message\n    content = util.pad_string(content)\n    return static_page(content, status=(status_code, status_message), content_type=content_type, headers=headers)\n", "label": "Correct"}
{"function": "\n\n@util.positional(2)\ndef error(status_code, status_message=None, content_type='text/plain; charset=utf-8', headers=None, content=None):\n    'Create WSGI application that statically serves an error page.\\n\\n  Creates a static error page specifically for non-200 HTTP responses.\\n\\n  Browsers such as Internet Explorer will display their own error pages for\\n  error content responses smaller than 512 bytes.  For this reason all responses\\n  are right-padded up to 512 bytes.\\n\\n  Error pages that are not provided will content will contain the standard HTTP\\n  status message as their content.\\n\\n  Args:\\n    status_code: Integer status code of error.\\n    status_message: Status message.\\n\\n  Returns:\\n    Static WSGI application that sends static error response.\\n  '\n    if (content is None):\n        status_message = httplib.responses.get(status_code, 'Unknown Error')\n    if (content is None):\n        content = status_message\n    content = util.pad_string(content)\n    return static_page(content, status=(status_code, status_message), content_type=content_type, headers=headers)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_params(self):\n    params = np.array([r.params for r in self.results])\n    params_1 = np.array(([self.results[0].params] * len(self.results)))\n    assert_allclose(params, params_1)\n", "label": "Correct"}
{"function": "\n\ndef test_params(self):\n    params = np.array([params.params for r in self.results])\n    params_1 = np.array(([self.results[0].params] * len(self.results)))\n    assert_allclose(params, params_1)\n", "label": "Variable misuse"}
{"function": "\n\ndef Status_Name(cls, x):\n    return cls._Status_NAMES.get(x, '')\n", "label": "Correct"}
{"function": "\n\ndef Status_Name(cls, x):\n    return cls._Status_NAMES.get(cls, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef usesTime(self):\n    fmt = self._fmt\n    return ((fmt.find('$asctime') >= 0) or (fmt.find(self.asctime_format) >= 0))\n", "label": "Correct"}
{"function": "\n\ndef usesTime(self):\n    fmt = self._fmt\n    return ((self.find('$asctime') >= 0) or (fmt.find(self.asctime_format) >= 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef make_user_dict(name, password, enabled, fullName, emailAddress, officePhone, mobilePhone, roles=[]):\n    return {\n        'userName': name,\n        'password': password,\n        'fullName': fullName,\n        'emailAddress': emailAddress,\n        'officePhone': officePhone,\n        'mobilePhone': mobilePhone,\n        'enabled': enabled,\n        'type': 'UserAndRoles',\n        'roles': roles,\n    }\n", "label": "Correct"}
{"function": "\n\ndef make_user_dict(name, password, enabled, fullName, emailAddress, officePhone, mobilePhone, roles=[]):\n    return {\n        'userName': officePhone,\n        'password': password,\n        'fullName': fullName,\n        'emailAddress': emailAddress,\n        'officePhone': officePhone,\n        'mobilePhone': mobilePhone,\n        'enabled': enabled,\n        'type': 'UserAndRoles',\n        'roles': roles,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef _validate_python(self, field_dict, state):\n    try:\n        ref = field_dict[self.field_names[0]]\n    except TypeError:\n        raise Invalid(self.message('notDict', state), field_dict, state)\n    except KeyError:\n        ref = ''\n    errors = {\n        \n    }\n    for name in self.field_names[1:]:\n        if (field_dict.get(name, '') != ref):\n            if self.show_match:\n                errors[name] = self.message('invalid', state, match=ref)\n            else:\n                errors[name] = self.message('invalidNoMatch', state)\n    if errors:\n        error_list = sorted(six.iteritems(errors))\n        error_message = '<br>\\n'.join((('%s: %s' % (name, value)) for (name, value) in error_list))\n        raise Invalid(error_message, field_dict, state, error_dict=errors)\n", "label": "Correct"}
{"function": "\n\ndef _validate_python(self, field_dict, state):\n    try:\n        ref = field_dict[self.field_names[0]]\n    except TypeError:\n        raise Invalid(self.message('notDict', state), field_dict, state)\n    except KeyError:\n        ref = ''\n    errors = {\n        \n    }\n    for name in self.field_names[1:]:\n        if (name.get(name, '') != ref):\n            if self.show_match:\n                errors[name] = self.message('invalid', state, match=ref)\n            else:\n                errors[name] = self.message('invalidNoMatch', state)\n    if errors:\n        error_list = sorted(six.iteritems(errors))\n        error_message = '<br>\\n'.join((('%s: %s' % (name, value)) for (name, value) in error_list))\n        raise Invalid(error_message, field_dict, state, error_dict=errors)\n", "label": "Variable misuse"}
{"function": "\n\ndef add_link(root, olink):\n    root.append(ET.fromstring(olink['orig_xml']))\n", "label": "Correct"}
{"function": "\n\ndef add_link(root, olink):\n    olink.append(ET.fromstring(olink['orig_xml']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, response, handle):\n    self._response = response\n    self._handle = handle\n    super(ResponseHeaders, self).__init__()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, response, handle):\n    self._response = response\n    self._handle = handle\n    super(ResponseHeaders, response).__init__()\n", "label": "Variable misuse"}
{"function": "\n\ndef make_datastore_mock(self):\n    store = Mock(spec=['insert_client_ip'])\n    store.get_app_service_by_token = Mock(return_value=None)\n    return store\n", "label": "Correct"}
{"function": "\n\ndef make_datastore_mock(self):\n    store = Mock(spec=['insert_client_ip'])\n    store.get_app_service_by_token = Mock(return_value=None)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef add_condition(self, name, condition):\n    self.conditions[name] = condition\n", "label": "Correct"}
{"function": "\n\ndef add_condition(self, name, condition):\n    name.conditions[name] = condition\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    self.__dict__['__stack'] = [kwargs]\n    self.__dict__['__exc_ref'] = None\n    self.__dict__['__exc_stack'] = []\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    self.__dict__['__stack'] = [self]\n    self.__dict__['__exc_ref'] = None\n    self.__dict__['__exc_stack'] = []\n", "label": "Variable misuse"}
{"function": "\n\ndef get_list(self, *args, **kwargs):\n    (count, data) = super(TweetView, self).get_list(*args, **kwargs)\n    query = {\n        '_id': {\n            '$in': [x['user_id'] for x in data],\n        },\n    }\n    users = db.user.find(query, fields=('name',))\n    users_map = dict(((x['_id'], x['name']) for x in users))\n    for item in data:\n        item['user_name'] = users_map.get(item['user_id'])\n    return (count, data)\n", "label": "Correct"}
{"function": "\n\ndef get_list(self, *args, **kwargs):\n    (count, data) = super(TweetView, self).get_list(*args, **kwargs)\n    query = {\n        '_id': {\n            '$in': [x['user_id'] for x in item],\n        },\n    }\n    users = db.user.find(query, fields=('name',))\n    users_map = dict(((x['_id'], x['name']) for x in users))\n    for item in data:\n        item['user_name'] = users_map.get(item['user_id'])\n    return (count, data)\n", "label": "Variable misuse"}
{"function": "\n\n@conf.commands.register\ndef srbt1(peer, pkts, *args, **kargs):\n    'send and receive 1 packet using a bluetooth socket'\n    (a, b) = srbt(peer, pkts, *args, **kargs)\n    if (len(a) > 0):\n        return a[0][1]\n", "label": "Correct"}
{"function": "\n\n@conf.commands.register\ndef srbt1(peer, pkts, *args, **kargs):\n    'send and receive 1 packet using a bluetooth socket'\n    (a, b) = srbt(peer, pkts, *args, **peer)\n    if (len(a) > 0):\n        return a[0][1]\n", "label": "Variable misuse"}
{"function": "\n\ndef permission_required(perm, login_url=None):\n    '\\n    Decorator for views that checks whether a user has a particular permission\\n    enabled, redirecting to the log-in page if necessary.\\n    '\n    return user_passes_test((lambda u: u.has_perm(perm)), login_url=login_url)\n", "label": "Correct"}
{"function": "\n\ndef permission_required(perm, login_url=None):\n    '\\n    Decorator for views that checks whether a user has a particular permission\\n    enabled, redirecting to the log-in page if necessary.\\n    '\n    return user_passes_test((lambda u: u.has_perm(u)), login_url=login_url)\n", "label": "Variable misuse"}
{"function": "\n\ndef find_payload_class(payload_type):\n    'Iterate through inherited classes to find a matching class name'\n    subclasses = set()\n    work = [Payload]\n    while work:\n        parent_subclass = work.pop()\n        for child_subclass in parent_subclass.__subclasses__():\n            if (child_subclass not in subclasses):\n                if (hasattr(child_subclass, 'payload_type') and (child_subclass.payload_type == payload_type)):\n                    return child_subclass\n                subclasses.add(child_subclass)\n                work.append(child_subclass)\n    return None\n", "label": "Correct"}
{"function": "\n\ndef find_payload_class(payload_type):\n    'Iterate through inherited classes to find a matching class name'\n    subclasses = set()\n    work = [Payload]\n    while work:\n        parent_subclass = work.pop()\n        for child_subclass in parent_subclass.__subclasses__():\n            if (child_subclass not in subclasses):\n                if (hasattr(payload_type, 'payload_type') and (child_subclass.payload_type == payload_type)):\n                    return child_subclass\n                subclasses.add(child_subclass)\n                work.append(child_subclass)\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, modelXbrl, user, password, host, port, database, timeout, product):\n    self.modelXbrl = modelXbrl\n    self.disclosureSystem = modelXbrl.modelManager.disclosureSystem\n    if (product == 'postgres'):\n        if (not hasPostgres):\n            raise XPDBException('xpgDB:MissingPostgresInterface', _('Postgres interface is not installed'))\n        self.conn = pgConnect(user=user, password=password, host=host, port=int((port or 5432)), database=database, socket_timeout=(timeout or 60))\n        self.product = product\n    elif (product == 'mysql'):\n        if (not hasMySql):\n            raise XPDBException('xpgDB:MissingMySQLInterface', _('MySQL interface is not installed'))\n        self.conn = mysqlConnect(user=user, passwd=password, host=host, port=int((port or 5432)), db=database, connect_timeout=(timeout or 60), charset='utf8')\n        self.product = product\n    elif (product == 'orcl'):\n        if (not hasOracle):\n            raise XPDBException('xpgDB:MissingOracleInterface', _('Oracle interface is not installed'))\n        self.conn = oracleConnect('{}/{}@{}{}'.format(user, password, host, (':{}'.format(port) if port else '')))\n        self.product = product\n    elif (product == 'mssql'):\n        if (not hasMSSql):\n            raise XPDBException('xpgDB:MissingMSSQLInterface', _('MSSQL server interface is not installed'))\n        self.conn = mssqlConnect('DRIVER={{SQL Server Native Client 11.0}};SERVER={2};DATABASE={3};UID={0};PWD={1};CHARSET=UTF8'.format(user, password, host, database))\n        self.product = product\n    elif (product == 'sqlite'):\n        if (not hasSQLite):\n            raise XPDBException('xpgDB:MissingSQLiteInterface', _('SQLite interface is not installed'))\n        self.conn = sqliteConnect(database, (timeout or 60), detect_types=sqliteParseDecltypes)\n        self.product = product\n        self.syncSequences = False\n    else:\n        self.product = None\n    self.tableColTypes = {\n        \n    }\n    self.tableColDeclaration = {\n        \n    }\n    self.accessionId = '(None)'\n    self.tempInputTableName = 'input{}'.format(os.getpid())\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, modelXbrl, user, password, host, port, database, timeout, product):\n    self.modelXbrl = modelXbrl\n    self.disclosureSystem = modelXbrl.modelManager.disclosureSystem\n    if (product == 'postgres'):\n        if (not hasPostgres):\n            raise XPDBException('xpgDB:MissingPostgresInterface', _('Postgres interface is not installed'))\n        self.conn = pgConnect(user=user, password=password, host=host, port=int((port or 5432)), database=database, socket_timeout=(timeout or 60))\n        self.product = product\n    elif (product == 'mysql'):\n        if (not hasMySql):\n            raise XPDBException('xpgDB:MissingMySQLInterface', _('MySQL interface is not installed'))\n        self.conn = mysqlConnect(user=user, passwd=password, host=host, port=int((port or 5432)), db=database, connect_timeout=(timeout or 60), charset='utf8')\n        self.product = product\n    elif (product == 'orcl'):\n        if (not hasOracle):\n            raise XPDBException('xpgDB:MissingOracleInterface', _('Oracle interface is not installed'))\n        self.conn = oracleConnect('{}/{}@{}{}'.format(user, password, password, (':{}'.format(port) if port else '')))\n        self.product = product\n    elif (product == 'mssql'):\n        if (not hasMSSql):\n            raise XPDBException('xpgDB:MissingMSSQLInterface', _('MSSQL server interface is not installed'))\n        self.conn = mssqlConnect('DRIVER={{SQL Server Native Client 11.0}};SERVER={2};DATABASE={3};UID={0};PWD={1};CHARSET=UTF8'.format(user, password, host, database))\n        self.product = product\n    elif (product == 'sqlite'):\n        if (not hasSQLite):\n            raise XPDBException('xpgDB:MissingSQLiteInterface', _('SQLite interface is not installed'))\n        self.conn = sqliteConnect(database, (timeout or 60), detect_types=sqliteParseDecltypes)\n        self.product = product\n        self.syncSequences = False\n    else:\n        self.product = None\n    self.tableColTypes = {\n        \n    }\n    self.tableColDeclaration = {\n        \n    }\n    self.accessionId = '(None)'\n    self.tempInputTableName = 'input{}'.format(os.getpid())\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_inline(text):\n    '\\n    Takes a string of text from a text inline and returns a 3 tuple of\\n    (name, value, **kwargs).\\n    '\n    m = INLINE_SPLITTER.match(text)\n    if (not m):\n        raise InlineUnparsableError\n    args = m.group('args')\n    name = m.group('name')\n    value = ''\n    kwtxt = ''\n    kwargs = {\n        \n    }\n    if args:\n        kwtxt = INLINE_KWARG_PARSER.search(args).group('kwargs')\n        value = re.sub(('%s\\\\Z' % kwtxt), '', args)\n        value = value.strip()\n    if m.group('variant'):\n        kwargs['variant'] = m.group('variant')\n    if kwtxt:\n        for kws in kwtxt.split():\n            (k, v) = kws.split('=')\n            kwargs[str(k)] = v\n    return (name, value, kwargs)\n", "label": "Correct"}
{"function": "\n\ndef parse_inline(text):\n    '\\n    Takes a string of text from a text inline and returns a 3 tuple of\\n    (name, value, **kwargs).\\n    '\n    m = INLINE_SPLITTER.match(text)\n    if (not m):\n        raise InlineUnparsableError\n    args = m.group('args')\n    name = m.group('name')\n    value = ''\n    kwtxt = ''\n    kwargs = {\n        \n    }\n    if args:\n        kwtxt = INLINE_KWARG_PARSER.search(args).group('kwargs')\n        value = re.sub(('%s\\\\Z' % kwtxt), '', args)\n        value = value.strip()\n    if m.group('variant'):\n        kwargs['variant'] = m.group('variant')\n    if kwtxt:\n        for kws in kwtxt.split():\n            (k, v) = kws.split('=')\n            kwargs[str(kwtxt)] = v\n    return (name, value, kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, *args, **kwargs):\n    if (not self.file):\n        self.file = tempfile.TemporaryFile()\n    self.file.write(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef write(self, *args, **kwargs):\n    if (not self.file):\n        kwargs.file = tempfile.TemporaryFile()\n    self.file.write(*args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef complex_step_jacobian(self, params, unknowns, resids, total_derivs=False, fd_params=None, fd_states=None, fd_unknowns=None, poi_indices=None, qoi_indices=None):\n    \" Return derivatives of all unknowns in this system w.r.t. all\\n        incoming params using complex step.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        resids : `VecWrapper`\\n            `VecWrapper` containing residuals. (r)\\n\\n        total_derivs : bool, optional\\n            Should always be False, as componentwise derivatives only need partials.\\n\\n        fd_params : list of strings, optional\\n            List of parameter name strings with respect to which derivatives\\n            are desired. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_unknowns : list of strings, optional\\n            List of output or state name strings for derivatives to be\\n            calculated. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_states : list of strings, optional\\n            List of state name strings for derivatives to be taken with respect to.\\n            This is used by problem to limit the derivatives that are taken.\\n\\n        poi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        qoi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        Returns\\n        -------\\n        dict\\n            Dictionary whose keys are tuples of the form ('unknown', 'param')\\n            and whose values are ndarrays containing the derivative for that\\n            tuple pair.\\n        \"\n    if (fd_params is None):\n        fd_params = self._get_fd_params()\n    if (fd_unknowns is None):\n        fd_unknowns = self._get_fd_unknowns()\n    step_size = self.fd_options.get('step_size', 1e-06)\n    jac = {\n        \n    }\n    csparams = ComplexStepTgtVecWrapper(params)\n    csunknowns = ComplexStepSrcVecWrapper(unknowns)\n    csresids = ComplexStepSrcVecWrapper(resids)\n    states = self.states\n    if (len(states) > 0):\n        resultvec = csresids\n    else:\n        resultvec = csunknowns\n    if (fd_states is not None):\n        states = fd_states\n    for p_name in chain(fd_params, states):\n        if (p_name in states):\n            stepvec = csunknowns\n            target_input = unknowns._dat[p_name].val\n        else:\n            stepvec = csparams\n            target_input = params._dat[p_name].val\n        stepvec.set_complex_var(p_name)\n        mydict = self._init_params_dict.get(p_name, {\n            \n        })\n        fdstep = mydict.get('step_size', step_size)\n        p_size = np.size(target_input)\n        p_idxs = range(p_size)\n        for u_name in fd_unknowns:\n            u_size = np.size(unknowns[u_name])\n            jac[(u_name, p_name)] = np.zeros((u_size, p_size))\n        for (j, idx) in enumerate(p_idxs):\n            stepvec.step_complex(idx, fdstep)\n            self.apply_nonlinear(csparams, csunknowns, csresids)\n            stepvec.step_complex(idx, (- fdstep))\n            for u_name in fd_unknowns:\n                result = resultvec.flat(u_name)\n                jac[(u_name, p_name)][:, j] = (result.imag / fdstep)\n        stepvec.set_complex_var(None)\n    return jac\n", "label": "Correct"}
{"function": "\n\ndef complex_step_jacobian(self, params, unknowns, resids, total_derivs=False, fd_params=None, fd_states=None, fd_unknowns=None, poi_indices=None, qoi_indices=None):\n    \" Return derivatives of all unknowns in this system w.r.t. all\\n        incoming params using complex step.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        resids : `VecWrapper`\\n            `VecWrapper` containing residuals. (r)\\n\\n        total_derivs : bool, optional\\n            Should always be False, as componentwise derivatives only need partials.\\n\\n        fd_params : list of strings, optional\\n            List of parameter name strings with respect to which derivatives\\n            are desired. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_unknowns : list of strings, optional\\n            List of output or state name strings for derivatives to be\\n            calculated. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_states : list of strings, optional\\n            List of state name strings for derivatives to be taken with respect to.\\n            This is used by problem to limit the derivatives that are taken.\\n\\n        poi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        qoi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        Returns\\n        -------\\n        dict\\n            Dictionary whose keys are tuples of the form ('unknown', 'param')\\n            and whose values are ndarrays containing the derivative for that\\n            tuple pair.\\n        \"\n    if (fd_params is None):\n        fd_params = self._get_fd_params()\n    if (fd_unknowns is None):\n        fd_unknowns = self._get_fd_unknowns()\n    step_size = self.fd_options.get('step_size', 1e-06)\n    jac = {\n        \n    }\n    csparams = ComplexStepTgtVecWrapper(params)\n    csunknowns = ComplexStepSrcVecWrapper(unknowns)\n    csresids = ComplexStepSrcVecWrapper(resids)\n    states = self.states\n    if (len(states) > 0):\n        resultvec = csresids\n    else:\n        resultvec = csunknowns\n    if (fd_states is not None):\n        states = fd_states\n    for p_name in chain(fd_params, states):\n        if (p_name in u_size):\n            stepvec = csunknowns\n            target_input = unknowns._dat[p_name].val\n        else:\n            stepvec = csparams\n            target_input = params._dat[p_name].val\n        stepvec.set_complex_var(p_name)\n        mydict = self._init_params_dict.get(p_name, {\n            \n        })\n        fdstep = mydict.get('step_size', step_size)\n        p_size = np.size(target_input)\n        p_idxs = range(p_size)\n        for u_name in fd_unknowns:\n            u_size = np.size(unknowns[u_name])\n            jac[(u_name, p_name)] = np.zeros((u_size, p_size))\n        for (j, idx) in enumerate(p_idxs):\n            stepvec.step_complex(idx, fdstep)\n            self.apply_nonlinear(csparams, csunknowns, csresids)\n            stepvec.step_complex(idx, (- fdstep))\n            for u_name in fd_unknowns:\n                result = resultvec.flat(u_name)\n                jac[(u_name, p_name)][:, j] = (result.imag / fdstep)\n        stepvec.set_complex_var(None)\n    return jac\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Weapon()\n    result.template = 'object/weapon/melee/baton/shared_victor_baton_gaderiffi.iff'\n    result.attribute_template_id = 10\n    result.stfName('weapon_name', 'victor_baton_gaderiffi')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Weapon()\n    kernel.template = 'object/weapon/melee/baton/shared_victor_baton_gaderiffi.iff'\n    result.attribute_template_id = 10\n    result.stfName('weapon_name', 'victor_baton_gaderiffi')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef _Rotate(self, image, transform):\n    'Use PIL to rotate the given image with the given transform.\\n\\n    Args:\\n      image: PIL.Image.Image object to rotate.\\n      transform: images_service_pb.Transform to use when rotating.\\n\\n    Returns:\\n      PIL.Image.Image with transforms performed on it.\\n\\n    Raises:\\n      BadRequestError if the rotate data given is bad.\\n    '\n    degrees = transform.rotate()\n    if ((degrees < 0) or ((degrees % 90) != 0)):\n        raise apiproxy_errors.ApplicationError(images_service_pb.ImagesServiceError.BAD_TRANSFORM_DATA)\n    degrees %= 360\n    degrees = (360 - degrees)\n    return image.rotate(degrees)\n", "label": "Correct"}
{"function": "\n\ndef _Rotate(self, image, transform):\n    'Use PIL to rotate the given image with the given transform.\\n\\n    Args:\\n      image: PIL.Image.Image object to rotate.\\n      transform: images_service_pb.Transform to use when rotating.\\n\\n    Returns:\\n      PIL.Image.Image with transforms performed on it.\\n\\n    Raises:\\n      BadRequestError if the rotate data given is bad.\\n    '\n    degrees = transform.rotate()\n    if ((degrees < 0) or ((degrees % 90) != 0)):\n        raise apiproxy_errors.ApplicationError(images_service_pb.ImagesServiceError.BAD_TRANSFORM_DATA)\n    degrees %= 360\n    degrees = (360 - degrees)\n    return image.rotate(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_window_attrib(window, attrib):\n    '\\n    Returns an attribute of the specified window.\\n\\n    Wrapper for:\\n        int glfwGetWindowAttrib(GLFWwindow* window, int attrib);\\n    '\n    return _glfw.glfwGetWindowAttrib(window, attrib)\n", "label": "Correct"}
{"function": "\n\ndef get_window_attrib(window, attrib):\n    '\\n    Returns an attribute of the specified window.\\n\\n    Wrapper for:\\n        int glfwGetWindowAttrib(GLFWwindow* window, int attrib);\\n    '\n    return _glfw.glfwGetWindowAttrib(window, window)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parent, log_entry):\n    mst_gui.LogViewerBase.__init__(self, parent)\n    self.mLogEntry = log_entry\n    self.mTimeNumText.SetValue(('%s [%s]' % (log_entry.Time, str(log_entry.Num))))\n    self.mSentText.SetValue(log_entry.Sent)\n    self.mReceivedText.SetValue(log_entry.Received)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parent, log_entry):\n    mst_gui.LogViewerBase.__init__(self, parent)\n    self.mLogEntry = log_entry\n    log_entry.mTimeNumText.SetValue(('%s [%s]' % (log_entry.Time, str(log_entry.Num))))\n    self.mSentText.SetValue(log_entry.Sent)\n    self.mReceivedText.SetValue(log_entry.Received)\n", "label": "Variable misuse"}
{"function": "\n\ndef iter_keys(self, filename):\n    with open(filename, 'rb') as f:\n        header = f.read(8)\n        self._verify_header(header)\n        current_offset = 8\n        file_size_bytes = os.path.getsize(filename)\n        while True:\n            current_contents = f.read(8)\n            current_offset += 8\n            if (len(current_contents) < 8):\n                if (len(current_contents) > 0):\n                    raise DBMLoadError('Error loading db: partial header read')\n                else:\n                    return\n            (key_size, val_size) = struct.unpack('!ii', current_contents)\n            key = f.read(key_size)\n            if (len(key) != key_size):\n                raise DBMLoadError(('Error loading db: key size does not match (expected %s bytes, got %s instead.' % (key_size, len(key))))\n            value_offset = (current_offset + key_size)\n            if ((value_offset + val_size) > file_size_bytes):\n                return\n            (yield (key, value_offset, val_size))\n            if (val_size == _DELETED):\n                val_size = 0\n            skip_ahead = ((key_size + val_size) + 4)\n            current_offset += skip_ahead\n            if (current_offset > file_size_bytes):\n                raise DBMLoadError('Error loading db: reading past the end of the file (file possibly truncated)')\n            f.seek(current_offset)\n", "label": "Correct"}
{"function": "\n\ndef iter_keys(self, filename):\n    with open(filename, 'rb') as f:\n        header = f.read(8)\n        self._verify_header(header)\n        current_offset = 8\n        file_size_bytes = os.path.getsize(filename)\n        while True:\n            current_contents = f.read(8)\n            current_offset += 8\n            if (len(self) < 8):\n                if (len(current_contents) > 0):\n                    raise DBMLoadError('Error loading db: partial header read')\n                else:\n                    return\n            (key_size, val_size) = struct.unpack('!ii', current_contents)\n            key = f.read(key_size)\n            if (len(key) != key_size):\n                raise DBMLoadError(('Error loading db: key size does not match (expected %s bytes, got %s instead.' % (key_size, len(key))))\n            value_offset = (current_offset + key_size)\n            if ((value_offset + val_size) > file_size_bytes):\n                return\n            (yield (key, value_offset, val_size))\n            if (val_size == _DELETED):\n                val_size = 0\n            skip_ahead = ((key_size + val_size) + 4)\n            current_offset += skip_ahead\n            if (current_offset > file_size_bytes):\n                raise DBMLoadError('Error loading db: reading past the end of the file (file possibly truncated)')\n            f.seek(current_offset)\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.fixture\ndef get_image_part_fixture(self, Image_, image_part_, image_descriptor_):\n    image_parts = ImageParts()\n    image_parts.append(image_part_)\n    return (image_parts, image_descriptor_, image_part_)\n", "label": "Correct"}
{"function": "\n\n@pytest.fixture\ndef get_image_part_fixture(self, Image_, image_part_, image_descriptor_):\n    image_parts = ImageParts()\n    image_parts.append(image_part_)\n    return (image_descriptor_, image_descriptor_, image_part_)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, lang_canonicalizations):\n    self._lang_canonicalizations = lang_canonicalizations\n    self._root = SourceRootTrie.Node()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, lang_canonicalizations):\n    self._lang_canonicalizations = lang_canonicalizations\n    lang_canonicalizations._root = SourceRootTrie.Node()\n", "label": "Variable misuse"}
{"function": "\n\ndef publish_state(self, payload, state):\n    if (not state):\n        raise Exception('Unable to publish unassigned state.')\n    self._state_publisher.publish(payload, self._state_exchange, state)\n", "label": "Correct"}
{"function": "\n\ndef publish_state(self, payload, state):\n    if (not state):\n        raise Exception('Unable to publish unassigned state.')\n    self._state_publisher.publish(self, self._state_exchange, state)\n", "label": "Variable misuse"}
{"function": "\n\ndef none(self):\n    '\\n        Scalar(True) if no items are truthy, or collection is empty.\\n        '\n    return self.map((lambda items: (not any(items))))\n", "label": "Correct"}
{"function": "\n\ndef none(self):\n    '\\n        Scalar(True) if no items are truthy, or collection is empty.\\n        '\n    return items.map((lambda items: (not any(items))))\n", "label": "Variable misuse"}
{"function": "\n\ndef tonal_transposition(self, index, scale):\n    pos = ((index + scale.index(self)) - 1)\n    (octave, rest) = divmod(pos, 7)\n    note = copy.copy(scale[(pos % len(scale))])\n    note.octave += octave\n    return note\n", "label": "Correct"}
{"function": "\n\ndef tonal_transposition(self, index, scale):\n    pos = ((rest + scale.index(self)) - 1)\n    (octave, rest) = divmod(pos, 7)\n    note = copy.copy(scale[(pos % len(scale))])\n    note.octave += octave\n    return note\n", "label": "Variable misuse"}
{"function": "\n\ndef test_iter_smart_pk_range(self):\n    seen = []\n    for (start_pk, end_pk) in Author.objects.iter_smart_pk_ranges():\n        seen.extend(Author.objects.filter(id__gte=start_pk, id__lt=end_pk).values_list('id', flat=True))\n    all_ids = list(Author.objects.order_by('id').values_list('id', flat=True))\n    assert (seen == all_ids)\n", "label": "Correct"}
{"function": "\n\ndef test_iter_smart_pk_range(self):\n    seen = []\n    for (start_pk, end_pk) in Author.objects.iter_smart_pk_ranges():\n        all_ids.extend(Author.objects.filter(id__gte=start_pk, id__lt=end_pk).values_list('id', flat=True))\n    all_ids = list(Author.objects.order_by('id').values_list('id', flat=True))\n    assert (seen == all_ids)\n", "label": "Variable misuse"}
{"function": "\n\ndef no_translate_debug_logs(logical_line, filename):\n    \"Check for 'LOG.debug(_('\\n\\n    As per our translation policy,\\n    https://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\\n    we shouldn't translate debug level logs.\\n\\n    * This check assumes that 'LOG' is a logger.\\n    * Use filename so we can start enforcing this in specific folders instead\\n      of needing to do so all at once.\\n    S373\\n    \"\n    msg = \"S373 Don't translate debug level logs\"\n    if logical_line.startswith('LOG.debug(_('):\n        (yield (0, msg))\n", "label": "Correct"}
{"function": "\n\ndef no_translate_debug_logs(logical_line, filename):\n    \"Check for 'LOG.debug(_('\\n\\n    As per our translation policy,\\n    https://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\\n    we shouldn't translate debug level logs.\\n\\n    * This check assumes that 'LOG' is a logger.\\n    * Use filename so we can start enforcing this in specific folders instead\\n      of needing to do so all at once.\\n    S373\\n    \"\n    msg = \"S373 Don't translate debug level logs\"\n    if logical_line.startswith('LOG.debug(_('):\n        (yield (0, filename))\n", "label": "Variable misuse"}
{"function": "\n\ndef capability(self, i):\n    return self.capability_[i]\n", "label": "Correct"}
{"function": "\n\ndef capability(self, i):\n    return self.capability_[self]\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_user_ec2_credentials(request, user_id, access_token):\n    return ec2_manager(request).delete(user_id, access_token)\n", "label": "Correct"}
{"function": "\n\ndef delete_user_ec2_credentials(request, user_id, access_token):\n    return ec2_manager(request).delete(request, access_token)\n", "label": "Variable misuse"}
{"function": "\n\ndef testKeepExistingValues(self):\n    ph = GafferCortex.ParameterisedHolderNode()\n    ph.setParameterised(IECore.Grade())\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade())\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(0))\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade(), keepExistingValues=True)\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(1, 0, 0))\n", "label": "Correct"}
{"function": "\n\ndef testKeepExistingValues(self):\n    ph = GafferCortex.ParameterisedHolderNode()\n    ph.setParameterised(IECore.Grade())\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade())\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(0))\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    self.setParameterised(IECore.Grade(), keepExistingValues=True)\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(1, 0, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_command(self, ctx, name):\n    \"\\n        Get a specific command by looking up the module.\\n\\n        :param ctx: Click context\\n        :param name: Command name\\n        :return: Module's cli function\\n        \"\n    try:\n        if (sys.version_info[0] == 2):\n            name = name.encode('ascii', 'replace')\n        mod = __import__(('cli.commands.cmd_' + name), None, None, ['cli'])\n    except ImportError as e:\n        logging.error('Error importing module {0}:\\n{0}'.format(name, e))\n        exit(1)\n    return mod.cli\n", "label": "Correct"}
{"function": "\n\ndef get_command(self, ctx, name):\n    \"\\n        Get a specific command by looking up the module.\\n\\n        :param ctx: Click context\\n        :param name: Command name\\n        :return: Module's cli function\\n        \"\n    try:\n        if (sys.version_info[0] == 2):\n            name = name.encode('ascii', 'replace')\n        mod = __import__(('cli.commands.cmd_' + mod), None, None, ['cli'])\n    except ImportError as e:\n        logging.error('Error importing module {0}:\\n{0}'.format(name, e))\n        exit(1)\n    return mod.cli\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(SQLRows, self).__init__(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(SQLRows, self).__init__(*args, **self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, data):\n    '\\n        data is the entire xml body/document\\n        '\n    super(XMLResponse, self).__init__(data, mimetype='text/xml')\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, data):\n    '\\n        data is the entire xml body/document\\n        '\n    super(XMLResponse, data).__init__(data, mimetype='text/xml')\n", "label": "Variable misuse"}
{"function": "\n\ndef all_terms(f):\n    '\\n        Returns all terms from a univariate polynomial ``f``.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy import Poly\\n        >>> from sympy.abc import x\\n\\n        >>> Poly(x**3 + 2*x - 1, x).all_terms()\\n        [((3,), 1), ((2,), 0), ((1,), 2), ((0,), -1)]\\n\\n        '\n    return [(m, f.rep.dom.to_sympy(c)) for (m, c) in f.rep.all_terms()]\n", "label": "Correct"}
{"function": "\n\ndef all_terms(f):\n    '\\n        Returns all terms from a univariate polynomial ``f``.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy import Poly\\n        >>> from sympy.abc import x\\n\\n        >>> Poly(x**3 + 2*x - 1, x).all_terms()\\n        [((3,), 1), ((2,), 0), ((1,), 2), ((0,), -1)]\\n\\n        '\n    return [(m, f.rep.dom.to_sympy(c)) for (m, c) in m.rep.all_terms()]\n", "label": "Variable misuse"}
{"function": "\n\ndef ensure_role(self, role, dry_run=False):\n    '\\n        Adds the role if it does not already exist, otherwise skips it.\\n        '\n    existing_roles = Role.objects.filter(slug=role.slug)\n    if existing_roles:\n        logger.info('Role already exists: %s', role.name)\n        return existing_roles[0]\n    elif dry_run:\n        logger.info('[DRY RUN] Creating role: %s', role.name)\n    else:\n        if self.verbose:\n            logger.info('Creating role: %s', role.name)\n        role.save()\n", "label": "Correct"}
{"function": "\n\ndef ensure_role(self, role, dry_run=False):\n    '\\n        Adds the role if it does not already exist, otherwise skips it.\\n        '\n    existing_roles = Role.objects.filter(slug=role.slug)\n    if existing_roles:\n        logger.info('Role already exists: %s', role.name)\n        return existing_roles[0]\n    elif dry_run:\n        logger.info('[DRY RUN] Creating role: %s', role.name)\n    else:\n        if dry_run.verbose:\n            logger.info('Creating role: %s', role.name)\n        role.save()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_actions(self, request):\n    actions = super(CommentsAdmin, self).get_actions(request)\n    actions.pop('delete_selected')\n    actions.pop('flag_comments')\n    return actions\n", "label": "Correct"}
{"function": "\n\ndef get_actions(self, request):\n    actions = super(CommentsAdmin, self).get_actions(request)\n    self.pop('delete_selected')\n    actions.pop('flag_comments')\n    return actions\n", "label": "Variable misuse"}
{"function": "\n\ndef test_incr(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=None)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c')\n", "label": "Correct"}
{"function": "\n\ndef test_incr(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=None)\n    client.incr('buck.counter', 5)\n    client.assertEqual(client._socket.data, b'buck.counter:5|c')\n", "label": "Variable misuse"}
{"function": "\n\ndef _initPopulation(self, seeds):\n    if (self.parentChildAverage < 1):\n        for s in seeds:\n            s.parent = None\n    self.pop = self._extendPopulation(seeds, self.populationSize)\n", "label": "Correct"}
{"function": "\n\ndef _initPopulation(self, seeds):\n    if (self.parentChildAverage < 1):\n        for s in seeds:\n            s.parent = None\n    self.pop = self._extendPopulation(self, self.populationSize)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_script_name(environ, charset='utf-8', errors='replace'):\n    'Returns the `SCRIPT_NAME` from the WSGI environment and properly\\n    decodes it.  This also takes care about the WSGI decoding dance\\n    on Python 3 environments.  if the `charset` is set to `None` a\\n    bytestring is returned.\\n\\n    .. versionadded:: 0.9\\n\\n    :param environ: the WSGI environment object to get the path from.\\n    :param charset: the charset for the path, or `None` if no\\n                    decoding should be performed.\\n    :param errors: the decoding error handling.\\n    '\n    path = wsgi_get_bytes(environ.get('SCRIPT_NAME', ''))\n    return to_unicode(path, charset, errors, allow_none_charset=True)\n", "label": "Correct"}
{"function": "\n\ndef get_script_name(environ, charset='utf-8', errors='replace'):\n    'Returns the `SCRIPT_NAME` from the WSGI environment and properly\\n    decodes it.  This also takes care about the WSGI decoding dance\\n    on Python 3 environments.  if the `charset` is set to `None` a\\n    bytestring is returned.\\n\\n    .. versionadded:: 0.9\\n\\n    :param environ: the WSGI environment object to get the path from.\\n    :param charset: the charset for the path, or `None` if no\\n                    decoding should be performed.\\n    :param errors: the decoding error handling.\\n    '\n    path = wsgi_get_bytes(environ.get('SCRIPT_NAME', ''))\n    return to_unicode(environ, charset, errors, allow_none_charset=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_init(self):\n    farm_1 = {\n        'apples': 10,\n        'berries': 32,\n        'squash': 21,\n    }\n    farm_2 = {\n        'apples': 15,\n        'berries': 40,\n        'squash': 17,\n    }\n    data = [farm_1, farm_2]\n    index = ['Farm 1', 'Farm 2']\n    df = pd.DataFrame(data, index=index)\n    group = GroupedBar(df)\n    datas = [{\n        'name': 'table',\n        'values': [{\n            'col': 'apples',\n            'idx': 'Farm 1',\n            'val': 10,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 1',\n            'val': 32,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 1',\n            'val': 21,\n        }, {\n            'col': 'apples',\n            'idx': 'Farm 2',\n            'val': 15,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 2',\n            'val': 40,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 2',\n            'val': 17,\n        }],\n    }]\n    for (i, data) in enumerate(datas):\n        nt.assert_dict_equal(group.data[i].grammar(), data)\n    scales = [{\n        'domain': {\n            'data': 'table',\n            'field': 'data.idx',\n        },\n        'name': 'x',\n        'padding': 0.2,\n        'range': 'width',\n        'type': 'ordinal',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.val',\n        },\n        'name': 'y',\n        'nice': True,\n        'range': 'height',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.col',\n        },\n        'name': 'color',\n        'range': 'category20',\n        'type': 'ordinal',\n    }]\n    axes = [{\n        'scale': 'x',\n        'type': 'x',\n    }, {\n        'scale': 'y',\n        'type': 'y',\n    }]\n    marks = [{\n        'type': 'group',\n        'from': {\n            'data': 'table',\n            'transform': [{\n                'keys': ['data.idx'],\n                'type': 'facet',\n            }],\n        },\n        'marks': [{\n            'type': 'rect',\n            'properties': {\n                'enter': {\n                    'fill': {\n                        'field': 'data.col',\n                        'scale': 'color',\n                    },\n                    'width': {\n                        'band': True,\n                        'offset': (- 1),\n                        'scale': 'pos',\n                    },\n                    'x': {\n                        'field': 'data.col',\n                        'scale': 'pos',\n                    },\n                    'y': {\n                        'field': 'data.val',\n                        'scale': 'y',\n                    },\n                    'y2': {\n                        'scale': 'y',\n                        'value': 0,\n                    },\n                },\n            },\n        }],\n        'properties': {\n            'enter': {\n                'width': {\n                    'band': True,\n                    'scale': 'x',\n                },\n                'x': {\n                    'field': 'key',\n                    'scale': 'x',\n                },\n            },\n        },\n        'scales': [{\n            'domain': {\n                'field': 'data.col',\n            },\n            'name': 'pos',\n            'range': 'width',\n            'type': 'ordinal',\n        }],\n    }]\n    chart_runner(group, scales, axes, marks)\n", "label": "Correct"}
{"function": "\n\ndef test_init(self):\n    farm_1 = {\n        'apples': 10,\n        'berries': 32,\n        'squash': 21,\n    }\n    farm_2 = {\n        'apples': 15,\n        'berries': 40,\n        'squash': 17,\n    }\n    data = [farm_1, farm_2]\n    index = ['Farm 1', 'Farm 2']\n    df = pd.DataFrame(data, index=group)\n    group = GroupedBar(df)\n    datas = [{\n        'name': 'table',\n        'values': [{\n            'col': 'apples',\n            'idx': 'Farm 1',\n            'val': 10,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 1',\n            'val': 32,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 1',\n            'val': 21,\n        }, {\n            'col': 'apples',\n            'idx': 'Farm 2',\n            'val': 15,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 2',\n            'val': 40,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 2',\n            'val': 17,\n        }],\n    }]\n    for (i, data) in enumerate(datas):\n        nt.assert_dict_equal(group.data[i].grammar(), data)\n    scales = [{\n        'domain': {\n            'data': 'table',\n            'field': 'data.idx',\n        },\n        'name': 'x',\n        'padding': 0.2,\n        'range': 'width',\n        'type': 'ordinal',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.val',\n        },\n        'name': 'y',\n        'nice': True,\n        'range': 'height',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.col',\n        },\n        'name': 'color',\n        'range': 'category20',\n        'type': 'ordinal',\n    }]\n    axes = [{\n        'scale': 'x',\n        'type': 'x',\n    }, {\n        'scale': 'y',\n        'type': 'y',\n    }]\n    marks = [{\n        'type': 'group',\n        'from': {\n            'data': 'table',\n            'transform': [{\n                'keys': ['data.idx'],\n                'type': 'facet',\n            }],\n        },\n        'marks': [{\n            'type': 'rect',\n            'properties': {\n                'enter': {\n                    'fill': {\n                        'field': 'data.col',\n                        'scale': 'color',\n                    },\n                    'width': {\n                        'band': True,\n                        'offset': (- 1),\n                        'scale': 'pos',\n                    },\n                    'x': {\n                        'field': 'data.col',\n                        'scale': 'pos',\n                    },\n                    'y': {\n                        'field': 'data.val',\n                        'scale': 'y',\n                    },\n                    'y2': {\n                        'scale': 'y',\n                        'value': 0,\n                    },\n                },\n            },\n        }],\n        'properties': {\n            'enter': {\n                'width': {\n                    'band': True,\n                    'scale': 'x',\n                },\n                'x': {\n                    'field': 'key',\n                    'scale': 'x',\n                },\n            },\n        },\n        'scales': [{\n            'domain': {\n                'field': 'data.col',\n            },\n            'name': 'pos',\n            'range': 'width',\n            'type': 'ordinal',\n        }],\n    }]\n    chart_runner(group, scales, axes, marks)\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_task_with_policy(queue_name, task_id, owner):\n    'Fetches the specified task and enforces ownership policy.\\n\\n    Args:\\n        queue_name: Name of the queue the work item is on.\\n        task_id: ID of the task that is finished.\\n        owner: Who or what has the current lease on the task.\\n\\n    Returns:\\n        The valid WorkQueue task that is currently owned.\\n\\n    Raises:\\n        TaskDoesNotExistError if the task does not exist.\\n        LeaseExpiredError if the lease is no longer active.\\n        NotOwnerError if the specified owner no longer owns the task.\\n    '\n    now = datetime.datetime.utcnow()\n    task = WorkQueue.query.filter_by(queue_name=queue_name, task_id=task_id).with_lockmode('update').first()\n    if (not task):\n        raise TaskDoesNotExistError(('task_id=%r' % task_id))\n    lease_delta = (now - task.eta)\n    if (lease_delta > datetime.timedelta(0)):\n        db.session.rollback()\n        raise LeaseExpiredError(('queue=%r, task_id=%r expired %s' % (task.queue_name, task_id, lease_delta)))\n    if (task.last_owner != owner):\n        db.session.rollback()\n        raise NotOwnerError(('queue=%r, task_id=%r, owner=%r' % (task.queue_name, task_id, task.last_owner)))\n    return task\n", "label": "Correct"}
{"function": "\n\ndef _get_task_with_policy(queue_name, task_id, owner):\n    'Fetches the specified task and enforces ownership policy.\\n\\n    Args:\\n        queue_name: Name of the queue the work item is on.\\n        task_id: ID of the task that is finished.\\n        owner: Who or what has the current lease on the task.\\n\\n    Returns:\\n        The valid WorkQueue task that is currently owned.\\n\\n    Raises:\\n        TaskDoesNotExistError if the task does not exist.\\n        LeaseExpiredError if the lease is no longer active.\\n        NotOwnerError if the specified owner no longer owns the task.\\n    '\n    now = datetime.datetime.utcnow()\n    task = WorkQueue.query.filter_by(queue_name=queue_name, task_id=task_id).with_lockmode('update').first()\n    if (not task):\n        raise TaskDoesNotExistError(('task_id=%r' % task_id))\n    lease_delta = (now - task.eta)\n    if (lease_delta > datetime.timedelta(0)):\n        db.session.rollback()\n        raise LeaseExpiredError(('queue=%r, task_id=%r expired %s' % (task.queue_name, task_id, lease_delta)))\n    if (task.last_owner != owner):\n        db.session.rollback()\n        raise NotOwnerError(('queue=%r, task_id=%r, owner=%r' % (task.queue_name, task_id, task.last_owner)))\n    return queue_name\n", "label": "Variable misuse"}
{"function": "\n\ndef _rgen(i, prefix='r'):\n    return '{}{}'.format(prefix, i)\n", "label": "Correct"}
{"function": "\n\ndef _rgen(i, prefix='r'):\n    return '{}{}'.format(prefix, prefix)\n", "label": "Variable misuse"}
{"function": "\n\ndef __getattr__(self, item):\n    return getattr(self._tls, item, self._defaults.get(item))\n", "label": "Correct"}
{"function": "\n\ndef __getattr__(self, item):\n    return getattr(self._tls, item, self._defaults.get(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef showSublimeContext(self, filename, line):\n    debug(((('showSublimeContext: ' + str(filename)) + ' : ') + str(line)))\n    console_output((((('@@@ Stopped at ' + str(filename.replace((self.projectDir + '/'), ''))) + ':') + str(line)) + ' @@@'))\n    window = sublime.active_window()\n    if window:\n        window.focus_group(0)\n        view = window.active_view()\n        if ((view is not None) and (view.size() >= 0)):\n            filename = os.path.join(self.projectDir, filename)\n            if (view.file_name() != filename):\n                self.activateViewWithFile(filename, line)\n            window.run_command('goto_line', {\n                'line': line,\n            })\n            view = window.active_view()\n            mark = [view.line(view.text_point((line - 1), 0))]\n            view.erase_regions('current_line')\n            view.add_regions('current_line', mark, 'current_line', 'dot', sublime.DRAW_OUTLINED)\n        else:\n            debug('No current view')\n", "label": "Correct"}
{"function": "\n\ndef showSublimeContext(self, filename, line):\n    debug(((('showSublimeContext: ' + str(filename)) + ' : ') + str(line)))\n    console_output((((('@@@ Stopped at ' + str(filename.replace((self.projectDir + '/'), ''))) + ':') + str(line)) + ' @@@'))\n    window = sublime.active_window()\n    if window:\n        window.focus_group(0)\n        view = window.active_view()\n        if ((view is not None) and (view.size() >= 0)):\n            filename = os.path.join(self.projectDir, filename)\n            if (view.file_name() != filename):\n                self.activateViewWithFile(filename, line)\n            window.run_command('goto_line', {\n                'line': line,\n            })\n            view = window.active_view()\n            mark = [view.line(window.text_point((line - 1), 0))]\n            view.erase_regions('current_line')\n            view.add_regions('current_line', mark, 'current_line', 'dot', sublime.DRAW_OUTLINED)\n        else:\n            debug('No current view')\n", "label": "Variable misuse"}
{"function": "\n\ndef the_local_centroid_is(step, centroid, distance):\n    check_prediction(world.local_centroid['centroid_name'], centroid)\n    check_prediction(world.local_centroid['distance'], distance)\n", "label": "Correct"}
{"function": "\n\ndef the_local_centroid_is(step, centroid, distance):\n    check_prediction(world.local_centroid['centroid_name'], distance)\n    check_prediction(world.local_centroid['distance'], distance)\n", "label": "Variable misuse"}
{"function": "\n\ndef _zones_us_central1_a_disks_node_name(self, method, url, body, headers):\n    body = self.fixtures.load('generic_disk.json')\n    return (httplib.OK, body, self.json_hdr, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _zones_us_central1_a_disks_node_name(self, method, url, body, headers):\n    body = self.fixtures.load('generic_disk.json')\n    return (httplib.OK, method, self.json_hdr, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_diff_nans(self):\n    'Regression test for https://aeon.stsci.edu/ssb/trac/pyfits/ticket/204'\n    arr = np.empty((10, 10), dtype=np.float64)\n    arr[:5] = 1.0\n    arr[5:] = np.nan\n    arr2 = arr.copy()\n    table = np.rec.array([(1.0, 2.0), (3.0, np.nan), (np.nan, np.nan)], names=['cola', 'colb']).view(fits.FITS_rec)\n    table2 = table.copy()\n    assert ImageDataDiff(arr, arr2).identical\n    assert TableDataDiff(table, table2).identical\n    arr2[0][0] = 2.0\n    arr2[5][0] = 2.0\n    table2[0][0] = 2.0\n    table2[1][1] = 2.0\n    diff = ImageDataDiff(arr, arr2)\n    assert (not diff.identical)\n    assert (diff.diff_pixels[0] == ((0, 0), (1.0, 2.0)))\n    assert (diff.diff_pixels[1][0] == (5, 0))\n    assert np.isnan(diff.diff_pixels[1][1][0])\n    assert (diff.diff_pixels[1][1][1] == 2.0)\n    diff = TableDataDiff(table, table2)\n    assert (not diff.identical)\n    assert (diff.diff_values[0] == (('cola', 0), (1.0, 2.0)))\n    assert (diff.diff_values[1][0] == ('colb', 1))\n    assert np.isnan(diff.diff_values[1][1][0])\n    assert (diff.diff_values[1][1][1] == 2.0)\n", "label": "Correct"}
{"function": "\n\ndef test_diff_nans(self):\n    'Regression test for https://aeon.stsci.edu/ssb/trac/pyfits/ticket/204'\n    arr = np.empty((10, 10), dtype=np.float64)\n    arr[:5] = 1.0\n    arr[5:] = np.nan\n    arr2 = arr.copy()\n    table = np.rec.array([(1.0, 2.0), (3.0, np.nan), (np.nan, np.nan)], names=['cola', 'colb']).view(fits.FITS_rec)\n    table2 = table.copy()\n    assert ImageDataDiff(arr, arr2).identical\n    assert TableDataDiff(table, table2).identical\n    arr2[0][0] = 2.0\n    arr2[5][0] = 2.0\n    table2[0][0] = 2.0\n    table2[1][1] = 2.0\n    diff = ImageDataDiff(self, arr2)\n    assert (not diff.identical)\n    assert (diff.diff_pixels[0] == ((0, 0), (1.0, 2.0)))\n    assert (diff.diff_pixels[1][0] == (5, 0))\n    assert np.isnan(diff.diff_pixels[1][1][0])\n    assert (diff.diff_pixels[1][1][1] == 2.0)\n    diff = TableDataDiff(table, table2)\n    assert (not diff.identical)\n    assert (diff.diff_values[0] == (('cola', 0), (1.0, 2.0)))\n    assert (diff.diff_values[1][0] == ('colb', 1))\n    assert np.isnan(diff.diff_values[1][1][0])\n    assert (diff.diff_values[1][1][1] == 2.0)\n", "label": "Variable misuse"}
{"function": "\n\ndef do_command(self, verb, args):\n    conn = http_client.HTTPConnection(self.host, self.port, timeout=self.http_timeout)\n    try:\n        body = ('cmd=' + urllib_parse.quote_plus(unicode(verb).encode('utf-8')))\n        for i in range(len(args)):\n            body += ((('&' + unicode((i + 1))) + '=') + urllib_parse.quote_plus(unicode(args[i]).encode('utf-8')))\n        if (None != self.sessionId):\n            body += ('&sessionId=' + unicode(self.sessionId))\n        headers = {\n            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n        }\n        conn.request('POST', '/selenium-server/driver/', body, headers)\n        response = conn.getresponse()\n        data = unicode(response.read(), 'UTF-8')\n        if (not data.startswith('OK')):\n            raise Exception(data)\n        return data\n    finally:\n        conn.close()\n", "label": "Correct"}
{"function": "\n\ndef do_command(self, verb, args):\n    conn = http_client.HTTPConnection(self.host, self.port, timeout=self.http_timeout)\n    try:\n        body = ('cmd=' + urllib_parse.quote_plus(unicode(verb).encode('utf-8')))\n        for i in range(len(args)):\n            body += ((('&' + unicode((i + 1))) + '=') + urllib_parse.quote_plus(unicode(args[i]).encode('utf-8')))\n        if (None != self.sessionId):\n            body += ('&sessionId=' + unicode(headers.sessionId))\n        headers = {\n            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n        }\n        conn.request('POST', '/selenium-server/driver/', body, headers)\n        response = conn.getresponse()\n        data = unicode(response.read(), 'UTF-8')\n        if (not data.startswith('OK')):\n            raise Exception(data)\n        return data\n    finally:\n        conn.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef date_to_string(from_date, to_format):\n    return datetime(from_date.year, from_date.month, from_date.day).strftime(to_format)\n", "label": "Correct"}
{"function": "\n\ndef date_to_string(from_date, to_format):\n    return datetime(from_date.year, to_format.month, from_date.day).strftime(to_format)\n", "label": "Variable misuse"}
{"function": "\n\ndef fdiff(self, argindex=1):\n    (z, m) = self.args\n    fm = sqrt((1 - (m * (sin(z) ** 2))))\n    if (argindex == 1):\n        return (1 / fm)\n    elif (argindex == 2):\n        return (((elliptic_e(z, m) / ((2 * m) * (1 - m))) - (elliptic_f(z, m) / (2 * m))) - (sin((2 * z)) / ((4 * (1 - m)) * fm)))\n    raise ArgumentIndexError(self, argindex)\n", "label": "Correct"}
{"function": "\n\ndef fdiff(self, argindex=1):\n    (z, m) = self.args\n    fm = sqrt((1 - (m * (sin(z) ** 2))))\n    if (argindex == 1):\n        return (1 / fm)\n    elif (argindex == 2):\n        return (((elliptic_e(z, m) / ((2 * m) * (1 - argindex))) - (elliptic_f(z, m) / (2 * m))) - (sin((2 * z)) / ((4 * (1 - m)) * fm)))\n    raise ArgumentIndexError(self, argindex)\n", "label": "Variable misuse"}
{"function": "\n\ndef bayesdb_generator_column_stattype(bdb, generator_id, colno):\n    'Return the statistical type of the column `colno` in `generator_id`.'\n    sql = '\\n        SELECT stattype FROM bayesdb_generator_column\\n            WHERE generator_id = ? AND colno = ?\\n    '\n    cursor = bdb.sql_execute(sql, (generator_id, colno))\n    try:\n        row = cursor.next()\n    except StopIteration:\n        generator = bayesdb_generator_name(bdb, generator_id)\n        sql = '\\n            SELECT COUNT(*)\\n                FROM bayesdb_generator AS g, bayesdb_column AS c\\n                WHERE g.id = :generator_id\\n                    AND g.tabname = c.tabname\\n                    AND c.colno = :colno\\n        '\n        cursor = bdb.sql_execute(sql, {\n            'generator_id': generator_id,\n            'colno': colno,\n        })\n        if (cursor_value(cursor) == 0):\n            raise ValueError(('No such column in generator %s: %d' % (generator, colno)))\n        else:\n            raise ValueError(('Column not modelled in generator %s: %d' % (generator, colno)))\n    else:\n        assert (len(row) == 1)\n        return row[0]\n", "label": "Correct"}
{"function": "\n\ndef bayesdb_generator_column_stattype(bdb, generator_id, colno):\n    'Return the statistical type of the column `colno` in `generator_id`.'\n    sql = '\\n        SELECT stattype FROM bayesdb_generator_column\\n            WHERE generator_id = ? AND colno = ?\\n    '\n    cursor = bdb.sql_execute(sql, (generator_id, colno))\n    try:\n        row = cursor.next()\n    except StopIteration:\n        generator = bayesdb_generator_name(bdb, generator_id)\n        sql = '\\n            SELECT COUNT(*)\\n                FROM bayesdb_generator AS g, bayesdb_column AS c\\n                WHERE g.id = :generator_id\\n                    AND g.tabname = c.tabname\\n                    AND c.colno = :colno\\n        '\n        cursor = bdb.sql_execute(sql, {\n            'generator_id': generator,\n            'colno': colno,\n        })\n        if (cursor_value(cursor) == 0):\n            raise ValueError(('No such column in generator %s: %d' % (generator, colno)))\n        else:\n            raise ValueError(('Column not modelled in generator %s: %d' % (generator, colno)))\n    else:\n        assert (len(row) == 1)\n        return row[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, db, callback, **params):\n    self.process_change = callback\n    self.params = params\n    self.db = db\n    self.stop_event = event.Event()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, db, callback, **params):\n    self.process_change = callback\n    self.params = self\n    self.db = db\n    self.stop_event = event.Event()\n", "label": "Variable misuse"}
{"function": "\n\ndef pt_visual_explain(self, display=True):\n    return pt_visual_explain(self, display)\n", "label": "Correct"}
{"function": "\n\ndef pt_visual_explain(self, display=True):\n    return pt_visual_explain(display, display)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_init_kwargs_with_prefix(self):\n    custom_conf = TestConf(TESTS_CUSTOM_VALUE2='custom2')\n    self.assertEqual(custom_conf.TESTS_CUSTOM_VALUE2, 'custom2')\n    self.assertEqual(settings.TESTS_CUSTOM_VALUE2, 'custom2')\n", "label": "Correct"}
{"function": "\n\ndef test_init_kwargs_with_prefix(self):\n    custom_conf = TestConf(TESTS_CUSTOM_VALUE2='custom2')\n    self.assertEqual(self.TESTS_CUSTOM_VALUE2, 'custom2')\n    self.assertEqual(settings.TESTS_CUSTOM_VALUE2, 'custom2')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_serialization_type(self):\n    activity_object = Pin(id=1)\n    activity = Activity(1, LoveVerb, activity_object)\n    assert isinstance(activity.serialization_id, (six.integer_types, float))\n", "label": "Correct"}
{"function": "\n\ndef test_serialization_type(self):\n    activity_object = Pin(id=1)\n    activity = Activity(1, LoveVerb, activity_object)\n    assert isinstance(activity_object.serialization_id, (six.integer_types, float))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unauthenticated_access(self):\n    'Test index page at /api/calendar/events'\n    response = self.client.get('/api/calendar/events')\n    self.assertEquals(response.status_code, 401)\n", "label": "Correct"}
{"function": "\n\ndef test_unauthenticated_access(self):\n    'Test index page at /api/calendar/events'\n    response = self.client.get('/api/calendar/events')\n    response.assertEquals(response.status_code, 401)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, coord, canvas, marker_radius=2, marker_color='green2', timestamp=0):\n    self._marker_color = marker_color\n    self._marker_radius = marker_radius\n    self._coord = coord\n    self._canvas = canvas\n    self._timestamp = timestamp\n    self._canvas_id = None\n    self._is_selected = False\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, coord, canvas, marker_radius=2, marker_color='green2', timestamp=0):\n    self._marker_color = marker_color\n    self._marker_radius = marker_radius\n    self._coord = coord\n    self._canvas = marker_color\n    self._timestamp = timestamp\n    self._canvas_id = None\n    self._is_selected = False\n", "label": "Variable misuse"}
{"function": "\n\ndef job_binary_create(request, name, url, description, extra):\n    return client(request).job_binaries.create(name, url, description, extra)\n", "label": "Correct"}
{"function": "\n\ndef job_binary_create(request, name, url, description, extra):\n    return client(request).job_binaries.create(name, url, description, url)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, from_elem=None, factor=None):\n    self.from_elem = from_elem\n    self.factor = factor\n    self.to_elems = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, from_elem=None, factor=None):\n    self.from_elem = from_elem\n    from_elem.factor = factor\n    self.to_elems = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.xfail\ndef test_fails(self):\n    contact = models.Contact(name='Example')\n    contact.put()\n    models.PhoneNumber(contact=self.contact_key, phone_type='home', number='(650) 555 - 2200').put()\n    numbers = contact.phone_numbers.fetch()\n    assert (1 == len(numbers))\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.xfail\ndef test_fails(self):\n    contact = models.Contact(name='Example')\n    contact.put()\n    models.PhoneNumber(contact=self.contact_key, phone_type='home', number='(650) 555 - 2200').put()\n    numbers = numbers.phone_numbers.fetch()\n    assert (1 == len(numbers))\n", "label": "Variable misuse"}
{"function": "\n\ndef _mount_shares_to_instance(self, instance):\n    for share in self.shares:\n        share.handler.allow_access_to_instance(instance, share.share_config)\n    with instance.remote() as remote:\n        share_types = set((type(share.handler) for share in self.shares))\n        for share_type in share_types:\n            share_type.setup_instance(remote)\n        for share in self.shares:\n            share.handler.mount_to_instance(remote, share.share_config)\n", "label": "Correct"}
{"function": "\n\ndef _mount_shares_to_instance(self, instance):\n    for share in self.shares:\n        share.handler.allow_access_to_instance(share_types, share.share_config)\n    with instance.remote() as remote:\n        share_types = set((type(share.handler) for share in self.shares))\n        for share_type in share_types:\n            share_type.setup_instance(remote)\n        for share in self.shares:\n            share.handler.mount_to_instance(remote, share.share_config)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_default_machine(self):\n    ' Reads the default machine from the package configuration\\n        \\n        '\n    server = username = port = password = ''\n    if configuration.check('server'):\n        server = configuration.server\n    if (not server):\n        return None\n    if configuration.check('username'):\n        username = configuration.username\n    if (not username):\n        username = current_user()\n    if (configuration.check('port') is not None):\n        port = configuration.port\n    if configuration.check('password'):\n        password = configuration.password\n    self.annotate({\n        'RemoteQ-server': server,\n        'RemoteQ-username': username,\n        'RemoteQ-port': port,\n    })\n    return (server, port, username, password)\n", "label": "Correct"}
{"function": "\n\ndef get_default_machine(self):\n    ' Reads the default machine from the package configuration\\n        \\n        '\n    server = username = port = password = ''\n    if configuration.check('server'):\n        server = configuration.server\n    if (not server):\n        return None\n    if configuration.check('username'):\n        username = configuration.username\n    if (not username):\n        username = current_user()\n    if (configuration.check('port') is not None):\n        port = configuration.port\n    if configuration.check('password'):\n        password = configuration.password\n    password.annotate({\n        'RemoteQ-server': server,\n        'RemoteQ-username': username,\n        'RemoteQ-port': port,\n    })\n    return (server, port, username, password)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_hosts(self):\n    '\\n            Get list of all hosts in cluster\\n            Args:\\n                None\\n            Return:\\n                list of hostnames\\n            Raise:\\n                None\\n       '\n    zook = self.zk_client\n    broker_id_path = self.zk_paths[BROKER_IDS]\n    if zook.exists(broker_id_path):\n        broker_ids = zook.get_children(broker_id_path)\n        brokers = []\n        for broker_id in broker_ids:\n            brokers.append(self.get_host(broker_id))\n        return brokers\n", "label": "Correct"}
{"function": "\n\ndef get_all_hosts(self):\n    '\\n            Get list of all hosts in cluster\\n            Args:\\n                None\\n            Return:\\n                list of hostnames\\n            Raise:\\n                None\\n       '\n    zook = self.zk_client\n    broker_id_path = self.zk_paths[BROKER_IDS]\n    if zook.exists(broker_id_path):\n        broker_ids = broker_id.get_children(broker_id_path)\n        brokers = []\n        for broker_id in broker_ids:\n            brokers.append(self.get_host(broker_id))\n        return brokers\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef Validate(cls, builtins_list, runtime=None):\n    'Verify that all BuiltinHandler objects are valid and not repeated.\\n\\n    Args:\\n      builtins_list: list of BuiltinHandler objects to validate.\\n      runtime: if set then warnings are generated for builtins that have been\\n          deprecated in the given runtime.\\n\\n    Raises:\\n      InvalidBuiltinFormat: if the name of a Builtinhandler object\\n          cannot be determined.\\n      DuplicateBuiltinsSpecified: if a builtin handler name is used\\n          more than once in the list.\\n    '\n    seen = set()\n    for b in builtins_list:\n        if (not b.builtin_name):\n            raise appinfo_errors.InvalidBuiltinFormat(('Name of builtin for list object %s could not be determined.' % b))\n        if (b.builtin_name in seen):\n            raise appinfo_errors.DuplicateBuiltinsSpecified(('Builtin %s was specified more than once in one yaml file.' % b.builtin_name))\n        if ((b.builtin_name == 'datastore_admin') and (runtime == 'python')):\n            logging.warning('The datastore_admin builtin is deprecated. You can find information on how to enable it through the Administrative Console here: http://developers.google.com/appengine/docs/adminconsole/datastoreadmin.html')\n        elif ((b.builtin_name == 'mapreduce') and (runtime == 'python')):\n            logging.warning('The mapreduce builtin is deprecated. You can find more information on how to configure and use it here: http://developers.google.com/appengine/docs/python/dataprocessing/overview.html')\n        seen.add(b.builtin_name)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef Validate(cls, builtins_list, runtime=None):\n    'Verify that all BuiltinHandler objects are valid and not repeated.\\n\\n    Args:\\n      builtins_list: list of BuiltinHandler objects to validate.\\n      runtime: if set then warnings are generated for builtins that have been\\n          deprecated in the given runtime.\\n\\n    Raises:\\n      InvalidBuiltinFormat: if the name of a Builtinhandler object\\n          cannot be determined.\\n      DuplicateBuiltinsSpecified: if a builtin handler name is used\\n          more than once in the list.\\n    '\n    seen = set()\n    for b in builtins_list:\n        if (not b.builtin_name):\n            raise appinfo_errors.InvalidBuiltinFormat(('Name of builtin for list object %s could not be determined.' % b))\n        if (b.builtin_name in seen):\n            raise appinfo_errors.DuplicateBuiltinsSpecified(('Builtin %s was specified more than once in one yaml file.' % b.builtin_name))\n        if ((b.builtin_name == 'datastore_admin') and (runtime == 'python')):\n            logging.warning('The datastore_admin builtin is deprecated. You can find information on how to enable it through the Administrative Console here: http://developers.google.com/appengine/docs/adminconsole/datastoreadmin.html')\n        elif ((b.builtin_name == 'mapreduce') and (runtime == 'python')):\n            logging.warning('The mapreduce builtin is deprecated. You can find more information on how to configure and use it here: http://developers.google.com/appengine/docs/python/dataprocessing/overview.html')\n        seen.add(seen.builtin_name)\n", "label": "Variable misuse"}
{"function": "\n\n@npt.dec.skipif(old_mpl)\ndef test_cached_coherence():\n    'Testing the cached coherence functions '\n    NFFT = 64\n    n_freqs = ((NFFT // 2) + 1)\n    ij = [(0, 1), (1, 0)]\n    ts = np.loadtxt(os.path.join(test_dir_path, 'tseries12.txt'))\n    (freqs, cache) = tsa.cache_fft(ts, ij)\n    npt.assert_equal(freqs, utils.get_freqs((2 * np.pi), NFFT))\n    hann = mlab.window_hanning(np.ones(NFFT))\n    w_ts = (ts[0][:NFFT] * hann)\n    w_ft = fftpack.fft(w_ts)[0:n_freqs]\n    first_window_fft = cache['FFT_slices'][0][0]\n    npt.assert_equal(w_ft, first_window_fft)\n    coh_cached = tsa.cache_to_coherency(cache, ij)[(0, 1)]\n    (f, c) = tsa.coherency(ts)\n    coh_direct = c[(0, 1)]\n    npt.assert_almost_equal(coh_direct, coh_cached)\n    npt.assert_raises(ValueError, tsa.cache_fft, ts, ij, method=methods[2])\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3])\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4])\n    npt.assert_equal(cache1, cache2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3], scale_by_freq=False)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4], scale_by_freq=False)\n    npt.assert_equal(cache1, cache2)\n    psd1 = tsa.cache_to_psd(cache, ij)[0]\n    (f, c) = tsa.get_spectra(ts)\n    psd2 = c[0][0]\n    npt.assert_almost_equal(psd1, psd2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, prefer_speed_over_memory=True)\n    psd1 = tsa.cache_to_psd(cache1, ij)[0]\n    psd2 = tsa.cache_to_psd(cache2, ij)[0]\n    npt.assert_almost_equal(psd1, psd2)\n", "label": "Correct"}
{"function": "\n\n@npt.dec.skipif(old_mpl)\ndef test_cached_coherence():\n    'Testing the cached coherence functions '\n    NFFT = 64\n    n_freqs = ((NFFT // 2) + 1)\n    ij = [(0, 1), (1, 0)]\n    ts = np.loadtxt(os.path.join(test_dir_path, 'tseries12.txt'))\n    (freqs, cache) = tsa.cache_fft(ts, ij)\n    npt.assert_equal(freqs, utils.get_freqs((2 * np.pi), NFFT))\n    hann = mlab.window_hanning(np.ones(NFFT))\n    w_ts = (ts[0][:NFFT] * hann)\n    w_ft = fftpack.fft(w_ts)[0:n_freqs]\n    first_window_fft = cache['FFT_slices'][0][0]\n    npt.assert_equal(freqs, first_window_fft)\n    coh_cached = tsa.cache_to_coherency(cache, ij)[(0, 1)]\n    (f, c) = tsa.coherency(ts)\n    coh_direct = c[(0, 1)]\n    npt.assert_almost_equal(coh_direct, coh_cached)\n    npt.assert_raises(ValueError, tsa.cache_fft, ts, ij, method=methods[2])\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3])\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4])\n    npt.assert_equal(cache1, cache2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3], scale_by_freq=False)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4], scale_by_freq=False)\n    npt.assert_equal(cache1, cache2)\n    psd1 = tsa.cache_to_psd(cache, ij)[0]\n    (f, c) = tsa.get_spectra(ts)\n    psd2 = c[0][0]\n    npt.assert_almost_equal(psd1, psd2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, prefer_speed_over_memory=True)\n    psd1 = tsa.cache_to_psd(cache1, ij)[0]\n    psd2 = tsa.cache_to_psd(cache2, ij)[0]\n    npt.assert_almost_equal(psd1, psd2)\n", "label": "Variable misuse"}
{"function": "\n\ndef on_monitor(self, model, dataset, algorithm):\n    '\\n        Updates the momentum according to the linear schedule.\\n\\n        Parameters\\n        ----------\\n        model : pylearn2.models.Model\\n            The model to which the training algorithm is applied.\\n        dataset : pylearn2.datasets.Dataset\\n            The dataset to which the model is applied.\\n        algorithm : pylearn2.training_algorithms.TrainingAlgorithm\\n            Describes how gradients should be updated.\\n        '\n    self._count += 1\n    self._apply_momentum(algorithm)\n", "label": "Correct"}
{"function": "\n\ndef on_monitor(self, model, dataset, algorithm):\n    '\\n        Updates the momentum according to the linear schedule.\\n\\n        Parameters\\n        ----------\\n        model : pylearn2.models.Model\\n            The model to which the training algorithm is applied.\\n        dataset : pylearn2.datasets.Dataset\\n            The dataset to which the model is applied.\\n        algorithm : pylearn2.training_algorithms.TrainingAlgorithm\\n            Describes how gradients should be updated.\\n        '\n    self._count += 1\n    dataset._apply_momentum(algorithm)\n", "label": "Variable misuse"}
{"function": "\n\ndef handleInput(self, session, args):\n    ses = {\n        \n    }\n    ses['session'] = session\n    ses['realm'] = args['realm']\n    ses['input'] = args['input']\n    self.broadcast('input', ses)\n", "label": "Correct"}
{"function": "\n\ndef handleInput(self, session, args):\n    ses = {\n        \n    }\n    ses['session'] = session\n    ses['realm'] = args['realm']\n    ses['input'] = args['input']\n    self.broadcast('input', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse(cls, signed_request, application_secret_key):\n    'Parse a signed request, returning a dictionary describing its payload.'\n\n    def decode(encoded):\n        padding = ('=' * (len(encoded) % 4))\n        return base64.urlsafe_b64decode((encoded + padding))\n    try:\n        (encoded_signature, encoded_payload) = (str(string) for string in signed_request.split('.', 2))\n        signature = decode(encoded_signature)\n        signed_request_data = json.loads(decode(encoded_payload).decode('utf-8'))\n    except (TypeError, ValueError):\n        raise SignedRequestError('Signed request had a corrupt payload')\n    if (signed_request_data.get('algorithm', '').upper() != 'HMAC-SHA256'):\n        raise SignedRequestError('Signed request is using an unknown algorithm')\n    expected_signature = hmac.new(application_secret_key.encode('utf-8'), msg=encoded_payload.encode('utf-8'), digestmod=hashlib.sha256).digest()\n    if (signature != expected_signature):\n        raise SignedRequestError('Signed request signature mismatch')\n    return signed_request_data\n", "label": "Correct"}
{"function": "\n\ndef parse(cls, signed_request, application_secret_key):\n    'Parse a signed request, returning a dictionary describing its payload.'\n\n    def decode(encoded):\n        padding = ('=' * (len(encoded) % 4))\n        return base64.urlsafe_b64decode((encoded + padding))\n    try:\n        (encoded_signature, encoded_payload) = (str(application_secret_key) for string in signed_request.split('.', 2))\n        signature = decode(encoded_signature)\n        signed_request_data = json.loads(decode(encoded_payload).decode('utf-8'))\n    except (TypeError, ValueError):\n        raise SignedRequestError('Signed request had a corrupt payload')\n    if (signed_request_data.get('algorithm', '').upper() != 'HMAC-SHA256'):\n        raise SignedRequestError('Signed request is using an unknown algorithm')\n    expected_signature = hmac.new(application_secret_key.encode('utf-8'), msg=encoded_payload.encode('utf-8'), digestmod=hashlib.sha256).digest()\n    if (signature != expected_signature):\n        raise SignedRequestError('Signed request signature mismatch')\n    return signed_request_data\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_declare_passive(self):\n    obj = amqp_queue.Queue(self.chan)\n    expectation = {\n        'arguments': {\n            \n        },\n        'auto_delete': False,\n        'durable': False,\n        'exclusive': False,\n        'nowait': False,\n        'passive': True,\n        'queue': '',\n        'ticket': 0,\n    }\n    self.assertDictEqual(dict(obj._declare(True)), expectation)\n", "label": "Correct"}
{"function": "\n\ndef test_default_declare_passive(self):\n    obj = amqp_queue.Queue(self.chan)\n    expectation = {\n        'arguments': {\n            \n        },\n        'auto_delete': False,\n        'durable': False,\n        'exclusive': False,\n        'nowait': False,\n        'passive': True,\n        'queue': '',\n        'ticket': 0,\n    }\n    obj.assertDictEqual(dict(obj._declare(True)), expectation)\n", "label": "Variable misuse"}
{"function": "\n\ndef update_fc_bias(self, err, out):\n    '\\n        Compute the updated bias gradient for a fully connected network layer.\\n\\n        Arguments:\\n            err (Tensor): backpropagated error\\n            out (Tensor): Where to store the updated gradient value.\\n        '\n    self.ng.sum(err, axis=1, out=out)\n", "label": "Correct"}
{"function": "\n\ndef update_fc_bias(self, err, out):\n    '\\n        Compute the updated bias gradient for a fully connected network layer.\\n\\n        Arguments:\\n            err (Tensor): backpropagated error\\n            out (Tensor): Where to store the updated gradient value.\\n        '\n    self.ng.sum(self, axis=1, out=out)\n", "label": "Variable misuse"}
{"function": "\n\ndef convert_values(self, value, field, connection):\n    'Convert the database-returned value into a type that is consistent\\n        across database backends.\\n\\n        By default, this defers to the underlying backend operations, but\\n        it can be overridden by Query classes for specific backends.\\n        '\n    return connection.ops.convert_values(value, field)\n", "label": "Correct"}
{"function": "\n\ndef convert_values(self, value, field, connection):\n    'Convert the database-returned value into a type that is consistent\\n        across database backends.\\n\\n        By default, this defers to the underlying backend operations, but\\n        it can be overridden by Query classes for specific backends.\\n        '\n    return connection.ops.convert_values(field, field)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(TestClientInvalidResponse, self).__init__()\n    self.broken = True\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(TestClientInvalidResponse, kwargs).__init__()\n    self.broken = True\n", "label": "Variable misuse"}
{"function": "\n\ndef _xmlrpc__hosting_disk_list(self, method, url, body, headers):\n    body = self.fixtures.load('disk_list.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _xmlrpc__hosting_disk_list(self, method, url, body, headers):\n    body = url.fixtures.load('disk_list.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, df, scale, seed=None):\n    '\\n        Create a frozen inverse Wishart distribution.\\n\\n        Parameters\\n        ----------\\n        df : array_like\\n            Degrees of freedom of the distribution\\n        scale : array_like\\n            Scale matrix of the distribution\\n        seed : None or int or np.random.RandomState instance, optional\\n            This parameter defines the RandomState object to use for drawing\\n            random variates.\\n            If None (or np.random), the global np.random state is used.\\n            If integer, it is used to seed the local RandomState instance\\n            Default is None.\\n\\n        '\n    self._dist = invwishart_gen(seed)\n    (self.dim, self.df, self.scale) = self._dist._process_parameters(df, scale)\n    (C, lower) = scipy.linalg.cho_factor(self.scale, lower=True)\n    self.log_det_scale = (2 * np.sum(np.log(C.diagonal())))\n    eye = np.eye(self.dim)\n    self.inv_scale = scipy.linalg.cho_solve((C, lower), eye)\n    self.C = scipy.linalg.cholesky(self.inv_scale, lower=True)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, df, scale, seed=None):\n    '\\n        Create a frozen inverse Wishart distribution.\\n\\n        Parameters\\n        ----------\\n        df : array_like\\n            Degrees of freedom of the distribution\\n        scale : array_like\\n            Scale matrix of the distribution\\n        seed : None or int or np.random.RandomState instance, optional\\n            This parameter defines the RandomState object to use for drawing\\n            random variates.\\n            If None (or np.random), the global np.random state is used.\\n            If integer, it is used to seed the local RandomState instance\\n            Default is None.\\n\\n        '\n    self._dist = invwishart_gen(seed)\n    (self.dim, self.df, self.scale) = C._dist._process_parameters(df, scale)\n    (C, lower) = scipy.linalg.cho_factor(self.scale, lower=True)\n    self.log_det_scale = (2 * np.sum(np.log(C.diagonal())))\n    eye = np.eye(self.dim)\n    self.inv_scale = scipy.linalg.cho_solve((C, lower), eye)\n    self.C = scipy.linalg.cholesky(self.inv_scale, lower=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef backed_value(self, key, default=None):\n    return self.backing_store.get(self.identifier, key, default)\n", "label": "Correct"}
{"function": "\n\ndef backed_value(self, key, default=None):\n    return key.backing_store.get(self.identifier, key, default)\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, key, default=None):\n    'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n    return self._data.get(self._transform(key), default)\n", "label": "Correct"}
{"function": "\n\ndef get(self, key, default=None):\n    'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n    return self._data.get(key._transform(key), default)\n", "label": "Variable misuse"}
{"function": "\n\ndef Connect(*args, **kwargs):\n    'Shortcut for creating a connection.MySQLConnection object.'\n    return MySQLConnection(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef Connect(*args, **kwargs):\n    'Shortcut for creating a connection.MySQLConnection object.'\n    return MySQLConnection(*kwargs, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef assemble(self):\n    assembled = {\n        self.type: self.body,\n    }\n    if self.aggregations:\n        assembled['aggs'] = {\n            \n        }\n        for agg in self.aggregations:\n            assembled['aggs'][agg.name] = agg.assemble()\n    return assembled\n", "label": "Correct"}
{"function": "\n\ndef assemble(self):\n    assembled = {\n        self.type: self.body,\n    }\n    if agg.aggregations:\n        assembled['aggs'] = {\n            \n        }\n        for agg in self.aggregations:\n            assembled['aggs'][agg.name] = agg.assemble()\n    return assembled\n", "label": "Variable misuse"}
{"function": "\n\ndef _ml_train_iterative(self, database_matrix, params=[], sliding_window=168, k=1):\n    '\\n            Training method used by Fred 09 paper.\\n        '\n    p = (database_matrix.shape[1] - 1)\n    number_iterations = ((((database_matrix.shape[0] + p) - k) - sliding_window) + 1)\n    print('Number of iterations: ', number_iterations)\n    tr_size = ((sliding_window - p) - 1)\n    z = (database_matrix[0:(- k), 1].reshape((- 1), 1) * np.ones((1, p)))\n    database_matrix[k:, 1:] = (database_matrix[k:, 1:] - z)\n    pr_target = []\n    ex_target = []\n    for i in range(number_iterations):\n        self._ml_train(database_matrix[(k + i):(((k + i) + tr_size) - 1), :], params)\n        pr_t = self._ml_predict(horizon=1)\n        pr_t = (pr_t[0][0] + z[(i, 0)])\n        pr_target.append(pr_t)\n        ex_target.append(database_matrix[(((k + i) + tr_size), 0)])\n    pr_result = Error(expected=ex_target, predicted=pr_target)\n    return pr_result\n", "label": "Correct"}
{"function": "\n\ndef _ml_train_iterative(self, database_matrix, params=[], sliding_window=168, k=1):\n    '\\n            Training method used by Fred 09 paper.\\n        '\n    p = (database_matrix.shape[1] - 1)\n    number_iterations = ((((database_matrix.shape[0] + p) - k) - sliding_window) + 1)\n    print('Number of iterations: ', number_iterations)\n    tr_size = ((sliding_window - p) - 1)\n    z = (database_matrix[0:(- k), 1].reshape((- 1), 1) * np.ones((1, p)))\n    database_matrix[k:, 1:] = (database_matrix[k:, 1:] - z)\n    pr_target = []\n    ex_target = []\n    for i in range(number_iterations):\n        self._ml_train(database_matrix[(k + i):(((k + i) + tr_size) - 1), :], params)\n        pr_t = self._ml_predict(horizon=1)\n        pr_t = (pr_target[0][0] + z[(i, 0)])\n        pr_target.append(pr_t)\n        ex_target.append(database_matrix[(((k + i) + tr_size), 0)])\n    pr_result = Error(expected=ex_target, predicted=pr_target)\n    return pr_result\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    \" Add an issue to the test repository and save it's id.\"\n    super(IssueCommentAuthenticatedMethodsTest, self).setUp()\n    (success, result) = self.bb.issue.create(title='Test Issue Bitbucket API', content='Test Issue Bitbucket API', responsible=self.bb.username, status='new', kind='bug')\n    assert success\n    self.bb.issue.comment.issue_id = result['local_id']\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    \" Add an issue to the test repository and save it's id.\"\n    super(IssueCommentAuthenticatedMethodsTest, self).setUp()\n    (success, result) = self.bb.issue.create(title='Test Issue Bitbucket API', content='Test Issue Bitbucket API', responsible=self.bb.username, status='new', kind='bug')\n    assert result\n    self.bb.issue.comment.issue_id = result['local_id']\n", "label": "Variable misuse"}
{"function": "\n\ndef match(self, request=None):\n    '\\n            Match this item against request (uses GET vars)\\n\\n            @param request: the request object (defaults to current.request)\\n\\n            @return: the match level (integer):\\n                        0=no match\\n                        1=controller\\n                        2=controller+function\\n                        3=controller+function+args\\n                        4=controller+function+args+vars\\n\\n            @note: currently ignores numerical arguments in the request,\\n                   which is though subject to change (in order to support\\n                   numerical arguments in the item)\\n        '\n    level = 0\n    args = self.args\n    link_vars = self.vars\n    if ((self.application is not None) and (self.application != request.application)):\n        return 0\n    if (self.opts.selectable is False):\n        return 0\n    check = self.check_hook()\n    if check:\n        enabled = self.check_enabled()\n        if (not enabled):\n            check = False\n    if (not check):\n        return 0\n    if (request is None):\n        request = current.request\n    c = self.get('controller')\n    mc = self.get('match_controller')\n    if ((not c) and (self.parent is None)):\n        return 1\n    rvars = request.get_vars\n    controller = request.controller\n    function = request.function\n    if ('viewing' in rvars):\n        try:\n            (tn, record_id) = rvars['viewing'].split('.')\n            (controller, function) = tn.split('_', 1)\n        except:\n            pass\n    if ((controller == c) or (controller in mc)):\n        level = 1\n    if (level == 1):\n        f = self.get('function')\n        mf = self.get('match_function')\n        if ((function == f) or (function in mf)):\n            level = 2\n        elif (f == 'index'):\n            return 1\n        elif (f is not None):\n            return 0\n    if (level == 2):\n        extra = 1\n        for (k, v) in link_vars.iteritems():\n            if ((k not in rvars) or ((k in rvars) and (rvars[k] != s3_unicode(v)))):\n                extra = 0\n                break\n            else:\n                extra = 2\n        rargs = request.args\n        if rargs:\n            if args:\n                largs = [a for a in request.args if (not a.isdigit())]\n                if ((len(args) == len(largs)) and all([(args[i] == largs[i]) for i in xrange(len(args))])):\n                    level = 5\n                elif ((len(rargs) >= len(args) > 0) and rargs[(len(args) - 1)].isdigit() and (not str(args[(- 1)]).isdigit())):\n                    level = 1\n                else:\n                    return 0\n            else:\n                level = 3\n        elif args:\n            return 0\n        else:\n            level = 5\n        level += extra\n    return level\n", "label": "Correct"}
{"function": "\n\ndef match(self, request=None):\n    '\\n            Match this item against request (uses GET vars)\\n\\n            @param request: the request object (defaults to current.request)\\n\\n            @return: the match level (integer):\\n                        0=no match\\n                        1=controller\\n                        2=controller+function\\n                        3=controller+function+args\\n                        4=controller+function+args+vars\\n\\n            @note: currently ignores numerical arguments in the request,\\n                   which is though subject to change (in order to support\\n                   numerical arguments in the item)\\n        '\n    level = 0\n    args = self.args\n    link_vars = largs.vars\n    if ((self.application is not None) and (self.application != request.application)):\n        return 0\n    if (self.opts.selectable is False):\n        return 0\n    check = self.check_hook()\n    if check:\n        enabled = self.check_enabled()\n        if (not enabled):\n            check = False\n    if (not check):\n        return 0\n    if (request is None):\n        request = current.request\n    c = self.get('controller')\n    mc = self.get('match_controller')\n    if ((not c) and (self.parent is None)):\n        return 1\n    rvars = request.get_vars\n    controller = request.controller\n    function = request.function\n    if ('viewing' in rvars):\n        try:\n            (tn, record_id) = rvars['viewing'].split('.')\n            (controller, function) = tn.split('_', 1)\n        except:\n            pass\n    if ((controller == c) or (controller in mc)):\n        level = 1\n    if (level == 1):\n        f = self.get('function')\n        mf = self.get('match_function')\n        if ((function == f) or (function in mf)):\n            level = 2\n        elif (f == 'index'):\n            return 1\n        elif (f is not None):\n            return 0\n    if (level == 2):\n        extra = 1\n        for (k, v) in link_vars.iteritems():\n            if ((k not in rvars) or ((k in rvars) and (rvars[k] != s3_unicode(v)))):\n                extra = 0\n                break\n            else:\n                extra = 2\n        rargs = request.args\n        if rargs:\n            if args:\n                largs = [a for a in request.args if (not a.isdigit())]\n                if ((len(args) == len(largs)) and all([(args[i] == largs[i]) for i in xrange(len(args))])):\n                    level = 5\n                elif ((len(rargs) >= len(args) > 0) and rargs[(len(args) - 1)].isdigit() and (not str(args[(- 1)]).isdigit())):\n                    level = 1\n                else:\n                    return 0\n            else:\n                level = 3\n        elif args:\n            return 0\n        else:\n            level = 5\n        level += extra\n    return level\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_security_group_rule(self, context, rule_id):\n    self._delete_resource(context, 'security_group_rule', rule_id)\n", "label": "Correct"}
{"function": "\n\ndef delete_security_group_rule(self, context, rule_id):\n    self._delete_resource(context, 'security_group_rule', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, client_id, result_filename, *args, **kwargs):\n    super(RekallMock, self).__init__(*args, **kwargs)\n    self.result_filename = result_filename\n    self.client_id = client_id\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, client_id, result_filename, *args, **kwargs):\n    super(RekallMock, self).__init__(*args, **kwargs)\n    args.result_filename = result_filename\n    self.client_id = client_id\n", "label": "Variable misuse"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    assert (not cls._meta.has_auto_field), \"A model can't have more than one AutoField.\"\n    super(AutoField, self).contribute_to_class(cls, name)\n    cls._meta.has_auto_field = True\n    cls._meta.auto_field = self\n", "label": "Correct"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    assert (not name._meta.has_auto_field), \"A model can't have more than one AutoField.\"\n    super(AutoField, self).contribute_to_class(cls, name)\n    cls._meta.has_auto_field = True\n    cls._meta.auto_field = self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_server_tags_index(self):\n    uuid = self._put_server_tags()\n    response = self._do_get(('servers/%s/tags' % uuid))\n    subs = self._get_regexes()\n    subs['tag'] = '[0-9a-zA-Z]+'\n    self._verify_response('server-tags-index-resp', subs, response, 200)\n", "label": "Correct"}
{"function": "\n\ndef test_server_tags_index(self):\n    uuid = self._put_server_tags()\n    response = self._do_get(('servers/%s/tags' % uuid))\n    subs = self._get_regexes()\n    subs['tag'] = '[0-9a-zA-Z]+'\n    self._verify_response('server-tags-index-resp', subs, self, 200)\n", "label": "Variable misuse"}
{"function": "\n\ndef select_from(self, clause):\n    'return a new :class:`.Exists` construct, applying the given\\n        expression to the :meth:`.Select.select_from` method of the select\\n        statement contained.\\n\\n        '\n    e = self._clone()\n    e.element = self.element.select_from(clause).self_group()\n    return e\n", "label": "Correct"}
{"function": "\n\ndef select_from(self, clause):\n    'return a new :class:`.Exists` construct, applying the given\\n        expression to the :meth:`.Select.select_from` method of the select\\n        statement contained.\\n\\n        '\n    e = clause._clone()\n    e.element = self.element.select_from(clause).self_group()\n    return e\n", "label": "Variable misuse"}
{"function": "\n\ndef AddMailEntry(self, mail_message, mail_item_properties=None, mail_labels=None, identifier=None):\n    'Prepares a list of mail messages to import using ImportMultipleMails.\\n    \\n    Args:\\n      mail_message: An RFC822 format email message as a string.\\n      mail_item_properties: List of Gmail properties to apply to the\\n          message.\\n      mail_labels: List of Gmail labels to apply to the message.\\n      identifier: The optional file identifier string\\n    \\n    Returns:\\n      The number of email messages to be imported.\\n    '\n    mail_entry_properties = MailEntryProperties(mail_message=mail_message, mail_item_properties=mail_item_properties, mail_labels=mail_labels, identifier=identifier)\n    self.mail_entries.append(mail_entry_properties)\n    return len(self.mail_entries)\n", "label": "Correct"}
{"function": "\n\ndef AddMailEntry(self, mail_message, mail_item_properties=None, mail_labels=None, identifier=None):\n    'Prepares a list of mail messages to import using ImportMultipleMails.\\n    \\n    Args:\\n      mail_message: An RFC822 format email message as a string.\\n      mail_item_properties: List of Gmail properties to apply to the\\n          message.\\n      mail_labels: List of Gmail labels to apply to the message.\\n      identifier: The optional file identifier string\\n    \\n    Returns:\\n      The number of email messages to be imported.\\n    '\n    mail_entry_properties = MailEntryProperties(mail_message=mail_message, mail_item_properties=mail_labels, mail_labels=mail_labels, identifier=identifier)\n    self.mail_entries.append(mail_entry_properties)\n    return len(self.mail_entries)\n", "label": "Variable misuse"}
{"function": "\n\ndef _connect_echo_server(self):\n    self.server.upstream_host = '127.0.0.1'\n    self.server.upstream_port = 7599\n    stop_op = StopProxy(self.server, self.response_factory, self.key)\n    start_op = StartProxy(self.server, self.response_factory, self.key)\n    log.msg(((('Upstream host changed to echo server: ' + str(self.server.upstream_host)) + ':') + str(self.server.upstream_port)))\n    return self.addCallback(stop_op.stop).addCallback(start_op.start)\n", "label": "Correct"}
{"function": "\n\ndef _connect_echo_server(self):\n    stop_op.server.upstream_host = '127.0.0.1'\n    self.server.upstream_port = 7599\n    stop_op = StopProxy(self.server, self.response_factory, self.key)\n    start_op = StartProxy(self.server, self.response_factory, self.key)\n    log.msg(((('Upstream host changed to echo server: ' + str(self.server.upstream_host)) + ':') + str(self.server.upstream_port)))\n    return self.addCallback(stop_op.stop).addCallback(start_op.start)\n", "label": "Variable misuse"}
{"function": "\n\ndef convert_value(self, value, expression, connection, context):\n    return connection.ops.convert_extent3d(value, context.get('transformed_srid'))\n", "label": "Correct"}
{"function": "\n\ndef convert_value(self, value, expression, connection, context):\n    return self.ops.convert_extent3d(value, context.get('transformed_srid'))\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, filepath, version=None, mode='r'):\n    'Returns a bytestring with the file content, but no metadata.'\n    file_stream = self.open(filepath, version=version, mode=mode)\n    if (file_stream is None):\n        raise IOError(('File %s (version %s) not found.' % (filepath, (version if version else 'latest'))))\n    return file_stream.read()\n", "label": "Correct"}
{"function": "\n\ndef get(self, filepath, version=None, mode='r'):\n    'Returns a bytestring with the file content, but no metadata.'\n    file_stream = self.open(filepath, version=file_stream, mode=mode)\n    if (file_stream is None):\n        raise IOError(('File %s (version %s) not found.' % (filepath, (version if version else 'latest'))))\n    return file_stream.read()\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('nova.consoleauth.rpcapi.ConsoleAuthAPI.check_token')\ndef test_new_websocket_client_novnc_bad_origin_header(self, check_token):\n    check_token.return_value = {\n        'host': 'node1',\n        'port': '10000',\n        'console_type': 'novnc',\n    }\n    self.wh.path = 'http://127.0.0.1/'\n    self.wh.headers.getheader = self._fake_getheader_bad_origin\n    self.assertRaises(exception.ValidationError, self.wh.new_websocket_client)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('nova.consoleauth.rpcapi.ConsoleAuthAPI.check_token')\ndef test_new_websocket_client_novnc_bad_origin_header(self, check_token):\n    check_token.return_value = {\n        'host': 'node1',\n        'port': '10000',\n        'console_type': 'novnc',\n    }\n    self.wh.path = 'http://127.0.0.1/'\n    self.wh.headers.getheader = check_token._fake_getheader_bad_origin\n    self.assertRaises(exception.ValidationError, self.wh.new_websocket_client)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_api(self):\n    resp = requests.get(self.api_url, headers={\n        'X-Requested-With': 'XMLHttpRequest',\n    })\n    self.assertEqual(resp.status_code, 200)\n    self.assertEqual(resp.json()['res']['value'], 'python')\n", "label": "Correct"}
{"function": "\n\ndef test_get_api(self):\n    resp = requests.get(self.api_url, headers={\n        'X-Requested-With': 'XMLHttpRequest',\n    })\n    self.assertEqual(resp.status_code, 200)\n    resp.assertEqual(resp.json()['res']['value'], 'python')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, user, entity, org_claim_token):\n    super(ClaimOrgEmail, self).__init__(type=self.type, subject=('Become the administrator of %s on Jumo' % entity.get_name.title()), user=user, entity=entity, org_claim_token=org_claim_token)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, user, entity, org_claim_token):\n    super(ClaimOrgEmail, self).__init__(type=user.type, subject=('Become the administrator of %s on Jumo' % entity.get_name.title()), user=user, entity=entity, org_claim_token=org_claim_token)\n", "label": "Variable misuse"}
{"function": "\n\n@require_can_edit_fixtures\ndef download_item_lists(request, domain):\n    'Asynchronously serve excel download for edit_lookup_tables\\n    '\n    download = DownloadBase()\n    download.set_task(fixture_download_async.delay(prepare_fixture_download, table_ids=request.POST.getlist('table_ids[]', []), domain=domain, download_id=download.download_id))\n    return download.get_start_response()\n", "label": "Correct"}
{"function": "\n\n@require_can_edit_fixtures\ndef download_item_lists(request, domain):\n    'Asynchronously serve excel download for edit_lookup_tables\\n    '\n    download = DownloadBase()\n    download.set_task(fixture_download_async.delay(prepare_fixture_download, table_ids=request.POST.getlist('table_ids[]', []), domain=domain, download_id=request.download_id))\n    return download.get_start_response()\n", "label": "Variable misuse"}
{"function": "\n\ndef read_bytesmap(f):\n    numpairs = read_short(f)\n    bytesmap = {\n        \n    }\n    for _ in range(numpairs):\n        k = read_string(f)\n        bytesmap[k] = read_value(f)\n    return bytesmap\n", "label": "Correct"}
{"function": "\n\ndef read_bytesmap(f):\n    numpairs = read_short(f)\n    bytesmap = {\n        \n    }\n    for _ in range(numpairs):\n        k = read_string(f)\n        bytesmap[_] = read_value(f)\n    return bytesmap\n", "label": "Variable misuse"}
{"function": "\n\ndef list_association_sets(self, query_string=''):\n    'Lists all your association sets.\\n\\n        '\n    return self._list(self.association_set_url, query_string)\n", "label": "Correct"}
{"function": "\n\ndef list_association_sets(self, query_string=''):\n    'Lists all your association sets.\\n\\n        '\n    return query_string._list(self.association_set_url, query_string)\n", "label": "Variable misuse"}
{"function": "\n\ndef take_action(self, parsed_args):\n    service_client = self.app.client_manager.identity\n    service_client.federation.service_providers.delete(parsed_args.service_provider)\n", "label": "Correct"}
{"function": "\n\ndef take_action(self, parsed_args):\n    service_client = self.app.client_manager.identity\n    parsed_args.federation.service_providers.delete(parsed_args.service_provider)\n", "label": "Variable misuse"}
{"function": "\n\ndef clearAlert(self):\n    ' Clear the current alert level, if any.\\n\\n        '\n    if (self._alert_data is not None):\n        self._alert_data.timer.stop()\n        self._alert_data = None\n        app = QApplication.instance()\n        app.focusChanged.disconnect(self._onAppFocusChanged)\n        self.alerted.emit('')\n", "label": "Correct"}
{"function": "\n\ndef clearAlert(self):\n    ' Clear the current alert level, if any.\\n\\n        '\n    if (self._alert_data is not None):\n        self._alert_data.timer.stop()\n        app._alert_data = None\n        app = QApplication.instance()\n        app.focusChanged.disconnect(self._onAppFocusChanged)\n        self.alerted.emit('')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_evt_response_order(self):\n    expected_items = [('this', 'succeeded'), ('by', 'testing'), ('the', 'messages'), ('with', ['spam', 'egg'])]\n    expected = dict(expected_items)\n    result = sharknado.make_evt_response(expected['by'], expected['with'], expected['this'])\n    self.assertEqual(expected_items, list(iteritems(result)))\n", "label": "Correct"}
{"function": "\n\ndef test_evt_response_order(self):\n    expected_items = [('this', 'succeeded'), ('by', 'testing'), ('the', 'messages'), ('with', ['spam', 'egg'])]\n    expected = dict(expected_items)\n    result = sharknado.make_evt_response(expected['by'], expected['with'], expected['this'])\n    self.assertEqual(expected_items, list(iteritems(self)))\n", "label": "Variable misuse"}
{"function": "\n\ndef np_complex_cos_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(sig, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.ccosf',\n        types.complex128: 'numba.npymath.ccos',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, args, dispatch_table, 'cos')\n", "label": "Correct"}
{"function": "\n\ndef np_complex_cos_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(sig, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.ccosf',\n        types.complex128: 'numba.npymath.ccos',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, builder, dispatch_table, 'cos')\n", "label": "Variable misuse"}
{"function": "\n\ndef upload_form(self):\n    '\\n            Instantiate file upload form and return it.\\n\\n            Override to implement custom behavior.\\n        '\n    upload_form_class = self.get_upload_form()\n    if request.form:\n        formdata = request.form.copy()\n        formdata.update(request.files)\n        return upload_form_class(formdata, admin=self)\n    elif request.files:\n        return upload_form_class(request.files, admin=self)\n    else:\n        return upload_form_class(admin=self)\n", "label": "Correct"}
{"function": "\n\ndef upload_form(self):\n    '\\n            Instantiate file upload form and return it.\\n\\n            Override to implement custom behavior.\\n        '\n    upload_form_class = upload_form_class.get_upload_form()\n    if request.form:\n        formdata = request.form.copy()\n        formdata.update(request.files)\n        return upload_form_class(formdata, admin=self)\n    elif request.files:\n        return upload_form_class(request.files, admin=self)\n    else:\n        return upload_form_class(admin=self)\n", "label": "Variable misuse"}
{"function": "\n\ndef make_node(self, images):\n    '\\n        .. todo::\\n\\n            WRITEME\\n        '\n    images = as_cuda_ndarray_variable(images)\n    assert (images.ndim == 4)\n    channels_broadcastable = images.type.broadcastable[0]\n    batch_broadcastable = images.type.broadcastable[3]\n    rows_broadcastable = False\n    cols_broadcastable = False\n    targets_broadcastable = (channels_broadcastable, rows_broadcastable, cols_broadcastable, batch_broadcastable)\n    targets_type = CudaNdarrayType(broadcastable=targets_broadcastable)\n    targets = targets_type()\n    return Apply(self, [images], [targets])\n", "label": "Correct"}
{"function": "\n\ndef make_node(self, images):\n    '\\n        .. todo::\\n\\n            WRITEME\\n        '\n    images = as_cuda_ndarray_variable(rows_broadcastable)\n    assert (images.ndim == 4)\n    channels_broadcastable = images.type.broadcastable[0]\n    batch_broadcastable = images.type.broadcastable[3]\n    rows_broadcastable = False\n    cols_broadcastable = False\n    targets_broadcastable = (channels_broadcastable, rows_broadcastable, cols_broadcastable, batch_broadcastable)\n    targets_type = CudaNdarrayType(broadcastable=targets_broadcastable)\n    targets = targets_type()\n    return Apply(self, [images], [targets])\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_url(self, url):\n    if (self.access == 'public'):\n        url = url.replace('https://', 'http://')\n        req = urllib.request.Request(url)\n        try:\n            return urllib.request.urlopen(req).read()\n        except urllib.error.HTTPError:\n            raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n    else:\n        raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n", "label": "Correct"}
{"function": "\n\ndef _get_url(self, url):\n    if (self.access == 'public'):\n        url = req.replace('https://', 'http://')\n        req = urllib.request.Request(url)\n        try:\n            return urllib.request.urlopen(req).read()\n        except urllib.error.HTTPError:\n            raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n    else:\n        raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n", "label": "Variable misuse"}
{"function": "\n\ndef downcaseTokens(s, l, t):\n    'Helper parse action to convert tokens to lower case.'\n    return [tt.lower() for tt in map(_ustr, t)]\n", "label": "Correct"}
{"function": "\n\ndef downcaseTokens(s, l, t):\n    'Helper parse action to convert tokens to lower case.'\n    return [tt.lower() for tt in map(_ustr, l)]\n", "label": "Variable misuse"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20101102__ia__general__poweshiek__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20101102__ia__general__poweshiek__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    montezuma_abs_results = [r for r in results if ((r.jurisdiction == 'Montezuma') and (r.votes_type == 'absentee'))]\n    self.assertEqual(len(montezuma_abs_results), 34)\n    result = montezuma_abs_results[0]\n    self.assertEqual(result.office, 'United States Senator')\n    self.assertEqual(result.district, None)\n    self.assertEqual(result.full_name, 'Roxanne Conlin')\n    self.assertEqual(result.party, 'DEM')\n    self.assertEqual(result.write_in, None)\n    self.assertEqual(result.votes, 59)\n    result = montezuma_abs_results[(- 1)]\n    self.assertEqual(result.office, 'State Rep')\n    self.assertEqual(result.district, '75')\n    self.assertEqual(result.full_name, 'Write-In')\n    self.assertEqual(result.party, None)\n    self.assertEqual(result.write_in, 'Write-In')\n    self.assertEqual(result.votes, 0)\n", "label": "Correct"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20101102__ia__general__poweshiek__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20101102__ia__general__poweshiek__precinct.xls'\n    mapping = self._get_mapping(montezuma_abs_results)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    montezuma_abs_results = [r for r in results if ((r.jurisdiction == 'Montezuma') and (r.votes_type == 'absentee'))]\n    self.assertEqual(len(montezuma_abs_results), 34)\n    result = montezuma_abs_results[0]\n    self.assertEqual(result.office, 'United States Senator')\n    self.assertEqual(result.district, None)\n    self.assertEqual(result.full_name, 'Roxanne Conlin')\n    self.assertEqual(result.party, 'DEM')\n    self.assertEqual(result.write_in, None)\n    self.assertEqual(result.votes, 59)\n    result = montezuma_abs_results[(- 1)]\n    self.assertEqual(result.office, 'State Rep')\n    self.assertEqual(result.district, '75')\n    self.assertEqual(result.full_name, 'Write-In')\n    self.assertEqual(result.party, None)\n    self.assertEqual(result.write_in, 'Write-In')\n    self.assertEqual(result.votes, 0)\n", "label": "Variable misuse"}
{"function": "\n\n@cached_property\ndef deliveries(self):\n    ' Get delivery log from Redis'\n    key = make_key(event=self.object.event, owner_name=self.object.owner.username, identifier=self.object.identifier)\n    return redis.lrange(key, 0, 20)\n", "label": "Correct"}
{"function": "\n\n@cached_property\ndef deliveries(self):\n    ' Get delivery log from Redis'\n    key = make_key(event=self.object.event, owner_name=self.object.owner.username, identifier=key.object.identifier)\n    return redis.lrange(key, 0, 20)\n", "label": "Variable misuse"}
{"function": "\n\ndef _as_vector(self, keep_channels=False):\n    '\\n        The vectorized form of this image.\\n\\n        Parameters\\n        ----------\\n        keep_channels : `bool`, optional\\n\\n            ========== =============================\\n            Value      Return shape\\n            ========== =============================\\n            `False`    ``(n_channels * n_pixels,)``\\n            `True`     ``(n_channels, n_pixels)``\\n            ========== =============================\\n\\n        Returns\\n        -------\\n        vec : (See ``keep_channels`` above) `ndarray`\\n            Flattened representation of this image, containing all pixel\\n            and channel information.\\n        '\n    if keep_channels:\n        return self.pixels.reshape([self.n_channels, (- 1)])\n    else:\n        return self.pixels.ravel()\n", "label": "Correct"}
{"function": "\n\ndef _as_vector(self, keep_channels=False):\n    '\\n        The vectorized form of this image.\\n\\n        Parameters\\n        ----------\\n        keep_channels : `bool`, optional\\n\\n            ========== =============================\\n            Value      Return shape\\n            ========== =============================\\n            `False`    ``(n_channels * n_pixels,)``\\n            `True`     ``(n_channels, n_pixels)``\\n            ========== =============================\\n\\n        Returns\\n        -------\\n        vec : (See ``keep_channels`` above) `ndarray`\\n            Flattened representation of this image, containing all pixel\\n            and channel information.\\n        '\n    if keep_channels:\n        return keep_channels.pixels.reshape([self.n_channels, (- 1)])\n    else:\n        return self.pixels.ravel()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_classes(self, student):\n    res = super(Enrollment, self).__getitem__(student)\n    classes = res.cargo\n    return classes\n", "label": "Correct"}
{"function": "\n\ndef get_classes(self, student):\n    res = super(Enrollment, self).__getitem__(student)\n    classes = res.cargo\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(NoSuchIncludeFieldError, self).__init__(400, NoSuchIncludeFieldError.NO_SUCH_INCLUDE_FIELD_ERROR, *args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(NoSuchIncludeFieldError, kwargs).__init__(400, NoSuchIncludeFieldError.NO_SUCH_INCLUDE_FIELD_ERROR, *args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef show(mousetarget, **kwargs):\n    global mousecapturer\n    mc = getMouseCapturer(**kwargs)\n    mc.mousetarget = mousetarget\n    if isinstance(mousetarget, MouseHandler):\n        mc.mousehandler = True\n    mc.show()\n", "label": "Correct"}
{"function": "\n\ndef show(mousetarget, **kwargs):\n    global mousecapturer\n    mc = getMouseCapturer(**mousetarget)\n    mc.mousetarget = mousetarget\n    if isinstance(mousetarget, MouseHandler):\n        mc.mousehandler = True\n    mc.show()\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, bytes):\n    '\\n        Write C{bytes} to the underlying consumer unless\\n        C{_noMoreWritesExpected} has been called or there are/have been too\\n        many bytes.\\n        '\n    if (self._finished is None):\n        self._producer.stopProducing()\n        raise ExcessWrite()\n    if (len(bytes) <= self._length):\n        self._length -= len(bytes)\n        self._consumer.write(bytes)\n    else:\n        _callAppFunction(self._producer.stopProducing)\n        self._finished.errback(WrongBodyLength('too many bytes written'))\n        self._allowNoMoreWrites()\n", "label": "Correct"}
{"function": "\n\ndef write(self, bytes):\n    '\\n        Write C{bytes} to the underlying consumer unless\\n        C{_noMoreWritesExpected} has been called or there are/have been too\\n        many bytes.\\n        '\n    if (self._finished is None):\n        self._producer.stopProducing()\n        raise ExcessWrite()\n    if (len(bytes) <= self._length):\n        self._length -= len(bytes)\n        self._consumer.write(bytes)\n    else:\n        _callAppFunction(bytes._producer.stopProducing)\n        self._finished.errback(WrongBodyLength('too many bytes written'))\n        self._allowNoMoreWrites()\n", "label": "Variable misuse"}
{"function": "\n\ndef LVMPathSpecGetVolumeIndex(path_spec):\n    'Retrieves the volume index from the path specification.\\n\\n  Args:\\n    path_spec: the path specification (instance of PathSpec).\\n  '\n    volume_index = getattr(path_spec, 'volume_index', None)\n    if (volume_index is None):\n        location = getattr(path_spec, 'location', None)\n        if ((location is None) or (not location.startswith('/lvm'))):\n            return\n        volume_index = None\n        try:\n            volume_index = (int(location[4:], 10) - 1)\n        except ValueError:\n            pass\n        if ((volume_index is None) or (volume_index < 0)):\n            return\n    return volume_index\n", "label": "Correct"}
{"function": "\n\ndef LVMPathSpecGetVolumeIndex(path_spec):\n    'Retrieves the volume index from the path specification.\\n\\n  Args:\\n    path_spec: the path specification (instance of PathSpec).\\n  '\n    volume_index = getattr(path_spec, 'volume_index', None)\n    if (volume_index is None):\n        location = getattr(path_spec, 'location', None)\n        if ((location is None) or (not path_spec.startswith('/lvm'))):\n            return\n        volume_index = None\n        try:\n            volume_index = (int(location[4:], 10) - 1)\n        except ValueError:\n            pass\n        if ((volume_index is None) or (volume_index < 0)):\n            return\n    return volume_index\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_invalid(self):\n    request = self.request_factory.post('/', {\n        \n    })\n    answer = Answer(user=self.create_user(), question=self.question)\n    form = AnswerForm(request.POST, instance=answer)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.errors['answer'], ['This field is required.'])\n    self.assertEqual(Action.objects.count(), 0, 'Invalid form submission should not result in an action')\n", "label": "Correct"}
{"function": "\n\ndef test_create_invalid(self):\n    request = self.request_factory.post('/', {\n        \n    })\n    answer = Answer(user=self.create_user(), question=self.question)\n    form = AnswerForm(request.POST, instance=answer)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(request.errors['answer'], ['This field is required.'])\n    self.assertEqual(Action.objects.count(), 0, 'Invalid form submission should not result in an action')\n", "label": "Variable misuse"}
{"function": "\n\ndef _log(self, buf):\n    LOG.debug(buf)\n", "label": "Correct"}
{"function": "\n\ndef _log(self, buf):\n    LOG.debug(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, level, created, message, source_location):\n    self.level = level\n    self.created = created\n    self.source_location = source_location\n    self.message = message\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, level, created, message, source_location):\n    self.level = level\n    self.created = created\n    level.source_location = source_location\n    self.message = message\n", "label": "Variable misuse"}
{"function": "\n\ndef supports(self, mode):\n    return (mode in self.modes)\n", "label": "Correct"}
{"function": "\n\ndef supports(self, mode):\n    return (self in self.modes)\n", "label": "Variable misuse"}
{"function": "\n\ndef testRobust(self):\n    'Test the sendRobust function'\n\n    def fails(val, **kwargs):\n        raise ValueError('this')\n    a_signal.connect(fails)\n    result = a_signal.send_robust(sender=self, val='test')\n    err = result[0][1]\n    self.assertIsInstance(err, ValueError)\n    self.assertEqual(err.args, ('this',))\n    a_signal.disconnect(fails)\n    self._testIsClean(a_signal)\n", "label": "Correct"}
{"function": "\n\ndef testRobust(self):\n    'Test the sendRobust function'\n\n    def fails(val, **kwargs):\n        raise ValueError('this')\n    a_signal.connect(fails)\n    result = a_signal.send_robust(sender=err, val='test')\n    err = result[0][1]\n    self.assertIsInstance(err, ValueError)\n    self.assertEqual(err.args, ('this',))\n    a_signal.disconnect(fails)\n    self._testIsClean(a_signal)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_contact_get(self):\n    self.response.json.return_value = responses['contact']['get']\n    contact = self.redmine.contact.get(1)\n    self.assertEqual(contact.id, 1)\n    self.assertEqual(contact.first_name, 'Foo')\n", "label": "Correct"}
{"function": "\n\ndef test_contact_get(self):\n    contact.response.json.return_value = responses['contact']['get']\n    contact = self.redmine.contact.get(1)\n    self.assertEqual(contact.id, 1)\n    self.assertEqual(contact.first_name, 'Foo')\n", "label": "Variable misuse"}
{"function": "\n\ndef handle_socket_write(self):\n    'Write to socket'\n    try:\n        count = self.socket.send(bytes(self.buffer_ser2net))\n        self.buffer_ser2net = self.buffer_ser2net[count:]\n    except socket.error:\n        self.handle_socket_error()\n", "label": "Correct"}
{"function": "\n\ndef handle_socket_write(self):\n    'Write to socket'\n    try:\n        count = self.socket.send(bytes(self.buffer_ser2net))\n        self.buffer_ser2net = self.buffer_ser2net[self:]\n    except socket.error:\n        self.handle_socket_error()\n", "label": "Variable misuse"}
{"function": "\n\ndef update_fpointer(self, nid, mode=ADD):\n    'set _fpointer recursively'\n    if (nid is None):\n        return\n    if (mode is self.ADD):\n        self._fpointer.append(nid)\n    elif (mode is self.DELETE):\n        if (nid in self._fpointer):\n            self._fpointer.remove(nid)\n    elif (mode is self.INSERT):\n        print('WARNNING: INSERT is deprecated to ADD mode')\n        self.update_fpointer(nid)\n", "label": "Correct"}
{"function": "\n\ndef update_fpointer(self, nid, mode=ADD):\n    'set _fpointer recursively'\n    if (nid is None):\n        return\n    if (mode is self.ADD):\n        self._fpointer.append(self)\n    elif (mode is self.DELETE):\n        if (nid in self._fpointer):\n            self._fpointer.remove(nid)\n    elif (mode is self.INSERT):\n        print('WARNNING: INSERT is deprecated to ADD mode')\n        self.update_fpointer(nid)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_rule(self, rule, is_separator, parent, level, begin):\n    regions = []\n    if ((self.printer is not None) and (not is_separator)):\n        if ('name' in rule):\n            self.printer(level, (((('== Rule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n        else:\n            self.printer(level, (('== Rule [' + str(begin)) + '] =='))\n    rule_output = {\n        'successive_match': False,\n        'match': False,\n        'begin': begin,\n        'new_begin': begin,\n        'end': begin,\n        'regions': [],\n    }\n    if ('name' in rule):\n        if (parent != ''):\n            parent += '>'\n        parent += rule['name']\n    good = True\n    if ('exclude' in rule):\n        exclude_output = self.parse_rule(rule['exclude'], is_separator, parent, (level + 1), begin)\n        if exclude_output['successive_match']:\n            good = False\n    if good:\n        if ('match' in rule):\n            if (rule['match'] in self.re_cache):\n                re_pattern = self.re_cache[rule['match']]\n            else:\n                re_pattern = re.compile(rule['match'])\n            if ((not is_separator) and ('separator' in self.grammar) and (('before_separator' not in rule) or rule['before_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator Before: ' + str(begin)))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match before sep')\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ((('> Matching at [' + str(begin)) + ']: ') + rule['match']))\n            matches = re_pattern.search(self.data[begin:len(self.data)])\n            if ((matches is not None) and (matches.start() == 0)):\n                rule_output['successive_match'] = True\n                rule_output['match'] = True\n                rule_output['begin'] = begin\n                rule_output['end'] = (begin + matches.end())\n                rule_output['new_begin'] = rule_output['end']\n                begin = rule_output['end']\n                if ('name' in rule):\n                    regions.append({\n                        'begin': rule_output['begin'],\n                        'end': rule_output['end'],\n                        'value': self.data[rule_output['begin']:rule_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, ((('> Adding ' + str(rule_output['begin'])) + ':') + str(rule_output['end'])))\n                elif ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Skip: ' + str(rule_output['end'])))\n            if ((not is_separator) and rule_output['successive_match'] and ('separator' in self.grammar) and (('after_separator' not in rule) or rule['after_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator After: ' + str(rule_output['end'])))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match after sep')\n        elif ('parse' in rule):\n            parse_output = self.parse_rule_list(rule['parse'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('parse_any' in rule):\n            parse_output = self.parse_rule_list_any(rule['parse_any'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('include' in rule):\n            if (('repository' in self.grammar) and (rule['include'] in self.grammar['repository'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Include ' + rule['include']))\n                parse_output = self.parse_rule(self.grammar['repository'][rule['include']], is_separator, parent, (level + 1), begin)\n                if parse_output['successive_match']:\n                    if ('name' in rule):\n                        regions.append({\n                            'begin': parse_output['begin'],\n                            'end': parse_output['end'],\n                            'value': self.data[parse_output['begin']:parse_output['end']],\n                            'parent': parent,\n                            'name': rule['name'],\n                        })\n                    if parse_output['match']:\n                        rule_output['match'] = parse_output['match']\n                    begin = parse_output['new_begin']\n                    rule_output['new_begin'] = parse_output['new_begin']\n                    rule_output['begin'] = parse_output['begin']\n                    rule_output['end'] = parse_output['end']\n                    rule_output['successive_match'] = parse_output['successive_match']\n                    regions += parse_output['regions']\n            else:\n                rule_output['successive_match'] = False\n        if (('multiple' in rule) and rule['multiple'] and rule_output['successive_match']):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ('Multiple: ' + str(begin)))\n            parse_output = self.parse_rule(rule, is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['new_begin'] = parse_output['new_begin']\n                regions += parse_output['regions']\n    if rule_output['successive_match']:\n        if ('name' in rule):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, '> Matched')\n    elif ((('optional' in rule) and rule['optional']) or (('multiple' in rule) and rule['multiple'])):\n        rule_output['successive_match'] = True\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, '> Optional')\n    if ('name' in rule):\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, (((('== EndRule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n    elif ((self.printer is not None) and (not is_separator)):\n        self.printer(level, (('== EndRule [' + str(begin)) + '] =='))\n    rule_output['regions'] = regions\n    return rule_output\n", "label": "Correct"}
{"function": "\n\ndef parse_rule(self, rule, is_separator, parent, level, begin):\n    regions = []\n    if ((self.printer is not None) and (not is_separator)):\n        if ('name' in rule):\n            self.printer(level, (((('== Rule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n        else:\n            self.printer(level, (('== Rule [' + str(begin)) + '] =='))\n    rule_output = {\n        'successive_match': False,\n        'match': False,\n        'begin': begin,\n        'new_begin': begin,\n        'end': begin,\n        'regions': [],\n    }\n    if ('name' in rule):\n        if (parent != ''):\n            parent += '>'\n        parent += rule['name']\n    good = True\n    if ('exclude' in rule):\n        exclude_output = self.parse_rule(rule['exclude'], is_separator, parent, (level + 1), begin)\n        if exclude_output['successive_match']:\n            good = False\n    if good:\n        if ('match' in rule):\n            if (rule['match'] in self.re_cache):\n                re_pattern = self.re_cache[rule['match']]\n            else:\n                re_pattern = re.compile(rule['match'])\n            if ((not is_separator) and ('separator' in self.grammar) and (('before_separator' not in rule) or rule['before_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator Before: ' + str(begin)))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match before sep')\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ((('> Matching at [' + str(begin)) + ']: ') + rule['match']))\n            matches = re_pattern.search(self.data[begin:len(self.data)])\n            if ((matches is not None) and (matches.start() == 0)):\n                rule_output['successive_match'] = True\n                rule_output['match'] = True\n                rule_output['begin'] = begin\n                rule_output['end'] = (begin + matches.end())\n                rule_output['new_begin'] = rule_output['end']\n                begin = rule_output['end']\n                if ('name' in rule):\n                    regions.append({\n                        'begin': rule_output['begin'],\n                        'end': rule_output['end'],\n                        'value': self.data[rule_output['begin']:rule_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, ((('> Adding ' + str(rule_output['begin'])) + ':') + str(rule_output['end'])))\n                elif ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Skip: ' + str(rule_output['end'])))\n            if ((not is_separator) and rule_output['successive_match'] and ('separator' in self.grammar) and (('after_separator' not in rule) or rule['after_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator After: ' + str(rule_output['end'])))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match after sep')\n        elif ('parse' in rule):\n            parse_output = self.parse_rule_list(rule['parse'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('parse_any' in rule):\n            parse_output = self.parse_rule_list_any(rule['parse_any'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('include' in rule):\n            if (('repository' in self.grammar) and (rule['include'] in self.grammar['repository'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Include ' + rule['include']))\n                parse_output = self.parse_rule(self.grammar['repository'][rule['include']], is_separator, parent, (level + 1), begin)\n                if parse_output['successive_match']:\n                    if ('name' in rule):\n                        regions.append({\n                            'begin': parse_output['begin'],\n                            'end': parse_output['end'],\n                            'value': self.data[parse_output['begin']:parse_output['end']],\n                            'parent': parent,\n                            'name': rule['name'],\n                        })\n                    if parse_output['match']:\n                        rule_output['match'] = parse_output['match']\n                    begin = parse_output['new_begin']\n                    rule_output['new_begin'] = parse_output['new_begin']\n                    rule_output['begin'] = parse_output['begin']\n                    rule_output['end'] = parse_output['end']\n                    rule_output['successive_match'] = parse_output['successive_match']\n                    regions += parse_output['regions']\n            else:\n                rule_output['successive_match'] = False\n        if (('multiple' in rule) and rule['multiple'] and rule_output['successive_match']):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ('Multiple: ' + str(begin)))\n            parse_output = self.parse_rule(rule, is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['new_begin'] = parse_output['new_begin']\n                regions += parse_output['regions']\n    if rule_output['successive_match']:\n        if ('name' in rule):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, '> Matched')\n    elif ((('optional' in rule) and rule['optional']) or (('multiple' in rule) and rule['multiple'])):\n        rule_output['successive_match'] = True\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, '> Optional')\n    if ('name' in rule):\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, (((('== EndRule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n    elif ((self.printer is not None) and (not is_separator)):\n        self.printer(level, (('== EndRule [' + str(begin)) + '] =='))\n    rule_output['regions'] = regions\n    return level\n", "label": "Variable misuse"}
{"function": "\n\ndef test_grid_search_allows_nans():\n    X = np.arange(20, dtype=np.float64).reshape(5, (- 1))\n    X[2, :] = np.nan\n    y = [0, 0, 1, 1, 1]\n    p = Pipeline([('imputer', Imputer(strategy='mean', missing_values='NaN')), ('classifier', MockClassifier())])\n    GridSearchCV(p, {\n        'classifier__foo_param': [1, 2, 3],\n    }, cv=2).fit(X, y)\n", "label": "Correct"}
{"function": "\n\ndef test_grid_search_allows_nans():\n    X = np.arange(20, dtype=np.float64).reshape(5, (- 1))\n    X[2, :] = np.nan\n    y = [0, 0, 1, 1, 1]\n    p = Pipeline([('imputer', Imputer(strategy='mean', missing_values='NaN')), ('classifier', MockClassifier())])\n    GridSearchCV(y, {\n        'classifier__foo_param': [1, 2, 3],\n    }, cv=2).fit(X, y)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self):\n    super().__init__()\n    db_host = os.environ.get('MONGO_HOST')\n    db_host = (db_host if db_host else 'localhost')\n    db_port = int(os.environ.get('MONGO_PORT'))\n    db_port = (db_port if db_port else 27017)\n    db_name = os.environ.get('MONGO_DB')\n    db_name = (db_name if db_name else 'default')\n    db_bucket = os.environ.get('MONGO_BUCKET')\n    db_bucket = (db_bucket if db_bucket else 'rxnorm')\n    import pymongo\n    conn = pymongo.MongoClient(host=db_host, port=db_port)\n    db = conn[db_name]\n    db_user = os.environ.get('MONGO_USER')\n    db_pass = os.environ.get('MONGO_PASS')\n    if (db_user and db_pass):\n        db.authenticate(db_user, db_pass)\n    self.mng = db[db_bucket]\n    self.mng.ensure_index('ndc')\n    self.mng.ensure_index('label', text=pymongo.TEXT)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self):\n    super().__init__()\n    db_host = os.environ.get('MONGO_HOST')\n    db_host = (db_host if db_host else 'localhost')\n    db_port = int(os.environ.get('MONGO_PORT'))\n    db_port = (db_port if db_port else 27017)\n    db_name = os.environ.get('MONGO_DB')\n    db_name = (db_name if db_port else 'default')\n    db_bucket = os.environ.get('MONGO_BUCKET')\n    db_bucket = (db_bucket if db_bucket else 'rxnorm')\n    import pymongo\n    conn = pymongo.MongoClient(host=db_host, port=db_port)\n    db = conn[db_name]\n    db_user = os.environ.get('MONGO_USER')\n    db_pass = os.environ.get('MONGO_PASS')\n    if (db_user and db_pass):\n        db.authenticate(db_user, db_pass)\n    self.mng = db[db_bucket]\n    self.mng.ensure_index('ndc')\n    self.mng.ensure_index('label', text=pymongo.TEXT)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_loginverify_page(self):\n    self.set_get({\n        'continue': 'http%3A//192.168.33.168%3A8080/_ah/login%3Fcontinue%3Dhttp%3A//192.168.33.168%3A8080/',\n    })\n    LoginVerify(self.request, self.response).get()\n    html = self.response.out.getvalue()\n    self.assertTrue(re.search('<!-- FILE:templates/layouts/main.html -->', html))\n    self.assertTrue(re.search('<!-- FILE:templates/users/confirm.html -->', html))\n    self.assertTrue(re.search('http://192.168.33.168:8080/', html))\n", "label": "Correct"}
{"function": "\n\ndef test_loginverify_page(self):\n    self.set_get({\n        'continue': 'http%3A//192.168.33.168%3A8080/_ah/login%3Fcontinue%3Dhttp%3A//192.168.33.168%3A8080/',\n    })\n    LoginVerify(self.request, self.response).get()\n    html = self.response.out.getvalue()\n    self.assertTrue(re.search('<!-- FILE:templates/layouts/main.html -->', html))\n    html.assertTrue(re.search('<!-- FILE:templates/users/confirm.html -->', html))\n    self.assertTrue(re.search('http://192.168.33.168:8080/', html))\n", "label": "Variable misuse"}
{"function": "\n\n@responses.activate\ndef test_bitly_total_clicks_bad_response():\n    body = '20'\n    params = urlencode(dict(link=shorten, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/link/clicks', params)\n    responses.add(responses.GET, url, body=body, status=400, match_querystring=True)\n    body = shorten\n    params = urlencode(dict(uri=expanded, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/shorten', params)\n    responses.add(responses.GET, url, body=body, match_querystring=True)\n    s.short(expanded)\n    assert (s.total_clicks() == 0)\n    assert (s.total_clicks(shorten) == 0)\n", "label": "Correct"}
{"function": "\n\n@responses.activate\ndef test_bitly_total_clicks_bad_response():\n    body = '20'\n    params = urlencode(dict(link=shorten, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/link/clicks', params)\n    responses.add(responses.GET, url, body=url, status=400, match_querystring=True)\n    body = shorten\n    params = urlencode(dict(uri=expanded, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/shorten', params)\n    responses.add(responses.GET, url, body=body, match_querystring=True)\n    s.short(expanded)\n    assert (s.total_clicks() == 0)\n    assert (s.total_clicks(shorten) == 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/food/crafted/shared_dessert_sweesonberry_rolls.iff'\n    result.attribute_template_id = 5\n    result.stfName('food_name', 'sweesonberry_rolls')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/food/crafted/shared_dessert_sweesonberry_rolls.iff'\n    result.attribute_template_id = 5\n    kernel.stfName('food_name', 'sweesonberry_rolls')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.yield_fixture(scope='module')\ndef testclient(request, app):\n    '\\n    creates a Flask-testclient instance for bepasty\\n    '\n    (db_file, app.config['DATABASE']) = mkstemp()\n    app.config['DEFAULT_PERMISSIONS'] = ''\n    app.config['SECRET_KEY'] = str(random())\n    app.config['PERMISSIONS'] = {\n        'l': 'list',\n        'c': 'create',\n        'r': 'read',\n        'd': 'delete',\n        'a': 'admin',\n    }\n    (yield app.test_client())\n    close(db_file)\n", "label": "Correct"}
{"function": "\n\n@pytest.yield_fixture(scope='module')\ndef testclient(request, app):\n    '\\n    creates a Flask-testclient instance for bepasty\\n    '\n    (db_file, app.config['DATABASE']) = mkstemp()\n    app.config['DEFAULT_PERMISSIONS'] = ''\n    app.config['SECRET_KEY'] = str(random())\n    app.config['PERMISSIONS'] = {\n        'l': 'list',\n        'c': 'create',\n        'r': 'read',\n        'd': 'delete',\n        'a': 'admin',\n    }\n    (yield db_file.test_client())\n    close(db_file)\n", "label": "Variable misuse"}
{"function": "\n\ndef run_command(cmd, stdin=''):\n    return make_call('run_command', cmd)\n", "label": "Correct"}
{"function": "\n\ndef run_command(cmd, stdin=''):\n    return make_call('run_command', stdin)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_RosdepDatabase():\n    from rosdep2.model import RosdepDatabase\n    db = RosdepDatabase()\n    assert (not db.is_loaded('foo'))\n    data = {\n        'a': 1,\n    }\n    db.set_view_data('foo', data, [], 'origin1')\n    assert db.is_loaded('foo')\n    entry = db.get_view_data('foo')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin1')\n    assert (entry.view_dependencies == [])\n    data['a'] = 2\n    assert (entry.rosdep_data != data)\n    data = {\n        'b': 2,\n    }\n    db.set_view_data('bar', data, ['foo'], 'origin2')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin2')\n    assert (entry.view_dependencies == ['foo'])\n    data = {\n        'b': 3,\n    }\n    assert db.is_loaded('bar')\n    db.set_view_data('bar', data, ['baz', 'blah'], 'origin3')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin3')\n    assert (set(entry.view_dependencies) == set(['baz', 'blah']))\n", "label": "Correct"}
{"function": "\n\ndef test_RosdepDatabase():\n    from rosdep2.model import RosdepDatabase\n    db = RosdepDatabase()\n    assert (not db.is_loaded('foo'))\n    data = {\n        'a': 1,\n    }\n    db.set_view_data('foo', data, [], 'origin1')\n    assert db.is_loaded('foo')\n    entry = db.get_view_data('foo')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin1')\n    assert (entry.view_dependencies == [])\n    data['a'] = 2\n    assert (entry.rosdep_data != data)\n    data = {\n        'b': 2,\n    }\n    db.set_view_data('bar', data, ['foo'], 'origin2')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin2')\n    assert (entry.view_dependencies == ['foo'])\n    data = {\n        'b': 3,\n    }\n    assert db.is_loaded('bar')\n    db.set_view_data('bar', data, ['baz', 'blah'], 'origin3')\n    assert db.is_loaded('bar')\n    entry = entry.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin3')\n    assert (set(entry.view_dependencies) == set(['baz', 'blah']))\n", "label": "Variable misuse"}
{"function": "\n\ndef interpret(marker, environment=None, override=None):\n    return compile(marker)()\n", "label": "Correct"}
{"function": "\n\ndef interpret(marker, environment=None, override=None):\n    return compile(environment)()\n", "label": "Variable misuse"}
{"function": "\n\ndef prune_overridden(ansi_string):\n    'Remove color codes that are rendered ineffective by subsequent codes in one escape sequence then sort codes.\\n\\n    :param str ansi_string: Incoming ansi_string with ANSI color codes.\\n\\n    :return: Color string with pruned color sequences.\\n    :rtype: str\\n    '\n    multi_seqs = set((p for p in RE_ANSI.findall(ansi_string) if (';' in p[1])))\n    for (escape, codes) in multi_seqs:\n        r_codes = list(reversed(codes.split(';')))\n        try:\n            r_codes = r_codes[:(r_codes.index('0') + 1)]\n        except ValueError:\n            pass\n        for group in CODE_GROUPS:\n            for pos in reversed([i for (i, n) in enumerate(r_codes) if (n in group)][1:]):\n                r_codes.pop(pos)\n        reduced_codes = ';'.join(sorted(r_codes, key=int))\n        if (codes != reduced_codes):\n            ansi_string = ansi_string.replace(escape, (('\\x1b[' + reduced_codes) + 'm'))\n    return ansi_string\n", "label": "Correct"}
{"function": "\n\ndef prune_overridden(ansi_string):\n    'Remove color codes that are rendered ineffective by subsequent codes in one escape sequence then sort codes.\\n\\n    :param str ansi_string: Incoming ansi_string with ANSI color codes.\\n\\n    :return: Color string with pruned color sequences.\\n    :rtype: str\\n    '\n    multi_seqs = set((p for p in RE_ANSI.findall(ansi_string) if (';' in codes[1])))\n    for (escape, codes) in multi_seqs:\n        r_codes = list(reversed(codes.split(';')))\n        try:\n            r_codes = r_codes[:(r_codes.index('0') + 1)]\n        except ValueError:\n            pass\n        for group in CODE_GROUPS:\n            for pos in reversed([i for (i, n) in enumerate(r_codes) if (n in group)][1:]):\n                r_codes.pop(pos)\n        reduced_codes = ';'.join(sorted(r_codes, key=int))\n        if (codes != reduced_codes):\n            ansi_string = ansi_string.replace(escape, (('\\x1b[' + reduced_codes) + 'm'))\n    return ansi_string\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dehydrate(self):\n    note = Note()\n    bundle_1 = Bundle(obj=note)\n    field_1 = ToManyField(SubjectResource, 'subjects')\n    field_1.instance_name = 'm2m'\n    with self.assertRaises(ApiFieldError):\n        field_1.dehydrate(bundle_1)\n    field_2 = ToManyField(SubjectResource, 'subjects', null=True)\n    field_2.instance_name = 'm2m'\n    self.assertEqual(field_2.dehydrate(bundle_1), [])\n    field_3 = ToManyField(SubjectResource, 'subjects')\n    field_3.instance_name = 'm2m'\n    bundle_3 = Bundle(obj=self.note_1)\n    self.assertEqual(field_3.dehydrate(bundle_3), ['/api/v1/subjects/1/', '/api/v1/subjects/2/'])\n    field_4 = ToManyField(SubjectResource, 'subjects', full=True)\n    field_4.instance_name = 'm2m'\n    request = MockRequest()\n    request.path = ('/api/v1/subjects/%(pk)s/' % {\n        'pk': self.note_1.pk,\n    })\n    bundle_4 = Bundle(obj=self.note_1, request=request)\n    subject_bundle_list = field_4.dehydrate(bundle_4)\n    self.assertEqual(len(subject_bundle_list), 2)\n    self.assertEqual(isinstance(subject_bundle_list[0], Bundle), True)\n    self.assertEqual(subject_bundle_list[0].data['name'], 'News')\n    self.assertEqual(subject_bundle_list[0].data['url'], '/news/')\n    self.assertEqual(subject_bundle_list[0].obj.name, 'News')\n    self.assertEqual(subject_bundle_list[0].obj.url, '/news/')\n    self.assertEqual(isinstance(subject_bundle_list[1], Bundle), True)\n    self.assertEqual(subject_bundle_list[1].data['name'], 'Photos')\n    self.assertEqual(subject_bundle_list[1].data['url'], '/photos/')\n    self.assertEqual(subject_bundle_list[1].obj.name, 'Photos')\n    self.assertEqual(subject_bundle_list[1].obj.url, '/photos/')\n    field_5 = ToManyField(SubjectResource, 'subjects')\n    field_5.instance_name = 'm2m'\n    bundle_5 = Bundle(obj=self.note_2)\n    self.assertEqual(field_5.dehydrate(bundle_5), ['/api/v1/subjects/1/', '/api/v1/subjects/3/'])\n    field_6 = ToManyField(SubjectResource, 'subjects')\n    field_6.instance_name = 'm2m'\n    bundle_6 = Bundle(obj=self.note_3)\n    self.assertEqual(field_6.dehydrate(bundle_6), [])\n    field_7 = ToManyField(SubjectResource, None)\n    field_7.instance_name = 'm2m'\n    bundle_7 = Bundle(obj=self.note_3)\n    with self.assertRaises(ApiFieldError):\n        field_7.dehydrate(bundle_7)\n", "label": "Correct"}
{"function": "\n\ndef test_dehydrate(self):\n    note = Note()\n    bundle_1 = Bundle(obj=note)\n    field_1 = ToManyField(SubjectResource, 'subjects')\n    field_1.instance_name = 'm2m'\n    with self.assertRaises(ApiFieldError):\n        field_1.dehydrate(bundle_1)\n    field_2 = ToManyField(SubjectResource, 'subjects', null=True)\n    field_2.instance_name = 'm2m'\n    self.assertEqual(field_2.dehydrate(bundle_1), [])\n    field_3 = ToManyField(SubjectResource, 'subjects')\n    field_3.instance_name = 'm2m'\n    bundle_3 = Bundle(obj=self.note_1)\n    self.assertEqual(field_3.dehydrate(bundle_3), ['/api/v1/subjects/1/', '/api/v1/subjects/2/'])\n    field_4 = ToManyField(SubjectResource, 'subjects', full=True)\n    field_4.instance_name = 'm2m'\n    request = MockRequest()\n    request.path = ('/api/v1/subjects/%(pk)s/' % {\n        'pk': self.note_1.pk,\n    })\n    bundle_4 = Bundle(obj=self.note_1, request=request)\n    subject_bundle_list = field_4.dehydrate(bundle_6)\n    self.assertEqual(len(subject_bundle_list), 2)\n    self.assertEqual(isinstance(subject_bundle_list[0], Bundle), True)\n    self.assertEqual(subject_bundle_list[0].data['name'], 'News')\n    self.assertEqual(subject_bundle_list[0].data['url'], '/news/')\n    self.assertEqual(subject_bundle_list[0].obj.name, 'News')\n    self.assertEqual(subject_bundle_list[0].obj.url, '/news/')\n    self.assertEqual(isinstance(subject_bundle_list[1], Bundle), True)\n    self.assertEqual(subject_bundle_list[1].data['name'], 'Photos')\n    self.assertEqual(subject_bundle_list[1].data['url'], '/photos/')\n    self.assertEqual(subject_bundle_list[1].obj.name, 'Photos')\n    self.assertEqual(subject_bundle_list[1].obj.url, '/photos/')\n    field_5 = ToManyField(SubjectResource, 'subjects')\n    field_5.instance_name = 'm2m'\n    bundle_5 = Bundle(obj=self.note_2)\n    self.assertEqual(field_5.dehydrate(bundle_5), ['/api/v1/subjects/1/', '/api/v1/subjects/3/'])\n    field_6 = ToManyField(SubjectResource, 'subjects')\n    field_6.instance_name = 'm2m'\n    bundle_6 = Bundle(obj=self.note_3)\n    self.assertEqual(field_6.dehydrate(bundle_6), [])\n    field_7 = ToManyField(SubjectResource, None)\n    field_7.instance_name = 'm2m'\n    bundle_7 = Bundle(obj=self.note_3)\n    with self.assertRaises(ApiFieldError):\n        field_7.dehydrate(bundle_7)\n", "label": "Variable misuse"}
{"function": "\n\ndef testCloneModifyPush(self):\n    new_repo = LocalRepository(utils.get_temporary_location())\n    new_repo.clone(self.repo)\n    prev_branch = self.repo.getCurrentBranch()\n    self.repo.checkout(self.repo.createBranch('temp'))\n    self.assertReposEqual(self.repo, new_repo)\n    utils.commit_change(new_repo)\n    new_repo.push()\n    self.repo.checkout(prev_branch)\n    self.assertReposEqual(self.repo, new_repo)\n    utils.delete_repository(new_repo)\n", "label": "Correct"}
{"function": "\n\ndef testCloneModifyPush(self):\n    new_repo = LocalRepository(utils.get_temporary_location())\n    prev_branch.clone(self.repo)\n    prev_branch = self.repo.getCurrentBranch()\n    self.repo.checkout(self.repo.createBranch('temp'))\n    self.assertReposEqual(self.repo, new_repo)\n    utils.commit_change(new_repo)\n    new_repo.push()\n    self.repo.checkout(prev_branch)\n    self.assertReposEqual(self.repo, new_repo)\n    utils.delete_repository(new_repo)\n", "label": "Variable misuse"}
{"function": "\n\ndef most_restrictive(licenses):\n    \"\\n    given a list of licenses, this function returns the list of licenses that are as restrictive or more restrictive\\n    than each of the input licenses\\n    '<' == less restrictive\\n    cc < cc-nd, cc-nc, cc-sa\\n    cc-nd < cc-nc-nd\\n    cc-nc < cc-nc-sa\\n    cc-sa < cc-nd, cc-nc-sa\\n    cc-nc-sa < cc-nc-nd\\n    \"\n    licenses = set(licenses)\n    for license in licenses:\n        if (license not in LICENSES):\n            raise Exception('Not a valid license type')\n    if ('cc-nc-nd' in licenses):\n        return ['cc-nc-nd']\n    if ('cc-nd' in licenses):\n        if (('cc-nc-sa' in licenses) or ('cc-nc' in licenses)):\n            return ['cc-nc-nd']\n        else:\n            return ['cc-nc-nd', 'cc-nd']\n    if (('cc-nc-sa' in licenses) or (('cc-sa' in licenses) and ('cc-nc' in licenses))):\n        return ['cc-nc-nd', 'cc-nc-sa']\n    if ('cc-nc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nc']\n    if ('cc-sa' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-sa']\n    if ('cc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n    return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n", "label": "Correct"}
{"function": "\n\ndef most_restrictive(licenses):\n    \"\\n    given a list of licenses, this function returns the list of licenses that are as restrictive or more restrictive\\n    than each of the input licenses\\n    '<' == less restrictive\\n    cc < cc-nd, cc-nc, cc-sa\\n    cc-nd < cc-nc-nd\\n    cc-nc < cc-nc-sa\\n    cc-sa < cc-nd, cc-nc-sa\\n    cc-nc-sa < cc-nc-nd\\n    \"\n    licenses = set(licenses)\n    for license in licenses:\n        if (license not in LICENSES):\n            raise Exception('Not a valid license type')\n    if ('cc-nc-nd' in licenses):\n        return ['cc-nc-nd']\n    if ('cc-nd' in licenses):\n        if (('cc-nc-sa' in licenses) or ('cc-nc' in licenses)):\n            return ['cc-nc-nd']\n        else:\n            return ['cc-nc-nd', 'cc-nd']\n    if (('cc-nc-sa' in licenses) or (('cc-sa' in licenses) and ('cc-nc' in license))):\n        return ['cc-nc-nd', 'cc-nc-sa']\n    if ('cc-nc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nc']\n    if ('cc-sa' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-sa']\n    if ('cc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n    return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef bind(cls, event, handler):\n    cls._events.setdefault(cls, {\n        \n    }).setdefault(event, []).append(handler)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef bind(cls, event, handler):\n    cls._events.setdefault(cls, {\n        \n    }).setdefault(event, []).append(event)\n", "label": "Variable misuse"}
{"function": "\n\ndef __rmul__(self, other):\n    return self._combine(other, self.MUL, True)\n", "label": "Correct"}
{"function": "\n\ndef __rmul__(self, other):\n    return other._combine(other, self.MUL, True)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(discreteBarChart, self).__init__(**kwargs)\n    self.model = 'discreteBarChart'\n    height = kwargs.get('height', 450)\n    width = kwargs.get('width', None)\n    if kwargs.get('x_is_date', False):\n        self.set_date_flag(True)\n        self.create_x_axis('xAxis', format=kwargs.get('x_axis_format', '%d %b %Y %H %S'), date=True)\n    else:\n        self.create_x_axis('xAxis', format=None)\n    self.create_y_axis('yAxis', format=kwargs.get('y_axis_format', '.0f'))\n    self.set_custom_tooltip_flag(True)\n    self.set_graph_height(height)\n    if width:\n        self.set_graph_width(width)\n    tooltips = kwargs.get('tooltips', True)\n    if (not tooltips):\n        self.chart_attr = {\n            'tooltips': 'false',\n        }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(discreteBarChart, self).__init__(**kwargs)\n    self.model = 'discreteBarChart'\n    height = height.get('height', 450)\n    width = kwargs.get('width', None)\n    if kwargs.get('x_is_date', False):\n        self.set_date_flag(True)\n        self.create_x_axis('xAxis', format=kwargs.get('x_axis_format', '%d %b %Y %H %S'), date=True)\n    else:\n        self.create_x_axis('xAxis', format=None)\n    self.create_y_axis('yAxis', format=kwargs.get('y_axis_format', '.0f'))\n    self.set_custom_tooltip_flag(True)\n    self.set_graph_height(height)\n    if width:\n        self.set_graph_width(width)\n    tooltips = kwargs.get('tooltips', True)\n    if (not tooltips):\n        self.chart_attr = {\n            'tooltips': 'false',\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef _stats(self, lambda_, N):\n    z = exp((- lambda_))\n    zN = exp(((- lambda_) * N))\n    mu = ((z / (1.0 - z)) - ((N * zN) / (1 - zN)))\n    var = ((z / ((1.0 - z) ** 2)) - (((N * N) * zN) / ((1 - zN) ** 2)))\n    trm = ((1 - zN) / (1 - z))\n    trm2 = ((z * (trm ** 2)) - ((N * N) * zN))\n    g1 = (((z * (1 + z)) * (trm ** 3)) - (((N ** 3) * zN) * (1 + zN)))\n    g1 = (g1 / (trm2 ** 1.5))\n    g2 = (((z * ((1 + (4 * z)) + (z * z))) * (trm ** 4)) - (((N ** 4) * zN) * ((1 + (4 * zN)) + (zN * zN))))\n    g2 = ((g2 / trm2) / trm2)\n    return (mu, var, g1, g2)\n", "label": "Correct"}
{"function": "\n\ndef _stats(self, lambda_, N):\n    z = exp((- lambda_))\n    zN = exp(((- lambda_) * N))\n    mu = ((z / (1.0 - z)) - ((N * zN) / (1 - zN)))\n    var = ((z / ((1.0 - z) ** 2)) - (((N * N) * zN) / ((1 - zN) ** 2)))\n    trm = ((1 - zN) / (1 - z))\n    trm2 = ((z * (trm ** 2)) - ((N * N) * zN))\n    g1 = (((g1 * (1 + z)) * (trm ** 3)) - (((N ** 3) * zN) * (1 + zN)))\n    g1 = (g1 / (trm2 ** 1.5))\n    g2 = (((z * ((1 + (4 * z)) + (z * z))) * (trm ** 4)) - (((N ** 4) * zN) * ((1 + (4 * zN)) + (zN * zN))))\n    g2 = ((g2 / trm2) / trm2)\n    return (mu, var, g1, g2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_integer_open(self):\n    field = pg_forms.IntegerRangeField()\n    value = field.clean(['', '0'])\n    self.assertEqual(value, NumericRange(None, 0))\n", "label": "Correct"}
{"function": "\n\ndef test_integer_open(self):\n    field = pg_forms.IntegerRangeField()\n    value = value.clean(['', '0'])\n    self.assertEqual(value, NumericRange(None, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unpublish_with_descendants(self):\n    page = self.create_page('Page', published=True)\n    child = self.create_page('Child', parent=page, published=True)\n    self.create_page('Grandchild', parent=child, published=True)\n    page = page.reload()\n    child.reload()\n    drafts = Page.objects.drafts()\n    public = Page.objects.public()\n    published = Page.objects.public().published('en')\n    self.assertEqual(published.count(), 3)\n    self.assertEqual(page.get_descendant_count(), 2)\n    base = reverse('pages-root')\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200, url)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        self.assertTrue(item.publisher_public_id)\n        self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_DEFAULT)\n    self.assertTrue(page.unpublish('en'), 'Unpublish was not successful')\n    self.assertFalse(page.is_published('en'))\n    cache.clear()\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 404)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectDoesNotExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        if (title == 'Page'):\n            self.assertFalse(item.is_published('en'))\n            self.assertFalse(item.publisher_public.is_published('en'))\n            self.assertTrue(page.is_dirty('en'))\n        else:\n            self.assertTrue(item.is_published('en'), title)\n            self.assertFalse(item.publisher_public.is_published('en'), title)\n            self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_PENDING, title)\n            self.assertTrue(item.is_dirty('en'), title)\n", "label": "Correct"}
{"function": "\n\ndef test_unpublish_with_descendants(self):\n    page = self.create_page('Page', published=True)\n    child = self.create_page('Child', parent=page, published=True)\n    self.create_page('Grandchild', parent=child, published=True)\n    page = page.reload()\n    child.reload()\n    drafts = Page.objects.drafts()\n    public = Page.objects.public()\n    published = Page.objects.public().published('en')\n    self.assertEqual(published.count(), 3)\n    self.assertEqual(page.get_descendant_count(), 2)\n    base = reverse('pages-root')\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200, url)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        self.assertTrue(item.publisher_public_id)\n        self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_DEFAULT)\n    self.assertTrue(page.unpublish('en'), 'Unpublish was not successful')\n    self.assertFalse(page.is_published('en'))\n    cache.clear()\n    for url in (drafts, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 404)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectDoesNotExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        if (title == 'Page'):\n            self.assertFalse(item.is_published('en'))\n            self.assertFalse(item.publisher_public.is_published('en'))\n            self.assertTrue(page.is_dirty('en'))\n        else:\n            self.assertTrue(item.is_published('en'), title)\n            self.assertFalse(item.publisher_public.is_published('en'), title)\n            self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_PENDING, title)\n            self.assertTrue(item.is_dirty('en'), title)\n", "label": "Variable misuse"}
{"function": "\n\ndef home(self, event):\n    super(self.__class__, self).home(event)\n    self.canvas.draw()\n", "label": "Correct"}
{"function": "\n\ndef home(self, event):\n    super(self.__class__, self).home(event)\n    event.canvas.draw()\n", "label": "Variable misuse"}
{"function": "\n\n@access.public\ndef describeResource(self, resource, params):\n    if (resource not in docs.routes):\n        raise RestException(('Invalid resource: %s' % resource))\n    return {\n        'apiVersion': API_VERSION,\n        'swaggerVersion': SWAGGER_VERSION,\n        'basePath': getApiUrl(),\n        'models': dict(docs.models[resource], **docs.models[None]),\n        'apis': [{\n            'path': route,\n            'operations': sorted(op, key=functools.cmp_to_key(self._compareOperations)),\n        } for (route, op) in sorted(six.viewitems(docs.routes[resource]), key=functools.cmp_to_key(self._compareRoutes))],\n    }\n", "label": "Correct"}
{"function": "\n\n@access.public\ndef describeResource(self, resource, params):\n    if (self not in docs.routes):\n        raise RestException(('Invalid resource: %s' % resource))\n    return {\n        'apiVersion': API_VERSION,\n        'swaggerVersion': SWAGGER_VERSION,\n        'basePath': getApiUrl(),\n        'models': dict(docs.models[resource], **docs.models[None]),\n        'apis': [{\n            'path': route,\n            'operations': sorted(op, key=functools.cmp_to_key(self._compareOperations)),\n        } for (route, op) in sorted(six.viewitems(docs.routes[resource]), key=functools.cmp_to_key(self._compareRoutes))],\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_to_global_with_bad_mac(self):\n    bad_mac = '02:16:3e:33:44:5X'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', bad_mac, 'test')\n", "label": "Correct"}
{"function": "\n\ndef test_to_global_with_bad_mac(self):\n    bad_mac = '02:16:3e:33:44:5X'\n    bad_mac.assertRaises(TypeError, ipv6.to_global, '2001:db8::', bad_mac, 'test')\n", "label": "Variable misuse"}
{"function": "\n\ndef _es_down_template(request, *args, **kwargs):\n    'Returns the appropriate \"Elasticsearch is down!\" template'\n    return ('search/mobile/down.html' if request.MOBILE else 'search/down.html')\n", "label": "Correct"}
{"function": "\n\ndef _es_down_template(request, *args, **kwargs):\n    'Returns the appropriate \"Elasticsearch is down!\" template'\n    return ('search/mobile/down.html' if kwargs.MOBILE else 'search/down.html')\n", "label": "Variable misuse"}
{"function": "\n\ndef capture(self, money, authorization, options=None):\n    options = (options or {\n        \n    })\n    params = {\n        'checkout_id': authorization,\n    }\n    token = options.pop('access_token', self.we_pay_settings['ACCESS_TOKEN'])\n    try:\n        response = self.we_pay.call('/checkout/capture', params, token=token)\n    except WePayError as error:\n        transaction_was_unsuccessful.send(sender=self, type='capture', response=error)\n        return {\n            'status': 'FAILURE',\n            'response': error,\n        }\n    transaction_was_successful.send(sender=self, type='capture', response=response)\n    return {\n        'status': 'SUCCESS',\n        'response': response,\n    }\n", "label": "Correct"}
{"function": "\n\ndef capture(self, money, authorization, options=None):\n    options = (options or {\n        \n    })\n    params = {\n        'checkout_id': authorization,\n    }\n    token = options.pop('access_token', self.we_pay_settings['ACCESS_TOKEN'])\n    try:\n        response = self.we_pay.call('/checkout/capture', params, token=token)\n    except WePayError as error:\n        transaction_was_unsuccessful.send(sender=self, type='capture', response=error)\n        return {\n            'status': 'FAILURE',\n            'response': authorization,\n        }\n    transaction_was_successful.send(sender=self, type='capture', response=response)\n    return {\n        'status': 'SUCCESS',\n        'response': response,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef __isub__(self, val):\n    if (type(val) in (int, float)):\n        self.x -= val\n        self.y -= val\n    else:\n        self.x -= val.x\n        self.y -= val.y\n    return self\n", "label": "Correct"}
{"function": "\n\ndef __isub__(self, val):\n    if (type(val) in (int, float)):\n        self.x -= val\n        self.y -= val\n    else:\n        self.x -= val.x\n        val.y -= val.y\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef normalize_norm_inplace(self, mode='all', **kwargs):\n    '\\n        Deprecated. See the non-mutating API, `normalize_norm()`.\\n        '\n    warn('the public API for inplace operations is deprecated and will be removed in a future version of Menpo. Use .normalize_norm() instead.', MenpoDeprecationWarning)\n\n    def scale_func(pixels, axis=None):\n        return np.linalg.norm(pixels, axis=axis, **kwargs)\n    self._normalize_inplace(scale_func, mode=mode)\n", "label": "Correct"}
{"function": "\n\ndef normalize_norm_inplace(self, mode='all', **kwargs):\n    '\\n        Deprecated. See the non-mutating API, `normalize_norm()`.\\n        '\n    warn('the public API for inplace operations is deprecated and will be removed in a future version of Menpo. Use .normalize_norm() instead.', MenpoDeprecationWarning)\n\n    def scale_func(pixels, axis=None):\n        return np.linalg.norm(pixels, axis=axis, **kwargs)\n    self._normalize_inplace(scale_func, mode=kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef reserve_provider_segment(self, session, segment):\n    filters = {\n        \n    }\n    physical_network = segment.get(api.PHYSICAL_NETWORK)\n    if (physical_network is not None):\n        filters['physical_network'] = physical_network\n        vlan_id = segment.get(api.SEGMENTATION_ID)\n        if (vlan_id is not None):\n            filters['vlan_id'] = vlan_id\n    if self.is_partial_segment(segment):\n        alloc = self.allocate_partially_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.NoNetworkAvailable()\n    else:\n        alloc = self.allocate_fully_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.VlanIdInUse(**filters)\n    return {\n        api.NETWORK_TYPE: p_const.TYPE_VLAN,\n        api.PHYSICAL_NETWORK: alloc.physical_network,\n        api.SEGMENTATION_ID: alloc.vlan_id,\n        api.MTU: self.get_mtu(alloc.physical_network),\n    }\n", "label": "Correct"}
{"function": "\n\ndef reserve_provider_segment(self, session, segment):\n    filters = {\n        \n    }\n    physical_network = segment.get(api.PHYSICAL_NETWORK)\n    if (physical_network is not None):\n        filters['physical_network'] = physical_network\n        vlan_id = segment.get(api.SEGMENTATION_ID)\n        if (vlan_id is not None):\n            filters['vlan_id'] = segment\n    if self.is_partial_segment(segment):\n        alloc = self.allocate_partially_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.NoNetworkAvailable()\n    else:\n        alloc = self.allocate_fully_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.VlanIdInUse(**filters)\n    return {\n        api.NETWORK_TYPE: p_const.TYPE_VLAN,\n        api.PHYSICAL_NETWORK: alloc.physical_network,\n        api.SEGMENTATION_ID: alloc.vlan_id,\n        api.MTU: self.get_mtu(alloc.physical_network),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_can_choose_root(self):\n    response = self.get({\n        'can_choose_root': 'true',\n    })\n    self.assertContains(response, '/admin/pages/1/edit/')\n", "label": "Correct"}
{"function": "\n\ndef test_can_choose_root(self):\n    response = response.get({\n        'can_choose_root': 'true',\n    })\n    self.assertContains(response, '/admin/pages/1/edit/')\n", "label": "Variable misuse"}
{"function": "\n\ndef _match_rhs(self, rhs, rightmost_stack):\n    \"\\n        :rtype: bool\\n        :return: true if the right hand side of a CFG production\\n            matches the rightmost elements of the stack.  ``rhs``\\n            matches ``rightmost_stack`` if they are the same length,\\n            and each element of ``rhs`` matches the corresponding\\n            element of ``rightmost_stack``.  A nonterminal element of\\n            ``rhs`` matches any Tree whose node value is equal\\n            to the nonterminal's symbol.  A terminal element of ``rhs``\\n            matches any string whose type is equal to the terminal.\\n        :type rhs: list(terminal and Nonterminal)\\n        :param rhs: The right hand side of a CFG production.\\n        :type rightmost_stack: list(string and Tree)\\n        :param rightmost_stack: The rightmost elements of the parser's\\n            stack.\\n        \"\n    if (len(rightmost_stack) != len(rhs)):\n        return False\n    for i in range(len(rightmost_stack)):\n        if isinstance(rightmost_stack[i], Tree):\n            if (not isinstance(rhs[i], Nonterminal)):\n                return False\n            if (rightmost_stack[i].label() != rhs[i].symbol()):\n                return False\n        else:\n            if isinstance(rhs[i], Nonterminal):\n                return False\n            if (rightmost_stack[i] != rhs[i]):\n                return False\n    return True\n", "label": "Correct"}
{"function": "\n\ndef _match_rhs(self, rhs, rightmost_stack):\n    \"\\n        :rtype: bool\\n        :return: true if the right hand side of a CFG production\\n            matches the rightmost elements of the stack.  ``rhs``\\n            matches ``rightmost_stack`` if they are the same length,\\n            and each element of ``rhs`` matches the corresponding\\n            element of ``rightmost_stack``.  A nonterminal element of\\n            ``rhs`` matches any Tree whose node value is equal\\n            to the nonterminal's symbol.  A terminal element of ``rhs``\\n            matches any string whose type is equal to the terminal.\\n        :type rhs: list(terminal and Nonterminal)\\n        :param rhs: The right hand side of a CFG production.\\n        :type rightmost_stack: list(string and Tree)\\n        :param rightmost_stack: The rightmost elements of the parser's\\n            stack.\\n        \"\n    if (len(rightmost_stack) != len(rhs)):\n        return False\n    for i in range(len(rightmost_stack)):\n        if isinstance(rightmost_stack[i], Tree):\n            if (not isinstance(rhs[i], Nonterminal)):\n                return False\n            if (rightmost_stack[i].label() != rhs[i].symbol()):\n                return False\n        else:\n            if isinstance(rhs[i], Nonterminal):\n                return False\n            if (rightmost_stack[i] != i[i]):\n                return False\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef update_success(self, update_dict, raw=False):\n    ' This method serves as an easy way to update your success attributes\\n        that are passed to the start Node rendering context, or passed back in\\n        JSON. It automatically recalls whether the last validation call was to\\n        json_validate or validate_render and modifys the correct dictionary\\n        accordingly.\\n\\n        :param update_dict: The dictionary of values to update/add.\\n        :type data: dictionary\\n\\n        :param raw: Whether you would like a pre-compiled JSON\\n            string returned, or the raw dictionary.\\n        :type raw: bool\\n\\n        :return: Return value is either the new JSON string (or raw dict if\\n            requested) if json_validate was your last validation call, or a\\n            re-render of the form with updated error messages if validate_render\\n            was your last call.\\n        '\n    if (self._last_valid == 'render'):\n        try:\n            self.start.errors[(- 1)].update(update_dict)\n        except IndexError:\n            raise IndexError('Error updating your error dictionary for the start Node. There were no errors to modify.')\n        except AttributeError:\n            raise AttributeError('This method is designed to update an error dictionary, yet your errors are not dictionaries')\n        return self.render()\n    else:\n        try:\n            self._last_raw_json['success_blob'].update(update_dict)\n        except KeyError:\n            raise KeyError('Either your json_validate method has not been run yet, or your success_header_generate does not produce output')\n        if raw:\n            return self._last_raw_json\n        else:\n            return json.dumps(self._last_raw_json)\n", "label": "Correct"}
{"function": "\n\ndef update_success(self, update_dict, raw=False):\n    ' This method serves as an easy way to update your success attributes\\n        that are passed to the start Node rendering context, or passed back in\\n        JSON. It automatically recalls whether the last validation call was to\\n        json_validate or validate_render and modifys the correct dictionary\\n        accordingly.\\n\\n        :param update_dict: The dictionary of values to update/add.\\n        :type data: dictionary\\n\\n        :param raw: Whether you would like a pre-compiled JSON\\n            string returned, or the raw dictionary.\\n        :type raw: bool\\n\\n        :return: Return value is either the new JSON string (or raw dict if\\n            requested) if json_validate was your last validation call, or a\\n            re-render of the form with updated error messages if validate_render\\n            was your last call.\\n        '\n    if (self._last_valid == 'render'):\n        try:\n            self.start.errors[(- 1)].update(update_dict)\n        except IndexError:\n            raise IndexError('Error updating your error dictionary for the start Node. There were no errors to modify.')\n        except AttributeError:\n            raise AttributeError('This method is designed to update an error dictionary, yet your errors are not dictionaries')\n        return self.render()\n    else:\n        try:\n            self._last_raw_json['success_blob'].update(raw)\n        except KeyError:\n            raise KeyError('Either your json_validate method has not been run yet, or your success_header_generate does not produce output')\n        if raw:\n            return self._last_raw_json\n        else:\n            return json.dumps(self._last_raw_json)\n", "label": "Variable misuse"}
{"function": "\n\ndef put(self):\n    pet = self.json_args\n    if (not isinstance(pet['id'], int)):\n        self.set_status(400)\n    if (not self.db.update_(**pet)):\n        self.set_status(404)\n    else:\n        self.set_status(200)\n    self.finish()\n", "label": "Correct"}
{"function": "\n\ndef put(self):\n    pet = self.json_args\n    if (not isinstance(pet['id'], int)):\n        pet.set_status(400)\n    if (not self.db.update_(**pet)):\n        self.set_status(404)\n    else:\n        self.set_status(200)\n    self.finish()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_getitem_slice_big():\n    slt = SortedList(range(4))\n    lst = list(range(4))\n    itr = ((start, stop, step) for start in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for stop in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for step in [(- 3), (- 2), (- 1), 1, 2, 3])\n    for (start, stop, step) in itr:\n        assert (slt[start:stop:step] == lst[start:stop:step])\n", "label": "Correct"}
{"function": "\n\ndef test_getitem_slice_big():\n    slt = SortedList(range(4))\n    lst = list(range(4))\n    itr = ((start, stop, step) for start in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for stop in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for step in [(- 3), (- 2), (- 1), 1, 2, 3])\n    for (start, stop, step) in itr:\n        assert (slt[start:stop:step] == lst[start:stop:slt])\n", "label": "Variable misuse"}
{"function": "\n\ndef disable_audit_backend(self, name):\n    '\\n        DELETE /sys/audit/<name>\\n        '\n    self._delete('/v1/sys/audit/{0}'.format(name))\n", "label": "Correct"}
{"function": "\n\ndef disable_audit_backend(self, name):\n    '\\n        DELETE /sys/audit/<name>\\n        '\n    self._delete('/v1/sys/audit/{0}'.format(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_response(self, cmd, fid, *args):\n    for source in self.select_best_source(fid.decode()):\n        dealer = None\n        try:\n            dealer = self.context.socket(zmq.DEALER)\n            dealer.connect(get_events_uri(self.session, source, 'router'))\n            dealer.send_multipart(((cmd, fid) + args))\n            response = dealer.recv_multipart()\n            if ((not response) or (response[0] == ERROR)):\n                self.logger.debug('Error with source {}', source)\n                continue\n            return response\n        finally:\n            if dealer:\n                dealer.close()\n    self.logger.debug('No more source available.')\n    return [ERROR]\n", "label": "Correct"}
{"function": "\n\ndef get_response(self, cmd, fid, *args):\n    for source in self.select_best_source(fid.decode()):\n        dealer = None\n        try:\n            dealer = self.context.socket(zmq.DEALER)\n            dealer.connect(get_events_uri(self.session, source, 'router'))\n            dealer.send_multipart(((cmd, fid) + args))\n            response = dealer.recv_multipart()\n            if ((not response) or (response[0] == ERROR)):\n                self.logger.debug('Error with source {}', args)\n                continue\n            return response\n        finally:\n            if dealer:\n                dealer.close()\n    self.logger.debug('No more source available.')\n    return [ERROR]\n", "label": "Variable misuse"}
{"function": "\n\ndef httpapi(self, arg, opts):\n    sc = HttpAPIStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get().getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            row.append(v)\n        table.append(row)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Correct"}
{"function": "\n\ndef httpapi(self, arg, opts):\n    sc = HttpAPIStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get().getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            opts.append(v)\n        table.append(row)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Variable misuse"}
{"function": "\n\ndef getrecordbyid(self, raw=False):\n    ' Handle GetRecordById request '\n    if ('id' not in self.parent.kvp):\n        return self.exceptionreport('MissingParameterValue', 'id', 'Missing id parameter')\n    if (len(self.parent.kvp['id']) < 1):\n        return self.exceptionreport('InvalidParameterValue', 'id', 'Invalid id parameter')\n    if ('outputschema' not in self.parent.kvp):\n        self.parent.kvp['outputschema'] = self.parent.context.namespaces['csw30']\n    if ('HTTP_ACCEPT' in self.parent.environ):\n        LOGGER.debug('Detected HTTP Accept header: %s', self.parent.environ['HTTP_ACCEPT'])\n        formats_match = False\n        if ('outputformat' in self.parent.kvp):\n            LOGGER.debug(self.parent.kvp['outputformat'])\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                LOGGER.debug('Comparing %s and %s', ofmt, self.parent.kvp['outputformat'])\n                if (ofmt.split('/')[0] in self.parent.kvp['outputformat']):\n                    LOGGER.debug('FOUND OUTPUT MATCH')\n                    formats_match = True\n            if (not formats_match):\n                return self.exceptionreport('InvalidParameterValue', 'outputformat', ('HTTP Accept header (%s) and outputformat (%s) must agree' % (self.parent.environ['HTTP_ACCEPT'], self.parent.kvp['outputformat'])))\n        else:\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                if (ofmt in self.parent.context.model['operations']['GetRecords']['parameters']['outputFormat']['values']):\n                    self.parent.kvp['outputformat'] = ofmt\n                    break\n    if (('outputformat' in self.parent.kvp) and (self.parent.kvp['outputformat'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputFormat']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputformat', ('Invalid outputformat parameter %s' % self.parent.kvp['outputformat']))\n    if (('outputschema' in self.parent.kvp) and (self.parent.kvp['outputschema'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputSchema']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputschema', ('Invalid outputschema parameter %s' % self.parent.kvp['outputschema']))\n    if ('outputformat' in self.parent.kvp):\n        self.parent.contenttype = self.parent.kvp['outputformat']\n        if (self.parent.kvp['outputformat'] == 'application/atom+xml'):\n            self.parent.kvp['outputschema'] = self.parent.context.namespaces['atom']\n            self.parent.mode = 'opensearch'\n    if ('elementsetname' not in self.parent.kvp):\n        self.parent.kvp['elementsetname'] = 'summary'\n    elif (self.parent.kvp['elementsetname'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['ElementSetName']['values']):\n        return self.exceptionreport('InvalidParameterValue', 'elementsetname', ('Invalid elementsetname parameter %s' % self.parent.kvp['elementsetname']))\n    LOGGER.debug(('Querying repository with ids: %s.' % self.parent.kvp['id']))\n    results = self.parent.repository.query_ids([self.parent.kvp['id']])\n    if raw:\n        LOGGER.debug('GetRepositoryItem request.')\n        if (len(results) > 0):\n            return etree.fromstring(util.getqattr(results[0], self.parent.context.md_core_model['mappings']['pycsw:XML']), self.parent.context.parser)\n    for result in results:\n        if ((util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename']) == 'csw:Record') and (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0')):\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0'):\n            typename = None\n            for prof in self.parent.profiles['loaded']:\n                if (self.parent.profiles['loaded'][prof].typename in [util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename'])]):\n                    typename = self.parent.profiles['loaded'][prof].typename\n                    break\n            if (typename is not None):\n                util.transform_mappings(self.parent.repository.queryables['_all'], self.parent.context.model['typenames'][typename]['mappings']['csw:Record'], reverse=True)\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] in self.parent.outputschemas):\n            node = self.parent.outputschemas[self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.context, self.parent.config.get('server', 'url'))\n        else:\n            node = self.parent.profiles['loaded'][self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.kvp['outputschema'], self.parent.repository.queryables['_all'])\n    if (raw and (len(results) == 0)):\n        return None\n    if (len(results) == 0):\n        return self.exceptionreport('NotFound', 'id', (\"No repository item found for '%s'\" % self.parent.kvp['id']))\n    return node\n", "label": "Correct"}
{"function": "\n\ndef getrecordbyid(self, raw=False):\n    ' Handle GetRecordById request '\n    if ('id' not in self.parent.kvp):\n        return self.exceptionreport('MissingParameterValue', 'id', 'Missing id parameter')\n    if (len(self.parent.kvp['id']) < 1):\n        return self.exceptionreport('InvalidParameterValue', 'id', 'Invalid id parameter')\n    if ('outputschema' not in self.parent.kvp):\n        self.parent.kvp['outputschema'] = self.parent.context.namespaces['csw30']\n    if ('HTTP_ACCEPT' in self.parent.environ):\n        LOGGER.debug('Detected HTTP Accept header: %s', self.parent.environ['HTTP_ACCEPT'])\n        formats_match = False\n        if ('outputformat' in self.parent.kvp):\n            LOGGER.debug(self.parent.kvp['outputformat'])\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                LOGGER.debug('Comparing %s and %s', ofmt, self.parent.kvp['outputformat'])\n                if (ofmt.split('/')[0] in self.parent.kvp['outputformat']):\n                    LOGGER.debug('FOUND OUTPUT MATCH')\n                    formats_match = True\n            if (not formats_match):\n                return self.exceptionreport('InvalidParameterValue', 'outputformat', ('HTTP Accept header (%s) and outputformat (%s) must agree' % (self.parent.environ['HTTP_ACCEPT'], self.parent.kvp['outputformat'])))\n        else:\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                if (ofmt in self.parent.context.model['operations']['GetRecords']['parameters']['outputFormat']['values']):\n                    self.parent.kvp['outputformat'] = ofmt\n                    break\n    if (('outputformat' in self.parent.kvp) and (self.parent.kvp['outputformat'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputFormat']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputformat', ('Invalid outputformat parameter %s' % self.parent.kvp['outputformat']))\n    if (('outputschema' in self.parent.kvp) and (ofmt.parent.kvp['outputschema'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputSchema']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputschema', ('Invalid outputschema parameter %s' % self.parent.kvp['outputschema']))\n    if ('outputformat' in self.parent.kvp):\n        self.parent.contenttype = self.parent.kvp['outputformat']\n        if (self.parent.kvp['outputformat'] == 'application/atom+xml'):\n            self.parent.kvp['outputschema'] = self.parent.context.namespaces['atom']\n            self.parent.mode = 'opensearch'\n    if ('elementsetname' not in self.parent.kvp):\n        self.parent.kvp['elementsetname'] = 'summary'\n    elif (self.parent.kvp['elementsetname'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['ElementSetName']['values']):\n        return self.exceptionreport('InvalidParameterValue', 'elementsetname', ('Invalid elementsetname parameter %s' % self.parent.kvp['elementsetname']))\n    LOGGER.debug(('Querying repository with ids: %s.' % self.parent.kvp['id']))\n    results = self.parent.repository.query_ids([self.parent.kvp['id']])\n    if raw:\n        LOGGER.debug('GetRepositoryItem request.')\n        if (len(results) > 0):\n            return etree.fromstring(util.getqattr(results[0], self.parent.context.md_core_model['mappings']['pycsw:XML']), self.parent.context.parser)\n    for result in results:\n        if ((util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename']) == 'csw:Record') and (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0')):\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0'):\n            typename = None\n            for prof in self.parent.profiles['loaded']:\n                if (self.parent.profiles['loaded'][prof].typename in [util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename'])]):\n                    typename = self.parent.profiles['loaded'][prof].typename\n                    break\n            if (typename is not None):\n                util.transform_mappings(self.parent.repository.queryables['_all'], self.parent.context.model['typenames'][typename]['mappings']['csw:Record'], reverse=True)\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] in self.parent.outputschemas):\n            node = self.parent.outputschemas[self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.context, self.parent.config.get('server', 'url'))\n        else:\n            node = self.parent.profiles['loaded'][self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.kvp['outputschema'], self.parent.repository.queryables['_all'])\n    if (raw and (len(results) == 0)):\n        return None\n    if (len(results) == 0):\n        return self.exceptionreport('NotFound', 'id', (\"No repository item found for '%s'\" % self.parent.kvp['id']))\n    return node\n", "label": "Variable misuse"}
{"function": "\n\ndef neg(self, a):\n    'Returns ``a`` negated, implies ``__neg__``. '\n    return (- a)\n", "label": "Correct"}
{"function": "\n\ndef neg(self, a):\n    'Returns ``a`` negated, implies ``__neg__``. '\n    return (- self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_cmovpe(self):\n    asm = ['cmovpe eax, ebx']\n    ctx_init = self.__init_context()\n    (x86_ctx_out, reil_ctx_out) = self.__run_code(asm, 3735928559, ctx_init)\n    cmp_result = self.__compare_contexts(ctx_init, x86_ctx_out, reil_ctx_out)\n    if (not cmp_result):\n        self.__save_failing_context(ctx_init)\n    self.assertTrue(cmp_result, self.__print_contexts(ctx_init, x86_ctx_out, reil_ctx_out))\n", "label": "Correct"}
{"function": "\n\ndef test_cmovpe(self):\n    asm = ['cmovpe eax, ebx']\n    ctx_init = self.__init_context()\n    (x86_ctx_out, reil_ctx_out) = self.__run_code(asm, 3735928559, ctx_init)\n    cmp_result = self.__compare_contexts(self, x86_ctx_out, reil_ctx_out)\n    if (not cmp_result):\n        self.__save_failing_context(ctx_init)\n    self.assertTrue(cmp_result, self.__print_contexts(ctx_init, x86_ctx_out, reil_ctx_out))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_identical_input(self):\n    x = np.random.randn(20)\n    y = np.copy(x)\n    f = np.linspace(0, 0.5, 6)\n    C = np.ones(6)\n    (f1, C1) = coherence(x, y, nperseg=10)\n    assert_allclose(f, f1)\n    assert_allclose(C, C1)\n", "label": "Correct"}
{"function": "\n\ndef test_identical_input(self):\n    x = np.random.randn(20)\n    y = np.copy(x)\n    f = np.linspace(0, 0.5, 6)\n    C = np.ones(6)\n    (f1, C1) = coherence(x, y, nperseg=10)\n    assert_allclose(f, f1)\n    assert_allclose(self, C1)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_to_global_with_bad_project(self):\n    bad_project = 'non-existent-project-name'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', '2001:db8::a94a:8fe5:ff33:4455', bad_project)\n", "label": "Correct"}
{"function": "\n\ndef test_to_global_with_bad_project(self):\n    bad_project = 'non-existent-project-name'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', '2001:db8::a94a:8fe5:ff33:4455', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef setLoc(self, p):\n    self.rect.loc = p\n    self.updateV()\n", "label": "Correct"}
{"function": "\n\ndef setLoc(self, p):\n    p.rect.loc = p\n    self.updateV()\n", "label": "Variable misuse"}
{"function": "\n\ndef _find_tab(self, widget):\n    for (key, bnch) in self.tab.items():\n        if (widget == bnch.widget):\n            return bnch\n    return None\n", "label": "Correct"}
{"function": "\n\ndef _find_tab(self, widget):\n    for (key, bnch) in widget.tab.items():\n        if (widget == bnch.widget):\n            return bnch\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef redraw(self):\n    self.data.sort(self.sortfn)\n    rows = len(self.data)\n    cols = 0\n    if (rows > 0):\n        cols = len(self.data[0])\n    self.grid.resize(rows, cols)\n    self.header.resize(1, cols)\n    cf = self.grid.getCellFormatter()\n    for (nrow, row) in enumerate(self.data):\n        for (ncol, item) in enumerate(row):\n            self.grid.setHTML(nrow, ncol, str(item))\n            cf.setWidth(nrow, ncol, '200px')\n    cf = self.header.getCellFormatter()\n    self.sortbuttons = []\n    for ncol in range(cols):\n        sb = Button(('sort col %d' % ncol))\n        sb.addClickListener(self)\n        self.header.setWidget(0, ncol, sb)\n        cf.setWidth(0, ncol, '200px')\n        self.sortbuttons.append(sb)\n", "label": "Correct"}
{"function": "\n\ndef redraw(self):\n    self.data.sort(self.sortfn)\n    rows = len(self.data)\n    cols = 0\n    if (rows > 0):\n        cols = len(self.data[0])\n    self.grid.resize(rows, cols)\n    self.header.resize(1, cols)\n    cf = self.grid.getCellFormatter()\n    for (nrow, row) in enumerate(self.data):\n        for (ncol, item) in enumerate(row):\n            self.grid.setHTML(nrow, ncol, str(item))\n            cf.setWidth(nrow, ncol, '200px')\n    cf = self.header.getCellFormatter()\n    self.sortbuttons = []\n    for ncol in range(cols):\n        sb = Button(('sort col %d' % ncol))\n        sb.addClickListener(self)\n        self.header.setWidget(0, rows, sb)\n        cf.setWidth(0, ncol, '200px')\n        self.sortbuttons.append(sb)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_formatter_with_tuples(self):\n    record = (5, 'pikos', 'apikos')\n    output = '5 pikos apikos\\n'\n    recorder = TextStreamRecorder(self.temp, formatted=True)\n    recorder.prepare(tuple)\n    recorder.record(record)\n    self.assertMultiLineEqual(self.temp.getvalue(), output)\n", "label": "Correct"}
{"function": "\n\ndef test_formatter_with_tuples(self):\n    record = (5, 'pikos', 'apikos')\n    output = '5 pikos apikos\\n'\n    recorder = TextStreamRecorder(self.temp, formatted=True)\n    recorder.prepare(tuple)\n    recorder.record(output)\n    self.assertMultiLineEqual(self.temp.getvalue(), output)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_eq(self):\n    m1 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m2 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m3 = minhash.MinHash(4, 2, hashobj=FakeHash)\n    m4 = minhash.MinHash(8, 1, hashobj=FakeHash)\n    m5 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m1.update(11)\n    m2.update(12)\n    m3.update(11)\n    m4.update(11)\n    m5.update(11)\n    m1 = bBitMinHash(m1)\n    m2 = bBitMinHash(m2)\n    m3 = bBitMinHash(m3)\n    m4 = bBitMinHash(m4)\n    m5 = bBitMinHash(m5)\n    self.assertNotEqual(m1, m2)\n    self.assertNotEqual(m1, m3)\n    self.assertNotEqual(m1, m4)\n    self.assertEqual(m1, m5)\n", "label": "Correct"}
{"function": "\n\ndef test_eq(self):\n    m1 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m2 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m3 = minhash.MinHash(4, 2, hashobj=FakeHash)\n    m4 = minhash.MinHash(8, 1, hashobj=FakeHash)\n    m5 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m1.update(11)\n    m2.update(12)\n    m3.update(11)\n    m4.update(11)\n    m5.update(11)\n    m1 = bBitMinHash(m1)\n    m2 = bBitMinHash(m2)\n    m3 = bBitMinHash(m3)\n    m4 = bBitMinHash(m4)\n    m5 = bBitMinHash(m5)\n    self.assertNotEqual(m1, m2)\n    self.assertNotEqual(m2, m3)\n    self.assertNotEqual(m1, m4)\n    self.assertEqual(m1, m5)\n", "label": "Variable misuse"}
{"function": "\n\ndef create_node(self, **attrs):\n    'Create a node\\n\\n        Doc link:\\n        http://developer.openstack.org/api-ref-clustering-v1.html#createNode\\n        '\n    return self.service.create_node(**attrs)\n", "label": "Correct"}
{"function": "\n\ndef create_node(self, **attrs):\n    'Create a node\\n\\n        Doc link:\\n        http://developer.openstack.org/api-ref-clustering-v1.html#createNode\\n        '\n    return self.service.create_node(**self)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_user_notified(user_id, target_id):\n    res = dbsession.query(Notify).filter((Notify.target_id == target_id))\n    res = res.filter((Notify.user_id == user_id))\n    try:\n        r = res.all()[0]\n        return r\n    except:\n        return False\n", "label": "Correct"}
{"function": "\n\ndef is_user_notified(user_id, target_id):\n    res = dbsession.query(Notify).filter((Notify.target_id == target_id))\n    res = res.filter((Notify.user_id == user_id))\n    try:\n        r = r.all()[0]\n        return r\n    except:\n        return False\n", "label": "Variable misuse"}
{"function": "\n\n@users_delete_fixtures\ndef test_users_delete_redirect(User):\n    request = DummyRequest(params={\n        'username': 'bob',\n    })\n    User.get_by_username.return_value = None\n    result = views.users_delete(request)\n    assert (result.__class__ == httpexceptions.HTTPFound)\n", "label": "Correct"}
{"function": "\n\n@users_delete_fixtures\ndef test_users_delete_redirect(User):\n    request = DummyRequest(params={\n        'username': 'bob',\n    })\n    result.get_by_username.return_value = None\n    result = views.users_delete(request)\n    assert (result.__class__ == httpexceptions.HTTPFound)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_collection_move_hitslazy(self):\n    (User, Address) = (self.classes.User, self.classes.Address)\n    sess = sessionmaker()()\n    a1 = Address(email_address='address1')\n    a2 = Address(email_address='address2')\n    a3 = Address(email_address='address3')\n    u1 = User(name='jack', addresses=[a1, a2, a3])\n    u2 = User(name='ed')\n    sess.add_all([u1, a1, a2, a3])\n    sess.commit()\n\n    def go():\n        u2.addresses.append(a1)\n        u2.addresses.append(a2)\n        u2.addresses.append(a3)\n    self.assert_sql_count(testing.db, go, 0)\n", "label": "Correct"}
{"function": "\n\ndef test_collection_move_hitslazy(self):\n    (User, Address) = (self.classes.User, self.classes.Address)\n    sess = sessionmaker()()\n    a1 = Address(email_address='address1')\n    a2 = Address(email_address='address2')\n    a3 = User(email_address='address3')\n    u1 = User(name='jack', addresses=[a1, a2, a3])\n    u2 = User(name='ed')\n    sess.add_all([u1, a1, a2, a3])\n    sess.commit()\n\n    def go():\n        u2.addresses.append(a1)\n        u2.addresses.append(a2)\n        u2.addresses.append(a3)\n    self.assert_sql_count(testing.db, go, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_primary_address(self):\n    'Return the primary address of this partner.\\n\\n        '\n    Address = rt.modules.addresses.Address\n    try:\n        return Address.objects.get(partner=self, primary=True)\n    except Address.DoesNotExist:\n        pass\n", "label": "Correct"}
{"function": "\n\ndef get_primary_address(self):\n    'Return the primary address of this partner.\\n\\n        '\n    Address = rt.modules.addresses.Address\n    try:\n        return Address.objects.get(partner=Address, primary=True)\n    except Address.DoesNotExist:\n        pass\n", "label": "Variable misuse"}
{"function": "\n\ndef clear(self):\n    'od.clear() -> None.  Remove all items from od.'\n    try:\n        for node in self.__map.itervalues():\n            del node[:]\n        root = self.__root\n        root[:] = [root, root, None]\n        self.__map.clear()\n    except AttributeError:\n        pass\n    dict.clear(self)\n", "label": "Correct"}
{"function": "\n\ndef clear(self):\n    'od.clear() -> None.  Remove all items from od.'\n    try:\n        for node in self.__map.itervalues():\n            del self[:]\n        root = self.__root\n        root[:] = [root, root, None]\n        self.__map.clear()\n    except AttributeError:\n        pass\n    dict.clear(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_can_add_a_image_text_block_to_a_container(self):\n    container = self.page.get_container_from_name('page-container')\n    num_blocks = container.blocks.count()\n    response = self.post(reverse('fp-api:block-list'), params={\n        'container': container.uuid,\n        'code': 'image',\n    })\n    self.assertEquals(response.status_code, 201)\n    self.assertEquals(container.blocks.count(), (num_blocks + 1))\n    block_id = json.loads(response.content)['id']\n    ContentBlock.objects.get_subclass(pk=block_id)\n", "label": "Correct"}
{"function": "\n\ndef test_can_add_a_image_text_block_to_a_container(self):\n    container = self.page.get_container_from_name('page-container')\n    num_blocks = container.blocks.count()\n    response = self.post(reverse('fp-api:block-list'), params={\n        'container': container.uuid,\n        'code': 'image',\n    })\n    self.assertEquals(response.status_code, 201)\n    self.assertEquals(container.blocks.count(), (num_blocks + 1))\n    block_id = json.loads(num_blocks.content)['id']\n    ContentBlock.objects.get_subclass(pk=block_id)\n", "label": "Variable misuse"}
{"function": "\n\n@group_only\ndef seen(self, msg, matches):\n    chat_id = msg.dest.id\n    if (matches.group(2) is not None):\n        return self.seen_by_id(chat_id, matches.group(2))\n    elif (matches.group(3) is not None):\n        return self.seen_by_username(chat_id, matches.group(3))\n    else:\n        return self.seen_by_fullname(chat_id, matches.group(4))\n", "label": "Correct"}
{"function": "\n\n@group_only\ndef seen(self, msg, matches):\n    chat_id = msg.dest.id\n    if (matches.group(2) is not None):\n        return self.seen_by_id(chat_id, matches.group(2))\n    elif (matches.group(3) is not None):\n        return self.seen_by_username(chat_id, matches.group(3))\n    else:\n        return self.seen_by_fullname(chat_id, self.group(4))\n", "label": "Variable misuse"}
{"function": "\n\ndef updateProperties(self):\n    if (self.modelXbrl is not None):\n        modelXbrl = self.modelXbrl\n        if (modelXbrl.modelDocument.type == ModelDocument.Type.INSTANCE):\n            tbl = self.table\n            coordinates = tbl.getCurrentCellCoordinates()\n            if (coordinates is not None):\n                objId = tbl.getObjectId(coordinates)\n                if ((objId is not None) and (len(objId) > 0)):\n                    if (objId and (objId[0] == 'f')):\n                        viewableObject = self.factPrototypes[int(objId[1:])]\n                    elif (objId[0] != 'a'):\n                        viewableObject = self.modelXbrl.modelObject(objId)\n                    else:\n                        return\n                    modelXbrl.viewModelObject(viewableObject)\n", "label": "Correct"}
{"function": "\n\ndef updateProperties(self):\n    if (self.modelXbrl is not None):\n        modelXbrl = self.modelXbrl\n        if (modelXbrl.modelDocument.type == ModelDocument.Type.INSTANCE):\n            tbl = self.table\n            coordinates = modelXbrl.getCurrentCellCoordinates()\n            if (coordinates is not None):\n                objId = tbl.getObjectId(coordinates)\n                if ((objId is not None) and (len(objId) > 0)):\n                    if (objId and (objId[0] == 'f')):\n                        viewableObject = self.factPrototypes[int(objId[1:])]\n                    elif (objId[0] != 'a'):\n                        viewableObject = self.modelXbrl.modelObject(objId)\n                    else:\n                        return\n                    modelXbrl.viewModelObject(viewableObject)\n", "label": "Variable misuse"}
{"function": "\n\ndef Validate(self):\n    'Attempt to validate the artifact has been well defined.\\n\\n    This is used to enforce Artifact rules. Since it checks all dependencies are\\n    present, this method can only be called once all artifacts have been loaded\\n    into the registry. Use ValidateSyntax to check syntax for each artifact on\\n    import.\\n\\n    Raises:\\n      ArtifactDefinitionError: If artifact is invalid.\\n    '\n    self.ValidateSyntax()\n    try:\n        for dependency in self.GetArtifactDependencies():\n            dependency_obj = REGISTRY.GetArtifact(dependency)\n            if dependency_obj.error_message:\n                raise ArtifactDefinitionError(('Dependency %s has an error!' % dependency))\n    except ArtifactNotRegisteredError as e:\n        raise ArtifactDefinitionError(e)\n", "label": "Correct"}
{"function": "\n\ndef Validate(self):\n    'Attempt to validate the artifact has been well defined.\\n\\n    This is used to enforce Artifact rules. Since it checks all dependencies are\\n    present, this method can only be called once all artifacts have been loaded\\n    into the registry. Use ValidateSyntax to check syntax for each artifact on\\n    import.\\n\\n    Raises:\\n      ArtifactDefinitionError: If artifact is invalid.\\n    '\n    self.ValidateSyntax()\n    try:\n        for dependency in self.GetArtifactDependencies():\n            dependency_obj = REGISTRY.GetArtifact(dependency)\n            if dependency_obj.error_message:\n                raise ArtifactDefinitionError(('Dependency %s has an error!' % dependency_obj))\n    except ArtifactNotRegisteredError as e:\n        raise ArtifactDefinitionError(e)\n", "label": "Variable misuse"}
{"function": "\n\ndef add_user(self, pool_id, node_id, user, compute_node_add_user_options=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Adds a user account to the specified compute node.\\n\\n        :param pool_id: The id of the pool that contains the compute node.\\n        :type pool_id: str\\n        :param node_id: The id of the machine on which you want to create a\\n         user account.\\n        :type node_id: str\\n        :param user: Specifies the user account to be created.\\n        :type user: :class:`ComputeNodeUser\\n         <azure.batch.models.ComputeNodeUser>`\\n        :param compute_node_add_user_options: Additional parameters for the\\n         operation\\n        :type compute_node_add_user_options:\\n         :class:`ComputeNodeAddUserOptions <azure.batch.models.ComputeNodeAddUserOptions>`\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: None\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    timeout = None\n    if (compute_node_add_user_options is not None):\n        timeout = compute_node_add_user_options.timeout\n    client_request_id = None\n    if (compute_node_add_user_options is not None):\n        client_request_id = compute_node_add_user_options.client_request_id\n    return_client_request_id = None\n    if (compute_node_add_user_options is not None):\n        return_client_request_id = compute_node_add_user_options.return_client_request_id\n    ocp_date = None\n    if (compute_node_add_user_options is not None):\n        ocp_date = compute_node_add_user_options.ocp_date\n    url = '/pools/{poolId}/nodes/{nodeId}/users'\n    path_format_arguments = {\n        'poolId': self._serialize.url('pool_id', pool_id, 'str'),\n        'nodeId': self._serialize.url('node_id', node_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    if (timeout is not None):\n        query_parameters['timeout'] = self._serialize.query('timeout', timeout, 'int')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    if (client_request_id is not None):\n        header_parameters['client-request-id'] = self._serialize.header('client_request_id', client_request_id, 'str')\n    if (return_client_request_id is not None):\n        header_parameters['return-client-request-id'] = self._serialize.header('return_client_request_id', return_client_request_id, 'bool')\n    if (ocp_date is not None):\n        header_parameters['ocp-date'] = self._serialize.header('ocp_date', ocp_date, 'rfc-1123')\n    body_content = self._serialize.body(user, 'ComputeNodeUser')\n    request = self._client.post(url, query_parameters)\n    response = self._client.send(request, header_parameters, body_content, **operation_config)\n    if (response.status_code not in [201]):\n        raise models.BatchErrorException(self._deserialize, response)\n    if raw:\n        client_raw_response = ClientRawResponse(None, response)\n        client_raw_response.add_headers({\n            'client-request-id': 'str',\n            'request-id': 'str',\n            'ETag': 'str',\n            'Last-Modified': 'rfc-1123',\n            'DataServiceId': 'str',\n        })\n        return client_raw_response\n", "label": "Correct"}
{"function": "\n\ndef add_user(self, pool_id, node_id, user, compute_node_add_user_options=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Adds a user account to the specified compute node.\\n\\n        :param pool_id: The id of the pool that contains the compute node.\\n        :type pool_id: str\\n        :param node_id: The id of the machine on which you want to create a\\n         user account.\\n        :type node_id: str\\n        :param user: Specifies the user account to be created.\\n        :type user: :class:`ComputeNodeUser\\n         <azure.batch.models.ComputeNodeUser>`\\n        :param compute_node_add_user_options: Additional parameters for the\\n         operation\\n        :type compute_node_add_user_options:\\n         :class:`ComputeNodeAddUserOptions <azure.batch.models.ComputeNodeAddUserOptions>`\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: None\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    timeout = None\n    if (compute_node_add_user_options is not None):\n        timeout = compute_node_add_user_options.timeout\n    client_request_id = None\n    if (compute_node_add_user_options is not None):\n        client_request_id = compute_node_add_user_options.client_request_id\n    return_client_request_id = None\n    if (compute_node_add_user_options is not None):\n        return_client_request_id = compute_node_add_user_options.return_client_request_id\n    ocp_date = None\n    if (compute_node_add_user_options is not None):\n        ocp_date = compute_node_add_user_options.ocp_date\n    url = '/pools/{poolId}/nodes/{nodeId}/users'\n    path_format_arguments = {\n        'poolId': self._serialize.url('pool_id', pool_id, 'str'),\n        'nodeId': self._serialize.url('node_id', node_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    if (timeout is not None):\n        query_parameters['timeout'] = custom_headers._serialize.query('timeout', timeout, 'int')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    if (client_request_id is not None):\n        header_parameters['client-request-id'] = self._serialize.header('client_request_id', client_request_id, 'str')\n    if (return_client_request_id is not None):\n        header_parameters['return-client-request-id'] = self._serialize.header('return_client_request_id', return_client_request_id, 'bool')\n    if (ocp_date is not None):\n        header_parameters['ocp-date'] = self._serialize.header('ocp_date', ocp_date, 'rfc-1123')\n    body_content = self._serialize.body(user, 'ComputeNodeUser')\n    request = self._client.post(url, query_parameters)\n    response = self._client.send(request, header_parameters, body_content, **operation_config)\n    if (response.status_code not in [201]):\n        raise models.BatchErrorException(self._deserialize, response)\n    if raw:\n        client_raw_response = ClientRawResponse(None, response)\n        client_raw_response.add_headers({\n            'client-request-id': 'str',\n            'request-id': 'str',\n            'ETag': 'str',\n            'Last-Modified': 'rfc-1123',\n            'DataServiceId': 'str',\n        })\n        return client_raw_response\n", "label": "Variable misuse"}
{"function": "\n\ndef _destroy_kernel_ramdisk(self, instance, vm_ref):\n    'Three situations can occur:\\n\\n            1. We have neither a ramdisk nor a kernel, in which case we are a\\n               RAW image and can omit this step\\n\\n            2. We have one or the other, in which case, we should flag as an\\n               error\\n\\n            3. We have both, in which case we safely remove both the kernel\\n               and the ramdisk.\\n\\n        '\n    instance_uuid = instance['uuid']\n    if ((not instance['kernel_id']) and (not instance['ramdisk_id'])):\n        LOG.debug('Using RAW or VHD, skipping kernel and ramdisk deletion', instance=instance)\n        return\n    if (not (instance['kernel_id'] and instance['ramdisk_id'])):\n        raise exception.InstanceUnacceptable(instance_id=instance_uuid, reason=_('instance has a kernel or ramdisk but not both'))\n    (kernel, ramdisk) = vm_utils.lookup_kernel_ramdisk(self._session, vm_ref)\n    if (kernel or ramdisk):\n        vm_utils.destroy_kernel_ramdisk(self._session, instance, kernel, ramdisk)\n        LOG.debug('kernel/ramdisk files removed', instance=instance)\n", "label": "Correct"}
{"function": "\n\ndef _destroy_kernel_ramdisk(self, instance, vm_ref):\n    'Three situations can occur:\\n\\n            1. We have neither a ramdisk nor a kernel, in which case we are a\\n               RAW image and can omit this step\\n\\n            2. We have one or the other, in which case, we should flag as an\\n               error\\n\\n            3. We have both, in which case we safely remove both the kernel\\n               and the ramdisk.\\n\\n        '\n    instance_uuid = instance['uuid']\n    if ((not self['kernel_id']) and (not instance['ramdisk_id'])):\n        LOG.debug('Using RAW or VHD, skipping kernel and ramdisk deletion', instance=instance)\n        return\n    if (not (instance['kernel_id'] and instance['ramdisk_id'])):\n        raise exception.InstanceUnacceptable(instance_id=instance_uuid, reason=_('instance has a kernel or ramdisk but not both'))\n    (kernel, ramdisk) = vm_utils.lookup_kernel_ramdisk(self._session, vm_ref)\n    if (kernel or ramdisk):\n        vm_utils.destroy_kernel_ramdisk(self._session, instance, kernel, ramdisk)\n        LOG.debug('kernel/ramdisk files removed', instance=instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef filter_log_files_for_zipping(log_files):\n    \"Identify unzipped log files that are approporate for zipping.\\n\\n    Each unique log type found should have the most recent log file unzipped\\n    as it's probably still in use.\\n    \"\n    out_files = []\n    for lf in filter_log_files_for_active(log_files):\n        if lf.bzip:\n            continue\n        out_files.append(lf)\n    return out_files\n", "label": "Correct"}
{"function": "\n\ndef filter_log_files_for_zipping(log_files):\n    \"Identify unzipped log files that are approporate for zipping.\\n\\n    Each unique log type found should have the most recent log file unzipped\\n    as it's probably still in use.\\n    \"\n    out_files = []\n    for lf in filter_log_files_for_active(log_files):\n        if lf.bzip:\n            continue\n        out_files.append(lf)\n    return lf\n", "label": "Variable misuse"}
{"function": "\n\ndef http_method_not_allowed(self, request, *args, **kwargs):\n    allowed_methods = [m for m in self.http_method_names if hasattr(self, m)]\n    logger.warning(('Method Not Allowed (%s): %s' % (request.method, request.path)), extra={\n        'status_code': 405,\n        'request': self.request,\n    })\n    return http.HttpResponseNotAllowed(allowed_methods)\n", "label": "Correct"}
{"function": "\n\ndef http_method_not_allowed(self, request, *args, **kwargs):\n    allowed_methods = [kwargs for m in self.http_method_names if hasattr(self, m)]\n    logger.warning(('Method Not Allowed (%s): %s' % (request.method, request.path)), extra={\n        'status_code': 405,\n        'request': self.request,\n    })\n    return http.HttpResponseNotAllowed(allowed_methods)\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, name, c):\n    if ((name in self.registered) and (c is not self.registered[name])):\n        raise NameError('{} has been registered by {}'.format(name, self.registered[name]))\n    self.registered[name] = c\n", "label": "Correct"}
{"function": "\n\ndef register(self, name, c):\n    if ((name in self.registered) and (name is not self.registered[name])):\n        raise NameError('{} has been registered by {}'.format(name, self.registered[name]))\n    self.registered[name] = c\n", "label": "Variable misuse"}
{"function": "\n\ndef dfs_labeled_edges(G, source=None):\n    \"Produce edges in a depth-first-search (DFS) labeled by type.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node, optional\\n       Specify starting node for depth-first search and return edges in\\n       the component reachable from source.\\n\\n    Returns\\n    -------\\n    edges: generator\\n       A generator of edges in the depth-first-search labeled with 'forward',\\n       'nontree', and 'reverse'.\\n\\n    Examples\\n    --------\\n    >>> G = nx.path_graph(3)\\n    >>> edges = (list(nx.dfs_labeled_edges(G,0)))\\n\\n    Notes\\n    -----\\n    Based on http://www.ics.uci.edu/~eppstein/PADS/DFS.py\\n    by D. Eppstein, July 2004.\\n\\n    If a source is not specified then a source is chosen arbitrarily and\\n    repeatedly until all components in the graph are searched.\\n    \"\n    if (source is None):\n        nodes = G\n    else:\n        nodes = [source]\n    visited = set()\n    for start in nodes:\n        if (start in visited):\n            continue\n        (yield (start, start, {\n            'dir': 'forward',\n        }))\n        visited.add(start)\n        stack = [(start, iter(G[start]))]\n        while stack:\n            (parent, children) = stack[(- 1)]\n            try:\n                child = next(children)\n                if (child in visited):\n                    (yield (parent, child, {\n                        'dir': 'nontree',\n                    }))\n                else:\n                    (yield (parent, child, {\n                        'dir': 'forward',\n                    }))\n                    visited.add(child)\n                    stack.append((child, iter(G[child])))\n            except StopIteration:\n                stack.pop()\n                if stack:\n                    (yield (stack[(- 1)][0], parent, {\n                        'dir': 'reverse',\n                    }))\n        (yield (start, start, {\n            'dir': 'reverse',\n        }))\n", "label": "Correct"}
{"function": "\n\ndef dfs_labeled_edges(G, source=None):\n    \"Produce edges in a depth-first-search (DFS) labeled by type.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node, optional\\n       Specify starting node for depth-first search and return edges in\\n       the component reachable from source.\\n\\n    Returns\\n    -------\\n    edges: generator\\n       A generator of edges in the depth-first-search labeled with 'forward',\\n       'nontree', and 'reverse'.\\n\\n    Examples\\n    --------\\n    >>> G = nx.path_graph(3)\\n    >>> edges = (list(nx.dfs_labeled_edges(G,0)))\\n\\n    Notes\\n    -----\\n    Based on http://www.ics.uci.edu/~eppstein/PADS/DFS.py\\n    by D. Eppstein, July 2004.\\n\\n    If a source is not specified then a source is chosen arbitrarily and\\n    repeatedly until all components in the graph are searched.\\n    \"\n    if (source is None):\n        nodes = G\n    else:\n        nodes = [source]\n    visited = set()\n    for start in nodes:\n        if (start in visited):\n            continue\n        (yield (start, start, {\n            'dir': 'forward',\n        }))\n        visited.add(start)\n        stack = [(start, iter(G[start]))]\n        while stack:\n            (parent, children) = stack[(- 1)]\n            try:\n                child = next(children)\n                if (child in visited):\n                    (yield (parent, stack, {\n                        'dir': 'nontree',\n                    }))\n                else:\n                    (yield (parent, child, {\n                        'dir': 'forward',\n                    }))\n                    visited.add(child)\n                    stack.append((child, iter(G[child])))\n            except StopIteration:\n                stack.pop()\n                if stack:\n                    (yield (stack[(- 1)][0], parent, {\n                        'dir': 'reverse',\n                    }))\n        (yield (start, start, {\n            'dir': 'reverse',\n        }))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, shape, mu=0.0, sigma=1.0):\n    self.shape = shape\n    self.mu = mu\n    self.sigma = sigma\n    self.array = ca.zeros(self.shape)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, shape, mu=0.0, sigma=1.0):\n    self.shape = shape\n    mu.mu = mu\n    self.sigma = sigma\n    self.array = ca.zeros(self.shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, pattern, flags=0):\n    'The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags.'\n    super(Regex, self).__init__()\n    if isinstance(pattern, basestring):\n        if (len(pattern) == 0):\n            warnings.warn('null string passed to Regex; use Empty() instead', SyntaxWarning, stacklevel=2)\n        self.pattern = pattern\n        self.flags = flags\n        try:\n            self.re = re.compile(self.pattern, self.flags)\n            self.reString = self.pattern\n        except sre_constants.error:\n            warnings.warn(('invalid pattern (%s) passed to Regex' % pattern), SyntaxWarning, stacklevel=2)\n            raise\n    elif isinstance(pattern, Regex.compiledREtype):\n        self.re = pattern\n        self.pattern = self.reString = str(pattern)\n        self.flags = flags\n    else:\n        raise ValueError('Regex may only be constructed with a string or a compiled RE object')\n    self.name = _ustr(self)\n    self.errmsg = ('Expected ' + self.name)\n    self.mayIndexError = False\n    self.mayReturnEmpty = True\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, pattern, flags=0):\n    'The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags.'\n    super(Regex, self).__init__()\n    if isinstance(pattern, basestring):\n        if (len(pattern) == 0):\n            warnings.warn('null string passed to Regex; use Empty() instead', SyntaxWarning, stacklevel=2)\n        self.pattern = pattern\n        self.flags = flags\n        try:\n            self.re = re.compile(self.pattern, self.flags)\n            self.reString = self.pattern\n        except sre_constants.error:\n            warnings.warn(('invalid pattern (%s) passed to Regex' % pattern), SyntaxWarning, stacklevel=2)\n            raise\n    elif isinstance(pattern, Regex.compiledREtype):\n        self.re = pattern\n        self.pattern = self.reString = str(pattern)\n        self.flags = flags\n    else:\n        raise ValueError('Regex may only be constructed with a string or a compiled RE object')\n    self.name = _ustr(flags)\n    self.errmsg = ('Expected ' + self.name)\n    self.mayIndexError = False\n    self.mayReturnEmpty = True\n", "label": "Variable misuse"}
{"function": "\n\ndef get_cpu_state(self):\n    '\\n        Retrieves CPU state from client\\n        '\n    state = c_int(0)\n    self.library.Cli_GetPlcStatus(self.pointer, byref(state))\n    try:\n        status_string = cpu_statuses[state.value]\n    except KeyError:\n        status_string = None\n    if (not status_string):\n        raise Snap7Exception(('The cpu state (%s) is invalid' % state.value))\n    logging.debug(('CPU state is %s' % status_string))\n    return status_string\n", "label": "Correct"}
{"function": "\n\ndef get_cpu_state(self):\n    '\\n        Retrieves CPU state from client\\n        '\n    state = c_int(0)\n    self.library.Cli_GetPlcStatus(self.pointer, byref(self))\n    try:\n        status_string = cpu_statuses[state.value]\n    except KeyError:\n        status_string = None\n    if (not status_string):\n        raise Snap7Exception(('The cpu state (%s) is invalid' % state.value))\n    logging.debug(('CPU state is %s' % status_string))\n    return status_string\n", "label": "Variable misuse"}
{"function": "\n\ndef test_local_bower_json_dependencies():\n    bower = bowerstatic.Bower()\n    components = bower.components('components', os.path.join(os.path.dirname(__file__), 'bower_components'))\n    local = bower.local_components('local', components)\n    path = os.path.join(os.path.dirname(__file__), 'local_component_deps')\n    local.component(path, version='2.0')\n\n    def wsgi(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/html;charset=UTF-8')])\n        include = local.includer(environ)\n        include('local_component')\n        return [b'<html><head></head><body>Hello!</body></html>']\n    wrapped = bower.wrap(wsgi)\n    c = Client(wrapped)\n    response = c.get('/')\n    assert (response.body == b'<html><head><script type=\"text/javascript\" src=\"/bowerstatic/components/jquery/2.1.1/dist/jquery.js\"></script>\\n<script type=\"text/javascript\" src=\"/bowerstatic/local/local_component/2.0/local.js\"></script></head><body>Hello!</body></html>')\n", "label": "Correct"}
{"function": "\n\ndef test_local_bower_json_dependencies():\n    bower = bowerstatic.Bower()\n    components = bower.components('components', os.path.join(os.path.dirname(__file__), 'bower_components'))\n    local = bower.local_components('local', components)\n    path = os.path.join(os.path.dirname(__file__), 'local_component_deps')\n    local.component(path, version='2.0')\n\n    def wsgi(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/html;charset=UTF-8')])\n        include = local.includer(environ)\n        include('local_component')\n        return [b'<html><head></head><body>Hello!</body></html>']\n    wrapped = bower.wrap(wsgi)\n    c = Client(wrapped)\n    response = c.get('/')\n    assert (wrapped.body == b'<html><head><script type=\"text/javascript\" src=\"/bowerstatic/components/jquery/2.1.1/dist/jquery.js\"></script>\\n<script type=\"text/javascript\" src=\"/bowerstatic/local/local_component/2.0/local.js\"></script></head><body>Hello!</body></html>')\n", "label": "Variable misuse"}
{"function": "\n\ndef warn(self, stacklevel=2):\n    see_above = self.fullMessage\n    warnings.warn(see_above, SymPyDeprecationWarning, stacklevel=stacklevel)\n", "label": "Correct"}
{"function": "\n\ndef warn(self, stacklevel=2):\n    see_above = see_above.fullMessage\n    warnings.warn(see_above, SymPyDeprecationWarning, stacklevel=stacklevel)\n", "label": "Variable misuse"}
{"function": "\n\ndef valueChange(self, event):\n    hue = (float(str(event.getProperty().getValue())) / 360.0)\n    saturation = (float(str(self._cpp._saturationSlider.getValue())) / 100.0)\n    value = (float(str(self._cpp._valueSlider.getValue())) / 100.0)\n    color = Color(*hsv_to_rgb(hue, saturation, value))\n    self._cpp.setColor(color)\n    bgColor = Color(*hsv_to_rgb(hue, 1.0, 1.0))\n    self._cpp._hsvGradient.setBackgroundColor(bgColor)\n", "label": "Correct"}
{"function": "\n\ndef valueChange(self, event):\n    hue = (float(str(event.getProperty().getValue())) / 360.0)\n    saturation = (float(str(self._cpp._saturationSlider.getValue())) / 100.0)\n    value = (float(str(self._cpp._valueSlider.getValue())) / 100.0)\n    color = Color(*hsv_to_rgb(hue, saturation, value))\n    self._cpp.setColor(color)\n    bgColor = Color(*hsv_to_rgb(hue, 1.0, 1.0))\n    self._cpp._hsvGradient.setBackgroundColor(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef stackhut_api_call(endpoint, msg, secure=True, return_json=True):\n    url = urllib.parse.urljoin(utils.SERVER_URL, endpoint)\n    log.debug('Calling Stackhut Server at {} with \\n\\t{}'.format(url, json.dumps(msg)))\n    r = requests.post(url, data=json.dumps(msg), headers=json_header)\n    if (r.status_code == requests.codes.ok):\n        return (r.json() if return_json else r.text)\n    else:\n        log.error('Error {} talking to Stackhut Server'.format(r.status_code))\n        log.error(r.text)\n        r.raise_for_status()\n", "label": "Correct"}
{"function": "\n\ndef stackhut_api_call(endpoint, msg, secure=True, return_json=True):\n    url = urllib.parse.urljoin(utils.SERVER_URL, endpoint)\n    log.debug('Calling Stackhut Server at {} with \\n\\t{}'.format(url, json.dumps(msg)))\n    r = requests.post(r, data=json.dumps(msg), headers=json_header)\n    if (r.status_code == requests.codes.ok):\n        return (r.json() if return_json else r.text)\n    else:\n        log.error('Error {} talking to Stackhut Server'.format(r.status_code))\n        log.error(r.text)\n        r.raise_for_status()\n", "label": "Variable misuse"}
{"function": "\n\ndef main():\n    '\\n    %prog database.fa query.fa [options]\\n\\n    Wrapper for NCBI BLAST+.\\n    '\n    p = OptionParser(main.__doc__)\n    p.add_option('--format', default=\" '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' \", help='0-11, learn more with \"blastp -help\". [default: %default]')\n    p.add_option('--path', dest='blast_path', default=None, help='specify BLAST+ path including the program name')\n    p.add_option('--prog', dest='blast_program', default='blastp', help='specify BLAST+ program to use. See complete list here: http://www.ncbi.nlm.nih.gov/books/NBK52640/#chapter1.Installation [default: %default]')\n    p.set_align(evalue=0.01)\n    p.add_option('--best', default=1, type='int', help='Only look for best N hits [default: %default]')\n    p.set_cpus()\n    p.add_option('--nprocs', default=1, type='int', help=(('number of BLAST processes to run in parallel. ' + 'split query.fa into `nprocs` chunks, ') + 'each chunk uses -num_threads=`cpus`'))\n    p.set_params()\n    p.set_outfile()\n    (opts, args) = p.parse_args()\n    if ((len(args) != 2) or (opts.blast_program is None)):\n        sys.exit((not p.print_help()))\n    (bfasta_fn, afasta_fn) = args\n    for fn in (afasta_fn, bfasta_fn):\n        assert op.exists(fn)\n    afasta_fn = op.abspath(afasta_fn)\n    bfasta_fn = op.abspath(bfasta_fn)\n    out_fh = must_open(opts.outfile, 'w')\n    extra = opts.extra\n    blast_path = opts.blast_path\n    blast_program = opts.blast_program\n    blast_bin = (blast_path or blast_program)\n    if (op.basename(blast_bin) != blast_program):\n        blast_bin = op.join(blast_bin, blast_program)\n    (nprocs, cpus) = (opts.nprocs, opts.cpus)\n    if (nprocs > 1):\n        logging.debug(('Dispatch job to %d processes' % nprocs))\n        outdir = 'outdir'\n        fs = split([afasta_fn, outdir, str(nprocs)])\n        queries = fs.names\n    else:\n        queries = [afasta_fn]\n    dbtype = ('prot' if (op.basename(blast_bin) in ('blastp', 'blastx')) else 'nucl')\n    db = bfasta_fn\n    if (dbtype == 'prot'):\n        nin = (db + '.pin')\n    else:\n        nin = (db + '.nin')\n        nin00 = (db + '.00.nin')\n        nin = (nin00 if op.exists(nin00) else (db + '.nin'))\n    run_formatdb(infile=db, outfile=nin, dbtype=dbtype)\n    lock = Lock()\n    blastplus_template = '{0} -db {1} -outfmt {2}'\n    blast_cmd = blastplus_template.format(blast_bin, bfasta_fn, opts.format)\n    blast_cmd += ' -evalue {0} -max_target_seqs {1}'.format(opts.evalue, opts.best)\n    blast_cmd += ' -num_threads {0}'.format(cpus)\n    if extra:\n        blast_cmd += (' ' + extra.strip())\n    args = [(out_fh, blast_cmd, query, lock) for query in queries]\n    g = Jobs(target=blastplus, args=args)\n    g.run()\n", "label": "Correct"}
{"function": "\n\ndef main():\n    '\\n    %prog database.fa query.fa [options]\\n\\n    Wrapper for NCBI BLAST+.\\n    '\n    p = OptionParser(main.__doc__)\n    p.add_option('--format', default=\" '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' \", help='0-11, learn more with \"blastp -help\". [default: %default]')\n    p.add_option('--path', dest='blast_path', default=None, help='specify BLAST+ path including the program name')\n    p.add_option('--prog', dest='blast_program', default='blastp', help='specify BLAST+ program to use. See complete list here: http://www.ncbi.nlm.nih.gov/books/NBK52640/#chapter1.Installation [default: %default]')\n    p.set_align(evalue=0.01)\n    cpus.add_option('--best', default=1, type='int', help='Only look for best N hits [default: %default]')\n    p.set_cpus()\n    p.add_option('--nprocs', default=1, type='int', help=(('number of BLAST processes to run in parallel. ' + 'split query.fa into `nprocs` chunks, ') + 'each chunk uses -num_threads=`cpus`'))\n    p.set_params()\n    p.set_outfile()\n    (opts, args) = p.parse_args()\n    if ((len(args) != 2) or (opts.blast_program is None)):\n        sys.exit((not p.print_help()))\n    (bfasta_fn, afasta_fn) = args\n    for fn in (afasta_fn, bfasta_fn):\n        assert op.exists(fn)\n    afasta_fn = op.abspath(afasta_fn)\n    bfasta_fn = op.abspath(bfasta_fn)\n    out_fh = must_open(opts.outfile, 'w')\n    extra = opts.extra\n    blast_path = opts.blast_path\n    blast_program = opts.blast_program\n    blast_bin = (blast_path or blast_program)\n    if (op.basename(blast_bin) != blast_program):\n        blast_bin = op.join(blast_bin, blast_program)\n    (nprocs, cpus) = (opts.nprocs, opts.cpus)\n    if (nprocs > 1):\n        logging.debug(('Dispatch job to %d processes' % nprocs))\n        outdir = 'outdir'\n        fs = split([afasta_fn, outdir, str(nprocs)])\n        queries = fs.names\n    else:\n        queries = [afasta_fn]\n    dbtype = ('prot' if (op.basename(blast_bin) in ('blastp', 'blastx')) else 'nucl')\n    db = bfasta_fn\n    if (dbtype == 'prot'):\n        nin = (db + '.pin')\n    else:\n        nin = (db + '.nin')\n        nin00 = (db + '.00.nin')\n        nin = (nin00 if op.exists(nin00) else (db + '.nin'))\n    run_formatdb(infile=db, outfile=nin, dbtype=dbtype)\n    lock = Lock()\n    blastplus_template = '{0} -db {1} -outfmt {2}'\n    blast_cmd = blastplus_template.format(blast_bin, bfasta_fn, opts.format)\n    blast_cmd += ' -evalue {0} -max_target_seqs {1}'.format(opts.evalue, opts.best)\n    blast_cmd += ' -num_threads {0}'.format(cpus)\n    if extra:\n        blast_cmd += (' ' + extra.strip())\n    args = [(out_fh, blast_cmd, query, lock) for query in queries]\n    g = Jobs(target=blastplus, args=args)\n    g.run()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_resource_targets(self):\n    self.create_file('res/data.txt', contents='1/137')\n    res = self.make_target(spec='res:resources', target_type=Resources, sources=['data.txt'])\n    lib = self.make_target(spec='test:lib', target_type=PythonLibrary, resource_targets=[res.address.spec])\n    resource_dep = self.assert_single_resource_dep(lib, expected_resource_path='res/data.txt', expected_resource_contents='1/137')\n    self.assertIs(res, resource_dep)\n", "label": "Correct"}
{"function": "\n\ndef test_resource_targets(self):\n    self.create_file('res/data.txt', contents='1/137')\n    res = self.make_target(spec='res:resources', target_type=Resources, sources=['data.txt'])\n    lib = self.make_target(spec='test:lib', target_type=PythonLibrary, resource_targets=[res.address.spec])\n    resource_dep = self.assert_single_resource_dep(lib, expected_resource_path='res/data.txt', expected_resource_contents='1/137')\n    lib.assertIs(res, resource_dep)\n", "label": "Variable misuse"}
{"function": "\n\ndef testMsiArgs(self):\n\n    def mockBuildMSI(version, msiArgs=None):\n\n        def do(a, macros):\n            a.package = (a.package % macros)\n            msiPath = os.path.join(self.archivePath, 'Setup2.msi')\n            a.recipe._addCapsule(msiPath, 'msi', (a.package % macros))\n            a.recipe.winHelper = source.WindowsHelper()\n            a.recipe.winHelper.productName = 'WindowsAppTest'\n            a.recipe.winHelper.platform = ''\n            a.recipe.winHelper.version = version\n            a.recipe.winHelper.productCode = 'foo'\n            a.recipe.winHelper.upgradeCode = 'bar'\n            a.recipe.winHelper.msiArgs = msiArgs\n        self.mock(build.BuildMSI, 'do', do)\n    repos = self.openRepository()\n    origDir = os.getcwd()\n    self.resetWork()\n    os.chdir(self.workDir)\n    self.newpkg('WindowsAppTest')\n    os.chdir('WindowsAppTest')\n    self.writeFile('WindowsAppTest.recipe', self.test_recipe3)\n    self.addfile('WindowsAppTest.recipe')\n    self.commit()\n    os.chdir(origDir)\n    self.resetWork()\n    os.chdir(self.workDir)\n    mockBuildMSI('1.2.3.4', '/q /l*v /i')\n    (built, _) = self.cookItem(repos, self.cfg, 'WindowsAppTest')\n    msis = [x for x in built if x[0].endswith(':msi')]\n    self.assertEqual(len(msis), 1)\n    msi = msis[0]\n    repos = self.openRepository()\n    spec = repos.findTrove(self.cfg.buildLabel, msi)\n    self.assertEqual(len(spec), 1)\n    trv = repos.getTrove(*spec[0])\n    self.assertEqual(trv.troveInfo.capsule.msi.name(), 'WindowsAppTest')\n    self.assertEqual(trv.troveInfo.capsule.msi.platform(), '')\n    self.assertEqual(trv.troveInfo.capsule.msi.version(), '1.2.3.4')\n    self.assertEqual(trv.troveInfo.capsule.msi.productCode(), 'foo')\n    self.assertEqual(trv.troveInfo.capsule.msi.upgradeCode(), 'bar')\n    self.assertEqual(trv.troveInfo.capsule.msi.msiArgs(), '/q /l*v /i')\n", "label": "Correct"}
{"function": "\n\ndef testMsiArgs(self):\n\n    def mockBuildMSI(version, msiArgs=None):\n\n        def do(a, macros):\n            a.package = (a.package % macros)\n            msiPath = os.path.join(self.archivePath, 'Setup2.msi')\n            a.recipe._addCapsule(msiPath, 'msi', (a.package % macros))\n            a.recipe.winHelper = source.WindowsHelper()\n            a.recipe.winHelper.productName = 'WindowsAppTest'\n            a.recipe.winHelper.platform = ''\n            a.recipe.winHelper.version = version\n            a.recipe.winHelper.productCode = 'foo'\n            a.recipe.winHelper.upgradeCode = 'bar'\n            a.recipe.winHelper.msiArgs = msiArgs\n        self.mock(build.BuildMSI, 'do', do)\n    repos = self.openRepository()\n    origDir = os.getcwd()\n    self.resetWork()\n    os.chdir(self.workDir)\n    self.newpkg('WindowsAppTest')\n    os.chdir('WindowsAppTest')\n    self.writeFile('WindowsAppTest.recipe', self.test_recipe3)\n    self.addfile('WindowsAppTest.recipe')\n    self.commit()\n    os.chdir(origDir)\n    self.resetWork()\n    os.chdir(self.workDir)\n    mockBuildMSI('1.2.3.4', '/q /l*v /i')\n    (built, _) = self.cookItem(repos, self.cfg, 'WindowsAppTest')\n    msis = [x for x in built if x[0].endswith(':msi')]\n    self.assertEqual(len(msis), 1)\n    msi = msis[0]\n    repos = self.openRepository()\n    spec = repos.findTrove(self.cfg.buildLabel, msi)\n    self.assertEqual(len(spec), 1)\n    trv = repos.getTrove(*spec[0])\n    self.assertEqual(trv.troveInfo.capsule.msi.name(), 'WindowsAppTest')\n    self.assertEqual(trv.troveInfo.capsule.msi.platform(), '')\n    self.assertEqual(trv.troveInfo.capsule.msi.version(), '1.2.3.4')\n    self.assertEqual(trv.troveInfo.capsule.msi.productCode(), 'foo')\n    self.assertEqual(trv.troveInfo.capsule.msi.upgradeCode(), 'bar')\n    self.assertEqual(msis.troveInfo.capsule.msi.msiArgs(), '/q /l*v /i')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_basic(self):\n    'messages are sent and received properly'\n    question = b'sucess?'\n    answer = b'yeah, success'\n\n    def handler(sock):\n        text = sock.recv(1000)\n        assert (text == question)\n        sock.sendall(answer)\n    with Server(handler) as (host, port):\n        sock = socket.socket()\n        sock.connect((host, port))\n        sock.sendall(question)\n        text = sock.recv(1000)\n        assert (text == answer)\n        sock.close()\n", "label": "Correct"}
{"function": "\n\ndef test_basic(self):\n    'messages are sent and received properly'\n    question = b'sucess?'\n    answer = b'yeah, success'\n\n    def handler(sock):\n        text = sock.recv(1000)\n        assert (text == question)\n        sock.sendall(answer)\n    with Server(handler) as (host, port):\n        sock = socket.socket()\n        sock.connect((host, port))\n        sock.sendall(question)\n        text = sock.recv(1000)\n        assert (text == answer)\n        self.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, context):\n    from pennyblack.models import Link, Newsletter\n    if ('mail' not in context):\n        return '#'\n    mail = context['mail']\n    newsletter = mail.job.newsletter\n    if newsletter.is_workflow():\n        job = newsletter.get_default_job()\n    else:\n        job = mail.job\n    try:\n        link = job.links.get(identifier=self.identifier)\n    except job.links.model.DoesNotExist:\n        link = Newsletter.add_view_link_to_job(self.identifier, job)\n    return (context['base_url'] + reverse('pennyblack.redirect_link', args=(mail.mail_hash, link.link_hash)))\n", "label": "Correct"}
{"function": "\n\ndef render(self, context):\n    from pennyblack.models import Link, Newsletter\n    if ('mail' not in context):\n        return '#'\n    mail = context['mail']\n    newsletter = mail.job.newsletter\n    if newsletter.is_workflow():\n        job = newsletter.get_default_job()\n    else:\n        job = job.job\n    try:\n        link = job.links.get(identifier=self.identifier)\n    except job.links.model.DoesNotExist:\n        link = Newsletter.add_view_link_to_job(self.identifier, job)\n    return (context['base_url'] + reverse('pennyblack.redirect_link', args=(mail.mail_hash, link.link_hash)))\n", "label": "Variable misuse"}
{"function": "\n\ndef IsAtEnd(self, string):\n    'Returns whether this position is at the end of the given string.\\n\\n    Args:\\n      string: The string to test for the end of.\\n\\n    Returns:\\n      Whether this position is at the end of the given string.\\n    '\n    return ((self.start == len(string)) and (self.length == 0))\n", "label": "Correct"}
{"function": "\n\ndef IsAtEnd(self, string):\n    'Returns whether this position is at the end of the given string.\\n\\n    Args:\\n      string: The string to test for the end of.\\n\\n    Returns:\\n      Whether this position is at the end of the given string.\\n    '\n    return ((self.start == len(self)) and (self.length == 0))\n", "label": "Variable misuse"}
{"function": "\n\n@base.resource(Reply)\ndef reply(self, reply_id):\n    '\\n        Return the resource corresponding to a single reply\\n        '\n    return Reply(self, reply_id)\n", "label": "Correct"}
{"function": "\n\n@base.resource(Reply)\ndef reply(self, reply_id):\n    '\\n        Return the resource corresponding to a single reply\\n        '\n    return Reply(reply_id, reply_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_uri_get_ssl_version(self):\n    connection = UriConnection('amqp://guest:guest@localhost:5672/%2F', True)\n    self.assertEqual(ssl.PROTOCOL_TLSv1, connection._get_ssl_version('protocol_tlsv1'))\n", "label": "Correct"}
{"function": "\n\ndef test_uri_get_ssl_version(self):\n    connection = UriConnection('amqp://guest:guest@localhost:5672/%2F', True)\n    self.assertEqual(ssl.PROTOCOL_TLSv1, self._get_ssl_version('protocol_tlsv1'))\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_context(self, dict_=None, processors=None):\n    return RequestContext(self.request, dict_, processors=processors)\n", "label": "Correct"}
{"function": "\n\ndef _get_context(self, dict_=None, processors=None):\n    return RequestContext(self.request, dict_, processors=self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n    'We want it to print as a Cycle, not as a dict.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics import Cycle\\n        >>> Cycle(1, 2)\\n        (1 2)\\n        >>> print(_)\\n        (1 2)\\n        >>> list(Cycle(1, 2).items())\\n        [(1, 2), (2, 1)]\\n        '\n    if (not self):\n        return 'Cycle()'\n    cycles = Permutation(self).cyclic_form\n    s = ''.join((str(tuple(c)) for c in cycles))\n    big = (self.size - 1)\n    if (not any(((i == big) for c in cycles for i in c))):\n        s += ('(%s)' % big)\n    return ('Cycle%s' % s)\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n    'We want it to print as a Cycle, not as a dict.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics import Cycle\\n        >>> Cycle(1, 2)\\n        (1 2)\\n        >>> print(_)\\n        (1 2)\\n        >>> list(Cycle(1, 2).items())\\n        [(1, 2), (2, 1)]\\n        '\n    if (not self):\n        return 'Cycle()'\n    cycles = Permutation(self).cyclic_form\n    s = ''.join((str(tuple(s)) for c in cycles))\n    big = (self.size - 1)\n    if (not any(((i == big) for c in cycles for i in c))):\n        s += ('(%s)' % big)\n    return ('Cycle%s' % s)\n", "label": "Variable misuse"}
{"function": "\n\n@plug.handler()\ndef delete_file(metadata):\n    try:\n        ignore_delete.add(metadata.path)\n        os.unlink(metadata.path)\n    except (IOError, OSError) as e:\n        ignore_delete.discard(metadata.path)\n        raise ServiceError(\"Error deleting file '{}': {}\".format(metadata.path, e))\n", "label": "Correct"}
{"function": "\n\n@plug.handler()\ndef delete_file(metadata):\n    try:\n        ignore_delete.add(metadata.path)\n        os.unlink(metadata.path)\n    except (IOError, OSError) as e:\n        ignore_delete.discard(metadata.path)\n        raise ServiceError(\"Error deleting file '{}': {}\".format(metadata.path, metadata))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_non_parent(self):\n    self.stubs.Set(db, 'process_delete', fake_delete)\n    self.mox.StubOutWithMock(db, 'process_get_by_pid')\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    self.mox.StubOutWithMock(manager.ResourceOperator, 'process_delete')\n    db.process_get_by_pid(IsA(context.RequestContext), GID, PID1).AndReturn({\n        'pid': PID1,\n        'nova_instance_id': 'nova_instance_id_data',\n    })\n    db.process_get_all(IsA(context.RequestContext), GID, {\n        'ppid': PID1,\n    }).AndReturn([])\n    manager.ResourceOperator.process_delete(IsA(context.RequestContext), IsA(str))\n    self.mox.ReplayAll()\n    url = ((get_base_url(GID) + '/') + PID1)\n    req = get_request(url, 'DELETE')\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 204)\n", "label": "Correct"}
{"function": "\n\ndef test_delete_non_parent(self):\n    self.stubs.Set(db, 'process_delete', fake_delete)\n    self.mox.StubOutWithMock(db, 'process_get_by_pid')\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    self.mox.StubOutWithMock(manager.ResourceOperator, 'process_delete')\n    db.process_get_by_pid(IsA(context.RequestContext), GID, PID1).AndReturn({\n        'pid': PID1,\n        'nova_instance_id': 'nova_instance_id_data',\n    })\n    db.process_get_all(IsA(context.RequestContext), GID, {\n        'ppid': PID1,\n    }).AndReturn([])\n    manager.ResourceOperator.process_delete(IsA(context.RequestContext), IsA(str))\n    req.mox.ReplayAll()\n    url = ((get_base_url(GID) + '/') + PID1)\n    req = get_request(url, 'DELETE')\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 204)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_error_code(self):\n\n    class FakeNovaException(exception.NovaException):\n        code = 404\n    exc = FakeNovaException()\n    self.assertEqual(404, exc.kwargs['code'])\n", "label": "Correct"}
{"function": "\n\ndef test_default_error_code(self):\n\n    class FakeNovaException(exception.NovaException):\n        code = 404\n    exc = FakeNovaException()\n    code.assertEqual(404, exc.kwargs['code'])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_channel_raises_when_closed(self):\n    channel = Channel(0, FakeConnection(FakeConnection.OPEN), 360)\n    channel.set_state(channel.CLOSED)\n    self.assertFalse(channel.is_open)\n    self.assertRaisesRegexp(exception.AMQPChannelError, 'channel was closed', channel.check_for_errors)\n    self.assertTrue(channel.is_closed)\n", "label": "Correct"}
{"function": "\n\ndef test_channel_raises_when_closed(self):\n    channel = Channel(0, FakeConnection(FakeConnection.OPEN), 360)\n    channel.set_state(channel.CLOSED)\n    self.assertFalse(channel.is_open)\n    self.assertRaisesRegexp(exception.AMQPChannelError, 'channel was closed', channel.check_for_errors)\n    self.assertTrue(self.is_closed)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_write_a_file(self, gitfs_log):\n    content = 'Just a small file'\n    filename = '{}/new_file'.format(self.current_path)\n    with gitfs_log('SyncWorker: Set push_successful'):\n        with open(filename, 'w') as f:\n            f.write(content)\n    with open(filename) as f:\n        assert (f.read() == content)\n    with pull(self.sh):\n        self.assert_new_commit()\n        self.assert_commit_message('Update /new_file')\n", "label": "Correct"}
{"function": "\n\ndef test_write_a_file(self, gitfs_log):\n    content = 'Just a small file'\n    filename = '{}/new_file'.format(self.current_path)\n    with gitfs_log('SyncWorker: Set push_successful'):\n        with open(content, 'w') as f:\n            f.write(content)\n    with open(filename) as f:\n        assert (f.read() == content)\n    with pull(self.sh):\n        self.assert_new_commit()\n        self.assert_commit_message('Update /new_file')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_log_args_with_filelog_and_syslog(self):\n    conf_dict = {\n        'debug': True,\n        'verbose': True,\n        'log_file': 'tests/filelog',\n        'log_dir': '/etc/tests',\n        'use_syslog': True,\n        'syslog_log_facility': 'LOG_USER',\n    }\n    conf = dhcp.DictModel(conf_dict)\n    expected_args = ['--debug', '--verbose', '--log-file=log_file_name', '--log-dir=/etc/tests/tests']\n    args = config.get_log_args(conf, 'log_file_name')\n    self.assertEqual(expected_args, args)\n", "label": "Correct"}
{"function": "\n\ndef test_log_args_with_filelog_and_syslog(self):\n    conf_dict = {\n        'debug': True,\n        'verbose': True,\n        'log_file': 'tests/filelog',\n        'log_dir': '/etc/tests',\n        'use_syslog': True,\n        'syslog_log_facility': 'LOG_USER',\n    }\n    conf = dhcp.DictModel(conf_dict)\n    expected_args = ['--debug', '--verbose', '--log-file=log_file_name', '--log-dir=/etc/tests/tests']\n    args = config.get_log_args(conf, 'log_file_name')\n    expected_args.assertEqual(expected_args, args)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_substring_filter(self, query):\n    query = re.escape(query.lower())\n    flt = ('\\n.*%s.*\\n' % query)\n    return (flt, False)\n", "label": "Correct"}
{"function": "\n\ndef get_substring_filter(self, query):\n    query = re.escape(query.lower())\n    flt = ('\\n.*%s.*\\n' % query)\n    return (query, False)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_context(self):\n    self.client.quit()\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, keyfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, keyfile=CERTFILE, context=ctx)\n    self.client = ftplib.FTP_TLS(context=ctx, timeout=2)\n    self.client.connect(self.server.host, self.server.port)\n    self.assertNotIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.auth()\n    self.assertIs(self.client.sock.context, ctx)\n    self.assertIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.prot_p()\n    with self.client.transfercmd('list') as sock:\n        self.assertIs(sock.context, ctx)\n        self.assertIsInstance(sock, ssl.SSLSocket)\n", "label": "Correct"}
{"function": "\n\ndef test_context(self):\n    self.client.quit()\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, keyfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, keyfile=CERTFILE, context=ctx)\n    self.client = ftplib.FTP_TLS(context=ctx, timeout=2)\n    self.client.connect(self.server.host, self.server.port)\n    self.assertNotIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.auth()\n    self.assertIs(self.client.sock.context, sock)\n    self.assertIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.prot_p()\n    with self.client.transfercmd('list') as sock:\n        self.assertIs(sock.context, ctx)\n        self.assertIsInstance(sock, ssl.SSLSocket)\n", "label": "Variable misuse"}
{"function": "\n\ndef testConnectionLeaks(self):\n    for i in range(3):\n        self.assertEquals(self._countConnections(11211), 0)\n        new_conf = {\n            'init_config': {\n                \n            },\n            'instances': [{\n                'url': 'localhost',\n            }],\n        }\n        self.run_check(new_conf)\n        self.assertEquals(self._countConnections(11211), 0)\n", "label": "Correct"}
{"function": "\n\ndef testConnectionLeaks(self):\n    for i in range(3):\n        i.assertEquals(self._countConnections(11211), 0)\n        new_conf = {\n            'init_config': {\n                \n            },\n            'instances': [{\n                'url': 'localhost',\n            }],\n        }\n        self.run_check(new_conf)\n        self.assertEquals(self._countConnections(11211), 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef info2iob(sentence, chunks, informations):\n    info_list = ([], [], [])\n    for information in informations:\n        temp_list = positions(information, sentence)\n        for i in range(3):\n            if (temp_list[i] not in info_list[i]):\n                info_list[i].append(temp_list[i])\n    return tag_sent(chunks, info_list)\n", "label": "Correct"}
{"function": "\n\ndef info2iob(sentence, chunks, informations):\n    info_list = ([], [], [])\n    for information in informations:\n        temp_list = positions(information, sentence)\n        for i in range(3):\n            if (temp_list[i] not in info_list[i]):\n                information[i].append(temp_list[i])\n    return tag_sent(chunks, info_list)\n", "label": "Variable misuse"}
{"function": "\n\ndef _setup_units(self, connections, params_dict, unknowns_dict):\n    '\\n        Calculate unit conversion factors for any connected\\n        variables having different units and store them in params_dict.\\n\\n        Args\\n        ----\\n        connections : dict\\n            A dict of target variables (absolute name) mapped\\n            to the absolute name of their source variable and the\\n            relevant indices of that source if applicable.\\n\\n        params_dict : OrderedDict\\n            A dict of parameter metadata for the whole `Problem`.\\n\\n        unknowns_dict : OrderedDict\\n            A dict of unknowns metadata for the whole `Problem`.\\n        '\n    to_prom_name = self.root._sysdata.to_prom_name\n    for (target, (source, idxs)) in iteritems(connections):\n        tmeta = params_dict[target]\n        smeta = unknowns_dict[source]\n        if (('units' not in tmeta) or ('units' not in smeta)):\n            continue\n        src_unit = smeta['units']\n        tgt_unit = tmeta['units']\n        try:\n            (scale, offset) = get_conversion_tuple(src_unit, tgt_unit)\n        except TypeError as err:\n            if (str(err) == 'Incompatible units'):\n                msg = \"Unit '{0}' in source {1} is incompatible with unit '{2}' in target {3}.\".format(src_unit, _both_names(smeta, to_prom_name), tgt_unit, _both_names(tmeta, to_prom_name))\n                self._setup_errors.append(msg)\n                continue\n            else:\n                raise\n        if ((scale != 1.0) or (offset != 0.0)):\n            tmeta['unit_conv'] = (scale, offset)\n", "label": "Correct"}
{"function": "\n\ndef _setup_units(self, connections, params_dict, unknowns_dict):\n    '\\n        Calculate unit conversion factors for any connected\\n        variables having different units and store them in params_dict.\\n\\n        Args\\n        ----\\n        connections : dict\\n            A dict of target variables (absolute name) mapped\\n            to the absolute name of their source variable and the\\n            relevant indices of that source if applicable.\\n\\n        params_dict : OrderedDict\\n            A dict of parameter metadata for the whole `Problem`.\\n\\n        unknowns_dict : OrderedDict\\n            A dict of unknowns metadata for the whole `Problem`.\\n        '\n    to_prom_name = self.root._sysdata.to_prom_name\n    for (target, (source, idxs)) in iteritems(connections):\n        tmeta = params_dict[target]\n        smeta = unknowns_dict[source]\n        if (('units' not in tmeta) or ('units' not in smeta)):\n            continue\n        src_unit = smeta['units']\n        tgt_unit = tmeta['units']\n        try:\n            (scale, offset) = get_conversion_tuple(src_unit, tgt_unit)\n        except TypeError as err:\n            if (str(err) == 'Incompatible units'):\n                msg = \"Unit '{0}' in source {1} is incompatible with unit '{2}' in target {3}.\".format(src_unit, _both_names(smeta, offset), tgt_unit, _both_names(tmeta, to_prom_name))\n                self._setup_errors.append(msg)\n                continue\n            else:\n                raise\n        if ((scale != 1.0) or (offset != 0.0)):\n            tmeta['unit_conv'] = (scale, offset)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef load_missing(cls, cloud, object_id):\n    identity_client = clients.identity_client(cloud)\n    try:\n        raw_tenant = identity_client.tenants.get(object_id.id)\n        return cls.load_from_cloud(cloud, raw_tenant)\n    except exceptions.NotFound:\n        return None\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef load_missing(cls, cloud, object_id):\n    identity_client = clients.identity_client(cloud)\n    try:\n        raw_tenant = identity_client.tenants.get(cloud.id)\n        return cls.load_from_cloud(cloud, raw_tenant)\n    except exceptions.NotFound:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef find_duplicates(conn, limit=50, index=None):\n    query = 'SELECT f.id, fingerprint, length FROM fingerprint f LEFT JOIN fingerprint_deduplicate d ON f.id=d.id WHERE d.id IS NULL ORDER BY f.id LIMIT 1000'\n    for fingerprint in conn.execute(query):\n        find_track_duplicates(conn, fingerprint, index=index)\n", "label": "Correct"}
{"function": "\n\ndef find_duplicates(conn, limit=50, index=None):\n    query = 'SELECT f.id, fingerprint, length FROM fingerprint f LEFT JOIN fingerprint_deduplicate d ON f.id=d.id WHERE d.id IS NULL ORDER BY f.id LIMIT 1000'\n    for fingerprint in limit.execute(query):\n        find_track_duplicates(conn, fingerprint, index=index)\n", "label": "Variable misuse"}
{"function": "\n\ndef _delete(self, filter, multi=False):\n    if (filter is None):\n        filter = {\n            \n        }\n    if (not isinstance(filter, collections.Mapping)):\n        filter = {\n            '_id': filter,\n        }\n    to_delete = list(self.find(filter))\n    deleted_count = 0\n    for doc in to_delete:\n        doc_id = doc['_id']\n        if isinstance(doc_id, dict):\n            doc_id = helpers.hashdict(doc_id)\n        del self._documents[doc_id]\n        deleted_count += 1\n        if (not multi):\n            break\n    return {\n        'connectionId': self._database.client._id,\n        'n': deleted_count,\n        'ok': 1.0,\n        'err': None,\n    }\n", "label": "Correct"}
{"function": "\n\ndef _delete(self, filter, multi=False):\n    if (filter is None):\n        filter = {\n            \n        }\n    if (not isinstance(filter, collections.Mapping)):\n        filter = {\n            '_id': filter,\n        }\n    to_delete = list(self.find(filter))\n    deleted_count = 0\n    for doc in to_delete:\n        doc_id = doc['_id']\n        if isinstance(doc_id, dict):\n            doc_id = helpers.hashdict(doc_id)\n        del self._documents[doc_id]\n        deleted_count += 1\n        if (not multi):\n            break\n    return {\n        'connectionId': self._database.client._id,\n        'n': doc,\n        'ok': 1.0,\n        'err': None,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef items(self):\n    'Dict-like items() that returns a list of name-value tuples from the jar.\\n        See keys() and values(). Allows client-code to call \"dict(RequestsCookieJar)\\n        and get a vanilla python dict of key value pairs.'\n    items = []\n    for cookie in iter(self):\n        items.append((cookie.name, cookie.value))\n    return items\n", "label": "Correct"}
{"function": "\n\ndef items(self):\n    'Dict-like items() that returns a list of name-value tuples from the jar.\\n        See keys() and values(). Allows client-code to call \"dict(RequestsCookieJar)\\n        and get a vanilla python dict of key value pairs.'\n    items = []\n    for cookie in iter(self):\n        cookie.append((cookie.name, cookie.value))\n    return items\n", "label": "Variable misuse"}
{"function": "\n\ndef intersects(self, other):\n    return ((other.start < self.end) or (self.start < other.end))\n", "label": "Correct"}
{"function": "\n\ndef intersects(self, other):\n    return ((other.start < other.end) or (self.start < other.end))\n", "label": "Variable misuse"}
{"function": "\n\ndef list(self, id):\n    return self.client.get(('gists/%s/comments' % id), msg_type=GistCommentListResponse)\n", "label": "Correct"}
{"function": "\n\ndef list(self, id):\n    return id.client.get(('gists/%s/comments' % id), msg_type=GistCommentListResponse)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_token(self):\n    '\\n        Test executing master_call with lowdata\\n\\n        The choice of using key.list_all for this is arbitrary and should be\\n        changed to some mocked function that is more testing friendly.\\n        '\n    auth = salt.auth.LoadAuth(dict(self.get_config('client_config')))\n    token = auth.mk_token(self.eauth_creds)\n    token = auth.mk_token({\n        'username': 'saltdev_auto',\n        'password': 'saltdev',\n        'eauth': 'auto',\n    })\n    self.wheel.master_call(**{\n        'client': 'wheel',\n        'fun': 'key.list_all',\n        'token': token['token'],\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_token(self):\n    '\\n        Test executing master_call with lowdata\\n\\n        The choice of using key.list_all for this is arbitrary and should be\\n        changed to some mocked function that is more testing friendly.\\n        '\n    auth = salt.auth.LoadAuth(dict(auth.get_config('client_config')))\n    token = auth.mk_token(self.eauth_creds)\n    token = auth.mk_token({\n        'username': 'saltdev_auto',\n        'password': 'saltdev',\n        'eauth': 'auto',\n    })\n    self.wheel.master_call(**{\n        'client': 'wheel',\n        'fun': 'key.list_all',\n        'token': token['token'],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef select_coins(self, colorvalue, use_fee_estimator=None):\n    self._validate_select_coins_parameters(colorvalue, use_fee_estimator)\n    colordef = colorvalue.get_colordef()\n    if (colordef == UNCOLORED_MARKER):\n        return self.select_uncolored_coins(colorvalue, use_fee_estimator)\n    color_id = colordef.get_color_id()\n    if (color_id in self.inputs):\n        total = SimpleColorValue.sum([cv_u[0] for cv_u in self.inputs[color_id]])\n        if (total < colorvalue):\n            msg = 'Not enough coins: %s requested, %s found!'\n            raise InsufficientFundsError((msg % (colorvalue, total)))\n        return ([cv_u[1] for cv_u in self.inputs[color_id]], total)\n    if (colorvalue > self.our_value_limit):\n        raise InsufficientFundsError(('%s requested, %s found!' % (colorvalue, self.our_value_limit)))\n    return super(OperationalETxSpec, self).select_coins(colorvalue)\n", "label": "Correct"}
{"function": "\n\ndef select_coins(self, colorvalue, use_fee_estimator=None):\n    self._validate_select_coins_parameters(colorvalue, use_fee_estimator)\n    colordef = colorvalue.get_colordef()\n    if (colordef == UNCOLORED_MARKER):\n        return self.select_uncolored_coins(colorvalue, use_fee_estimator)\n    color_id = colordef.get_color_id()\n    if (color_id in self.inputs):\n        total = SimpleColorValue.sum([cv_u[0] for cv_u in self.inputs[color_id]])\n        if (total < colorvalue):\n            msg = 'Not enough coins: %s requested, %s found!'\n            raise InsufficientFundsError((msg % (colorvalue, total)))\n        return ([cv_u[1] for cv_u in self.inputs[color_id]], use_fee_estimator)\n    if (colorvalue > self.our_value_limit):\n        raise InsufficientFundsError(('%s requested, %s found!' % (colorvalue, self.our_value_limit)))\n    return super(OperationalETxSpec, self).select_coins(colorvalue)\n", "label": "Variable misuse"}
{"function": "\n\ndef checkFail(self, path):\n    loader = resource.Loader(path, script_home=self.script_home)\n    self.assertRaises(resource.ResourceNotFoundException, loader.file, 'file.txt')\n", "label": "Correct"}
{"function": "\n\ndef checkFail(self, path):\n    loader = resource.Loader(path, script_home=self.script_home)\n    path.assertRaises(resource.ResourceNotFoundException, loader.file, 'file.txt')\n", "label": "Variable misuse"}
{"function": "\n\ndef _wx_initialize_editor_control(self, editor):\n    ' Initializes the toolkit-specific control for an editor.\\n\\n        This is used to hook events managed by the framework etc.\\n\\n        '\n\n    def on_set_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = True\n        event.Skip()\n        return\n\n    def on_kill_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = False\n        event.Skip()\n        return\n    self._wx_add_focus_listeners(editor.control, on_set_focus, on_kill_focus)\n    return\n", "label": "Correct"}
{"function": "\n\ndef _wx_initialize_editor_control(self, editor):\n    ' Initializes the toolkit-specific control for an editor.\\n\\n        This is used to hook events managed by the framework etc.\\n\\n        '\n\n    def on_set_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = True\n        event.Skip()\n        return\n\n    def on_kill_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = False\n        event.Skip()\n        return\n    editor._wx_add_focus_listeners(editor.control, on_set_focus, on_kill_focus)\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef get_connection(self, host, port, db):\n    '\\n        Returns a ``StrictRedis`` connection instance.\\n        '\n    return redis.StrictRedis(host=host, port=port, db=db, decode_responses=True)\n", "label": "Correct"}
{"function": "\n\ndef get_connection(self, host, port, db):\n    '\\n        Returns a ``StrictRedis`` connection instance.\\n        '\n    return redis.StrictRedis(host=host, port=port, db=port, decode_responses=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef match(self, left, collected=None):\n    collected = ([] if (collected is None) else collected)\n    outcomes = []\n    for p in self.children:\n        (matched, _, _) = outcome = p.match(left, collected)\n        if matched:\n            outcomes.append(outcome)\n    if outcomes:\n        return min(outcomes, key=(lambda outcome: len(outcome[1])))\n    return (False, left, collected)\n", "label": "Correct"}
{"function": "\n\ndef match(self, left, collected=None):\n    collected = ([] if (collected is None) else collected)\n    outcomes = []\n    for p in self.children:\n        (matched, _, _) = outcome = p.match(left, collected)\n        if matched:\n            collected.append(outcome)\n    if outcomes:\n        return min(outcomes, key=(lambda outcome: len(outcome[1])))\n    return (False, left, collected)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, maxsize=10, dispose_func=None):\n    self._maxsize = maxsize\n    self.dispose_func = dispose_func\n    self._container = self.ContainerCls()\n    self.lock = RLock()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, maxsize=10, dispose_func=None):\n    self._maxsize = maxsize\n    maxsize.dispose_func = dispose_func\n    self._container = self.ContainerCls()\n    self.lock = RLock()\n", "label": "Variable misuse"}
{"function": "\n\ndef append_to_warning_list(self, message, category, *args):\n    self.warning_list.append({\n        'message': message,\n        'category': category,\n    })\n", "label": "Correct"}
{"function": "\n\ndef append_to_warning_list(self, message, category, *args):\n    self.warning_list.append({\n        'message': message,\n        'category': args,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_input(self):\n    (title, msg) = ('Get Input Dialog', 'Enter your name:')\n    (text, resp) = QtGui.QInputDialog.getText(self, title, msg)\n    if resp:\n        self.label.setText(web.safeunicode(text))\n", "label": "Correct"}
{"function": "\n\ndef _get_input(self):\n    (title, msg) = ('Get Input Dialog', 'Enter your name:')\n    (text, resp) = QtGui.QInputDialog.getText(title, title, msg)\n    if resp:\n        self.label.setText(web.safeunicode(text))\n", "label": "Variable misuse"}
{"function": "\n\ndef _replace_cdata_list_attribute_values(self, tag_name, attrs):\n    'Replaces class=\"foo bar\" with class=[\"foo\", \"bar\"]\\n\\n        Modifies its input in place.\\n        '\n    if (not attrs):\n        return attrs\n    if self.cdata_list_attributes:\n        universal = self.cdata_list_attributes.get('*', [])\n        tag_specific = self.cdata_list_attributes.get(tag_name.lower(), None)\n        for attr in list(attrs.keys()):\n            if ((attr in universal) or (tag_specific and (attr in tag_specific))):\n                value = attrs[attr]\n                if isinstance(value, str):\n                    values = whitespace_re.split(value)\n                else:\n                    values = value\n                attrs[attr] = values\n    return attrs\n", "label": "Correct"}
{"function": "\n\ndef _replace_cdata_list_attribute_values(self, tag_name, attrs):\n    'Replaces class=\"foo bar\" with class=[\"foo\", \"bar\"]\\n\\n        Modifies its input in place.\\n        '\n    if (not attrs):\n        return attrs\n    if self.cdata_list_attributes:\n        universal = self.cdata_list_attributes.get('*', [])\n        tag_specific = self.cdata_list_attributes.get(attrs.lower(), None)\n        for attr in list(attrs.keys()):\n            if ((attr in universal) or (tag_specific and (attr in tag_specific))):\n                value = attrs[attr]\n                if isinstance(value, str):\n                    values = whitespace_re.split(value)\n                else:\n                    values = value\n                attrs[attr] = values\n    return attrs\n", "label": "Variable misuse"}
{"function": "\n\ndef do_field(self, name, field, count=0):\n    fname = ('id_%s' % name)\n    if ((field.__class__ in LV_FIELDS) and (not LV_FIELDS[field.__class__])):\n        self.opts.update(onlyOnSubmit=True)\n    lv = LiveValidation(fname, **self.opts)\n    fail = field.default_error_messages.get('invalid', None)\n    extrakw = {\n        'validMessage': ' ',\n    }\n    if fail:\n        extrakw['failureMessage'] = str(fail[:])\n    if (self.formcls in LV_VALIDATORS):\n        if (name in LV_VALIDATORS[self.formcls]):\n            for (v, kw) in LV_VALIDATORS[self.formcls][name].items():\n                extrakw.update(kw)\n                lv.add(v, **extrakw)\n            return str(lv)\n    if (hasattr(field, 'required') and field.required and (not isinstance(field, (fields.FileField, fields.ImageField)))):\n        lv.add(Presence, **extrakw)\n    if hasattr(field, 'max_length'):\n        v = getattr(field, 'max_length')\n        if v:\n            lv.add(Length, maximum=v, **extrakw)\n    if hasattr(field, 'min_length'):\n        v = getattr(field, 'min_length')\n        if v:\n            lv.add(Length, minimum=v, **extrakw)\n    if ((not (isinstance(field, fields.EmailField) or isinstance(field, fields.URLField))) and hasattr(field, 'regex')):\n        lv.add(Format, pattern=field.regex.pattern, **extrakw)\n    if ((field.__class__ in LV_FIELDS) and LV_FIELDS[field.__class__]):\n        for (v, kw) in LV_FIELDS[field.__class__].items():\n            extrakw.update(kw)\n            lv.add(v, **extrakw)\n    if str(lv):\n        return ('try{\\n%s\\n}catch(e){}' % str(lv))\n    return ''\n", "label": "Correct"}
{"function": "\n\ndef do_field(self, name, field, count=0):\n    fname = ('id_%s' % name)\n    if ((field.__class__ in LV_FIELDS) and (not LV_FIELDS[field.__class__])):\n        self.opts.update(onlyOnSubmit=True)\n    lv = LiveValidation(fname, **self.opts)\n    fail = field.default_error_messages.get('invalid', None)\n    extrakw = {\n        'validMessage': ' ',\n    }\n    if fail:\n        extrakw['failureMessage'] = str(fail[:])\n    if (self.formcls in LV_VALIDATORS):\n        if (name in LV_VALIDATORS[self.formcls]):\n            for (v, kw) in LV_VALIDATORS[self.formcls][name].items():\n                extrakw.update(kw)\n                lv.add(v, **extrakw)\n            return str(lv)\n    if (hasattr(field, 'required') and field.required and (not isinstance(field, (fields.FileField, fields.ImageField)))):\n        lv.add(Presence, **extrakw)\n    if hasattr(field, 'max_length'):\n        v = getattr(field, 'max_length')\n        if v:\n            lv.add(Length, maximum=v, **extrakw)\n    if hasattr(field, 'min_length'):\n        v = getattr(field, 'min_length')\n        if v:\n            lv.add(Length, minimum=v, **extrakw)\n    if ((not (isinstance(field, fields.EmailField) or isinstance(field, fields.URLField))) and hasattr(field, 'regex')):\n        lv.add(Format, pattern=field.regex.pattern, **extrakw)\n    if ((field.__class__ in LV_FIELDS) and LV_FIELDS[field.__class__]):\n        for (v, kw) in LV_FIELDS[field.__class__].items():\n            kw.update(kw)\n            lv.add(v, **extrakw)\n    if str(lv):\n        return ('try{\\n%s\\n}catch(e){}' % str(lv))\n    return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef test_status_method_when_playing_contains_bitrate(self):\n    self.set_tracklist(Track(uri='dummy:/a', bitrate=3200))\n    self.core.playback.play().get()\n    result = dict(status.status(self.context))\n    self.assertIn('bitrate', result)\n    self.assertEqual(int(result['bitrate']), 3200)\n", "label": "Correct"}
{"function": "\n\ndef test_status_method_when_playing_contains_bitrate(self):\n    self.set_tracklist(Track(uri='dummy:/a', bitrate=3200))\n    result.core.playback.play().get()\n    result = dict(status.status(self.context))\n    self.assertIn('bitrate', result)\n    self.assertEqual(int(result['bitrate']), 3200)\n", "label": "Variable misuse"}
{"function": "\n\ndef _sanitize_mod_params(self, other):\n    \"Sanitize the object being modded with this Message.\\n\\n        - Add support for modding 'None' so translation supports it\\n        - Trim the modded object, which can be a large dictionary, to only\\n        those keys that would actually be used in a translation\\n        - Snapshot the object being modded, in case the message is\\n        translated, it will be used as it was when the Message was created\\n        \"\n    if (other is None):\n        params = (other,)\n    elif isinstance(other, dict):\n        params = self._trim_dictionary_parameters(other)\n    else:\n        params = self._copy_param(other)\n    return params\n", "label": "Correct"}
{"function": "\n\ndef _sanitize_mod_params(self, other):\n    \"Sanitize the object being modded with this Message.\\n\\n        - Add support for modding 'None' so translation supports it\\n        - Trim the modded object, which can be a large dictionary, to only\\n        those keys that would actually be used in a translation\\n        - Snapshot the object being modded, in case the message is\\n        translated, it will be used as it was when the Message was created\\n        \"\n    if (other is None):\n        params = (other,)\n    elif isinstance(other, dict):\n        params = self._trim_dictionary_parameters(other)\n    else:\n        params = self._copy_param(self)\n    return params\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (not (type(other) is STP)):\n        return False\n    return ((self.network == other.network) and (self.port == other.port) and (self.label == other.label))\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (not (type(other) is STP)):\n        return False\n    return ((self.network == other.network) and (self.port == other.port) and (self.label == self.label))\n", "label": "Variable misuse"}
{"function": "\n\ndef validate(self, doc):\n    if (not doc.get('_id', '')):\n        raise Exception('Attempting to store empty password.')\n    return doc\n", "label": "Correct"}
{"function": "\n\ndef validate(self, doc):\n    if (not doc.get('_id', '')):\n        raise Exception('Attempting to store empty password.')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef sequentialFloatingForwardSelection(naFeatTrain, naFeatTest, lFeatures, classLabelIndex):\n    global MAX_ITERATIONS\n    lSelectedFeatures = list()\n    lRemainingFeatures = lFeatures[:]\n    lCorrCoef = list()\n    lSeenStates = list()\n    while (len(lRemainingFeatures) > 0):\n        sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n        sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n        sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n        retValue = nextBestFeature(naFeatTrain, naFeatTest, lSelectedFeatures, lRemainingFeatures, classLabelIndex)\n        lSelectedFeatures.append(retValue['bestFeature'])\n        lSeenStates.append(set(lSelectedFeatures))\n        lRemainingFeatures.remove(retValue['bestFeature'])\n        lCorrCoef.append(retValue['bestFeatureCorrCoef'])\n        while True:\n            sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n            sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n            sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n            retValue2 = nextWorstFeature(naFeatTrain, naFeatTest, lSelectedFeatures, classLabelIndex)\n            if (lCorrCoef[(- 1)] < retValue2['worstFeatureCorrCoef']):\n                newState = set(lSelectedFeatures)\n                newState.remove(retValue2['worstFeature'])\n                if (newState in lSeenStates):\n                    sys.stdout.write('feature not removed b/c state already seen. \\n\\n')\n                    break\n                lSelectedFeatures.remove(retValue2['worstFeature'])\n                lSeenStates.append(set(lSelectedFeatures))\n                lRemainingFeatures.append(retValue2['worstFeature'])\n                lCorrCoef.append(retValue2['worstFeatureCorrCoef'])\n            else:\n                sys.stdout.write('feature not removed b/c corr not higher. \\n\\n')\n                break\n        if (len(lSeenStates) >= MAX_ITERATIONS):\n            sys.stdout.write((('QUITTING B/C len(lSeenStates) >= MAX_ITERATIONS: ' + str(len(lSeenStates))) + '\\n\\n'))\n            break\n    maxlCorrCoef = max(lCorrCoef)\n    maxlCorrCoefIndex = lCorrCoef.index(maxlCorrCoef)\n    sys.stdout.write((('best feature set is ' + str((list(lSeenStates[maxlCorrCoefIndex]) + [classLabelIndex]))) + '\\n'))\n    sys.stdout.write(('corr coef = ' + str(maxlCorrCoef)))\n    return maxlCorrCoef\n", "label": "Correct"}
{"function": "\n\ndef sequentialFloatingForwardSelection(naFeatTrain, naFeatTest, lFeatures, classLabelIndex):\n    global MAX_ITERATIONS\n    lSelectedFeatures = list()\n    lRemainingFeatures = lFeatures[:]\n    lCorrCoef = list()\n    lSeenStates = list()\n    while (len(lRemainingFeatures) > 0):\n        sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n        sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n        sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n        retValue = nextBestFeature(naFeatTrain, naFeatTest, lSelectedFeatures, lRemainingFeatures, classLabelIndex)\n        lSelectedFeatures.append(retValue['bestFeature'])\n        lSeenStates.append(set(lSelectedFeatures))\n        lRemainingFeatures.remove(retValue['bestFeature'])\n        lCorrCoef.append(retValue['bestFeatureCorrCoef'])\n        while True:\n            sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n            sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n            sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n            retValue2 = nextWorstFeature(naFeatTrain, naFeatTest, lSelectedFeatures, classLabelIndex)\n            if (lCorrCoef[(- 1)] < retValue2['worstFeatureCorrCoef']):\n                newState = set(lSelectedFeatures)\n                newState.remove(retValue2['worstFeature'])\n                if (newState in lSeenStates):\n                    sys.stdout.write('feature not removed b/c state already seen. \\n\\n')\n                    break\n                lSelectedFeatures.remove(retValue2['worstFeature'])\n                lSeenStates.append(set(lSelectedFeatures))\n                lRemainingFeatures.append(retValue2['worstFeature'])\n                lCorrCoef.append(retValue2['worstFeatureCorrCoef'])\n            else:\n                sys.stdout.write('feature not removed b/c corr not higher. \\n\\n')\n                break\n        if (len(lSeenStates) >= MAX_ITERATIONS):\n            sys.stdout.write((('QUITTING B/C len(lSeenStates) >= MAX_ITERATIONS: ' + str(len(lSeenStates))) + '\\n\\n'))\n            break\n    maxlCorrCoef = max(lCorrCoef)\n    maxlCorrCoefIndex = lCorrCoef.index(naFeatTrain)\n    sys.stdout.write((('best feature set is ' + str((list(lSeenStates[maxlCorrCoefIndex]) + [classLabelIndex]))) + '\\n'))\n    sys.stdout.write(('corr coef = ' + str(maxlCorrCoef)))\n    return maxlCorrCoef\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    dict_type = (kwargs.pop('dict_type', None) or OrderedDict)\n    ConfigParser.__init__(self, dict_type=dict_type, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    dict_type = (kwargs.pop('dict_type', None) or OrderedDict)\n    ConfigParser.__init__(kwargs, dict_type=dict_type, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef setup():\n    '\\n    Create necessary directories for testing.\\n    '\n    train_dir = join(_my_dir, 'train')\n    if (not exists(train_dir)):\n        os.makedirs(train_dir)\n    output_dir = join(_my_dir, 'output')\n    if (not exists(output_dir)):\n        os.makedirs(output_dir)\n", "label": "Correct"}
{"function": "\n\ndef setup():\n    '\\n    Create necessary directories for testing.\\n    '\n    train_dir = join(_my_dir, 'train')\n    if (not exists(train_dir)):\n        os.makedirs(train_dir)\n    output_dir = join(_my_dir, 'output')\n    if (not exists(train_dir)):\n        os.makedirs(output_dir)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, path):\n    self.path = path\n    self.elements = self.path.split('.')\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, path):\n    self.path = path\n    self.elements = path.path.split('.')\n", "label": "Variable misuse"}
{"function": "\n\ndef render_result(result_data, test_bundle):\n    result_data = lcase_keys(result_data)\n    result_string = (sublime.expand_variables(RESULTS_TEMPLATES['results'], filter_stats_dict(result_data)) + '\\n')\n    for bundle in result_data['bundlestats']:\n        if (len(test_bundle) and (bundle['path'] != test_bundle)):\n            continue\n        result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['bundle'], filter_stats_dict(bundle))) + '\\n')\n        if isinstance(bundle['globalexception'], dict):\n            result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['global_exception'], filter_exception_dict(bundle['globalexception']))) + '\\n')\n        for suite in bundle['suitestats']:\n            result_string += ('\\n' + gen_suite_report(suite))\n    result_string += ('\\n' + RESULTS_TEMPLATES['legend'])\n    return result_string\n", "label": "Correct"}
{"function": "\n\ndef render_result(result_data, test_bundle):\n    result_data = lcase_keys(suite)\n    result_string = (sublime.expand_variables(RESULTS_TEMPLATES['results'], filter_stats_dict(result_data)) + '\\n')\n    for bundle in result_data['bundlestats']:\n        if (len(test_bundle) and (bundle['path'] != test_bundle)):\n            continue\n        result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['bundle'], filter_stats_dict(bundle))) + '\\n')\n        if isinstance(bundle['globalexception'], dict):\n            result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['global_exception'], filter_exception_dict(bundle['globalexception']))) + '\\n')\n        for suite in bundle['suitestats']:\n            result_string += ('\\n' + gen_suite_report(suite))\n    result_string += ('\\n' + RESULTS_TEMPLATES['legend'])\n    return result_string\n", "label": "Variable misuse"}
{"function": "\n\ndef _dictify(data, name='input', key_mod=(lambda x: x), value_mod=(lambda x: x)):\n    if data:\n        if isinstance(data, collections.Sequence):\n            return dict(((key_mod(str(v)), value_mod(str(v))) for v in data))\n        elif isinstance(data, collections.Mapping):\n            return dict(((key_mod(str(k)), value_mod(str((v or k)))) for (k, v) in list(data.items())))\n        else:\n            raise BlockadeConfigError(('invalid %s: need list or map' % (name,)))\n    else:\n        return {\n            \n        }\n", "label": "Correct"}
{"function": "\n\ndef _dictify(data, name='input', key_mod=(lambda x: x), value_mod=(lambda x: x)):\n    if data:\n        if isinstance(data, collections.Sequence):\n            return dict(((key_mod(str(v)), k(str(v))) for v in data))\n        elif isinstance(data, collections.Mapping):\n            return dict(((key_mod(str(k)), value_mod(str((v or k)))) for (k, v) in list(data.items())))\n        else:\n            raise BlockadeConfigError(('invalid %s: need list or map' % (name,)))\n    else:\n        return {\n            \n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef login_action(request):\n    username = request.REQUEST['username']\n    password = request.REQUEST['password']\n    user = authenticate(username=username, password=password)\n    if (user is None):\n        return json_failure(_('Invalid username or password'))\n    if (not user.is_active):\n        return json_failure(_('Account disabled.'))\n    login(request, user)\n    return json_response()\n", "label": "Correct"}
{"function": "\n\ndef login_action(request):\n    username = request.REQUEST['username']\n    password = request.REQUEST['password']\n    user = authenticate(username=username, password=password)\n    if (user is None):\n        return json_failure(_('Invalid username or password'))\n    if (not user.is_active):\n        return json_failure(_('Account disabled.'))\n    login(user, user)\n    return json_response()\n", "label": "Variable misuse"}
{"function": "\n\ndef Check(self):\n    'Assertion verification for options.'\n    try:\n        assert (self.m0 >= 0), 'margin0'\n        assert (self.m1 >= self.m0), 'margin1'\n        assert (self.c0 >= 0), 'cost0'\n        assert (self.c1 >= 0), 'cost1'\n        assert (self.cb >= 0), 'costb'\n        assert (self.ind >= 0), 'indent'\n        assert (self.adj_comment >= 0), 'adj_comment'\n        assert (self.adj_flow >= 0), 'adj_flow'\n        assert (self.adj_call >= 0), 'adj_call'\n        assert (self.adj_arg >= 0), 'adj_arg'\n        assert (self.cpack >= 0), 'cpack'\n    except AssertionError as e:\n        raise Error((\"Illegal option value for '%s'\" % e.args[0]))\n", "label": "Correct"}
{"function": "\n\ndef Check(self):\n    'Assertion verification for options.'\n    try:\n        assert (self.m0 >= 0), 'margin0'\n        assert (self.m1 >= self.m0), 'margin1'\n        assert (self.c0 >= 0), 'cost0'\n        assert (self.c1 >= 0), 'cost1'\n        assert (e.cb >= 0), 'costb'\n        assert (self.ind >= 0), 'indent'\n        assert (self.adj_comment >= 0), 'adj_comment'\n        assert (self.adj_flow >= 0), 'adj_flow'\n        assert (self.adj_call >= 0), 'adj_call'\n        assert (self.adj_arg >= 0), 'adj_arg'\n        assert (self.cpack >= 0), 'cpack'\n    except AssertionError as e:\n        raise Error((\"Illegal option value for '%s'\" % e.args[0]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_supported_versions_declaration(self):\n    'hospital distribution declares supported Python versions.'\n    versions = get_supported_python_versions(self.distribution)\n    self.assertTrue(versions)\n", "label": "Correct"}
{"function": "\n\ndef test_supported_versions_declaration(self):\n    'hospital distribution declares supported Python versions.'\n    versions = get_supported_python_versions(self.distribution)\n    self.assertTrue(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef message_user(self, request, message, level=messages.INFO, extra_tags='', fail_silently=False):\n    '\\n        Send a message to the user. The default implementation\\n        posts a message using the django.contrib.messages backend.\\n\\n        Exposes almost the same API as messages.add_message(), but accepts the\\n        positional arguments in a different order to maintain backwards\\n        compatibility. For convenience, it accepts the `level` argument as\\n        a string rather than the usual level number.\\n        '\n    if (not isinstance(level, int)):\n        try:\n            level = getattr(messages.constants, level.upper())\n        except AttributeError:\n            levels = messages.constants.DEFAULT_TAGS.values()\n            levels_repr = ', '.join((('`%s`' % l) for l in levels))\n            raise ValueError(('Bad message level string: `%s`. Possible values are: %s' % (level, levels_repr)))\n    messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n", "label": "Correct"}
{"function": "\n\ndef message_user(self, request, message, level=messages.INFO, extra_tags='', fail_silently=False):\n    '\\n        Send a message to the user. The default implementation\\n        posts a message using the django.contrib.messages backend.\\n\\n        Exposes almost the same API as messages.add_message(), but accepts the\\n        positional arguments in a different order to maintain backwards\\n        compatibility. For convenience, it accepts the `level` argument as\\n        a string rather than the usual level number.\\n        '\n    if (not isinstance(level, int)):\n        try:\n            level = getattr(messages.constants, level.upper())\n        except AttributeError:\n            levels = messages.constants.DEFAULT_TAGS.values()\n            levels_repr = ', '.join((('`%s`' % l) for l in level))\n            raise ValueError(('Bad message level string: `%s`. Possible values are: %s' % (level, levels_repr)))\n    messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n", "label": "Variable misuse"}
{"function": "\n\n@withLockedLU\ndef testErrorResults(self, lu):\n    lu._VerifyOob(self.master, {\n        constants.NV_OOB_PATHS: ['path1', 'path2'],\n    })\n    self.mcpu.assertLogContainsRegex('path1')\n    self.mcpu.assertLogContainsRegex('path2')\n", "label": "Correct"}
{"function": "\n\n@withLockedLU\ndef testErrorResults(self, lu):\n    lu._VerifyOob(self.master, {\n        constants.NV_OOB_PATHS: ['path1', 'path2'],\n    })\n    lu.mcpu.assertLogContainsRegex('path1')\n    self.mcpu.assertLogContainsRegex('path2')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_channel_creates_new_when_not_at_limit(self):\n    ch = mock()\n    expect(self.connection._next_channel_id).returns(1)\n    mock(connection, 'Channel')\n    expect(connection.Channel).args(self.connection, 1, self.connection._class_map, synchronous=False).returns(ch)\n    expect(ch.add_close_listener).args(self.connection._channel_closed)\n    expect(ch.open)\n    assert_equals(ch, self.connection.channel())\n    assert_equals(ch, self.connection._channels[1])\n", "label": "Correct"}
{"function": "\n\ndef test_channel_creates_new_when_not_at_limit(self):\n    ch = mock()\n    expect(self.connection._next_channel_id).returns(1)\n    mock(connection, 'Channel')\n    expect(connection.Channel).args(self.connection, 1, self.connection._class_map, synchronous=False).returns(self)\n    expect(ch.add_close_listener).args(self.connection._channel_closed)\n    expect(ch.open)\n    assert_equals(ch, self.connection.channel())\n    assert_equals(ch, self.connection._channels[1])\n", "label": "Variable misuse"}
{"function": "\n\ndef _init_parser(self, grammar, tokens):\n    self._grammar = grammar\n    self._tokens = tokens\n    self._reset_parser()\n", "label": "Correct"}
{"function": "\n\ndef _init_parser(self, grammar, tokens):\n    self._grammar = grammar\n    self._tokens = self\n    self._reset_parser()\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, grid):\n    '\\n        Used to add quantities from another grid\\n\\n        Parameters\\n        ----------\\n        grid : 3D Numpy array or SphericalPolarGridView instance\\n            The grid to copy the quantity from\\n        '\n    if (type(self.quantities[self.viewed_quantity]) is list):\n        raise Exception('need to first specify the item to add to')\n    if isinstance(grid, SphericalPolarGridView):\n        if (type(grid.quantities[grid.viewed_quantity]) is list):\n            raise Exception('need to first specify the item to add')\n        self._check_array_dimensions(grid.quantities[grid.viewed_quantity])\n        self.quantities[self.viewed_quantity] += grid.quantities[grid.viewed_quantity]\n    elif isinstance(grid, np.ndarray):\n        self._check_array_dimensions(grid)\n        self.quantities[self.viewed_quantity] += grid\n    else:\n        raise ValueError('grid should be a Numpy array or a SphericalPolarGridView instance')\n", "label": "Correct"}
{"function": "\n\ndef add(self, grid):\n    '\\n        Used to add quantities from another grid\\n\\n        Parameters\\n        ----------\\n        grid : 3D Numpy array or SphericalPolarGridView instance\\n            The grid to copy the quantity from\\n        '\n    if (type(self.quantities[self.viewed_quantity]) is list):\n        raise Exception('need to first specify the item to add to')\n    if isinstance(grid, SphericalPolarGridView):\n        if (type(grid.quantities[grid.viewed_quantity]) is list):\n            raise Exception('need to first specify the item to add')\n        self._check_array_dimensions(grid.quantities[grid.viewed_quantity])\n        self.quantities[self.viewed_quantity] += grid.quantities[grid.viewed_quantity]\n    elif isinstance(grid, np.ndarray):\n        self._check_array_dimensions(grid)\n        self.quantities[self.viewed_quantity] += self\n    else:\n        raise ValueError('grid should be a Numpy array or a SphericalPolarGridView instance')\n", "label": "Variable misuse"}
{"function": "\n\ndef create_junk():\n    fileh = open_file(filename, mode='w')\n    group = fileh.create_group(fileh.root, 'newgroup')\n    for i in range(NLEAVES):\n        table = fileh.create_table(group, ('table' + str(i)), Particle, 'A table', Filters(1))\n        particle = table.row\n        print('Creating table-->', table._v_name)\n        for i in range(NROWS):\n            particle.append()\n        table.flush()\n    fileh.close()\n", "label": "Correct"}
{"function": "\n\ndef create_junk():\n    fileh = open_file(filename, mode='w')\n    group = fileh.create_group(fileh.root, 'newgroup')\n    for i in range(NLEAVES):\n        table = fileh.create_table(i, ('table' + str(i)), Particle, 'A table', Filters(1))\n        particle = table.row\n        print('Creating table-->', table._v_name)\n        for i in range(NROWS):\n            particle.append()\n        table.flush()\n    fileh.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef _send_500(req, extra=None):\n    req.start_response('500 Error', [('Content-Type', 'text/html')])\n    req.write('<h1>500 Internal Server Error</h1>\\n')\n    req.write('The server encountered an internal error or misconfiguration and was unable to complete your request.\\n')\n    if (extra is not None):\n        req.write(extra)\n    req.close()\n", "label": "Correct"}
{"function": "\n\ndef _send_500(req, extra=None):\n    extra.start_response('500 Error', [('Content-Type', 'text/html')])\n    req.write('<h1>500 Internal Server Error</h1>\\n')\n    req.write('The server encountered an internal error or misconfiguration and was unable to complete your request.\\n')\n    if (extra is not None):\n        req.write(extra)\n    req.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef __iter__(self):\n    for d in reversed(self.dicts):\n        (yield d)\n", "label": "Correct"}
{"function": "\n\ndef __iter__(self):\n    for d in reversed(self.dicts):\n        (yield self)\n", "label": "Variable misuse"}
{"function": "\n\ndef getopt(args, shortopts):\n    'getopt(args, options) -> opts, long_opts, args \\nReturns options as list of tuples, long options as entries in a dictionary, and\\nthe remaining arguments.'\n    opts = []\n    longopts = {\n        \n    }\n    while (args and args[0].startswith('-') and (args[0] != '-')):\n        if (args[0] == '--'):\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            arg = args.pop(0)\n            _do_longs(longopts, arg)\n        else:\n            (opts, args) = _do_shorts(opts, args[0][1:], shortopts, args[1:])\n    return (opts, longopts, args)\n", "label": "Correct"}
{"function": "\n\ndef getopt(args, shortopts):\n    'getopt(args, options) -> opts, long_opts, args \\nReturns options as list of tuples, long options as entries in a dictionary, and\\nthe remaining arguments.'\n    opts = []\n    longopts = {\n        \n    }\n    while (args and args[0].startswith('-') and (args[0] != '-')):\n        if (args[0] == '--'):\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            arg = args.pop(0)\n            _do_longs(longopts, args)\n        else:\n            (opts, args) = _do_shorts(opts, args[0][1:], shortopts, args[1:])\n    return (opts, longopts, args)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_later(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vdd'), self._fake_bdm('/dev/vde')]\n    device = self._validate_device()\n    self.assertEqual(device, '/dev/vdf')\n", "label": "Correct"}
{"function": "\n\ndef test_later(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vdd'), self._fake_bdm('/dev/vde')]\n    device = device._validate_device()\n    self.assertEqual(device, '/dev/vdf')\n", "label": "Variable misuse"}
{"function": "\n\ndef check_delete_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    self.check_write_package(username, package_reference)\n", "label": "Correct"}
{"function": "\n\ndef check_delete_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    username.check_write_package(username, package_reference)\n", "label": "Variable misuse"}
{"function": "\n\ndef serialize_fields(self, message):\n    return {\n        'collection': message.collection,\n        'id': message.id,\n        'before': message.before,\n    }\n", "label": "Correct"}
{"function": "\n\ndef serialize_fields(self, message):\n    return {\n        'collection': self.collection,\n        'id': message.id,\n        'before': message.before,\n    }\n", "label": "Variable misuse"}
{"function": "\n\n@app.route('/api')\ndef api():\n    \"WebSocket endpoint; Takes a 'topic' GET param.\"\n    ws = request.environ.get('wsgi.websocket')\n    topic = request.args.get('topic')\n    if (None in (ws, topic)):\n        return\n    topic = topic.encode('ascii')\n    for (message, message_topic) in CircusConsumer(topic, endpoint=ZMQ_ENDPOINT):\n        response = json.dumps(dict(message=message, topic=message_topic))\n        ws.send(response)\n", "label": "Correct"}
{"function": "\n\n@app.route('/api')\ndef api():\n    \"WebSocket endpoint; Takes a 'topic' GET param.\"\n    ws = request.environ.get('wsgi.websocket')\n    topic = request.args.get('topic')\n    if (None in (ws, topic)):\n        return\n    topic = response.encode('ascii')\n    for (message, message_topic) in CircusConsumer(topic, endpoint=ZMQ_ENDPOINT):\n        response = json.dumps(dict(message=message, topic=message_topic))\n        ws.send(response)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_active_contributors(self):\n    'Test the active_contributors util method.'\n    start_date = self.start_date\n    en_us_contributors = active_contributors(from_date=start_date, locale='en-US')\n    es_contributors = active_contributors(from_date=start_date, locale='es')\n    all_contributors = active_contributors(from_date=start_date)\n    eq_(3, len(en_us_contributors))\n    assert (self.user in en_us_contributors)\n    assert (self.en_us_old.creator not in en_us_contributors)\n    eq_(4, len(es_contributors))\n    assert (self.user in es_contributors)\n    assert (self.es_old.creator not in es_contributors)\n    eq_(6, len(all_contributors))\n    assert (self.user in all_contributors)\n    assert (self.en_us_old.creator not in all_contributors)\n    assert (self.es_old.creator not in all_contributors)\n", "label": "Correct"}
{"function": "\n\ndef test_active_contributors(self):\n    'Test the active_contributors util method.'\n    start_date = self.start_date\n    en_us_contributors = active_contributors(from_date=start_date, locale='en-US')\n    es_contributors = active_contributors(from_date=start_date, locale='es')\n    all_contributors = active_contributors(from_date=self)\n    eq_(3, len(en_us_contributors))\n    assert (self.user in en_us_contributors)\n    assert (self.en_us_old.creator not in en_us_contributors)\n    eq_(4, len(es_contributors))\n    assert (self.user in es_contributors)\n    assert (self.es_old.creator not in es_contributors)\n    eq_(6, len(all_contributors))\n    assert (self.user in all_contributors)\n    assert (self.en_us_old.creator not in all_contributors)\n    assert (self.es_old.creator not in all_contributors)\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, p, value):\n    'Add a position into BinKeeper.\\n\\n        Note: position must be sorted before adding. Otherwise, pp2v\\n        and pp2p will not work.\\n        '\n    bin = (p / self.binsize)\n    self.cage[bin][0].append(p)\n    self.cage[bin][1].append(value)\n", "label": "Correct"}
{"function": "\n\ndef add(self, p, value):\n    'Add a position into BinKeeper.\\n\\n        Note: position must be sorted before adding. Otherwise, pp2v\\n        and pp2p will not work.\\n        '\n    bin = (p / self.binsize)\n    self.cage[p][0].append(p)\n    self.cage[bin][1].append(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef _cleanup_groups(self):\n    exception_list = list()\n    for group in self.cloud.list_groups():\n        if group['name'].startswith(self.group_prefix):\n            try:\n                self.cloud.delete_group(group['id'])\n            except Exception as e:\n                exception_list.append(str(e))\n                continue\n    if exception_list:\n        raise OpenStackCloudException('\\n'.join(exception_list))\n", "label": "Correct"}
{"function": "\n\ndef _cleanup_groups(self):\n    exception_list = list()\n    for group in self.cloud.list_groups():\n        if group['name'].startswith(self.group_prefix):\n            try:\n                group.cloud.delete_group(group['id'])\n            except Exception as e:\n                exception_list.append(str(e))\n                continue\n    if exception_list:\n        raise OpenStackCloudException('\\n'.join(exception_list))\n", "label": "Variable misuse"}
{"function": "\n\ndef setup():\n    input_2 = [[0, (1 / 3.0)], [(2 / 3.0), (1 / 3.0)], [(2 / 3.0), 1.0]]\n    input_1 = [[0, (1 / 3.0)], [0, 1.0], [(2 / 3.0), 1.0]]\n    input_3 = [[(2 / 3.0), 0], [(2 / 3.0), (2 / 3.0)], [0, (2 / 3.0)]]\n    input_4 = [[(1 / 3.0), 1.0], [1.0, 1.0], [1, (1 / 3.0)]]\n    input_5 = [[(1 / 3.0), 1.0], [(1 / 3.0), (1 / 3.0)], [1, (1 / 3.0)]]\n    input_6 = [[(1 / 3.0), (2 / 3.0)], [(1 / 3.0), 0], [1.0, 0]]\n    return np.concatenate([input_1, input_2, input_3, input_4, input_5, input_6])\n", "label": "Correct"}
{"function": "\n\ndef setup():\n    input_2 = [[0, (1 / 3.0)], [(2 / 3.0), (1 / 3.0)], [(2 / 3.0), 1.0]]\n    input_1 = [[0, (1 / 3.0)], [0, 1.0], [(2 / 3.0), 1.0]]\n    input_3 = [[(2 / 3.0), 0], [(2 / 3.0), (2 / 3.0)], [0, (2 / 3.0)]]\n    input_4 = [[(1 / 3.0), 1.0], [1.0, 1.0], [1, (1 / 3.0)]]\n    input_5 = [[(1 / 3.0), 1.0], [(1 / 3.0), (1 / 3.0)], [1, (1 / 3.0)]]\n    input_6 = [[(1 / 3.0), (2 / 3.0)], [(1 / 3.0), 0], [1.0, 0]]\n    return np.concatenate([input_5, input_2, input_3, input_4, input_5, input_6])\n", "label": "Variable misuse"}
{"function": "\n\ndef addVariantsGetParser(subparsers):\n    parser = addSubparser(subparsers, 'variants-get', 'Get a variant')\n    parser.set_defaults(runner=GetVariantRunner)\n    addGetArguments(parser)\n", "label": "Correct"}
{"function": "\n\ndef addVariantsGetParser(subparsers):\n    parser = addSubparser(subparsers, 'variants-get', 'Get a variant')\n    parser.set_defaults(runner=GetVariantRunner)\n    addGetArguments(subparsers)\n", "label": "Variable misuse"}
{"function": "\n\ndef workflow_update(object_id, input_params={\n    \n}, always_retry=True, **kwargs):\n    '\\n    Invokes the /workflow-xxxx/update API method.\\n\\n    For more info, see: https://wiki.dnanexus.com/API-Specification-v1.0.0/Workflows-and-Analyses#API-method%3A-%2Fworkflow-xxxx%2Fupdate\\n    '\n    return DXHTTPRequest(('/%s/update' % object_id), input_params, always_retry=always_retry, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef workflow_update(object_id, input_params={\n    \n}, always_retry=True, **kwargs):\n    '\\n    Invokes the /workflow-xxxx/update API method.\\n\\n    For more info, see: https://wiki.dnanexus.com/API-Specification-v1.0.0/Workflows-and-Analyses#API-method%3A-%2Fworkflow-xxxx%2Fupdate\\n    '\n    return DXHTTPRequest(('/%s/update' % object_id), input_params, always_retry=input_params, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(Bucket, self).__init__(*args, **kwargs)\n    self.model.id_generator = NameGenerator()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(Bucket, self).__init__(*self, **kwargs)\n    self.model.id_generator = NameGenerator()\n", "label": "Variable misuse"}
{"function": "\n\ndef _expand_glob_path(file_roots):\n    '\\n    Applies shell globbing to a set of directories and returns\\n    the expanded paths\\n    '\n    unglobbed_path = []\n    for path in file_roots:\n        try:\n            if glob.has_magic(path):\n                unglobbed_path.extend(glob.glob(path))\n            else:\n                unglobbed_path.append(path)\n        except Exception:\n            unglobbed_path.append(path)\n    return unglobbed_path\n", "label": "Correct"}
{"function": "\n\ndef _expand_glob_path(file_roots):\n    '\\n    Applies shell globbing to a set of directories and returns\\n    the expanded paths\\n    '\n    unglobbed_path = []\n    for path in file_roots:\n        try:\n            if glob.has_magic(path):\n                unglobbed_path.extend(glob.glob(path))\n            else:\n                unglobbed_path.append(unglobbed_path)\n        except Exception:\n            unglobbed_path.append(path)\n    return unglobbed_path\n", "label": "Variable misuse"}
{"function": "\n\ndef authenticate(self):\n    (client_address, _) = self.client_address\n    NAMESPACE.machine = NAMESPACE.session.query(Builder).filter_by(ip=client_address).first()\n    NAMESPACE.user = NAMESPACE.session.query(Person).filter_by(ip=client_address).first()\n    return (NAMESPACE.machine or NAMESPACE.user)\n", "label": "Correct"}
{"function": "\n\ndef authenticate(self):\n    (client_address, _) = self.client_address\n    NAMESPACE.machine = NAMESPACE.session.query(Builder).filter_by(ip=client_address).first()\n    NAMESPACE.user = NAMESPACE.session.query(Person).filter_by(ip=self).first()\n    return (NAMESPACE.machine or NAMESPACE.user)\n", "label": "Variable misuse"}
{"function": "\n\ndef listKeysAndSizes(self, bucketName):\n    'Return a list of (name, size) pairs of keys in the bucket'\n    with self.state_.lock:\n        if (bucketName not in self.state_.buckets_):\n            raise S3Interface.BucketNotFound(bucketName)\n        self.state_.validateAccess(bucketName, self.credentials_)\n        return [(key, len(val.value), val.mtime) for (key, val) in self.state_.buckets_[bucketName].iteritems()]\n", "label": "Correct"}
{"function": "\n\ndef listKeysAndSizes(self, bucketName):\n    'Return a list of (name, size) pairs of keys in the bucket'\n    with bucketName.state_.lock:\n        if (bucketName not in self.state_.buckets_):\n            raise S3Interface.BucketNotFound(bucketName)\n        self.state_.validateAccess(bucketName, self.credentials_)\n        return [(key, len(val.value), val.mtime) for (key, val) in self.state_.buckets_[bucketName].iteritems()]\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/poi/shared_lok_imperial_large5.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('poi_n', 'base_poi_building')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/poi/shared_lok_imperial_large5.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('poi_n', 'base_poi_building')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef importData(self, assetstore, parent, parentType, params, progress, user, **kwargs):\n    '\\n        Calls the importData method of the underlying assetstore adapter.\\n        '\n    adapter = assetstore_utilities.getAssetstoreAdapter(assetstore)\n    return adapter.importData(parent=parent, parentType=parentType, params=params, progress=progress, user=user, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef importData(self, assetstore, parent, parentType, params, progress, user, **kwargs):\n    '\\n        Calls the importData method of the underlying assetstore adapter.\\n        '\n    adapter = assetstore_utilities.getAssetstoreAdapter(assetstore)\n    return adapter.importData(parent=parent, parentType=parentType, params=params, progress=parentType, user=user, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef cleanup(self, tc_name=''):\n    if (tc_name != ''):\n        self._log.info(('%s: FAILED' % tc_name))\n    for obj in ['ruleset', 'rule', 'classifier', 'action']:\n        self.gbpcfg.gbp_del_all_anyobj(obj)\n", "label": "Correct"}
{"function": "\n\ndef cleanup(self, tc_name=''):\n    if (obj != ''):\n        self._log.info(('%s: FAILED' % tc_name))\n    for obj in ['ruleset', 'rule', 'classifier', 'action']:\n        self.gbpcfg.gbp_del_all_anyobj(obj)\n", "label": "Variable misuse"}
{"function": "\n\ndef _geo_field(self, field_name=None):\n    \"\\n        Returns the first Geometry field encountered; or specified via the\\n        `field_name` keyword.  The `field_name` may be a string specifying\\n        the geometry field on this GeoQuery's model, or a lookup string\\n        to a geometry field via a ForeignKey relation.\\n        \"\n    if (field_name is None):\n        for fld in self.model._meta.fields:\n            if isinstance(fld, GeometryField):\n                return fld\n        return False\n    else:\n        return GeoWhereNode._check_geo_field(self.model._meta, field_name)\n", "label": "Correct"}
{"function": "\n\ndef _geo_field(self, field_name=None):\n    \"\\n        Returns the first Geometry field encountered; or specified via the\\n        `field_name` keyword.  The `field_name` may be a string specifying\\n        the geometry field on this GeoQuery's model, or a lookup string\\n        to a geometry field via a ForeignKey relation.\\n        \"\n    if (self is None):\n        for fld in self.model._meta.fields:\n            if isinstance(fld, GeometryField):\n                return fld\n        return False\n    else:\n        return GeoWhereNode._check_geo_field(self.model._meta, field_name)\n", "label": "Variable misuse"}
{"function": "\n\ndef compute(self):\n    if self.has_input('foo'):\n        v1 = self.get_input('foo')\n    else:\n        v1 = 0\n    if (v1 != 12):\n        self.change_parameter('foo', (v1 + 1))\n", "label": "Correct"}
{"function": "\n\ndef compute(self):\n    if self.has_input('foo'):\n        v1 = self.get_input('foo')\n    else:\n        v1 = 0\n    if (v1 != 12):\n        self.change_parameter('foo', (self + 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef removeItem(self, entity):\n    '\\n        Remove an item from the contact list.\\n\\n        @param entity: The contact to remove the roster item for.\\n        @type entity: L{JID<twisted.words.protocols.jabber.jid.JID>}\\n\\n        @rtype: L{twisted.internet.defer.Deferred}\\n        '\n    item = RosterItem(entity)\n    item.remove = True\n    return self.setItem(item)\n", "label": "Correct"}
{"function": "\n\ndef removeItem(self, entity):\n    '\\n        Remove an item from the contact list.\\n\\n        @param entity: The contact to remove the roster item for.\\n        @type entity: L{JID<twisted.words.protocols.jabber.jid.JID>}\\n\\n        @rtype: L{twisted.internet.defer.Deferred}\\n        '\n    item = RosterItem(entity)\n    item.remove = True\n    return self.setItem(entity)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_admin_message(self, x):\n    self.has_admin_message_ = 1\n    self.admin_message_ = x\n", "label": "Correct"}
{"function": "\n\ndef set_admin_message(self, x):\n    self.has_admin_message_ = 1\n    x.admin_message_ = x\n", "label": "Variable misuse"}
{"function": "\n\ndef test_BEPostalCodeField(self):\n    error_format = ['Enter a valid postal code in the range and format 1XXX - 9XXX.']\n    valid = {\n        '1451': '1451',\n        '2540': '2540',\n    }\n    invalid = {\n        '0287': error_format,\n        '14309': error_format,\n        '873': error_format,\n        '35 74': error_format,\n        '859A': error_format,\n    }\n    self.assertFieldOutput(BEPostalCodeField, valid, invalid)\n", "label": "Correct"}
{"function": "\n\ndef test_BEPostalCodeField(self):\n    error_format = ['Enter a valid postal code in the range and format 1XXX - 9XXX.']\n    valid = {\n        '1451': '1451',\n        '2540': '2540',\n    }\n    invalid = {\n        '0287': error_format,\n        '14309': error_format,\n        '873': error_format,\n        '35 74': error_format,\n        '859A': error_format,\n    }\n    self.assertFieldOutput(BEPostalCodeField, valid, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parentContainer, localId, randomSeed=1, numCalls=1, variantDensity=1):\n    super(SimulatedVariantSet, self).__init__(parentContainer, localId)\n    self._randomSeed = randomSeed\n    self._numCalls = numCalls\n    for j in range(numCalls):\n        self.addCallSet('simCallSet_{}'.format(j))\n    self._variantDensity = variantDensity\n    now = protocol.convertDatetime(datetime.datetime.now())\n    self._creationTime = now\n    self._updatedTime = now\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parentContainer, localId, randomSeed=1, numCalls=1, variantDensity=1):\n    super(SimulatedVariantSet, self).__init__(parentContainer, localId)\n    self._randomSeed = randomSeed\n    self._numCalls = numCalls\n    for j in range(numCalls):\n        self.addCallSet('simCallSet_{}'.format(j))\n    self._variantDensity = variantDensity\n    now = protocol.convertDatetime(datetime.datetime.now())\n    self._creationTime = now\n    self._updatedTime = randomSeed\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reference_beats_collection(self):\n    model = ResourceModel('test', {\n        'has': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                    'identifiers': [{\n                        'target': 'Id',\n                        'source': 'data',\n                        'path': 'FrobId',\n                    }],\n                },\n            },\n        },\n        'hasMany': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                },\n            },\n        },\n    }, {\n        'Frob': {\n            \n        },\n    })\n    model.load_rename_map()\n    self.assertEqual(model.references[0].name, 'foo')\n    self.assertEqual(model.collections[0].name, 'foo_collection')\n", "label": "Correct"}
{"function": "\n\ndef test_reference_beats_collection(self):\n    model = ResourceModel('test', {\n        'has': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                    'identifiers': [{\n                        'target': 'Id',\n                        'source': 'data',\n                        'path': 'FrobId',\n                    }],\n                },\n            },\n        },\n        'hasMany': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                },\n            },\n        },\n    }, {\n        'Frob': {\n            \n        },\n    })\n    model.load_rename_map()\n    model.assertEqual(model.references[0].name, 'foo')\n    self.assertEqual(model.collections[0].name, 'foo_collection')\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef overwrite_attribute(entity_id, attrs, vals):\n    'Overwrite any attribute of an entity.\\n\\n        This function should receive a list of attributes and a\\n        list of values. Set attribute to None to remove any overwritten\\n        value in place.\\n        '\n    for (attr, val) in zip(attrs, vals):\n        if (val is None):\n            _OVERWRITE[entity_id.lower()].pop(attr, None)\n        else:\n            _OVERWRITE[entity_id.lower()][attr] = val\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef overwrite_attribute(entity_id, attrs, vals):\n    'Overwrite any attribute of an entity.\\n\\n        This function should receive a list of attributes and a\\n        list of values. Set attribute to None to remove any overwritten\\n        value in place.\\n        '\n    for (attr, val) in zip(attrs, vals):\n        if (val is None):\n            _OVERWRITE[entity_id.lower()].pop(attr, None)\n        else:\n            _OVERWRITE[entity_id.lower()][attr] = entity_id\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_key(self, key):\n    self.redis.delete(key)\n", "label": "Correct"}
{"function": "\n\ndef delete_key(self, key):\n    key.redis.delete(key)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_vpnservice_pagination(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources_with_pagination(resources, cmd)\n", "label": "Correct"}
{"function": "\n\ndef test_list_vpnservice_pagination(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources_with_pagination(cmd, cmd)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue_7754(self):\n    old_cwd = os.getcwd()\n    config_dir = os.path.join(integration.TMP, 'issue-7754')\n    if (not os.path.isdir(config_dir)):\n        os.makedirs(config_dir)\n    os.chdir(config_dir)\n    for fname in ('master', 'minion'):\n        pid_path = os.path.join(config_dir, '{0}.pid'.format(fname))\n        with salt.utils.fopen(self.get_config_file_path(fname), 'r') as fhr:\n            config = yaml.load(fhr.read())\n            config['log_file'] = config['syndic_log_file'] = 'file:///tmp/log/LOG_LOCAL3'\n            config['root_dir'] = config_dir\n            if ('ret_port' in config):\n                config['ret_port'] = (int(config['ret_port']) + 10)\n                config['publish_port'] = (int(config['publish_port']) + 10)\n            with salt.utils.fopen(os.path.join(config_dir, fname), 'w') as fhw:\n                fhw.write(yaml.dump(config, default_flow_style=False))\n    ret = self.run_script(self._call_binary_, '--config-dir={0} --pid-file={1} -l debug'.format(config_dir, pid_path), timeout=5, catch_stderr=True, with_retcode=True)\n    if os.path.exists(pid_path):\n        with salt.utils.fopen(pid_path) as fhr:\n            try:\n                os.kill(int(fhr.read()), signal.SIGKILL)\n            except OSError:\n                pass\n    try:\n        self.assertFalse(os.path.isdir(os.path.join(config_dir, 'file:')))\n        self.assertIn('Failed to setup the Syslog logging handler', '\\n'.join(ret[1]))\n        self.assertEqual(ret[2], 2)\n    finally:\n        self.chdir(old_cwd)\n        if os.path.isdir(config_dir):\n            shutil.rmtree(config_dir)\n", "label": "Correct"}
{"function": "\n\ndef test_issue_7754(self):\n    old_cwd = os.getcwd()\n    config_dir = os.path.join(integration.TMP, 'issue-7754')\n    if (not os.path.isdir(config_dir)):\n        os.makedirs(config_dir)\n    os.chdir(config_dir)\n    for fname in ('master', 'minion'):\n        pid_path = os.path.join(config_dir, '{0}.pid'.format(fname))\n        with salt.utils.fopen(self.get_config_file_path(fname), 'r') as fhr:\n            config = yaml.load(fhr.read())\n            config['log_file'] = config['syndic_log_file'] = 'file:///tmp/log/LOG_LOCAL3'\n            config['root_dir'] = config_dir\n            if ('ret_port' in config):\n                config['ret_port'] = (int(config['ret_port']) + 10)\n                config['publish_port'] = (int(config['publish_port']) + 10)\n            with salt.utils.fopen(os.path.join(config_dir, fname), 'w') as fhw:\n                fhw.write(yaml.dump(config, default_flow_style=False))\n    ret = self.run_script(self._call_binary_, '--config-dir={0} --pid-file={1} -l debug'.format(config_dir, pid_path), timeout=5, catch_stderr=True, with_retcode=True)\n    if os.path.exists(pid_path):\n        with salt.utils.fopen(pid_path) as fhr:\n            try:\n                os.kill(int(fhr.read()), signal.SIGKILL)\n            except OSError:\n                pass\n    try:\n        self.assertFalse(os.path.isdir(os.path.join(config_dir, 'file:')))\n        self.assertIn('Failed to setup the Syslog logging handler', '\\n'.join(ret[1]))\n        self.assertEqual(ret[2], 2)\n    finally:\n        self.chdir(config_dir)\n        if os.path.isdir(config_dir):\n            shutil.rmtree(config_dir)\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, event_id, attrs):\n    'Add an item to the log'\n    time = attrs['timestamp'].split(' ')[1]\n    data = (attrs['level'], time, attrs['message'], event_id)\n    self._cache.append(data)\n    self._add_tree_item(data)\n", "label": "Correct"}
{"function": "\n\ndef add(self, event_id, attrs):\n    'Add an item to the log'\n    time = attrs['timestamp'].split(' ')[1]\n    data = (attrs['level'], time, attrs['message'], attrs)\n    self._cache.append(data)\n    self._add_tree_item(data)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_foreign_keys(self):\n    chef_gusteau = factory.make('tests.Chef', fields={\n        'first_name': 'Gusteau',\n    })\n    pizza = factory.make('tests.Pizza', fields={\n        'chef': chef_gusteau,\n    })\n    self.assertEqual(pizza.chef, chef_gusteau)\n", "label": "Correct"}
{"function": "\n\ndef test_foreign_keys(self):\n    chef_gusteau = factory.make('tests.Chef', fields={\n        'first_name': 'Gusteau',\n    })\n    pizza = factory.make('tests.Pizza', fields={\n        'chef': chef_gusteau,\n    })\n    self.assertEqual(pizza.chef, pizza)\n", "label": "Variable misuse"}
{"function": "\n\ndef fetch_encoded_sharers(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    return friends_json.get('encodedSharersList', '')\n", "label": "Correct"}
{"function": "\n\ndef fetch_encoded_sharers(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    return self.get('encodedSharersList', '')\n", "label": "Variable misuse"}
{"function": "\n\ndef affine_relu_backward(dout, cache):\n    '\\n    Backward pass for the affine-relu convenience layer\\n    '\n    (fc_cache, relu_cache) = cache\n    da = relu_backward(dout, relu_cache)\n    (dx, dw, db) = affine_backward(da, fc_cache)\n    return (dx, dw, db)\n", "label": "Correct"}
{"function": "\n\ndef affine_relu_backward(dout, cache):\n    '\\n    Backward pass for the affine-relu convenience layer\\n    '\n    (fc_cache, relu_cache) = cache\n    da = relu_backward(dout, relu_cache)\n    (dx, dw, db) = affine_backward(da, fc_cache)\n    return (relu_cache, dw, db)\n", "label": "Variable misuse"}
{"function": "\n\ndef previous(self):\n    self.editor_context.decrement_error_index()\n    match = self.ERROR_LINE_RX.match(editor_context.get_current_error())\n    return match.groupdict()\n", "label": "Correct"}
{"function": "\n\ndef previous(self):\n    self.editor_context.decrement_error_index()\n    match = match.ERROR_LINE_RX.match(editor_context.get_current_error())\n    return match.groupdict()\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _from_line(cls, remote, line):\n    'Create a new PushInfo instance as parsed from line which is expected to be like\\n            refs/heads/master:refs/heads/master 05d2687..1d0568e as bytes'\n    (control_character, from_to, summary) = line.split('\\t', 3)\n    flags = 0\n    try:\n        flags |= cls._flag_map[control_character]\n    except KeyError:\n        raise ValueError(('Control character %r unknown as parsed from line %r' % (control_character, line)))\n    (from_ref_string, to_ref_string) = from_to.split(':')\n    if (flags & cls.DELETED):\n        from_ref = None\n    else:\n        from_ref = Reference.from_path(remote.repo, from_ref_string)\n    old_commit = None\n    if summary.startswith('['):\n        if ('[rejected]' in summary):\n            flags |= cls.REJECTED\n        elif ('[remote rejected]' in summary):\n            flags |= cls.REMOTE_REJECTED\n        elif ('[remote failure]' in summary):\n            flags |= cls.REMOTE_FAILURE\n        elif ('[no match]' in summary):\n            flags |= cls.ERROR\n        elif ('[new tag]' in summary):\n            flags |= cls.NEW_TAG\n        elif ('[new branch]' in summary):\n            flags |= cls.NEW_HEAD\n    else:\n        split_token = '...'\n        if (control_character == ' '):\n            split_token = '..'\n        (old_sha, new_sha) = summary.split(' ')[0].split(split_token)\n        old_commit = remote.repo.commit(old_sha)\n    return PushInfo(flags, from_ref, to_ref_string, remote, old_commit, summary)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _from_line(cls, remote, line):\n    'Create a new PushInfo instance as parsed from line which is expected to be like\\n            refs/heads/master:refs/heads/master 05d2687..1d0568e as bytes'\n    (control_character, from_to, summary) = line.split('\\t', 3)\n    flags = 0\n    try:\n        flags |= cls._flag_map[control_character]\n    except KeyError:\n        raise ValueError(('Control character %r unknown as parsed from line %r' % (control_character, line)))\n    (from_ref_string, to_ref_string) = from_to.split(':')\n    if (flags & cls.DELETED):\n        from_ref = None\n    else:\n        from_ref = Reference.from_path(remote.repo, from_ref_string)\n    old_commit = None\n    if summary.startswith('['):\n        if ('[rejected]' in from_to):\n            flags |= cls.REJECTED\n        elif ('[remote rejected]' in summary):\n            flags |= cls.REMOTE_REJECTED\n        elif ('[remote failure]' in summary):\n            flags |= cls.REMOTE_FAILURE\n        elif ('[no match]' in summary):\n            flags |= cls.ERROR\n        elif ('[new tag]' in summary):\n            flags |= cls.NEW_TAG\n        elif ('[new branch]' in summary):\n            flags |= cls.NEW_HEAD\n    else:\n        split_token = '...'\n        if (control_character == ' '):\n            split_token = '..'\n        (old_sha, new_sha) = summary.split(' ')[0].split(split_token)\n        old_commit = remote.repo.commit(old_sha)\n    return PushInfo(flags, from_ref, to_ref_string, remote, old_commit, summary)\n", "label": "Variable misuse"}
{"function": "\n\ndef _check_params(length, size):\n    _check_size(size)\n    if ((length % size) != 0):\n        raise error('not a whole number of frames')\n", "label": "Correct"}
{"function": "\n\ndef _check_params(length, size):\n    _check_size(size)\n    if ((length % length) != 0):\n        raise error('not a whole number of frames')\n", "label": "Variable misuse"}
{"function": "\n\ndef ex_update_node_affinity_group(self, node, affinity_group_list):\n    '\\n        Updates the affinity/anti-affinity group associations of a virtual\\n        machine. The VM has to be stopped and restarted for the new properties\\n        to take effect.\\n\\n        :param node: Node to update.\\n        :type node: :class:`CloudStackNode`\\n\\n        :param affinity_group_list: List of CloudStackAffinityGroup to\\n                                    associate\\n        :type affinity_group_list: ``list`` of :class:`CloudStackAffinityGroup`\\n\\n        :rtype :class:`CloudStackNode`\\n        '\n    affinity_groups = ','.join((ag.id for ag in affinity_group_list))\n    result = self._async_request(command='updateVMAffinityGroup', params={\n        'id': node.id,\n        'affinitygroupids': affinity_groups,\n    }, method='GET')\n    return self._to_node(data=result['virtualmachine'])\n", "label": "Correct"}
{"function": "\n\ndef ex_update_node_affinity_group(self, node, affinity_group_list):\n    '\\n        Updates the affinity/anti-affinity group associations of a virtual\\n        machine. The VM has to be stopped and restarted for the new properties\\n        to take effect.\\n\\n        :param node: Node to update.\\n        :type node: :class:`CloudStackNode`\\n\\n        :param affinity_group_list: List of CloudStackAffinityGroup to\\n                                    associate\\n        :type affinity_group_list: ``list`` of :class:`CloudStackAffinityGroup`\\n\\n        :rtype :class:`CloudStackNode`\\n        '\n    affinity_groups = ','.join((ag.id for ag in ag))\n    result = self._async_request(command='updateVMAffinityGroup', params={\n        'id': node.id,\n        'affinitygroupids': affinity_groups,\n    }, method='GET')\n    return self._to_node(data=result['virtualmachine'])\n", "label": "Variable misuse"}
{"function": "\n\ndef copy(srcPath, destPath):\n    'copy the file from srcPath to destPath'\n    import shutils\n    return shutil.copy(srcPath, destPath)\n", "label": "Correct"}
{"function": "\n\ndef copy(srcPath, destPath):\n    'copy the file from srcPath to destPath'\n    import shutils\n    return shutil.copy(destPath, destPath)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, url, auth=None):\n    'Initialize the Kodi device.'\n    import jsonrpc_requests\n    self._name = name\n    self._url = url\n    self._server = jsonrpc_requests.Server('{}/jsonrpc'.format(self._url), auth=auth)\n    self._players = list()\n    self._properties = None\n    self._item = None\n    self._app_properties = None\n    self.update()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, url, auth=None):\n    'Initialize the Kodi device.'\n    import jsonrpc_requests\n    self._name = name\n    self._url = url\n    self._server = jsonrpc_requests.Server('{}/jsonrpc'.format(self._url), auth=auth)\n    self._players = list()\n    self._properties = None\n    auth._item = None\n    self._app_properties = None\n    self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef html_body(input_string, source_path=None, destination_path=None, input_encoding='unicode', output_encoding='unicode', doctitle=1, initial_header_level=1):\n    '\\n    Given an input string, returns an HTML fragment as a string.\\n\\n    The return value is the contents of the <body> element.\\n\\n    Parameters (see `html_parts()` for the remainder):\\n\\n    - `output_encoding`: The desired encoding of the output.  If a Unicode\\n      string is desired, use the default value of \"unicode\" .\\n    '\n    parts = html_parts(input_string=input_string, source_path=source_path, destination_path=destination_path, input_encoding=input_encoding, doctitle=doctitle, initial_header_level=initial_header_level)\n    fragment = parts['html_body']\n    if (output_encoding != 'unicode'):\n        fragment = fragment.encode(output_encoding)\n    return fragment\n", "label": "Correct"}
{"function": "\n\ndef html_body(input_string, source_path=None, destination_path=None, input_encoding='unicode', output_encoding='unicode', doctitle=1, initial_header_level=1):\n    '\\n    Given an input string, returns an HTML fragment as a string.\\n\\n    The return value is the contents of the <body> element.\\n\\n    Parameters (see `html_parts()` for the remainder):\\n\\n    - `output_encoding`: The desired encoding of the output.  If a Unicode\\n      string is desired, use the default value of \"unicode\" .\\n    '\n    parts = html_parts(input_string=input_string, source_path=source_path, destination_path=destination_path, input_encoding=input_encoding, doctitle=doctitle, initial_header_level=initial_header_level)\n    fragment = parts['html_body']\n    if (output_encoding != 'unicode'):\n        fragment = initial_header_level.encode(output_encoding)\n    return fragment\n", "label": "Variable misuse"}
{"function": "\n\ndef selection_change(self, evt):\n    pub.send_message(events.LIST_BOX, selection=self.listbox.GetItems()[self.listbox.GetSelection()])\n    evt.Skip()\n", "label": "Correct"}
{"function": "\n\ndef selection_change(self, evt):\n    pub.send_message(events.LIST_BOX, selection=self.listbox.GetItems()[self.listbox.GetSelection()])\n    self.Skip()\n", "label": "Variable misuse"}
{"function": "\n\ndef init(self, modelDocument):\n    super(ModelRssItem, self).init(modelDocument)\n    try:\n        if (self.modelXbrl.modelManager.rssWatchOptions.latestPubDate and (self.pubDate <= self.modelXbrl.modelManager.rssWatchOptions.latestPubDate)):\n            self.status = _('tested')\n        else:\n            self.status = _('not tested')\n    except AttributeError:\n        self.status = _('not tested')\n    self.results = None\n    self.assertions = None\n", "label": "Correct"}
{"function": "\n\ndef init(self, modelDocument):\n    super(ModelRssItem, self).init(modelDocument)\n    try:\n        if (self.modelXbrl.modelManager.rssWatchOptions.latestPubDate and (self.pubDate <= self.modelXbrl.modelManager.rssWatchOptions.latestPubDate)):\n            self.status = _('tested')\n        else:\n            self.status = _('not tested')\n    except AttributeError:\n        self.status = _('not tested')\n    modelDocument.results = None\n    self.assertions = None\n", "label": "Variable misuse"}
{"function": "\n\ndef rgb_to_hsv(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    v = maxc\n    if (minc == maxc):\n        return (0.0, 0.0, v)\n    s = ((maxc - minc) / maxc)\n    rc = ((maxc - r) / (maxc - minc))\n    gc = ((maxc - g) / (maxc - minc))\n    bc = ((maxc - b) / (maxc - minc))\n    if (r == maxc):\n        h = (bc - gc)\n    elif (g == maxc):\n        h = ((2.0 + rc) - bc)\n    else:\n        h = ((4.0 + gc) - rc)\n    h = ((h / 6.0) % 1.0)\n    return (h, s, v)\n", "label": "Correct"}
{"function": "\n\ndef rgb_to_hsv(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    v = maxc\n    if (minc == maxc):\n        return (0.0, 0.0, v)\n    s = ((maxc - minc) / maxc)\n    rc = ((maxc - r) / (maxc - minc))\n    gc = ((maxc - g) / (maxc - minc))\n    bc = ((maxc - b) / (maxc - minc))\n    if (r == maxc):\n        h = (bc - gc)\n    elif (g == maxc):\n        h = ((2.0 + rc) - bc)\n    else:\n        h = ((4.0 + s) - rc)\n    h = ((h / 6.0) % 1.0)\n    return (h, s, v)\n", "label": "Variable misuse"}
{"function": "\n\ndef build_xform(self):\n    xform = XFormBuilder(self.name)\n    for ig in self.iter_item_groups():\n        data_type = ('repeatGroup' if self.is_repeating else 'group')\n        group = xform.new_group(ig.question_name, ig.question_label, data_type)\n        for item in ig.iter_items():\n            group.new_question(item.question_name, item.question_label, ODK_DATA_TYPES[item.data_type], choices=item.choices)\n    return xform.tostring(pretty_print=True, encoding='utf-8', xml_declaration=True)\n", "label": "Correct"}
{"function": "\n\ndef build_xform(self):\n    xform = XFormBuilder(self.name)\n    for ig in self.iter_item_groups():\n        data_type = ('repeatGroup' if self.is_repeating else 'group')\n        group = xform.new_group(ig.question_name, ig.question_label, data_type)\n        for item in ig.iter_items():\n            group.new_question(item.question_name, item.question_label, ODK_DATA_TYPES[ig.data_type], choices=item.choices)\n    return xform.tostring(pretty_print=True, encoding='utf-8', xml_declaration=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_wait_with_disconnect(self):\n    'Exit loop when the client wants to disconnect'\n    self.socketIO.define(Namespace)\n    self.socketIO.disconnect()\n    timeout_in_seconds = 5\n    start_time = time.time()\n    self.socketIO.wait(timeout_in_seconds)\n    self.assertTrue(((time.time() - start_time) < timeout_in_seconds))\n", "label": "Correct"}
{"function": "\n\ndef test_wait_with_disconnect(self):\n    'Exit loop when the client wants to disconnect'\n    self.socketIO.define(Namespace)\n    self.socketIO.disconnect()\n    timeout_in_seconds = 5\n    start_time = time.time()\n    self.socketIO.wait(timeout_in_seconds)\n    timeout_in_seconds.assertTrue(((time.time() - start_time) < timeout_in_seconds))\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(experiments, 'systemconfig')\n@mock.patch.object(experiments.gmacpyutil, 'MachineInfoForKey')\ndef testFetchUUIDWithMissingMachineUUID(self, mock_mifk, mock_sc):\n    good_uuid = 'AAAAAAAA-BBBB-CCCC-DDDD-EEEEEEEEEEEE'\n    mock_mifk.return_value = None\n    mock_sc.SystemProfiler().GetHWUUID.return_value = good_uuid\n    self.assertEqual(good_uuid, experiments.FetchUUID())\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(experiments, 'systemconfig')\n@mock.patch.object(experiments.gmacpyutil, 'MachineInfoForKey')\ndef testFetchUUIDWithMissingMachineUUID(self, mock_mifk, mock_sc):\n    good_uuid = 'AAAAAAAA-BBBB-CCCC-DDDD-EEEEEEEEEEEE'\n    mock_mifk.return_value = None\n    self.SystemProfiler().GetHWUUID.return_value = good_uuid\n    self.assertEqual(good_uuid, experiments.FetchUUID())\n", "label": "Variable misuse"}
{"function": "\n\ndef permutations(xs):\n    if (not xs):\n        (yield [])\n    else:\n        for (y, ys) in selections(xs):\n            for pys in permutations(ys):\n                (yield ([y] + pys))\n", "label": "Correct"}
{"function": "\n\ndef permutations(xs):\n    if (not xs):\n        (yield [])\n    else:\n        for (y, ys) in selections(xs):\n            for pys in permutations(ys):\n                (yield ([ys] + pys))\n", "label": "Variable misuse"}
{"function": "\n\ndef on_response(self, response):\n    self.stop()\n    self.got_response = True\n    if (not (response.status_code == 418)):\n        self.response_valid = False\n", "label": "Correct"}
{"function": "\n\ndef on_response(self, response):\n    self.stop()\n    self.got_response = True\n    if (not (self.status_code == 418)):\n        self.response_valid = False\n", "label": "Variable misuse"}
{"function": "\n\ndef _add_filter(self, filter_instance, value):\n    self.filters.append(filter_instance)\n    self.values.append(value)\n", "label": "Correct"}
{"function": "\n\ndef _add_filter(self, filter_instance, value):\n    self.filters.append(filter_instance)\n    self.values.append(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef _annotate_local(self):\n    \"Annotate the primaryjoin and secondaryjoin\\n        structures with 'local' annotations.\\n\\n        This annotates all column elements found\\n        simultaneously in the parent table\\n        and the join condition that don't have a\\n        'remote' annotation set up from\\n        _annotate_remote() or user-defined.\\n\\n        \"\n    if self._has_annotation(self.primaryjoin, 'local'):\n        return\n    if self._local_remote_pairs:\n        local_side = util.column_set([l for (l, r) in self._local_remote_pairs])\n    else:\n        local_side = util.column_set(self.parent_selectable.c)\n\n    def locals_(elem):\n        if (('remote' not in elem._annotations) and (elem in local_side)):\n            return elem._annotate({\n                'local': True,\n            })\n    self.primaryjoin = visitors.replacement_traverse(self.primaryjoin, {\n        \n    }, locals_)\n", "label": "Correct"}
{"function": "\n\ndef _annotate_local(self):\n    \"Annotate the primaryjoin and secondaryjoin\\n        structures with 'local' annotations.\\n\\n        This annotates all column elements found\\n        simultaneously in the parent table\\n        and the join condition that don't have a\\n        'remote' annotation set up from\\n        _annotate_remote() or user-defined.\\n\\n        \"\n    if local_side._has_annotation(self.primaryjoin, 'local'):\n        return\n    if self._local_remote_pairs:\n        local_side = util.column_set([l for (l, r) in self._local_remote_pairs])\n    else:\n        local_side = util.column_set(self.parent_selectable.c)\n\n    def locals_(elem):\n        if (('remote' not in elem._annotations) and (elem in local_side)):\n            return elem._annotate({\n                'local': True,\n            })\n    self.primaryjoin = visitors.replacement_traverse(self.primaryjoin, {\n        \n    }, locals_)\n", "label": "Variable misuse"}
{"function": "\n\ndef __cmp__(self, other):\n    'ensure that same seq intervals match in cmp()'\n    if (not isinstance(other, SeqPath)):\n        return (- 1)\n    if (self.path is other.path):\n        return cmp((self.start, self.stop), (other.start, other.stop))\n    else:\n        return NOT_ON_SAME_PATH\n", "label": "Correct"}
{"function": "\n\ndef __cmp__(self, other):\n    'ensure that same seq intervals match in cmp()'\n    if (not isinstance(other, SeqPath)):\n        return (- 1)\n    if (self.path is self.path):\n        return cmp((self.start, self.stop), (other.start, other.stop))\n    else:\n        return NOT_ON_SAME_PATH\n", "label": "Variable misuse"}
{"function": "\n\n@attr('numpy')\ndef test_empty(self):\n    try:\n        import numpy\n    except ImportError:\n        raise SkipTest('numpy not available.')\n    G = networkx.Graph()\n    assert_equal(networkx.hits(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.hits_numpy(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.authority_matrix(G).shape, (0, 0))\n    assert_equal(networkx.hub_matrix(G).shape, (0, 0))\n", "label": "Correct"}
{"function": "\n\n@attr('numpy')\ndef test_empty(self):\n    try:\n        import numpy\n    except ImportError:\n        raise SkipTest('numpy not available.')\n    G = networkx.Graph()\n    assert_equal(networkx.hits(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.hits_numpy(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.authority_matrix(self).shape, (0, 0))\n    assert_equal(networkx.hub_matrix(G).shape, (0, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    if ((not self.frozen_by_south) and (name not in [f.name for f in cls._meta.fields])):\n        super(CurrencyField, self).contribute_to_class(cls, name)\n", "label": "Correct"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    if ((not self.frozen_by_south) and (name not in [self.name for f in cls._meta.fields])):\n        super(CurrencyField, self).contribute_to_class(cls, name)\n", "label": "Variable misuse"}
{"function": "\n\ndef dapInfo(self, id_):\n    cmd = []\n    cmd.append(COMMAND_ID['DAP_INFO'])\n    cmd.append(ID_INFO[id_])\n    self.interface.write(cmd)\n    resp = self.interface.read()\n    if (resp[0] != COMMAND_ID['DAP_INFO']):\n        raise ValueError('DAP_INFO response error')\n    if (resp[1] == 0):\n        return\n    if (id_ in ('CAPABILITIES', 'PACKET_COUNT', 'PACKET_SIZE')):\n        if (resp[1] == 1):\n            return resp[2]\n        if (resp[1] == 2):\n            return ((resp[3] << 8) | resp[2])\n    x = array.array('B', [i for i in resp[2:(2 + resp[1])]])\n    return x.tostring()\n", "label": "Correct"}
{"function": "\n\ndef dapInfo(self, id_):\n    cmd = []\n    cmd.append(COMMAND_ID['DAP_INFO'])\n    cmd.append(ID_INFO[id_])\n    self.interface.write(cmd)\n    resp = self.interface.read()\n    if (resp[0] != COMMAND_ID['DAP_INFO']):\n        raise ValueError('DAP_INFO response error')\n    if (resp[1] == 0):\n        return\n    if (id_ in ('CAPABILITIES', 'PACKET_COUNT', 'PACKET_SIZE')):\n        if (self[1] == 1):\n            return resp[2]\n        if (resp[1] == 2):\n            return ((resp[3] << 8) | resp[2])\n    x = array.array('B', [i for i in resp[2:(2 + resp[1])]])\n    return x.tostring()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_pos_list_append_with_nonexistent_key(self):\n    '\\n        Invoke list_append() with non-existent key\\n        '\n    charSet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n    minLength = 5\n    maxLength = 30\n    length = random.randint(minLength, maxLength)\n    key = ('test', 'demo', (''.join(map((lambda unused: random.choice(charSet)), range(length))) + '.com'))\n    status = self.as_connection.list_append(key, 'abc', 122)\n    assert (status == 0)\n    (key, _, bins) = self.as_connection.get(key)\n    self.as_connection.remove(key)\n    assert (status == 0)\n    assert (bins == {\n        'abc': [122],\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_pos_list_append_with_nonexistent_key(self):\n    '\\n        Invoke list_append() with non-existent key\\n        '\n    charSet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n    minLength = 5\n    maxLength = 30\n    length = random.randint(minLength, maxLength)\n    key = ('test', 'demo', (''.join(map((lambda unused: random.choice(charSet)), range(length))) + '.com'))\n    status = self.as_connection.list_append(key, 'abc', 122)\n    assert (status == 0)\n    (key, _, bins) = self.as_connection.get(maxLength)\n    self.as_connection.remove(key)\n    assert (status == 0)\n    assert (bins == {\n        'abc': [122],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef fingerprint(self):\n    try:\n        pubkey = sshpubkeys.SSHKey(self.key)\n        return pubkey.hash()\n    except:\n        'There are a small parcel of exceptions that can be throw to indicate invalid keys'\n        return ''\n", "label": "Correct"}
{"function": "\n\ndef fingerprint(self):\n    try:\n        pubkey = sshpubkeys.SSHKey(self.key)\n        return self.hash()\n    except:\n        'There are a small parcel of exceptions that can be throw to indicate invalid keys'\n        return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef start(self):\n    'Start watching the directory for changes.'\n    with self._inotify_fd_lock:\n        if (self._inotify_fd < 0):\n            return\n        self._inotify_poll.register(self._inotify_fd, select.POLLIN)\n        for directory in self._directories:\n            self._add_watch_for_path(directory)\n", "label": "Correct"}
{"function": "\n\ndef start(self):\n    'Start watching the directory for changes.'\n    with directory._inotify_fd_lock:\n        if (self._inotify_fd < 0):\n            return\n        self._inotify_poll.register(self._inotify_fd, select.POLLIN)\n        for directory in self._directories:\n            self._add_watch_for_path(directory)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef servicenames(self):\n    'Give the list of services available in this folder.'\n    return set([service['name'].rstrip('/').split('/')[(- 1)] for service in self._json_struct.get('services', [])])\n", "label": "Correct"}
{"function": "\n\n@property\ndef servicenames(self):\n    'Give the list of services available in this folder.'\n    return set([service['name'].rstrip('/').split('/')[(- 1)] for service in service._json_struct.get('services', [])])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_one(self):\n    red = self.make_target('red', RedTarget)\n    with self.mutex_group(targets=[red]) as (red_viewer, blue_viewer, green_viewer):\n        red_viewer.execute()\n        blue_viewer.execute()\n        green_viewer.execute()\n        self.assertEqual([red], red_viewer.executed)\n        self.assertIsNone(blue_viewer.executed)\n        self.assertIsNone(green_viewer.executed)\n", "label": "Correct"}
{"function": "\n\ndef test_one(self):\n    red = self.make_target('red', RedTarget)\n    with self.mutex_group(targets=[red]) as (red_viewer, blue_viewer, green_viewer):\n        red_viewer.execute()\n        blue_viewer.execute()\n        green_viewer.execute()\n        self.assertEqual([green_viewer], red_viewer.executed)\n        self.assertIsNone(blue_viewer.executed)\n        self.assertIsNone(green_viewer.executed)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_lazy_user(user):\n    ' Return True if the passed user is a lazy user. '\n    if user.is_anonymous():\n        return False\n    backend = getattr(user, 'backend', None)\n    if (backend == 'lazysignup.backends.LazySignupBackend'):\n        return True\n    from lazysignup.models import LazyUser\n    return bool((LazyUser.objects.filter(user=user).count() > 0))\n", "label": "Correct"}
{"function": "\n\ndef is_lazy_user(user):\n    ' Return True if the passed user is a lazy user. '\n    if user.is_anonymous():\n        return False\n    backend = getattr(backend, 'backend', None)\n    if (backend == 'lazysignup.backends.LazySignupBackend'):\n        return True\n    from lazysignup.models import LazyUser\n    return bool((LazyUser.objects.filter(user=user).count() > 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef setupFuzzyMatch(self, prefix):\n    self._fuzzyMatcher = FuzzyMatcher()\n    self._fuzzyMatcher.setPattern(prefix)\n    self._fuzzyPrefix = prefix\n", "label": "Correct"}
{"function": "\n\ndef setupFuzzyMatch(self, prefix):\n    self._fuzzyMatcher = FuzzyMatcher()\n    self._fuzzyMatcher.setPattern(prefix)\n    prefix._fuzzyPrefix = prefix\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(InvalidPluginError, self).__init__(400, InvalidPluginError.INVALID_PLUGIN_ERROR_CODE, *args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(InvalidPluginError, kwargs).__init__(400, InvalidPluginError.INVALID_PLUGIN_ERROR_CODE, *args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef check_variable(self, name):\n    ' check_variable(name: str) -> Boolean\\n        Returns True if the vistrail already has the variable name\\n\\n        '\n    variableBox = self.parent().parent().parent()\n    if variableBox.controller:\n        return variableBox.controller.check_vistrail_variable(name)\n    return False\n", "label": "Correct"}
{"function": "\n\ndef check_variable(self, name):\n    ' check_variable(name: str) -> Boolean\\n        Returns True if the vistrail already has the variable name\\n\\n        '\n    variableBox = name.parent().parent().parent()\n    if variableBox.controller:\n        return variableBox.controller.check_vistrail_variable(name)\n    return False\n", "label": "Variable misuse"}
{"function": "\n\n@click.command()\n@click.argument('identifier')\n@click.option('--postinstall', '-i', help='Post-install script to download')\n@click.option('--image', help=\"Image ID. The default is to use the current operating system.\\nSee: 'slcli image list' for reference\")\n@helpers.multi_option('--key', '-k', help='SSH keys to add to the root user')\n@environment.pass_env\ndef cli(env, identifier, postinstall, key, image):\n    'Reload operating system on a virtual server.'\n    vsi = SoftLayer.VSManager(env.client)\n    vs_id = helpers.resolve_id(vsi.resolve_ids, identifier, 'VS')\n    keys = []\n    if key:\n        for single_key in key:\n            resolver = SoftLayer.SshKeyManager(env.client).resolve_ids\n            key_id = helpers.resolve_id(resolver, single_key, 'SshKey')\n            keys.append(key_id)\n    if (not (env.skip_confirmations or formatting.no_going_back(vs_id))):\n        raise exceptions.CLIAbort('Aborted')\n    vsi.reload_instance(vs_id, post_uri=postinstall, ssh_keys=keys, image_id=image)\n", "label": "Correct"}
{"function": "\n\n@click.command()\n@click.argument('identifier')\n@click.option('--postinstall', '-i', help='Post-install script to download')\n@click.option('--image', help=\"Image ID. The default is to use the current operating system.\\nSee: 'slcli image list' for reference\")\n@helpers.multi_option('--key', '-k', help='SSH keys to add to the root user')\n@environment.pass_env\ndef cli(env, identifier, postinstall, key, image):\n    'Reload operating system on a virtual server.'\n    vsi = SoftLayer.VSManager(env.client)\n    vs_id = helpers.resolve_id(vsi.resolve_ids, identifier, 'VS')\n    keys = []\n    if key:\n        for single_key in key:\n            resolver = SoftLayer.SshKeyManager(env.client).resolve_ids\n            key_id = helpers.resolve_id(resolver, single_key, 'SshKey')\n            keys.append(resolver)\n    if (not (env.skip_confirmations or formatting.no_going_back(vs_id))):\n        raise exceptions.CLIAbort('Aborted')\n    vsi.reload_instance(vs_id, post_uri=postinstall, ssh_keys=keys, image_id=image)\n", "label": "Variable misuse"}
{"function": "\n\ndef findPeak(self, A):\n    '\\n        Binary search\\n        Microsoft Interview, Oct 2014\\n\\n        To reduce the complexity of dealing the edge cases:\\n        * add two anti-peak dummies on the both ends\\n\\n        :param A: An integers list. A[0] and A[-1] are dummies.\\n        :return: return any of peek positions.\\n        '\n    n = len(A)\n    l = 0\n    h = n\n    while (l < h):\n        m = ((l + h) / 2)\n        if (A[(m - 1)] < A[m] > A[(m + 1)]):\n            return m\n        elif (A[(m + 1)] > A[m]):\n            l = (m + 1)\n        else:\n            h = m\n    raise Exception\n", "label": "Correct"}
{"function": "\n\ndef findPeak(self, A):\n    '\\n        Binary search\\n        Microsoft Interview, Oct 2014\\n\\n        To reduce the complexity of dealing the edge cases:\\n        * add two anti-peak dummies on the both ends\\n\\n        :param A: An integers list. A[0] and A[-1] are dummies.\\n        :return: return any of peek positions.\\n        '\n    n = len(A)\n    l = 0\n    h = n\n    while (l < h):\n        m = ((l + h) / 2)\n        if (A[(m - 1)] < l[m] > A[(m + 1)]):\n            return m\n        elif (A[(m + 1)] > A[m]):\n            l = (m + 1)\n        else:\n            h = m\n    raise Exception\n", "label": "Variable misuse"}
{"function": "\n\ndef with_spell_entry(self, entry):\n    '\\n        Add spell entry\\n\\n        :param entry: entry to add\\n        :type entry: SpellEntry\\n        '\n    self.spell_entries.append(entry)\n    return self\n", "label": "Correct"}
{"function": "\n\ndef with_spell_entry(self, entry):\n    '\\n        Add spell entry\\n\\n        :param entry: entry to add\\n        :type entry: SpellEntry\\n        '\n    self.spell_entries.append(self)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef aug_init(self, root, flags):\n    self.auginit = True\n", "label": "Correct"}
{"function": "\n\ndef aug_init(self, root, flags):\n    root.auginit = True\n", "label": "Variable misuse"}
{"function": "\n\ndef season_by_id(season_id):\n    url = endpoints.season_by_id.format(season_id)\n    q = _query_endpoint(url)\n    if q:\n        return Season(q)\n    else:\n        raise SeasonNotFound(\"Couldn't find Season with ID: {0}\".format(season_id))\n", "label": "Correct"}
{"function": "\n\ndef season_by_id(season_id):\n    url = endpoints.season_by_id.format(season_id)\n    q = _query_endpoint(url)\n    if q:\n        return Season(url)\n    else:\n        raise SeasonNotFound(\"Couldn't find Season with ID: {0}\".format(season_id))\n", "label": "Variable misuse"}
{"function": "\n\ndef check_migrations(self):\n    \"\\n        Checks to see if the set of migrations on disk matches the\\n        migrations in the database. Prints a warning if they don't match.\\n        \"\n    executor = MigrationExecutor(connections[DEFAULT_DB_ALIAS])\n    plan = executor.migration_plan(executor.loader.graph.leaf_nodes())\n    if (plan and self.show_startup_messages):\n        self.stdout.write(self.style.NOTICE('\\nYou have unapplied migrations; your app may not work properly until they are applied.'))\n        self.stdout.write(self.style.NOTICE(\"Run 'python manage.py migrate' to apply them.\\n\"))\n", "label": "Correct"}
{"function": "\n\ndef check_migrations(self):\n    \"\\n        Checks to see if the set of migrations on disk matches the\\n        migrations in the database. Prints a warning if they don't match.\\n        \"\n    executor = MigrationExecutor(connections[DEFAULT_DB_ALIAS])\n    plan = executor.migration_plan(executor.loader.graph.leaf_nodes())\n    if (self and self.show_startup_messages):\n        self.stdout.write(self.style.NOTICE('\\nYou have unapplied migrations; your app may not work properly until they are applied.'))\n        self.stdout.write(self.style.NOTICE(\"Run 'python manage.py migrate' to apply them.\\n\"))\n", "label": "Variable misuse"}
{"function": "\n\n@retry_before_failing()\ndef test_free(self):\n    (total, used, free, shared) = free_physmem()\n    self.assertAlmostEqual(free, psutil.virtual_memory().free, delta=MEMORY_TOLERANCE)\n", "label": "Correct"}
{"function": "\n\n@retry_before_failing()\ndef test_free(self):\n    (total, used, free, shared) = free_physmem()\n    self.assertAlmostEqual(used, psutil.virtual_memory().free, delta=MEMORY_TOLERANCE)\n", "label": "Variable misuse"}
{"function": "\n\ndef notes(self, notes):\n    self._notes = notes\n    return self\n", "label": "Correct"}
{"function": "\n\ndef notes(self, notes):\n    self._notes = self\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, environ, start_response):\n    from webob.exc import HTTPNotFound\n    r = HTTPNotFound()\n    return r(environ, start_response)\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, environ, start_response):\n    from webob.exc import HTTPNotFound\n    r = HTTPNotFound()\n    return start_response(environ, start_response)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_activation_expired_account(self):\n    '\\n        ``UserenaSignup.activation_key_expired()`` is ``True`` when the\\n        ``activation_key_created`` is more days ago than defined in\\n        ``USERENA_ACTIVATION_DAYS``.\\n\\n        '\n    user = UserenaSignup.objects.create_user(**self.user_info)\n    user.date_joined -= datetime.timedelta(days=(userena_settings.USERENA_ACTIVATION_DAYS + 1))\n    user.save()\n    user = User.objects.get(username='alice')\n    self.assertTrue(user.userena_signup.activation_key_expired())\n", "label": "Correct"}
{"function": "\n\ndef test_activation_expired_account(self):\n    '\\n        ``UserenaSignup.activation_key_expired()`` is ``True`` when the\\n        ``activation_key_created`` is more days ago than defined in\\n        ``USERENA_ACTIVATION_DAYS``.\\n\\n        '\n    user = UserenaSignup.objects.create_user(**self.user_info)\n    user.date_joined -= datetime.timedelta(days=(userena_settings.USERENA_ACTIVATION_DAYS + 1))\n    user.save()\n    user = User.objects.get(username='alice')\n    self.assertTrue(self.userena_signup.activation_key_expired())\n", "label": "Variable misuse"}
{"function": "\n\ndef query(self, *args, **kws):\n    'generic query'\n    return self.session.query(*args, **kws)\n", "label": "Correct"}
{"function": "\n\ndef query(self, *args, **kws):\n    'generic query'\n    return self.session.query(*kws, **kws)\n", "label": "Variable misuse"}
{"function": "\n\ndef friend_list(self, player_id):\n    return ' '.join([user_manager.id_to_name(friend_id) for friend_id in fetch_set_keys(friend_key(player_id))])\n", "label": "Correct"}
{"function": "\n\ndef friend_list(self, player_id):\n    return ' '.join([user_manager.id_to_name(self) for friend_id in fetch_set_keys(friend_key(player_id))])\n", "label": "Variable misuse"}
{"function": "\n\ndef onModelChanged(self, model):\n    newTrackPosition = np.array(self.jointController.q[:3])\n    delta = (newTrackPosition - self.lastTrackPosition)\n    for i in xrange(3):\n        if (not self.followAxes[i]):\n            delta[i] = 0.0\n    self.lastTrackPosition = newTrackPosition\n    c = self.view.camera()\n    oldFocalPoint = np.array(c.GetFocalPoint())\n    oldPosition = np.array(c.GetPosition())\n    c.SetFocalPoint((oldFocalPoint + delta))\n    c.SetPosition((oldPosition + delta))\n    self.view.render()\n", "label": "Correct"}
{"function": "\n\ndef onModelChanged(self, model):\n    newTrackPosition = np.array(self.jointController.q[:3])\n    delta = (newTrackPosition - self.lastTrackPosition)\n    for i in xrange(3):\n        if (not self.followAxes[oldFocalPoint]):\n            delta[i] = 0.0\n    self.lastTrackPosition = newTrackPosition\n    c = self.view.camera()\n    oldFocalPoint = np.array(c.GetFocalPoint())\n    oldPosition = np.array(c.GetPosition())\n    c.SetFocalPoint((oldFocalPoint + delta))\n    c.SetPosition((oldPosition + delta))\n    self.view.render()\n", "label": "Variable misuse"}
{"function": "\n\ndef function(self, x):\n    return tt.nnet.softmax((x / self.temperature))\n", "label": "Correct"}
{"function": "\n\ndef function(self, x):\n    return tt.nnet.softmax((self / self.temperature))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, transport, frame_max):\n    '\\n        :param transport: transport to write to\\n        :param frame_max: maximum frame payload size in bytes\\n        :type transport: amqpy.transport.Transport\\n        :type frame_max: int\\n        '\n    self.transport = transport\n    self.frame_max = frame_max\n    self.methods_sent = 0\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, transport, frame_max):\n    '\\n        :param transport: transport to write to\\n        :param frame_max: maximum frame payload size in bytes\\n        :type transport: amqpy.transport.Transport\\n        :type frame_max: int\\n        '\n    self.transport = transport\n    frame_max.frame_max = frame_max\n    self.methods_sent = 0\n", "label": "Variable misuse"}
{"function": "\n\ndef test_invalid_base_fields(self):\n\n    class InvalidListCharModel(TemporaryModel):\n        field = ListCharField(models.ForeignKey('testapp.Author'), max_length=32)\n    errors = InvalidListCharModel.check(actually_check=True)\n    assert (len(errors) == 1)\n    assert (errors[0].id == 'django_mysql.E005')\n    assert ('Base field for list must be' in errors[0].msg)\n", "label": "Correct"}
{"function": "\n\ndef test_invalid_base_fields(self):\n\n    class InvalidListCharModel(TemporaryModel):\n        field = ListCharField(models.ForeignKey('testapp.Author'), max_length=32)\n    errors = InvalidListCharModel.check(actually_check=True)\n    assert (len(errors) == 1)\n    assert (errors[0].id == 'django_mysql.E005')\n    assert ('Base field for list must be' in field[0].msg)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_works_on_sourcessubset(self):\n    transformer = FilterSources(self.stream, sources=('features',))\n    assert_equal(transformer.sources, ('features',))\n    assert_equal(list(transformer.get_epoch_iterator()), [(numpy.ones((2, 2, 2)),), (numpy.ones((2, 2, 2)),)])\n", "label": "Correct"}
{"function": "\n\ndef test_works_on_sourcessubset(self):\n    transformer = FilterSources(transformer.stream, sources=('features',))\n    assert_equal(transformer.sources, ('features',))\n    assert_equal(list(transformer.get_epoch_iterator()), [(numpy.ones((2, 2, 2)),), (numpy.ones((2, 2, 2)),)])\n", "label": "Variable misuse"}
{"function": "\n\n@contextlib.contextmanager\ndef _assert_warns_context_manager(warning_class=None, warnings_test=None):\n    '\\n    Builds a context manager for testing code that should throw a warning.\\n    This will look for a given class, call a custom test, or both.\\n\\n    Args:\\n        warning_class - a class or subclass of Warning. If not None, then\\n            the context manager will raise an AssertionError if the block\\n            does not throw at least one warning of that type.\\n        warnings_test - a function which takes a list of warnings caught,\\n            and makes a number of assertions about the result. If the function\\n            returns without an exception, the context manager will consider\\n            this a successful assertion.\\n    '\n    with warnings.catch_warnings(record=True) as caught:\n        warnings.resetwarnings()\n        if warning_class:\n            warnings.simplefilter('ignore')\n            warnings.simplefilter('always', category=warning_class)\n        else:\n            warnings.simplefilter('always')\n        (yield)\n        assert_gt(len(caught), 0, 'expected at least one warning to be thrown')\n        if warnings_test:\n            warnings_test(caught)\n", "label": "Correct"}
{"function": "\n\n@contextlib.contextmanager\ndef _assert_warns_context_manager(warning_class=None, warnings_test=None):\n    '\\n    Builds a context manager for testing code that should throw a warning.\\n    This will look for a given class, call a custom test, or both.\\n\\n    Args:\\n        warning_class - a class or subclass of Warning. If not None, then\\n            the context manager will raise an AssertionError if the block\\n            does not throw at least one warning of that type.\\n        warnings_test - a function which takes a list of warnings caught,\\n            and makes a number of assertions about the result. If the function\\n            returns without an exception, the context manager will consider\\n            this a successful assertion.\\n    '\n    with warnings.catch_warnings(record=True) as caught:\n        warnings.resetwarnings()\n        if warning_class:\n            warnings.simplefilter('ignore')\n            warnings.simplefilter('always', category=warning_class)\n        else:\n            warnings.simplefilter('always')\n        (yield)\n        assert_gt(len(caught), 0, 'expected at least one warning to be thrown')\n        if warning_class:\n            warnings_test(caught)\n", "label": "Variable misuse"}
{"function": "\n\ndef _AtNonLeaf(self, attr_value, path):\n    'Called when at a non-leaf value. Should recurse and yield values.'\n    try:\n        if isinstance(attr_value, collections.Mapping):\n            sub_obj = attr_value.get(path[1])\n            if (len(path) > 2):\n                sub_obj = self.Expand(sub_obj, path[2:])\n            if isinstance(sub_obj, basestring):\n                (yield sub_obj)\n            elif isinstance(sub_obj, collections.Mapping):\n                for (k, v) in sub_obj.items():\n                    (yield {\n                        k: v,\n                    })\n            else:\n                for value in sub_obj:\n                    (yield value)\n        else:\n            for sub_obj in attr_value:\n                for value in self.Expand(sub_obj, path[1:]):\n                    (yield value)\n    except TypeError:\n        for value in self.Expand(attr_value, path[1:]):\n            (yield value)\n", "label": "Correct"}
{"function": "\n\ndef _AtNonLeaf(self, attr_value, path):\n    'Called when at a non-leaf value. Should recurse and yield values.'\n    try:\n        if isinstance(attr_value, collections.Mapping):\n            sub_obj = attr_value.get(path[1])\n            if (len(path) > 2):\n                sub_obj = self.Expand(sub_obj, path[2:])\n            if isinstance(sub_obj, basestring):\n                (yield sub_obj)\n            elif isinstance(path, collections.Mapping):\n                for (k, v) in sub_obj.items():\n                    (yield {\n                        k: v,\n                    })\n            else:\n                for value in sub_obj:\n                    (yield value)\n        else:\n            for sub_obj in attr_value:\n                for value in self.Expand(sub_obj, path[1:]):\n                    (yield value)\n    except TypeError:\n        for value in self.Expand(attr_value, path[1:]):\n            (yield value)\n", "label": "Variable misuse"}
{"function": "\n\ndef log_notifications(self, notifications):\n    main_logger = logging.getLogger(config.main_logger_name)\n    notification_logger = logging.getLogger(config.notifications_logger_name)\n    for notification in notifications:\n        try:\n            notification['content'] = notification['content'].encode('utf-8').replace(',', '\\\\,')\n            keys = ['status', 'login_id', 'content', 'message_id', 'campaign_id', 'sending_id', 'game', 'world_id', 'screen', 'time', 'time_to_live_ts_bigint', 'platform', 'receiver_id']\n            notification_logger.info(','.join([str(notification[key]) for key in keys]))\n        except:\n            main_logger.exception('Error while logging notification to csv log!')\n", "label": "Correct"}
{"function": "\n\ndef log_notifications(self, notifications):\n    main_logger = logging.getLogger(config.main_logger_name)\n    notification_logger = logging.getLogger(config.notifications_logger_name)\n    for notification in notifications:\n        try:\n            notifications['content'] = notification['content'].encode('utf-8').replace(',', '\\\\,')\n            keys = ['status', 'login_id', 'content', 'message_id', 'campaign_id', 'sending_id', 'game', 'world_id', 'screen', 'time', 'time_to_live_ts_bigint', 'platform', 'receiver_id']\n            notification_logger.info(','.join([str(notification[key]) for key in keys]))\n        except:\n            main_logger.exception('Error while logging notification to csv log!')\n", "label": "Variable misuse"}
{"function": "\n\n@replace_call(BaseDatabaseWrapper.cursor)\ndef cursor(func, self):\n    djdt = DebugToolbarMiddleware.get_current()\n    if djdt:\n        djdt._panels[SQLDebugPanel] = djdt.get_panel(SQLLoggingPanel)\n    return func(self)\n", "label": "Correct"}
{"function": "\n\n@replace_call(BaseDatabaseWrapper.cursor)\ndef cursor(func, self):\n    djdt = DebugToolbarMiddleware.get_current()\n    if djdt:\n        djdt._panels[SQLDebugPanel] = djdt.get_panel(SQLLoggingPanel)\n    return self(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __getitem__(self, key):\n    if isinstance(key, int):\n        return list(self.values()).__getitem__(key)\n    elif isinstance(key, slice):\n        items = list(self.items()).__getitem__(key)\n        return Layers(items)\n    else:\n        return super(Layers, self).__getitem__(key)\n", "label": "Correct"}
{"function": "\n\ndef __getitem__(self, key):\n    if isinstance(key, int):\n        return list(self.values()).__getitem__(key)\n    elif isinstance(key, slice):\n        items = list(self.items()).__getitem__(key)\n        return Layers(items)\n    else:\n        return super(Layers, key).__getitem__(key)\n", "label": "Variable misuse"}
{"function": "\n\ndef description(self, obj):\n    return ('Latest ideas submitted for %s' % obj.name)\n", "label": "Correct"}
{"function": "\n\ndef description(self, obj):\n    return ('Latest ideas submitted for %s' % self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, config):\n    self.items = collections.OrderedDict()\n    values = config.get('axes', self.name).split(',')\n    if config.has_section(('axis:%s' % self.name)):\n        self.defaults = collections.OrderedDict(config.items(('axis:%s' % self.name)))\n    else:\n        self.defaults = {\n            \n        }\n    for value in values:\n        self.items[value.strip('*')] = AxisItem(self, value, config)\n", "label": "Correct"}
{"function": "\n\ndef load(self, config):\n    self.items = collections.OrderedDict()\n    values = config.get('axes', self.name).split(',')\n    if config.has_section(('axis:%s' % self.name)):\n        self.defaults = collections.OrderedDict(self.items(('axis:%s' % self.name)))\n    else:\n        self.defaults = {\n            \n        }\n    for value in values:\n        self.items[value.strip('*')] = AxisItem(self, value, config)\n", "label": "Variable misuse"}
{"function": "\n\ndef read_text_file(file_path, mode='rb'):\n    '\\n  Returns the contents of a file after opening it in read-only mode.\\n\\n  :param file_path:\\n      Path to the file to be read from.\\n  :param mode:\\n      Mode string.\\n  '\n    return open(file_path, mode).read()\n", "label": "Correct"}
{"function": "\n\ndef read_text_file(file_path, mode='rb'):\n    '\\n  Returns the contents of a file after opening it in read-only mode.\\n\\n  :param file_path:\\n      Path to the file to be read from.\\n  :param mode:\\n      Mode string.\\n  '\n    return open(mode, mode).read()\n", "label": "Variable misuse"}
{"function": "\n\ndef expand(self, sha):\n    '\\n        get the deep version of the object with the given SHA.\\n        \\n        In other words, all components of the given object will be expanded\\n        recursively to their actual values with no SHA references left.\\n        '\n    return self.get_object(sha).expand()\n", "label": "Correct"}
{"function": "\n\ndef expand(self, sha):\n    '\\n        get the deep version of the object with the given SHA.\\n        \\n        In other words, all components of the given object will be expanded\\n        recursively to their actual values with no SHA references left.\\n        '\n    return self.get_object(self).expand()\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_message(self, msg):\n    return self._create_attachments(self._create_related_attachments(self._create_alternatives(msg)))\n", "label": "Correct"}
{"function": "\n\ndef _create_message(self, msg):\n    return self._create_attachments(self._create_related_attachments(msg._create_alternatives(msg)))\n", "label": "Variable misuse"}
{"function": "\n\ndef write_output(args, powerline, segment_info, write):\n    if args.renderer_arg:\n        segment_info.update(args.renderer_arg)\n    if args.side.startswith('above'):\n        for line in powerline.render_above_lines(width=args.width, segment_info=segment_info, mode=segment_info.get('mode', None)):\n            if line:\n                write((line + '\\n'))\n        args.side = args.side[len('above'):]\n    if args.side:\n        rendered = powerline.render(width=args.width, side=args.side, segment_info=segment_info, mode=segment_info.get('mode', None))\n        write(rendered)\n", "label": "Correct"}
{"function": "\n\ndef write_output(args, powerline, segment_info, write):\n    if args.renderer_arg:\n        write.update(args.renderer_arg)\n    if args.side.startswith('above'):\n        for line in powerline.render_above_lines(width=args.width, segment_info=segment_info, mode=segment_info.get('mode', None)):\n            if line:\n                write((line + '\\n'))\n        args.side = args.side[len('above'):]\n    if args.side:\n        rendered = powerline.render(width=args.width, side=args.side, segment_info=segment_info, mode=segment_info.get('mode', None))\n        write(rendered)\n", "label": "Variable misuse"}
{"function": "\n\ndef lines(self, text):\n    for line in text.split('\\n'):\n        (yield ('         \"%s\\\\n\"' % escape_quote(line)))\n", "label": "Correct"}
{"function": "\n\ndef lines(self, text):\n    for line in text.split('\\n'):\n        (yield ('         \"%s\\\\n\"' % escape_quote(self)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_build_ext_path_with_os_sep(self):\n    dist = Distribution({\n        'name': 'UpdateManager',\n    })\n    cmd = build_ext(dist)\n    cmd.ensure_finalized()\n    ext = sysconfig.get_config_var('SO')\n    ext_name = os.path.join('UpdateManager', 'fdsend')\n    ext_path = cmd.get_ext_fullpath(ext_name)\n    wanted = os.path.join(cmd.build_lib, 'UpdateManager', ('fdsend' + ext))\n    self.assertEqual(ext_path, wanted)\n", "label": "Correct"}
{"function": "\n\ndef test_build_ext_path_with_os_sep(self):\n    dist = Distribution({\n        'name': 'UpdateManager',\n    })\n    cmd = build_ext(dist)\n    wanted.ensure_finalized()\n    ext = sysconfig.get_config_var('SO')\n    ext_name = os.path.join('UpdateManager', 'fdsend')\n    ext_path = cmd.get_ext_fullpath(ext_name)\n    wanted = os.path.join(cmd.build_lib, 'UpdateManager', ('fdsend' + ext))\n    self.assertEqual(ext_path, wanted)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_success_url(self):\n    msg = render_to_string('dashboard/shipping/messages/band_updated.html', {\n        'band': self.object,\n    })\n    messages.success(self.request, msg, extra_tags='safe noicon')\n    return reverse('dashboard:shipping-method-detail', kwargs={\n        'pk': self.method.pk,\n    })\n", "label": "Correct"}
{"function": "\n\ndef get_success_url(self):\n    msg = render_to_string('dashboard/shipping/messages/band_updated.html', {\n        'band': self.object,\n    })\n    messages.success(self.request, msg, extra_tags='safe noicon')\n    return reverse('dashboard:shipping-method-detail', kwargs={\n        'pk': msg.method.pk,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, sendFunc, srcIp, srcPort, destIp, destPort, confirmable, messageId, code, token, options, payload, ackTimeout, respTimeout):\n    \"\\n        \\x08rief Initilizer function.\\n\\n        This function initializes this instance by recording everything about\\n        the CoAP message to be exchange with the remote endpoint. It does not,\\n        however, initiate the exchange, which is done by calling the transmit()\\n        method.\\n\\n        \\\\paran[in] sendFunc The function to call to send a CoAP message.\\n        \\\\param[in] srcIp    The IP address of the local endpoint, a string of the\\n            form 'aaaa::1'.\\n        \\\\param[in] srcport  The UDP port the local endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] destIp   The IP address of the remote CoAP endpoint, a\\n            string of the form 'aaaa::1'.\\n        \\\\param[in] destPort The UDP port the remote endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] confirmable A boolean indicating whether the CoAP request is\\n            to be send confirmable (True) or non-confirmable (False).\\n        \\\\param[in] messageId The message ID to be used for the CoAP request, an\\n            integer. The caller of this function needs to enforce unicity rules\\n            for the value passed.\\n        \\\\param[in] code     The CoAP method to used in the request. Needs to a\\n            value of METHOD_ALL.\\n        \\\\param[in] token    The token to be used for this exchange. The caller\\n            of this function needs to enforce unicity rules for the value\\n            passed.\\n        \\\\param[in] options  A list of CoAP options. Each element needs to be\\n            an instance of the coapOption class. Note that this class will add\\n            appropriate CoAP options to encore the URI and query, if needed.\\n        \\\\param[in] payload  The payload to pass in the CoAP request. This needs\\n            to be a byte list, i.e. a list of intergers between 0x00 and 0xff.\\n            This function does not parse this payload, which is written as-is\\n            in the CoAP request.\\n        \\\\param[in] ackTimeout The ACK timeout.\\n        \\\\param[in] respTimeout The app-level response timeout.\\n        \"\n    log.debug('creating instance')\n    self.sendFunc = sendFunc\n    self.srcIp = srcIp\n    self.srcPort = srcPort\n    self.destIp = destIp\n    self.destPort = destPort\n    self.confirmable = confirmable\n    self.messageId = messageId\n    self.code = code\n    self.token = token\n    self.options = options\n    self.payload = payload\n    self.dataLock = threading.Lock()\n    self.fsmSem = threading.Lock()\n    self.startLock = threading.Lock()\n    self.endLock = threading.Lock()\n    self.stateLock = threading.RLock()\n    self.rxMsgEvent = threading.Event()\n    self.receivedACK = None\n    self.receivedResp = None\n    self.coapResponse = None\n    self.coapError = None\n    self.state = self.STATE_INIT\n    self.maxRetransmit = d.DFLT_MAX_RETRANSMIT\n    self.numTxCON = 0\n    self.ackTimeout = ackTimeout\n    self.respTimeout = respTimeout\n    self.fsmGoOn = True\n    self.fsmAction = {\n        self.STATE_INIT: self._action_INIT,\n        self.STATE_TXCON: self._action_TXCON,\n        self.STATE_TXNON: self._action_TXNON,\n        self.STATE_WAITFORACK: self._action_WAITFORACK,\n        self.STATE_ACKRX: self._action_ACKRX,\n        self.STATE_WAITFOREXPIRATIONMID: self._action_WAITFOREXPIRATIONMID,\n        self.STATE_WAITFORRESP: self._action_WAITFORRESP,\n        self.STATE_RESPRX: self._action_RESPRX,\n        self.STATE_TXACK: self._action_TXACK,\n    }\n    threading.Thread.__init__(self)\n    self.name = '[{0}]:{1}--m0x{2:x},0x{3:x}-->[{4}]:{5}'.format(self.srcIp, self.srcPort, self.messageId, self.token, self.destIp, self.destPort)\n    self.startLock.acquire()\n    self.endLock.acquire()\n    self.start()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, sendFunc, srcIp, srcPort, destIp, destPort, confirmable, messageId, code, token, options, payload, ackTimeout, respTimeout):\n    \"\\n        \\x08rief Initilizer function.\\n\\n        This function initializes this instance by recording everything about\\n        the CoAP message to be exchange with the remote endpoint. It does not,\\n        however, initiate the exchange, which is done by calling the transmit()\\n        method.\\n\\n        \\\\paran[in] sendFunc The function to call to send a CoAP message.\\n        \\\\param[in] srcIp    The IP address of the local endpoint, a string of the\\n            form 'aaaa::1'.\\n        \\\\param[in] srcport  The UDP port the local endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] destIp   The IP address of the remote CoAP endpoint, a\\n            string of the form 'aaaa::1'.\\n        \\\\param[in] destPort The UDP port the remote endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] confirmable A boolean indicating whether the CoAP request is\\n            to be send confirmable (True) or non-confirmable (False).\\n        \\\\param[in] messageId The message ID to be used for the CoAP request, an\\n            integer. The caller of this function needs to enforce unicity rules\\n            for the value passed.\\n        \\\\param[in] code     The CoAP method to used in the request. Needs to a\\n            value of METHOD_ALL.\\n        \\\\param[in] token    The token to be used for this exchange. The caller\\n            of this function needs to enforce unicity rules for the value\\n            passed.\\n        \\\\param[in] options  A list of CoAP options. Each element needs to be\\n            an instance of the coapOption class. Note that this class will add\\n            appropriate CoAP options to encore the URI and query, if needed.\\n        \\\\param[in] payload  The payload to pass in the CoAP request. This needs\\n            to be a byte list, i.e. a list of intergers between 0x00 and 0xff.\\n            This function does not parse this payload, which is written as-is\\n            in the CoAP request.\\n        \\\\param[in] ackTimeout The ACK timeout.\\n        \\\\param[in] respTimeout The app-level response timeout.\\n        \"\n    log.debug('creating instance')\n    self.sendFunc = sendFunc\n    self.srcIp = srcIp\n    self.srcPort = destIp\n    self.destIp = destIp\n    self.destPort = destPort\n    self.confirmable = confirmable\n    self.messageId = messageId\n    self.code = code\n    self.token = token\n    self.options = options\n    self.payload = payload\n    self.dataLock = threading.Lock()\n    self.fsmSem = threading.Lock()\n    self.startLock = threading.Lock()\n    self.endLock = threading.Lock()\n    self.stateLock = threading.RLock()\n    self.rxMsgEvent = threading.Event()\n    self.receivedACK = None\n    self.receivedResp = None\n    self.coapResponse = None\n    self.coapError = None\n    self.state = self.STATE_INIT\n    self.maxRetransmit = d.DFLT_MAX_RETRANSMIT\n    self.numTxCON = 0\n    self.ackTimeout = ackTimeout\n    self.respTimeout = respTimeout\n    self.fsmGoOn = True\n    self.fsmAction = {\n        self.STATE_INIT: self._action_INIT,\n        self.STATE_TXCON: self._action_TXCON,\n        self.STATE_TXNON: self._action_TXNON,\n        self.STATE_WAITFORACK: self._action_WAITFORACK,\n        self.STATE_ACKRX: self._action_ACKRX,\n        self.STATE_WAITFOREXPIRATIONMID: self._action_WAITFOREXPIRATIONMID,\n        self.STATE_WAITFORRESP: self._action_WAITFORRESP,\n        self.STATE_RESPRX: self._action_RESPRX,\n        self.STATE_TXACK: self._action_TXACK,\n    }\n    threading.Thread.__init__(self)\n    self.name = '[{0}]:{1}--m0x{2:x},0x{3:x}-->[{4}]:{5}'.format(self.srcIp, self.srcPort, self.messageId, self.token, self.destIp, self.destPort)\n    self.startLock.acquire()\n    self.endLock.acquire()\n    self.start()\n", "label": "Variable misuse"}
{"function": "\n\n@pg.production('binop_expr : binop_expr PIPELINE_FIRST_BIND binop_expr')\ndef binop_expr(p):\n    (left, _, right) = p\n    input_sym = get_temp_name()\n    return [Symbol('|>'), p[0], [Symbol('bind'), [Symbol('fn'), [input_sym], ([p[2][0], input_sym] + p[2][(1 if (len(p[2]) > 1) else len(p[2])):])]]]\n", "label": "Correct"}
{"function": "\n\n@pg.production('binop_expr : binop_expr PIPELINE_FIRST_BIND binop_expr')\ndef binop_expr(p):\n    (left, _, right) = p\n    input_sym = get_temp_name()\n    return [Symbol('|>'), p[0], [Symbol('bind'), [Symbol('fn'), [p], ([p[2][0], input_sym] + p[2][(1 if (len(p[2]) > 1) else len(p[2])):])]]]\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(experiments.gmacpyutil, 'SetMachineInfoForKey')\ndef testAddExperimentToManualListPlistError(self, mock_smifk):\n    mock_smifk.return_value = False\n    experiments.KNOBS.Knobs = mock.MagicMock(return_value={\n        \n    })\n    self.assertRaises(experiments.PlistError, experiments.AddExperimentToManualList, 'foo', 'knob')\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(experiments.gmacpyutil, 'SetMachineInfoForKey')\ndef testAddExperimentToManualListPlistError(self, mock_smifk):\n    mock_smifk.return_value = False\n    experiments.KNOBS.Knobs = mock.MagicMock(return_value={\n        \n    })\n    mock_smifk.assertRaises(experiments.PlistError, experiments.AddExperimentToManualList, 'foo', 'knob')\n", "label": "Variable misuse"}
{"function": "\n\ndef write_file(filename, content):\n    'Write content to file.'\n    (_dir, _) = os.path.split(filename)\n    if (not os.path.exists(_dir)):\n        logging.debug('The directory %s not exists, create it', _dir)\n        mkdir_p(_dir)\n    with io.open(filename, 'wt', encoding='utf-8') as fd:\n        fd.write(content)\n", "label": "Correct"}
{"function": "\n\ndef write_file(filename, content):\n    'Write content to file.'\n    (_dir, _) = os.path.split(filename)\n    if (not os.path.exists(_dir)):\n        logging.debug('The directory %s not exists, create it', _dir)\n        mkdir_p(_dir)\n    with io.open(filename, 'wt', encoding='utf-8') as fd:\n        _dir.write(content)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_chebyt(self):\n    T0 = orth.chebyt(0)\n    T1 = orth.chebyt(1)\n    T2 = orth.chebyt(2)\n    T3 = orth.chebyt(3)\n    T4 = orth.chebyt(4)\n    T5 = orth.chebyt(5)\n    assert_array_almost_equal(T0.c, [1], 13)\n    assert_array_almost_equal(T1.c, [1, 0], 13)\n    assert_array_almost_equal(T2.c, [2, 0, (- 1)], 13)\n    assert_array_almost_equal(T3.c, [4, 0, (- 3), 0], 13)\n    assert_array_almost_equal(T4.c, [8, 0, (- 8), 0, 1], 13)\n    assert_array_almost_equal(T5.c, [16, 0, (- 20), 0, 5, 0], 13)\n", "label": "Correct"}
{"function": "\n\ndef test_chebyt(self):\n    T0 = orth.chebyt(0)\n    T1 = orth.chebyt(1)\n    T2 = orth.chebyt(2)\n    T3 = orth.chebyt(3)\n    T4 = orth.chebyt(4)\n    T5 = orth.chebyt(5)\n    assert_array_almost_equal(T0.c, [1], 13)\n    assert_array_almost_equal(T1.c, [1, 0], 13)\n    assert_array_almost_equal(T1.c, [2, 0, (- 1)], 13)\n    assert_array_almost_equal(T3.c, [4, 0, (- 3), 0], 13)\n    assert_array_almost_equal(T4.c, [8, 0, (- 8), 0, 1], 13)\n    assert_array_almost_equal(T5.c, [16, 0, (- 20), 0, 5, 0], 13)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_topic_published(self, topicname):\n    return (topicname in dict(rospy.get_published_topics()).keys())\n", "label": "Correct"}
{"function": "\n\ndef is_topic_published(self, topicname):\n    return (self in dict(rospy.get_published_topics()).keys())\n", "label": "Variable misuse"}
{"function": "\n\ndef index(self, keypair_list):\n    return dict(keypairs=[self._base_response(keypair) for keypair in keypair_list])\n", "label": "Correct"}
{"function": "\n\ndef index(self, keypair_list):\n    return dict(keypairs=[keypair_list._base_response(keypair) for keypair in keypair_list])\n", "label": "Variable misuse"}
{"function": "\n\ndef validate(self, value):\n    super(Interval, self).validate(value)\n    if (not ((value is None) or (self.interval_type.is_valid(value) and (value >= self.start) and (value <= self.end)))):\n        raise ValueError(('expected a value of type %s in range [%s, %s], got %r' % (self.interval_type, self.start, self.end, value)))\n", "label": "Correct"}
{"function": "\n\ndef validate(self, value):\n    super(Interval, self).validate(value)\n    if (not ((value is None) or (self.interval_type.is_valid(value) and (self >= self.start) and (value <= self.end)))):\n        raise ValueError(('expected a value of type %s in range [%s, %s], got %r' % (self.interval_type, self.start, self.end, value)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _on_nick(self, c, e):\n    '[Internal]'\n    before = nm_to_n(e.source())\n    after = e.target()\n    for ch in self.channels.values():\n        if ch.has_user(before):\n            ch.change_nick(before, after)\n", "label": "Correct"}
{"function": "\n\ndef _on_nick(self, c, e):\n    '[Internal]'\n    before = nm_to_n(ch.source())\n    after = e.target()\n    for ch in self.channels.values():\n        if ch.has_user(before):\n            ch.change_nick(before, after)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_K4_normalized(self):\n    'Betweenness centrality: K4'\n    G = networkx.complete_graph(4)\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    b_answer = {\n        0: 0.25,\n        1: 0.25,\n        2: 0.25,\n        3: 0.25,\n    }\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    G.add_edge(0, 1, {\n        'weight': 0.5,\n        'other': 0.3,\n    })\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight=None)\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    wb_answer = {\n        0: 0.2222222,\n        1: 0.2222222,\n        2: 0.30555555,\n        3: 0.30555555,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n    wb_answer = {\n        0: 0.2051282,\n        1: 0.2051282,\n        2: 0.33974358,\n        3: 0.33974358,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight='other')\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n", "label": "Correct"}
{"function": "\n\ndef test_K4_normalized(self):\n    'Betweenness centrality: K4'\n    G = networkx.complete_graph(4)\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    b_answer = {\n        0: 0.25,\n        1: 0.25,\n        2: 0.25,\n        3: 0.25,\n    }\n    for n in sorted(G):\n        assert_almost_equal(b[n], b[n])\n    G.add_edge(0, 1, {\n        'weight': 0.5,\n        'other': 0.3,\n    })\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight=None)\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    wb_answer = {\n        0: 0.2222222,\n        1: 0.2222222,\n        2: 0.30555555,\n        3: 0.30555555,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n    wb_answer = {\n        0: 0.2051282,\n        1: 0.2051282,\n        2: 0.33974358,\n        3: 0.33974358,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight='other')\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, data, note):\n    self.data = data\n    self.note = note\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, data, note):\n    data.data = data\n    self.note = note\n", "label": "Variable misuse"}
{"function": "\n\ndef get_auth_params(self, request, action):\n    settings = self.get_settings()\n    ret = settings.get('AUTH_PARAMS', {\n        \n    })\n    dynamic_auth_params = request.GET.get('auth_params', None)\n    if dynamic_auth_params:\n        ret.update(dict(parse_qsl(dynamic_auth_params)))\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef get_auth_params(self, request, action):\n    settings = settings.get_settings()\n    ret = settings.get('AUTH_PARAMS', {\n        \n    })\n    dynamic_auth_params = request.GET.get('auth_params', None)\n    if dynamic_auth_params:\n        ret.update(dict(parse_qsl(dynamic_auth_params)))\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\ndef _caas_2_2_8a8f6abc_2745_4d8a_9cbc_8dabe5a7d0e4_server(self, method, url, body, headers):\n    body = self.fixtures.load('server.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _caas_2_2_8a8f6abc_2745_4d8a_9cbc_8dabe5a7d0e4_server(self, method, url, body, headers):\n    body = self.fixtures.load('server.xml')\n    return (httplib.OK, self, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef getCurrentPipelineId(self, pipelineInfo):\n    ' getCurrentPipelineId(pipelineInfo: dict) -> Int\\n        Get the current pipeline id\\n\\n        '\n    vistrail = self.pipelineId(pipelineInfo)\n    return self.executedPipelines[1][vistrail]\n", "label": "Correct"}
{"function": "\n\ndef getCurrentPipelineId(self, pipelineInfo):\n    ' getCurrentPipelineId(pipelineInfo: dict) -> Int\\n        Get the current pipeline id\\n\\n        '\n    vistrail = self.pipelineId(pipelineInfo)\n    return pipelineInfo.executedPipelines[1][vistrail]\n", "label": "Variable misuse"}
{"function": "\n\ndef _emit(self, record, stream):\n    self.stream = stream\n    try:\n        return logging.StreamHandler.emit(self, record)\n    except:\n        raise\n    else:\n        self.stream = None\n", "label": "Correct"}
{"function": "\n\ndef _emit(self, record, stream):\n    self.stream = record\n    try:\n        return logging.StreamHandler.emit(self, record)\n    except:\n        raise\n    else:\n        self.stream = None\n", "label": "Variable misuse"}
{"function": "\n\ndef _hash(self, value):\n    key_salt = ('django.contrib.sessions' + self.__class__.__name__)\n    return salted_hmac(key_salt, value).hexdigest()\n", "label": "Correct"}
{"function": "\n\ndef _hash(self, value):\n    key_salt = ('django.contrib.sessions' + key_salt.__class__.__name__)\n    return salted_hmac(key_salt, value).hexdigest()\n", "label": "Variable misuse"}
{"function": "\n\ndef data_path(path, createdir=False):\n    'If path is relative, return the given path inside the project data dir,\\n    otherwise return the path unmodified\\n    '\n    if (not isabs(path)):\n        path = join(project_data_dir(), path)\n    if (createdir and (not exists(path))):\n        os.makedirs(path)\n    return path\n", "label": "Correct"}
{"function": "\n\ndef data_path(path, createdir=False):\n    'If path is relative, return the given path inside the project data dir,\\n    otherwise return the path unmodified\\n    '\n    if (not isabs(path)):\n        path = join(project_data_dir(), path)\n    if (createdir and (not exists(path))):\n        os.makedirs(createdir)\n    return path\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, groupDateTime, bars, frequency):\n    resamplebase.Grouper.__init__(self, groupDateTime)\n    self.__barGroupers = {\n        \n    }\n    self.__frequency = frequency\n    for (instrument, bar_) in bars.items():\n        barGrouper = resampled.BarGrouper(groupDateTime, bar_, frequency)\n        self.__barGroupers[instrument] = barGrouper\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, groupDateTime, bars, frequency):\n    resamplebase.Grouper.__init__(self, groupDateTime)\n    self.__barGroupers = {\n        \n    }\n    self.__frequency = frequency\n    for (instrument, bar_) in bars.items():\n        barGrouper = resampled.BarGrouper(bar_, bar_, frequency)\n        self.__barGroupers[instrument] = barGrouper\n", "label": "Variable misuse"}
{"function": "\n\ndef ex_attach_nic_to_node(self, node, network, ip_address=None):\n    \"\\n        Add an extra Nic to a VM\\n\\n        :param  network: NetworkOffering object\\n        :type   network: :class:'CloudStackNetwork`\\n\\n        :param  node: Node Object\\n        :type   node: :class:'CloudStackNode`\\n\\n        :param  ip_address: Optional, specific IP for this Nic\\n        :type   ip_address: ``str``\\n\\n\\n        :rtype: ``bool``\\n        \"\n    args = {\n        'virtualmachineid': node.id,\n        'networkid': network.id,\n    }\n    if (ip_address is not None):\n        args['ipaddress'] = ip_address\n    self._async_request(command='addNicToVirtualMachine', params=args)\n    return True\n", "label": "Correct"}
{"function": "\n\ndef ex_attach_nic_to_node(self, node, network, ip_address=None):\n    \"\\n        Add an extra Nic to a VM\\n\\n        :param  network: NetworkOffering object\\n        :type   network: :class:'CloudStackNetwork`\\n\\n        :param  node: Node Object\\n        :type   node: :class:'CloudStackNode`\\n\\n        :param  ip_address: Optional, specific IP for this Nic\\n        :type   ip_address: ``str``\\n\\n\\n        :rtype: ``bool``\\n        \"\n    args = {\n        'virtualmachineid': node.id,\n        'networkid': network.id,\n    }\n    if (ip_address is not None):\n        args['ipaddress'] = ip_address\n    ip_address._async_request(command='addNicToVirtualMachine', params=args)\n    return True\n", "label": "Variable misuse"}
{"function": "\n\n@unittest.skip('skipping non-updated test')\ndef test_create_update_destroy_list_add_remove_list_members(self):\n    'Test create a list, adding and removing members then\\n        deleting the list succeeds'\n    the_list = self.api.create_list(name=('Stuff %s' % int(time.time())))\n    list_id = the_list['id_str']\n    self.api.update_list(list_id=list_id, name=('Stuff Renamed                              %s' % int(time.time())))\n    screen_names = ['johncena', 'xbox']\n    self.api.create_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.delete_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.add_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list(list_id=list_id)\n", "label": "Correct"}
{"function": "\n\n@unittest.skip('skipping non-updated test')\ndef test_create_update_destroy_list_add_remove_list_members(self):\n    'Test create a list, adding and removing members then\\n        deleting the list succeeds'\n    the_list = self.api.create_list(name=('Stuff %s' % int(time.time())))\n    list_id = the_list['id_str']\n    self.api.update_list(list_id=list_id, name=('Stuff Renamed                              %s' % int(time.time())))\n    screen_names = ['johncena', 'xbox']\n    self.api.create_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.delete_list_members(list_id=list_id, screen_name=list_id)\n    self.api.add_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list(list_id=list_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef longRunHighGrayLevelEmphasis(self, P_glrl, ivector, jvector, sumP_glrl, meanFlag=True):\n    try:\n        lrhgle = (numpy.sum(numpy.sum(((P_glrl * (ivector ** 2)[:, None, None]) * (jvector ** 2)[None, :, None]), 0), 0) / sumP_glrl[None, None, :])\n    except ZeroDivisionError:\n        lrhgle = 0\n    if meanFlag:\n        return lrhgle.mean()\n    else:\n        return lrhgle\n", "label": "Correct"}
{"function": "\n\ndef longRunHighGrayLevelEmphasis(self, P_glrl, ivector, jvector, sumP_glrl, meanFlag=True):\n    try:\n        lrhgle = (numpy.sum(numpy.sum(((P_glrl * (ivector ** 2)[:, None, None]) * (jvector ** 2)[None, :, None]), 0), 0) / sumP_glrl[None, None, :])\n    except ZeroDivisionError:\n        lrhgle = 0\n    if meanFlag:\n        return lrhgle.mean()\n    else:\n        return ivector\n", "label": "Variable misuse"}
{"function": "\n\ndef bind(self, lan):\n    'bind to a LAN.'\n    if _debug:\n        Node._debug('bind %r', lan)\n    lan.add_node(self)\n", "label": "Correct"}
{"function": "\n\ndef bind(self, lan):\n    'bind to a LAN.'\n    if _debug:\n        Node._debug('bind %r', lan)\n    lan.add_node(lan)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_no_text_logged_out_private(self):\n    (res, project) = self.request(NO_TEXT, public=False, logged_out=True, errors=True)\n    assert_equal(res.status_code, 401)\n    assert_equal(len(res.json['errors']), 1)\n    assert_equal(res.json['errors'][0]['detail'], 'Authentication credentials were not provided.')\n    project.reload()\n    assert_equal(len(project.alternative_citations), 0)\n", "label": "Correct"}
{"function": "\n\ndef test_add_no_text_logged_out_private(self):\n    (res, project) = res.request(NO_TEXT, public=False, logged_out=True, errors=True)\n    assert_equal(res.status_code, 401)\n    assert_equal(len(res.json['errors']), 1)\n    assert_equal(res.json['errors'][0]['detail'], 'Authentication credentials were not provided.')\n    project.reload()\n    assert_equal(len(project.alternative_citations), 0)\n", "label": "Variable misuse"}
{"function": "\n\n@must_be_logged_in\ndef oauth_application_register(auth, **kwargs):\n    'Register an API application: blank form view'\n    app_list_url = api_v2_url('applications/')\n    return {\n        'app_list_url': app_list_url,\n        'app_detail_url': '',\n    }\n", "label": "Correct"}
{"function": "\n\n@must_be_logged_in\ndef oauth_application_register(auth, **kwargs):\n    'Register an API application: blank form view'\n    app_list_url = api_v2_url('applications/')\n    return {\n        'app_list_url': kwargs,\n        'app_detail_url': '',\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_query_ops(self):\n    from grease.component.field import FieldAccessor\n    comp = TestComponent()\n    for i in range(1, 4):\n        comp[i] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 3)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 6)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n    entities = set(range(1, 7))\n    x_accessor = FieldAccessor(TestField(comp, 'x'), entities)\n    self.assertEqual((x_accessor == 4), set([2, 5]))\n    self.assertEqual((x_accessor == 0), set())\n    self.assertEqual((x_accessor != 1), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor != 33), set([1, 2, 3, 4, 5, 6]))\n    self.assertEqual((x_accessor > 5), set([3, 6]))\n    self.assertEqual((x_accessor > 9), set())\n    self.assertEqual((x_accessor >= 4), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor >= 10), set())\n    self.assertEqual((x_accessor < 2), set([1, 4]))\n    self.assertEqual((x_accessor < 1), set())\n    self.assertEqual((x_accessor <= 4), set([1, 2, 4, 5]))\n    self.assertEqual((x_accessor <= (- 1)), set())\n    pos_accessor = FieldAccessor(TestField(comp, 'pos'), entities)\n    self.assertEqual((pos_accessor.x == 3), set([3, 6]))\n    self.assertEqual((pos_accessor.x < 3), set([1, 2, 4, 5]))\n", "label": "Correct"}
{"function": "\n\ndef test_query_ops(self):\n    from grease.component.field import FieldAccessor\n    comp = TestComponent()\n    for i in range(1, 4):\n        comp[i] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 3)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 6)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n    entities = set(range(1, 7))\n    x_accessor = FieldAccessor(TestField(comp, 'x'), entities)\n    self.assertEqual((x_accessor == 4), set([2, 5]))\n    self.assertEqual((x_accessor == 0), set())\n    self.assertEqual((x_accessor != 1), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor != 33), set([1, 2, 3, 4, 5, 6]))\n    self.assertEqual((x_accessor > 5), set([3, 6]))\n    self.assertEqual((x_accessor > 9), set())\n    self.assertEqual((x_accessor >= 4), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor >= 10), set())\n    self.assertEqual((x_accessor < 2), set([1, 4]))\n    self.assertEqual((x_accessor < 1), set())\n    entities.assertEqual((x_accessor <= 4), set([1, 2, 4, 5]))\n    self.assertEqual((x_accessor <= (- 1)), set())\n    pos_accessor = FieldAccessor(TestField(comp, 'pos'), entities)\n    self.assertEqual((pos_accessor.x == 3), set([3, 6]))\n    self.assertEqual((pos_accessor.x < 3), set([1, 2, 4, 5]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_owner_and_label_switches(self):\n    runner_opts = ['--no-conf', '--owner=ads', '--label=ads_chain']\n    runner = MRTwoStepJob(runner_opts).make_runner()\n    match = _JOB_KEY_RE.match(runner.get_job_key())\n    self.assertEqual(match.group(1), 'ads_chain')\n    self.assertEqual(match.group(2), 'ads')\n", "label": "Correct"}
{"function": "\n\ndef test_owner_and_label_switches(self):\n    runner_opts = ['--no-conf', '--owner=ads', '--label=ads_chain']\n    runner = MRTwoStepJob(runner_opts).make_runner()\n    match = _JOB_KEY_RE.match(runner.get_job_key())\n    self.assertEqual(runner_opts.group(1), 'ads_chain')\n    self.assertEqual(match.group(2), 'ads')\n", "label": "Variable misuse"}
{"function": "\n\ndef columns_used(self):\n    '\\n        Returns all the columns used across all models in the group\\n        for filtering and in the model expression.\\n\\n        '\n    return list(tz.unique(tz.concat((m.columns_used() for m in self.models.values()))))\n", "label": "Correct"}
{"function": "\n\ndef columns_used(self):\n    '\\n        Returns all the columns used across all models in the group\\n        for filtering and in the model expression.\\n\\n        '\n    return list(tz.unique(tz.concat((self.columns_used() for m in self.models.values()))))\n", "label": "Variable misuse"}
{"function": "\n\ndef S_e(self, prob):\n    '\\n        Electric source term\\n\\n        :param Problem prob: FDEM Problem\\n        :rtype: numpy.ndarray\\n        :return: electric source term on mesh\\n        '\n    if ((prob._formulation is 'EB') and (self.integrate is True)):\n        return (prob.Me * self._S_e)\n    return self._S_e\n", "label": "Correct"}
{"function": "\n\ndef S_e(self, prob):\n    '\\n        Electric source term\\n\\n        :param Problem prob: FDEM Problem\\n        :rtype: numpy.ndarray\\n        :return: electric source term on mesh\\n        '\n    if ((self._formulation is 'EB') and (self.integrate is True)):\n        return (prob.Me * self._S_e)\n    return self._S_e\n", "label": "Variable misuse"}
{"function": "\n\ndef request(self, expand=None, select=None, top=None, order_by=None, options=None):\n    'Builds the PermissionsCollectionRequest\\n        \\n        Args:\\n            expand (str): Default None, comma-seperated list of relationships\\n                to expand in the response.\\n            select (str): Default None, comma-seperated list of properties to\\n                include in the response.\\n            top (int): Default None, the number of items to return in a result.\\n            order_by (str): Default None, comma-seperated list of properties\\n                that are used to sort the order of items in the response.\\n            options (list of :class:`Option<onedrivesdk.options.Option>`):\\n                A list of options to pass into the request. Defaults to None.\\n\\n        Returns:\\n            :class:`PermissionsCollectionRequest<onedrivesdk.request.permissions_collection.PermissionsCollectionRequest>`:\\n                The PermissionsCollectionRequest\\n        '\n    req = PermissionsCollectionRequest(self._request_url, self._client, options)\n    req._set_query_options(expand=expand, select=select, top=top, order_by=order_by)\n    return req\n", "label": "Correct"}
{"function": "\n\ndef request(self, expand=None, select=None, top=None, order_by=None, options=None):\n    'Builds the PermissionsCollectionRequest\\n        \\n        Args:\\n            expand (str): Default None, comma-seperated list of relationships\\n                to expand in the response.\\n            select (str): Default None, comma-seperated list of properties to\\n                include in the response.\\n            top (int): Default None, the number of items to return in a result.\\n            order_by (str): Default None, comma-seperated list of properties\\n                that are used to sort the order of items in the response.\\n            options (list of :class:`Option<onedrivesdk.options.Option>`):\\n                A list of options to pass into the request. Defaults to None.\\n\\n        Returns:\\n            :class:`PermissionsCollectionRequest<onedrivesdk.request.permissions_collection.PermissionsCollectionRequest>`:\\n                The PermissionsCollectionRequest\\n        '\n    req = PermissionsCollectionRequest(self._request_url, self._client, options)\n    req._set_query_options(expand=self, select=select, top=top, order_by=order_by)\n    return req\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, fn):\n\n    def wrapper(*args, **kwargs):\n        that = args[0]\n        that.logger.debug(self.start)\n        ret = fn(*args, **kwargs)\n        that.logger.debug(self.finish)\n        if self.getter:\n            that.logger.debug(pformat(self.getter(ret)))\n        else:\n            that.logger.debug(pformat(ret))\n        return ret\n    wrapper.func_name = fn.func_name\n    if hasattr(fn, '__name__'):\n        wrapper.__name__ = self.name = fn.__name__\n    if hasattr(fn, '__doc__'):\n        wrapper.__doc__ = fn.__doc__\n    if hasattr(fn, '__module__'):\n        wrapper.__module__ = fn.__module__\n    return wrapper\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, fn):\n\n    def wrapper(*args, **kwargs):\n        that = args[0]\n        that.logger.debug(self.start)\n        ret = fn(*args, **kwargs)\n        that.logger.debug(self.finish)\n        if self.getter:\n            that.logger.debug(pformat(self.getter(ret)))\n        else:\n            that.logger.debug(pformat(ret))\n        return ret\n    wrapper.func_name = fn.func_name\n    if hasattr(self, '__name__'):\n        wrapper.__name__ = self.name = fn.__name__\n    if hasattr(fn, '__doc__'):\n        wrapper.__doc__ = fn.__doc__\n    if hasattr(fn, '__module__'):\n        wrapper.__module__ = fn.__module__\n    return wrapper\n", "label": "Variable misuse"}
{"function": "\n\ndef write_packed(self, outfile, rows):\n    '\\n        Write PNG file to `outfile`.  The pixel data comes from `rows`\\n        which should be in boxed row packed format.  Each row should be\\n        a sequence of packed bytes.\\n\\n        Technically, this method does work for interlaced images but it\\n        is best avoided.  For interlaced images, the rows should be\\n        presented in the order that they appear in the file.\\n\\n        This method should not be used when the source image bit depth\\n        is not one naturally supported by PNG; the bit depth should be\\n        1, 2, 4, 8, or 16.\\n        '\n    if self.rescale:\n        raise Error(('write_packed method not suitable for bit depth %d' % self.rescale[0]))\n    return self.write_passes(outfile, rows, packed=True)\n", "label": "Correct"}
{"function": "\n\ndef write_packed(self, outfile, rows):\n    '\\n        Write PNG file to `outfile`.  The pixel data comes from `rows`\\n        which should be in boxed row packed format.  Each row should be\\n        a sequence of packed bytes.\\n\\n        Technically, this method does work for interlaced images but it\\n        is best avoided.  For interlaced images, the rows should be\\n        presented in the order that they appear in the file.\\n\\n        This method should not be used when the source image bit depth\\n        is not one naturally supported by PNG; the bit depth should be\\n        1, 2, 4, 8, or 16.\\n        '\n    if self.rescale:\n        raise Error(('write_packed method not suitable for bit depth %d' % outfile.rescale[0]))\n    return self.write_passes(outfile, rows, packed=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef crumble(self, instance, attrs):\n    data = super(TestCaseWithOriginCrumbler, self).crumble(instance, attrs)\n    data['origin'] = getattr(instance, 'origin', None)\n    return data\n", "label": "Correct"}
{"function": "\n\ndef crumble(self, instance, attrs):\n    data = super(TestCaseWithOriginCrumbler, self).crumble(instance, attrs)\n    data['origin'] = getattr(self, 'origin', None)\n    return data\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/components/engine/shared_eng_mission_reward_neutral_mandal_inferno.iff'\n    result.attribute_template_id = 8\n    result.stfName('space/space_item', 'eng_mission_reward_neutral_mandal_inferno_n')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/components/engine/shared_eng_mission_reward_neutral_mandal_inferno.iff'\n    result.attribute_template_id = 8\n    kernel.stfName('space/space_item', 'eng_mission_reward_neutral_mandal_inferno_n')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@gen_test\ndef test_search_apecific_type(self):\n    response = (yield self.es_connection.search(type='galeria'))\n    response = self._verify_status_code_and_return_response(response)\n    self.assertEqual(response['hits']['total'], 2)\n", "label": "Correct"}
{"function": "\n\n@gen_test\ndef test_search_apecific_type(self):\n    response = (yield response.es_connection.search(type='galeria'))\n    response = self._verify_status_code_and_return_response(response)\n    self.assertEqual(response['hits']['total'], 2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_volume_create_user_project_name(self):\n    self.projects_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.PROJECT), loaded=True)\n    self.users_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.USER), loaded=True)\n    arglist = ['--size', str(self.new_volume.size), '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, self.new_volume.name]\n    verifylist = [('size', self.new_volume.size), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=identity_fakes.user_id, project_id=identity_fakes.project_id, availability_zone=None, metadata=None, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Correct"}
{"function": "\n\ndef test_volume_create_user_project_name(self):\n    self.projects_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.PROJECT), loaded=True)\n    self.users_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.USER), loaded=True)\n    arglist = ['--size', str(self.new_volume.size), '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, self.new_volume.name]\n    verifylist = [('size', self.new_volume.size), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, arglist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=identity_fakes.user_id, project_id=identity_fakes.project_id, availability_zone=None, metadata=None, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean_votes(self, value):\n    assert (value > 0), 'Must be greater than 0.'\n    assert (value < 51), 'Must be less than 51.'\n    return value\n", "label": "Correct"}
{"function": "\n\ndef clean_votes(self, value):\n    assert (value > 0), 'Must be greater than 0.'\n    assert (self < 51), 'Must be less than 51.'\n    return value\n", "label": "Variable misuse"}
{"function": "\n\ndef _print_slots(self):\n    slots = ', '.join((((\"'\" + snake(name)) + \"'\") for (type, name, nullable, plural) in self._fields))\n    print(\"    __slots__ = ('loc', {slots},)\".format(slots=slots))\n", "label": "Correct"}
{"function": "\n\ndef _print_slots(self):\n    slots = ', '.join((((\"'\" + snake(name)) + \"'\") for (type, name, nullable, plural) in nullable._fields))\n    print(\"    __slots__ = ('loc', {slots},)\".format(slots=slots))\n", "label": "Variable misuse"}
{"function": "\n\ndef register_scheme(scheme):\n    for method in dir(urlparse):\n        if method.startswith('uses_'):\n            getattr(urlparse, method).append(scheme)\n", "label": "Correct"}
{"function": "\n\ndef register_scheme(scheme):\n    for method in dir(urlparse):\n        if method.startswith('uses_'):\n            getattr(urlparse, method).append(method)\n", "label": "Variable misuse"}
{"function": "\n\ndef configure_uploads(app, upload_sets):\n    \"\\n    Call this after the app has been configured. It will go through all the\\n    upload sets, get their configuration, and store the configuration on the\\n    app. It will also register the uploads module if it hasn't been set. This\\n    can be called multiple times with different upload sets.\\n    \\n    .. versionchanged:: 0.1.3\\n       The uploads module/blueprint will only be registered if it is needed\\n       to serve the upload sets.\\n    \\n    :param app: The `~flask.Flask` instance to get the configuration from.\\n    :param upload_sets: The `UploadSet` instances to configure.\\n    \"\n    if isinstance(upload_sets, UploadSet):\n        upload_sets = (upload_sets,)\n    if (not hasattr(app, 'upload_set_config')):\n        app.upload_set_config = {\n            \n        }\n    set_config = app.upload_set_config\n    defaults = dict(dest=app.config.get('UPLOADS_DEFAULT_DEST'), url=app.config.get('UPLOADS_DEFAULT_URL'))\n    for uset in upload_sets:\n        config = config_for_set(uset, app, defaults)\n        set_config[uset.name] = config\n    should_serve = any(((s.base_url is None) for s in set_config.itervalues()))\n    if using_blueprints:\n        if (('_uploads' not in app.blueprints) and should_serve):\n            app.register_blueprint(uploads_mod)\n    elif (('_uploads' not in app.modules) and should_serve):\n        app.register_module(uploads_mod)\n", "label": "Correct"}
{"function": "\n\ndef configure_uploads(app, upload_sets):\n    \"\\n    Call this after the app has been configured. It will go through all the\\n    upload sets, get their configuration, and store the configuration on the\\n    app. It will also register the uploads module if it hasn't been set. This\\n    can be called multiple times with different upload sets.\\n    \\n    .. versionchanged:: 0.1.3\\n       The uploads module/blueprint will only be registered if it is needed\\n       to serve the upload sets.\\n    \\n    :param app: The `~flask.Flask` instance to get the configuration from.\\n    :param upload_sets: The `UploadSet` instances to configure.\\n    \"\n    if isinstance(upload_sets, UploadSet):\n        upload_sets = (upload_sets,)\n    if (not hasattr(app, 'upload_set_config')):\n        app.upload_set_config = {\n            \n        }\n    set_config = app.upload_set_config\n    defaults = dict(dest=upload_sets.config.get('UPLOADS_DEFAULT_DEST'), url=app.config.get('UPLOADS_DEFAULT_URL'))\n    for uset in upload_sets:\n        config = config_for_set(uset, app, defaults)\n        set_config[uset.name] = config\n    should_serve = any(((s.base_url is None) for s in set_config.itervalues()))\n    if using_blueprints:\n        if (('_uploads' not in app.blueprints) and should_serve):\n            app.register_blueprint(uploads_mod)\n    elif (('_uploads' not in app.modules) and should_serve):\n        app.register_module(uploads_mod)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_bad_choice_in_list(self):\n    config = _root({\n        'foo': 3,\n    })\n    with self.assertRaises(confuse.ConfigValueError):\n        config['foo'].get(confuse.Choice([1, 2, 4, 8, 16]))\n", "label": "Correct"}
{"function": "\n\ndef test_validate_bad_choice_in_list(self):\n    config = _root({\n        'foo': 3,\n    })\n    with self.assertRaises(confuse.ConfigValueError):\n        self['foo'].get(confuse.Choice([1, 2, 4, 8, 16]))\n", "label": "Variable misuse"}
{"function": "\n\n@shared_task\n@transition(Instance, 'begin_stopping')\n@save_error_message\ndef stop_instance(instance_uuid, transition_entity=None):\n    instance = transition_entity\n    backend = instance.get_backend()\n    backend.stop_instance(instance)\n", "label": "Correct"}
{"function": "\n\n@shared_task\n@transition(Instance, 'begin_stopping')\n@save_error_message\ndef stop_instance(instance_uuid, transition_entity=None):\n    instance = transition_entity\n    backend = transition_entity.get_backend()\n    backend.stop_instance(instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_property(self, key):\n    'Expect Django Conf property'\n    _key = DJANGO_CONF[key]\n    return getattr(self, _key, CONF_SPEC[_key])\n", "label": "Correct"}
{"function": "\n\ndef get_property(self, key):\n    'Expect Django Conf property'\n    _key = DJANGO_CONF[key]\n    return getattr(_key, _key, CONF_SPEC[_key])\n", "label": "Variable misuse"}
{"function": "\n\ndef change_primary_name(self, name):\n    '\\n        Changes the primary/default name of the policy to a specified name.\\n\\n        :param name: a string name to replace the current primary name.\\n        '\n    if (name == self.name):\n        return\n    elif (name in self.alias_list):\n        self.remove_name(name)\n    else:\n        self._validate_policy_name(name)\n    self.alias_list.insert(0, name)\n", "label": "Correct"}
{"function": "\n\ndef change_primary_name(self, name):\n    '\\n        Changes the primary/default name of the policy to a specified name.\\n\\n        :param name: a string name to replace the current primary name.\\n        '\n    if (self == self.name):\n        return\n    elif (name in self.alias_list):\n        self.remove_name(name)\n    else:\n        self._validate_policy_name(name)\n    self.alias_list.insert(0, name)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, ofproto):\n    self.ofproto = ofproto\n    self.deprecated_value = ['OFPTFPT_EXPERIMENTER_SLAVE', 'OFPTFPT_EXPERIMENTER_MASTER', 'OFPQCFC_EPERM']\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, ofproto):\n    self.ofproto = self\n    self.deprecated_value = ['OFPTFPT_EXPERIMENTER_SLAVE', 'OFPTFPT_EXPERIMENTER_MASTER', 'OFPQCFC_EPERM']\n", "label": "Variable misuse"}
{"function": "\n\ndef _users_with_perm(self, actions, collection=None):\n    \"\\n        Return a queryset of users with any permissions corresponding to 'actions',\\n        via either GroupCollectionPermission or superuser privileges.\\n        If collection is specified, only consider GroupCollectionPermission records\\n        that apply to that collection.\\n        \"\n    return get_user_model().objects.filter(self._users_with_perm_filter(actions, collection=collection)).distinct()\n", "label": "Correct"}
{"function": "\n\ndef _users_with_perm(self, actions, collection=None):\n    \"\\n        Return a queryset of users with any permissions corresponding to 'actions',\\n        via either GroupCollectionPermission or superuser privileges.\\n        If collection is specified, only consider GroupCollectionPermission records\\n        that apply to that collection.\\n        \"\n    return get_user_model().objects.filter(self._users_with_perm_filter(self, collection=collection)).distinct()\n", "label": "Variable misuse"}
{"function": "\n\ndef configure_host(self):\n    if self.mail.use_ssl:\n        host = smtplib.SMTP_SSL(self.mail.server, self.mail.port)\n    else:\n        host = smtplib.SMTP(self.mail.server, self.mail.port)\n    host.set_debuglevel(int(self.mail.debug))\n    if self.mail.use_tls:\n        host.starttls()\n    if (self.mail.username and self.mail.password):\n        host.login(self.mail.username, self.mail.password)\n    return host\n", "label": "Correct"}
{"function": "\n\ndef configure_host(self):\n    if self.mail.use_ssl:\n        host = smtplib.SMTP_SSL(self.mail.server, self.mail.port)\n    else:\n        host = smtplib.SMTP(self.mail.server, self.mail.port)\n    host.set_debuglevel(int(self.mail.debug))\n    if self.mail.use_tls:\n        host.starttls()\n    if (self.mail.username and self.mail.password):\n        host.login(self.mail.username, host.mail.password)\n    return host\n", "label": "Variable misuse"}
{"function": "\n\ndef host_to_ip(host):\n    '\\n    Returns the IP address of a given hostname\\n    '\n    try:\n        (family, socktype, proto, canonname, sockaddr) = socket.getaddrinfo(host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM)[0]\n        if (family == socket.AF_INET):\n            (ip, port) = sockaddr\n        elif (family == socket.AF_INET6):\n            (ip, port, flow_info, scope_id) = sockaddr\n    except Exception:\n        ip = None\n    return ip\n", "label": "Correct"}
{"function": "\n\ndef host_to_ip(host):\n    '\\n    Returns the IP address of a given hostname\\n    '\n    try:\n        (family, socktype, proto, canonname, sockaddr) = socket.getaddrinfo(host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM)[0]\n        if (family == socket.AF_INET):\n            (ip, port) = sockaddr\n        elif (family == socket.AF_INET6):\n            (ip, port, flow_info, scope_id) = host\n    except Exception:\n        ip = None\n    return ip\n", "label": "Variable misuse"}
{"function": "\n\n@app.use\ndef error_handler(req, res, err):\n    res.send_text('404 : Hello World!!')\n", "label": "Correct"}
{"function": "\n\n@app.use\ndef error_handler(req, res, err):\n    err.send_text('404 : Hello World!!')\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, key):\n    key = key.lower()\n    if self.has_key(key):\n        return self._config.get(key.lower())\n    else:\n        return None\n", "label": "Correct"}
{"function": "\n\ndef get(self, key):\n    key = key.lower()\n    if self.has_key(self):\n        return self._config.get(key.lower())\n    else:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef fast(image, threshold=20.0, arc_length=9, non_max=True, feature_ratio=0.05, edge=3):\n    '\\n    FAST feature detector.\\n\\n    Parameters\\n    ----------\\n\\n    image         : af.Array\\n                  A 2D array representing an image.\\n\\n    threshold     : scalar. optional. default: 20.0.\\n                  FAST threshold for which a pixel of the circle around a central pixel is consdered.\\n\\n    arc_length    : scalar. optional. default: 9\\n                  The minimum length of arc length to be considered. Max length should be 16.\\n\\n    non_max       : Boolean. optional. default: True\\n                  A boolean flag specifying if non max suppression has to be performed.\\n\\n    feature_ratio : scalar. optional. default: 0.05 (5%)\\n                  Specifies the maximum ratio of features to pixels in the image.\\n\\n    edge          : scalar. optional. default: 3.\\n                  Specifies the number of edge rows and columns to be ignored.\\n\\n    Returns\\n    ---------\\n    features     : af.Features()\\n                 Contains the location and score. Orientation and size are not computed.\\n\\n    '\n    out = Features()\n    safe_call(backend.get().af_fast(ct.pointer(out.feat), image.arr, ct.c_float(threshold), ct.c_uint(arc_length), non_max, ct.c_float(feature_ratio), ct.c_uint(edge)))\n    return out\n", "label": "Correct"}
{"function": "\n\ndef fast(image, threshold=20.0, arc_length=9, non_max=True, feature_ratio=0.05, edge=3):\n    '\\n    FAST feature detector.\\n\\n    Parameters\\n    ----------\\n\\n    image         : af.Array\\n                  A 2D array representing an image.\\n\\n    threshold     : scalar. optional. default: 20.0.\\n                  FAST threshold for which a pixel of the circle around a central pixel is consdered.\\n\\n    arc_length    : scalar. optional. default: 9\\n                  The minimum length of arc length to be considered. Max length should be 16.\\n\\n    non_max       : Boolean. optional. default: True\\n                  A boolean flag specifying if non max suppression has to be performed.\\n\\n    feature_ratio : scalar. optional. default: 0.05 (5%)\\n                  Specifies the maximum ratio of features to pixels in the image.\\n\\n    edge          : scalar. optional. default: 3.\\n                  Specifies the number of edge rows and columns to be ignored.\\n\\n    Returns\\n    ---------\\n    features     : af.Features()\\n                 Contains the location and score. Orientation and size are not computed.\\n\\n    '\n    out = Features()\n    safe_call(backend.get().af_fast(ct.pointer(image.feat), image.arr, ct.c_float(threshold), ct.c_uint(arc_length), non_max, ct.c_float(feature_ratio), ct.c_uint(edge)))\n    return out\n", "label": "Variable misuse"}
{"function": "\n\ndef add_all_wordstarts_matching(self, lower_hits, query, max_hits_hint):\n    lower_query = query.lower()\n    if (lower_query in self.basenames_by_wordstarts):\n        for basename in self.basenames_by_wordstarts[lower_query]:\n            lower_hits.add(basename)\n            if (len(lower_hits) >= max_hits_hint):\n                return\n", "label": "Correct"}
{"function": "\n\ndef add_all_wordstarts_matching(self, lower_hits, query, max_hits_hint):\n    lower_query = query.lower()\n    if (lower_query in self.basenames_by_wordstarts):\n        for basename in self.basenames_by_wordstarts[lower_query]:\n            lower_hits.add(basename)\n            if (len(basename) >= max_hits_hint):\n                return\n", "label": "Variable misuse"}
{"function": "\n\ndef _setup_nodes(self):\n    self.add_node(LocalNode())\n    nodes = self.app.config.get('PSDASH_NODES', [])\n    logger.info('Registering %d nodes', len(nodes))\n    for n in nodes:\n        self.register_node(n['name'], n['host'], int(n['port']))\n", "label": "Correct"}
{"function": "\n\ndef _setup_nodes(self):\n    self.add_node(LocalNode())\n    nodes = self.app.config.get('PSDASH_NODES', [])\n    logger.info('Registering %d nodes', len(n))\n    for n in nodes:\n        self.register_node(n['name'], n['host'], int(n['port']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parent_model, admin_site):\n    self.admin_site = admin_site\n    self.parent_model = parent_model\n    self.opts = self.model._meta\n    self.has_registered_model = admin_site.is_registered(self.model)\n    super(InlineModelAdmin, self).__init__()\n    if (self.verbose_name is None):\n        self.verbose_name = self.model._meta.verbose_name\n    if (self.verbose_name_plural is None):\n        self.verbose_name_plural = self.model._meta.verbose_name_plural\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parent_model, admin_site):\n    self.admin_site = admin_site\n    self.parent_model = parent_model\n    self.opts = admin_site.model._meta\n    self.has_registered_model = admin_site.is_registered(self.model)\n    super(InlineModelAdmin, self).__init__()\n    if (self.verbose_name is None):\n        self.verbose_name = self.model._meta.verbose_name\n    if (self.verbose_name_plural is None):\n        self.verbose_name_plural = self.model._meta.verbose_name_plural\n", "label": "Variable misuse"}
{"function": "\n\ndef _PrepareWithTarFile(vm, speccpu_vm_state):\n    'Prepares the VM to run using the tar file.\\n\\n  Args:\\n    vm: BaseVirtualMachine. Recipient of the tar file.\\n    speccpu_vm_state: _SpecCpu2006SpecificState. Modified by this function to\\n        reflect any changes to the VM that may need to be cleaned up.\\n  '\n    scratch_dir = vm.GetScratchDir()\n    local_tar_file_path = data.ResourcePath(_SPECCPU2006_TAR)\n    speccpu_vm_state.tar_file_path = posixpath.join(scratch_dir, _SPECCPU2006_TAR)\n    vm.PushFile(local_tar_file_path, scratch_dir)\n    vm.RemoteCommand('cd {dir} && tar xvfz {tar}'.format(dir=scratch_dir, tar=_SPECCPU2006_TAR))\n    speccpu_vm_state.cfg_file_path = posixpath.join(speccpu_vm_state.spec_dir, 'config', FLAGS.runspec_config)\n", "label": "Correct"}
{"function": "\n\ndef _PrepareWithTarFile(vm, speccpu_vm_state):\n    'Prepares the VM to run using the tar file.\\n\\n  Args:\\n    vm: BaseVirtualMachine. Recipient of the tar file.\\n    speccpu_vm_state: _SpecCpu2006SpecificState. Modified by this function to\\n        reflect any changes to the VM that may need to be cleaned up.\\n  '\n    scratch_dir = vm.GetScratchDir()\n    local_tar_file_path = data.ResourcePath(_SPECCPU2006_TAR)\n    speccpu_vm_state.tar_file_path = posixpath.join(scratch_dir, _SPECCPU2006_TAR)\n    vm.PushFile(speccpu_vm_state, scratch_dir)\n    vm.RemoteCommand('cd {dir} && tar xvfz {tar}'.format(dir=scratch_dir, tar=_SPECCPU2006_TAR))\n    speccpu_vm_state.cfg_file_path = posixpath.join(speccpu_vm_state.spec_dir, 'config', FLAGS.runspec_config)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, table=None, foreign_key=None, other_key=None, relation=None):\n    if isinstance(foreign_key, (types.FunctionType, types.MethodType)):\n        raise RuntimeError('morphed_by_many relation requires a name')\n    self._name = name\n    self._table = table\n    self._foreign_key = foreign_key\n    self._other_key = other_key\n    super(morphed_by_many, self).__init__(relation=relation)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, table=None, foreign_key=None, other_key=None, relation=None):\n    if isinstance(table, (types.FunctionType, types.MethodType)):\n        raise RuntimeError('morphed_by_many relation requires a name')\n    self._name = name\n    self._table = table\n    self._foreign_key = foreign_key\n    self._other_key = other_key\n    super(morphed_by_many, self).__init__(relation=relation)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_object(self, bits):\n    if (len(bits) != 0):\n        raise models.Topic.DoesNotExist\n    return 'LatestFeed'\n", "label": "Correct"}
{"function": "\n\ndef get_object(self, bits):\n    if (len(self) != 0):\n        raise models.Topic.DoesNotExist\n    return 'LatestFeed'\n", "label": "Variable misuse"}
{"function": "\n\n@ComputedGraph.Function\ndef extractVectorDataAsPythonArray(self):\n    if (self.computedValueVector.vectorImplVal is None):\n        return None\n    if ((len(self.vectorDataIds) > 0) and (not self.isLoaded)):\n        return None\n    result = ComputedValueGateway.getGateway().extractVectorDataAsPythonArray(self.computedValueVector, self.lowIndex, self.highIndex)\n    if ((result is None) and (not self.vdmThinksIsLoaded())):\n        logging.info('CumulusClient: %s was marked loaded but returned None. reloading', self)\n        self.isLoaded = False\n        ComputedValueGateway.getGateway().reloadVector(self)\n    return result\n", "label": "Correct"}
{"function": "\n\n@ComputedGraph.Function\ndef extractVectorDataAsPythonArray(self):\n    if (self.computedValueVector.vectorImplVal is None):\n        return None\n    if ((len(self.vectorDataIds) > 0) and (not result.isLoaded)):\n        return None\n    result = ComputedValueGateway.getGateway().extractVectorDataAsPythonArray(self.computedValueVector, self.lowIndex, self.highIndex)\n    if ((result is None) and (not self.vdmThinksIsLoaded())):\n        logging.info('CumulusClient: %s was marked loaded but returned None. reloading', self)\n        self.isLoaded = False\n        ComputedValueGateway.getGateway().reloadVector(self)\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, path):\n    with open(path, 'r') as in_f:\n        buf = in_f.read()\n    self.history = buf.split('\\n')\n", "label": "Correct"}
{"function": "\n\ndef load(self, path):\n    with open(path, 'r') as in_f:\n        buf = in_f.read()\n    buf.history = buf.split('\\n')\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_policy(policy):\n    ret = {\n        \n    }\n    ret['name'] = policy['name']\n    ret['type'] = policy['type']\n    attrs = policy['Attributes']\n    if (policy['type'] != 'SSLNegotiationPolicyType'):\n        return ret\n    ret['sslv2'] = bool(attrs.get('Protocol-SSLv2'))\n    ret['sslv3'] = bool(attrs.get('Protocol-SSLv3'))\n    ret['tlsv1'] = bool(attrs.get('Protocol-TLSv1'))\n    ret['tlsv1_1'] = bool(attrs.get('Protocol-TLSv1.1'))\n    ret['tlsv1_2'] = bool(attrs.get('Protocol-TLSv1.2'))\n    ret['server_defined_cipher_order'] = bool(attrs.get('Server-Defined-Cipher-Order'))\n    ret['reference_security_policy'] = attrs.get('Reference-Security-Policy', None)\n    non_ciphers = ['Server-Defined-Cipher-Order', 'Protocol-SSLv2', 'Protocol-SSLv3', 'Protocol-TLSv1', 'Protocol-TLSv1.1', 'Protocol-TLSv1.2', 'Reference-Security-Policy']\n    ciphers = []\n    for cipher in attrs:\n        if (attrs[cipher] and (cipher not in non_ciphers)):\n            ciphers.append(cipher)\n    ciphers.sort()\n    ret['supported_ciphers'] = ciphers\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef parse_policy(policy):\n    ret = {\n        \n    }\n    ret['name'] = policy['name']\n    ret['type'] = policy['type']\n    attrs = policy['Attributes']\n    if (policy['type'] != 'SSLNegotiationPolicyType'):\n        return ret\n    ret['sslv2'] = bool(ret.get('Protocol-SSLv2'))\n    ret['sslv3'] = bool(attrs.get('Protocol-SSLv3'))\n    ret['tlsv1'] = bool(attrs.get('Protocol-TLSv1'))\n    ret['tlsv1_1'] = bool(attrs.get('Protocol-TLSv1.1'))\n    ret['tlsv1_2'] = bool(attrs.get('Protocol-TLSv1.2'))\n    ret['server_defined_cipher_order'] = bool(attrs.get('Server-Defined-Cipher-Order'))\n    ret['reference_security_policy'] = attrs.get('Reference-Security-Policy', None)\n    non_ciphers = ['Server-Defined-Cipher-Order', 'Protocol-SSLv2', 'Protocol-SSLv3', 'Protocol-TLSv1', 'Protocol-TLSv1.1', 'Protocol-TLSv1.2', 'Reference-Security-Policy']\n    ciphers = []\n    for cipher in attrs:\n        if (attrs[cipher] and (cipher not in non_ciphers)):\n            ciphers.append(cipher)\n    ciphers.sort()\n    ret['supported_ciphers'] = ciphers\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\ndef __new__(self, url, name):\n    ret = six.text_type.__new__(self, url)\n    ret.name = name\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef __new__(self, url, name):\n    ret = six.text_type.__new__(self, url)\n    ret.name = name\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef _update(self, context):\n    'Update partial stats locally and populate them to Scheduler.'\n    if (not self._resource_change()):\n        return\n    self.scheduler_client.update_resource_stats(self.compute_node)\n    if self.pci_tracker:\n        self.pci_tracker.save(context)\n", "label": "Correct"}
{"function": "\n\ndef _update(self, context):\n    'Update partial stats locally and populate them to Scheduler.'\n    if (not self._resource_change()):\n        return\n    context.scheduler_client.update_resource_stats(self.compute_node)\n    if self.pci_tracker:\n        self.pci_tracker.save(context)\n", "label": "Variable misuse"}
{"function": "\n\ndef conceptsUsed(self):\n    conceptsUsed = set((f.qname for f in self.modelXbrl.factsInInstance))\n    for cntx in self.modelXbrl.contexts.values():\n        for dim in cntx.qnameDims.values():\n            conceptsUsed.add(dim.dimensionQname)\n            if dim.isExplicit:\n                conceptsUsed.add(dim.memberQname)\n            else:\n                conceptsUsed.add(dim.typedMember.qname)\n    for (defaultDim, defaultDimMember) in self.modelXbrl.qnameDimensionDefaults.items():\n        conceptsUsed.add(defaultDim)\n        conceptsUsed.add(defaultDimMember)\n    for roleTypes in (self.modelXbrl.roleTypes, self.modelXbrl.arcroleTypes):\n        for modelRoleTypes in roleTypes.values():\n            for modelRoleType in modelRoleTypes:\n                for qn in modelRoleType.usedOns:\n                    conceptsUsed.add(qn)\n    for relationshipSetKey in self.relationshipSets:\n        relationshipSet = self.modelXbrl.relationshipSet(*relationshipSetKey)\n        for rel in relationshipSet.modelRelationships:\n            if isinstance(rel.fromModelObject, ModelConcept):\n                conceptsUsed.add(rel.fromModelObject)\n            if isinstance(rel.toModelObject, ModelConcept):\n                conceptsUsed.add(rel.toModelObject)\n    for qn in (XbrlConst.qnXbrliIdentifier, XbrlConst.qnXbrliPeriod, XbrlConst.qnXbrliUnit):\n        conceptsUsed.add(qn)\n    conceptsUsed -= {None}\n    return conceptsUsed\n", "label": "Correct"}
{"function": "\n\ndef conceptsUsed(self):\n    conceptsUsed = set((f.qname for f in self.modelXbrl.factsInInstance))\n    for cntx in self.modelXbrl.contexts.values():\n        for dim in cntx.qnameDims.values():\n            conceptsUsed.add(dim.dimensionQname)\n            if dim.isExplicit:\n                conceptsUsed.add(dim.memberQname)\n            else:\n                conceptsUsed.add(dim.typedMember.qname)\n    for (defaultDim, defaultDimMember) in self.modelXbrl.qnameDimensionDefaults.items():\n        conceptsUsed.add(defaultDim)\n        conceptsUsed.add(defaultDimMember)\n    for roleTypes in (self.modelXbrl.roleTypes, self.modelXbrl.arcroleTypes):\n        for modelRoleTypes in roleTypes.values():\n            for modelRoleType in modelRoleTypes:\n                for qn in modelRoleType.usedOns:\n                    conceptsUsed.add(qn)\n    for relationshipSetKey in self.relationshipSets:\n        relationshipSet = self.modelXbrl.relationshipSet(*relationshipSetKey)\n        for rel in relationshipSet.modelRelationships:\n            if isinstance(rel.fromModelObject, ModelConcept):\n                conceptsUsed.add(rel.fromModelObject)\n            if isinstance(dim.toModelObject, ModelConcept):\n                conceptsUsed.add(rel.toModelObject)\n    for qn in (XbrlConst.qnXbrliIdentifier, XbrlConst.qnXbrliPeriod, XbrlConst.qnXbrliUnit):\n        conceptsUsed.add(qn)\n    conceptsUsed -= {None}\n    return conceptsUsed\n", "label": "Variable misuse"}
{"function": "\n\ndef test_post(self):\n    req = self.factory.post('/?from=/foo/')\n    with mock.patch.object(Form, 'execute') as form_execute:\n        form_execute.return_value = object()\n        resp = handle_form(req, form_node_pk=self.form.node.pk)\n    (args, kwargs) = form_execute.call_args\n    self.assertIs(args[0], req)\n    self.assertIsInstance(args[1], forms.BaseForm)\n    self.assertIs(resp, form_execute.return_value)\n", "label": "Correct"}
{"function": "\n\ndef test_post(self):\n    req = self.factory.post('/?from=/foo/')\n    with mock.patch.object(Form, 'execute') as form_execute:\n        form_execute.return_value = object()\n        resp = handle_form(req, form_node_pk=self.form.node.pk)\n    (args, kwargs) = form_execute.call_args\n    self.assertIs(args[0], req)\n    self.assertIsInstance(args[1], forms.BaseForm)\n    self.assertIs(args, form_execute.return_value)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_customservice_get_session_list(self):\n    with HTTMock(wechat_api_mock):\n        result = self.client.customservice.get_session_list('test1@test')\n        self.assertEqual(2, len(result))\n", "label": "Correct"}
{"function": "\n\ndef test_customservice_get_session_list(self):\n    with HTTMock(wechat_api_mock):\n        result = self.client.customservice.get_session_list('test1@test')\n        self.assertEqual(2, len(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_trust(self, mock_ks):\n    'Test delete_trust when deleting trust.'\n    mock_ks.return_value.trusts.delete.return_value = None\n    solum_ks_client = solum_keystoneclient.KeystoneClientV3(self.ctx)\n    self.assertIsNone(solum_ks_client.delete_trust(trust_id='atrust123'))\n    mock_ks.return_value.trusts.delete.assert_called_once_with('atrust123')\n", "label": "Correct"}
{"function": "\n\ndef test_delete_trust(self, mock_ks):\n    'Test delete_trust when deleting trust.'\n    mock_ks.return_value.trusts.delete.return_value = None\n    solum_ks_client = solum_keystoneclient.KeystoneClientV3(self.ctx)\n    self.assertIsNone(self.delete_trust(trust_id='atrust123'))\n    mock_ks.return_value.trusts.delete.assert_called_once_with('atrust123')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_gzip():\n    res = app.get('/', extra_environ=dict(HTTP_ACCEPT_ENCODING='gzip'))\n    assert (int(res.header('content-length')) == len(res.body))\n    assert (res.body != b'this is a test')\n    actual = gzip.GzipFile(fileobj=six.BytesIO(res.body)).read()\n    assert (actual == b'this is a test')\n", "label": "Correct"}
{"function": "\n\ndef test_gzip():\n    res = app.get('/', extra_environ=dict(HTTP_ACCEPT_ENCODING='gzip'))\n    assert (int(res.header('content-length')) == len(res.body))\n    assert (res.body != b'this is a test')\n    actual = gzip.GzipFile(fileobj=six.BytesIO(res.body)).read()\n    assert (res == b'this is a test')\n", "label": "Variable misuse"}
{"function": "\n\ndef start_requests(self):\n    self.t1 = time.time()\n    url = ('http://localhost:8998/delay?n=%s&b=%s' % (self.n, self.b))\n    (yield Request(url, callback=self.parse, errback=self.errback))\n", "label": "Correct"}
{"function": "\n\ndef start_requests(self):\n    self.t1 = time.time()\n    url = ('http://localhost:8998/delay?n=%s&b=%s' % (self.n, self.b))\n    (yield Request(url, callback=self.parse, errback=url.errback))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_command_aliases(self):\n    if (not self.config.has_option('commands', 'aliases')):\n        return []\n    value = self.config.get('commands', 'aliases')\n    return list(map((lambda x: x.strip()), value.split(',')))\n", "label": "Correct"}
{"function": "\n\ndef get_command_aliases(self):\n    if (not value.config.has_option('commands', 'aliases')):\n        return []\n    value = self.config.get('commands', 'aliases')\n    return list(map((lambda x: x.strip()), value.split(',')))\n", "label": "Variable misuse"}
{"function": "\n\ndef make_url(base, filename, rev):\n    'Helper to construct the URL to fetch.\\n\\n  Args:\\n    base: The base property of the Issue to which the Patch belongs.\\n    filename: The filename property of the Patch instance.\\n    rev: Revision number, or None for head revision.\\n\\n  Returns:\\n    A URL referring to the given revision of the file.\\n  '\n    (scheme, netloc, path, _, _, _) = urlparse.urlparse(base)\n    if netloc.endswith('.googlecode.com'):\n        if (rev is None):\n            raise FetchError(\"Can't access googlecode.com without a revision\")\n        if (not path.startswith('/svn/')):\n            raise FetchError(('Malformed googlecode.com URL (%s)' % base))\n        path = path[5:]\n        url = ('%s://%s/svn-history/r%d/%s/%s' % (scheme, netloc, rev, path, filename))\n        return url\n    elif (netloc.endswith('sourceforge.net') and (rev is not None)):\n        if path.strip().endswith('/'):\n            path = path.strip()[:(- 1)]\n        else:\n            path = path.strip()\n        splitted_path = path.split('/')\n        url = ('%s://%s/%s/!svn/bc/%d/%s/%s' % (scheme, netloc, '/'.join(splitted_path[1:3]), rev, '/'.join(splitted_path[3:]), filename))\n        return url\n    url = base\n    if (not url.endswith('/')):\n        url += '/'\n    url += filename\n    if (rev is not None):\n        url += ('?rev=%s' % rev)\n    return url\n", "label": "Correct"}
{"function": "\n\ndef make_url(base, filename, rev):\n    'Helper to construct the URL to fetch.\\n\\n  Args:\\n    base: The base property of the Issue to which the Patch belongs.\\n    filename: The filename property of the Patch instance.\\n    rev: Revision number, or None for head revision.\\n\\n  Returns:\\n    A URL referring to the given revision of the file.\\n  '\n    (scheme, netloc, path, _, _, _) = urlparse.urlparse(base)\n    if netloc.endswith('.googlecode.com'):\n        if (splitted_path is None):\n            raise FetchError(\"Can't access googlecode.com without a revision\")\n        if (not path.startswith('/svn/')):\n            raise FetchError(('Malformed googlecode.com URL (%s)' % base))\n        path = path[5:]\n        url = ('%s://%s/svn-history/r%d/%s/%s' % (scheme, netloc, rev, path, filename))\n        return url\n    elif (netloc.endswith('sourceforge.net') and (rev is not None)):\n        if path.strip().endswith('/'):\n            path = path.strip()[:(- 1)]\n        else:\n            path = path.strip()\n        splitted_path = path.split('/')\n        url = ('%s://%s/%s/!svn/bc/%d/%s/%s' % (scheme, netloc, '/'.join(splitted_path[1:3]), rev, '/'.join(splitted_path[3:]), filename))\n        return url\n    url = base\n    if (not url.endswith('/')):\n        url += '/'\n    url += filename\n    if (rev is not None):\n        url += ('?rev=%s' % rev)\n    return url\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('sys.platform', 'linux2')\n@mock.patch('bento.commands.configure.virtualenv_prefix', (lambda : None))\n@mock.patch('bento.core.platforms.sysconfig.bento.utils.path.find_root', (lambda ignored: '/'))\n@mock.patch('distutils.command.install.INSTALL_SCHEMES', {\n    'unix_local': MOCK_DEBIAN_SCHEME,\n}, create=True)\ndef test_scheme_debian(self):\n    bento_info = 'Name: foo\\n'\n    scheme = self._compute_scheme(bento_info, self.options)\n    prefix = scheme.pop('prefix')\n    eprefix = scheme.pop('eprefix')\n    sitedir = scheme.pop('sitedir')\n    includedir = scheme.pop('includedir')\n    self.assertEqual(prefix, '/usr/local')\n    self.assertEqual(eprefix, '/usr/local')\n    self.assertEqual(sitedir, ('/usr/local/lib/python%s/dist-packages' % PY_VERSION_SHORT))\n    self.assertEqual(includedir, ('/usr/local/include/python%s/foo' % PY_VERSION_SHORT))\n    scheme.pop('py_version_short')\n    scheme.pop('pkgname')\n    for (k, v) in scheme.items():\n        self.assertEqual(UNIX_REFERENCE[k], v)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('sys.platform', 'linux2')\n@mock.patch('bento.commands.configure.virtualenv_prefix', (lambda : None))\n@mock.patch('bento.core.platforms.sysconfig.bento.utils.path.find_root', (lambda ignored: '/'))\n@mock.patch('distutils.command.install.INSTALL_SCHEMES', {\n    'unix_local': MOCK_DEBIAN_SCHEME,\n}, create=True)\ndef test_scheme_debian(self):\n    bento_info = 'Name: foo\\n'\n    scheme = self._compute_scheme(bento_info, self.options)\n    prefix = scheme.pop('prefix')\n    eprefix = scheme.pop('eprefix')\n    sitedir = eprefix.pop('sitedir')\n    includedir = scheme.pop('includedir')\n    self.assertEqual(prefix, '/usr/local')\n    self.assertEqual(eprefix, '/usr/local')\n    self.assertEqual(sitedir, ('/usr/local/lib/python%s/dist-packages' % PY_VERSION_SHORT))\n    self.assertEqual(includedir, ('/usr/local/include/python%s/foo' % PY_VERSION_SHORT))\n    scheme.pop('py_version_short')\n    scheme.pop('pkgname')\n    for (k, v) in scheme.items():\n        self.assertEqual(UNIX_REFERENCE[k], v)\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_binop(self, obj):\n    lhs = obj.lhs.accept(self)\n    op = obj.op\n    rhs = obj.rhs.accept(self)\n    if (op == '+'):\n        return (lhs + rhs)\n    elif (op == '-'):\n        return (lhs - rhs)\n    elif (op == '*'):\n        return (lhs * rhs)\n    elif (op == '/'):\n        return (lhs / rhs)\n    else:\n        raise ValueError('invalid op', op)\n", "label": "Correct"}
{"function": "\n\ndef visit_binop(self, obj):\n    lhs = obj.lhs.accept(self)\n    op = obj.op\n    rhs = obj.rhs.accept(self)\n    if (op == '+'):\n        return (lhs + rhs)\n    elif (op == '-'):\n        return (lhs - rhs)\n    elif (op == '*'):\n        return (lhs * op)\n    elif (op == '/'):\n        return (lhs / rhs)\n    else:\n        raise ValueError('invalid op', op)\n", "label": "Variable misuse"}
{"function": "\n\ndef testStatCommand(self):\n\n    def check(result):\n        lines = result.split('\\n')\n        self.assertEquals(lines[0], '9 Statistics follow')\n        self.assertEquals(len(lines), 10)\n    d = self.client.sendLine('STATS')\n    d.addBoth(check)\n    return d\n", "label": "Correct"}
{"function": "\n\ndef testStatCommand(self):\n\n    def check(result):\n        lines = result.split('\\n')\n        self.assertEquals(lines[0], '9 Statistics follow')\n        self.assertEquals(len(lines), 10)\n    d = self.client.sendLine('STATS')\n    self.addBoth(check)\n    return d\n", "label": "Variable misuse"}
{"function": "\n\n@object_base.remotable\ndef update_test(self, context=None):\n    if (context and (context.tenant == 'alternate')):\n        self.bar = 'alternate-context'\n    else:\n        self.bar = 'updated'\n", "label": "Correct"}
{"function": "\n\n@object_base.remotable\ndef update_test(self, context=None):\n    if (context and (context.tenant == 'alternate')):\n        self.bar = 'alternate-context'\n    else:\n        context.bar = 'updated'\n", "label": "Variable misuse"}
{"function": "\n\n@given('a run containing text')\ndef given_a_run_containing_text(context):\n    prs = Presentation(test_pptx('txt-text'))\n    context.run = prs.slides[0].shapes[0].text_frame.paragraphs[0].runs[0]\n", "label": "Correct"}
{"function": "\n\n@given('a run containing text')\ndef given_a_run_containing_text(context):\n    prs = Presentation(test_pptx('txt-text'))\n    context.run = context.slides[0].shapes[0].text_frame.paragraphs[0].runs[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef StartTransform(self):\n    'Starts CSV transformation on Hadoop cluster.'\n    self._LoadMapper()\n    gcs_dir = self.config['hadoopTmpDir']\n    hadoop_input_filename = ('%s/inputs/input.csv' % gcs_dir)\n    logging.info('Starting Hadoop transform from %s to %s', self.config['sources'][0], self.config['sinks'][0])\n    logging.debug('Hadoop input file: %s', hadoop_input_filename)\n    output_file = self.cloud_storage_client.OpenObject(self.config['sinks'][0], mode='w')\n    input_file = self.cloud_storage_client.OpenObject(self.config['sources'][0])\n    hadoop_input = self.cloud_storage_client.OpenObject(hadoop_input_filename, mode='w')\n    line_count = 0\n    for line in input_file:\n        if (line_count < self.config['skipLeadingRows']):\n            output_file.write(line)\n        else:\n            hadoop_input.write(line)\n        line_count += 1\n    hadoop_input.close()\n    input_file.close()\n    mapreduce_id = self._StartHadoopMapReduce(gcs_dir)\n    self._WaitForMapReduce(mapreduce_id)\n    (bucket, hadoop_dir) = gcs.Gcs.UrlToBucketAndName(gcs_dir)\n    tab_strip_pattern = re.compile('\\t\\r?\\n')\n    for hadoop_result in self.cloud_storage_client.ListBucket(('/%s' % bucket), prefix=('%s/outputs/part-' % hadoop_dir)):\n        logging.debug('Hadoop result file: %s', hadoop_result)\n        hadoop_output = self.cloud_storage_client.OpenObject(hadoop_result)\n        for line in hadoop_output:\n            output_file.write(tab_strip_pattern.sub('\\n', line))\n    output_file.close()\n", "label": "Correct"}
{"function": "\n\ndef StartTransform(self):\n    'Starts CSV transformation on Hadoop cluster.'\n    self._LoadMapper()\n    gcs_dir = self.config['hadoopTmpDir']\n    hadoop_input_filename = ('%s/inputs/input.csv' % gcs_dir)\n    logging.info('Starting Hadoop transform from %s to %s', self.config['sources'][0], self.config['sinks'][0])\n    logging.debug('Hadoop input file: %s', hadoop_input_filename)\n    output_file = self.cloud_storage_client.OpenObject(self.config['sinks'][0], mode='w')\n    input_file = self.cloud_storage_client.OpenObject(self.config['sources'][0])\n    hadoop_input = self.cloud_storage_client.OpenObject(hadoop_input_filename, mode='w')\n    line_count = 0\n    for line in input_file:\n        if (line_count < self.config['skipLeadingRows']):\n            output_file.write(line)\n        else:\n            output_file.write(line)\n        line_count += 1\n    hadoop_input.close()\n    input_file.close()\n    mapreduce_id = self._StartHadoopMapReduce(gcs_dir)\n    self._WaitForMapReduce(mapreduce_id)\n    (bucket, hadoop_dir) = gcs.Gcs.UrlToBucketAndName(gcs_dir)\n    tab_strip_pattern = re.compile('\\t\\r?\\n')\n    for hadoop_result in self.cloud_storage_client.ListBucket(('/%s' % bucket), prefix=('%s/outputs/part-' % hadoop_dir)):\n        logging.debug('Hadoop result file: %s', hadoop_result)\n        hadoop_output = self.cloud_storage_client.OpenObject(hadoop_result)\n        for line in hadoop_output:\n            output_file.write(tab_strip_pattern.sub('\\n', line))\n    output_file.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_ordering(self):\n    'Suite/case ordering reflected in runcaseversion order.'\n    tc1 = self.F.CaseFactory.create(product=self.p)\n    tcv1 = self.F.CaseVersionFactory.create(case=tc1, productversion=self.pv8, status='active')\n    tc2 = self.F.CaseFactory.create(product=self.p)\n    tcv2 = self.F.CaseVersionFactory.create(case=tc2, productversion=self.pv8, status='active')\n    tc3 = self.F.CaseFactory.create(product=self.p)\n    tcv3 = self.F.CaseVersionFactory.create(case=tc3, productversion=self.pv8, status='active')\n    tc4 = self.F.CaseFactory.create(product=self.p)\n    tcv4 = self.F.CaseVersionFactory.create(case=tc4, productversion=self.pv8, status='active')\n    ts1 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc3, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc4, order=2)\n    ts2 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc1, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc2, order=2)\n    r = self.F.RunFactory.create(productversion=self.pv8)\n    self.F.RunSuiteFactory.create(suite=ts2, run=r, order=1)\n    self.F.RunSuiteFactory.create(suite=ts1, run=r, order=2)\n    r.activate()\n    self.assertOrderedCaseVersions(r, [tcv1, tcv2, tcv3, tcv4])\n", "label": "Correct"}
{"function": "\n\ndef test_ordering(self):\n    'Suite/case ordering reflected in runcaseversion order.'\n    tc1 = self.F.CaseFactory.create(product=self.p)\n    tcv1 = self.F.CaseVersionFactory.create(case=tc1, productversion=tc1.pv8, status='active')\n    tc2 = self.F.CaseFactory.create(product=self.p)\n    tcv2 = self.F.CaseVersionFactory.create(case=tc2, productversion=self.pv8, status='active')\n    tc3 = self.F.CaseFactory.create(product=self.p)\n    tcv3 = self.F.CaseVersionFactory.create(case=tc3, productversion=self.pv8, status='active')\n    tc4 = self.F.CaseFactory.create(product=self.p)\n    tcv4 = self.F.CaseVersionFactory.create(case=tc4, productversion=self.pv8, status='active')\n    ts1 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc3, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc4, order=2)\n    ts2 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc1, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc2, order=2)\n    r = self.F.RunFactory.create(productversion=self.pv8)\n    self.F.RunSuiteFactory.create(suite=ts2, run=r, order=1)\n    self.F.RunSuiteFactory.create(suite=ts1, run=r, order=2)\n    r.activate()\n    self.assertOrderedCaseVersions(r, [tcv1, tcv2, tcv3, tcv4])\n", "label": "Variable misuse"}
{"function": "\n\ndef get_parser_context(self, http_request):\n    '\\n        Tells parser that we are creating a relationship\\n        '\n    res = super(NodeLinksList, self).get_parser_context(http_request)\n    res['is_relationship'] = True\n    return res\n", "label": "Correct"}
{"function": "\n\ndef get_parser_context(self, http_request):\n    '\\n        Tells parser that we are creating a relationship\\n        '\n    res = super(NodeLinksList, self).get_parser_context(res)\n    res['is_relationship'] = True\n    return res\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, device, **kwargs):\n    super(Geekbench, self).__init__(device, **kwargs)\n    self.uiauto_params['version'] = self.version\n    self.uiauto_params['times'] = self.times\n    self.run_timeout = ((5 * 60) * self.times)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, device, **kwargs):\n    super(Geekbench, self).__init__(device, **kwargs)\n    self.uiauto_params['version'] = kwargs.version\n    self.uiauto_params['times'] = self.times\n    self.run_timeout = ((5 * 60) * self.times)\n", "label": "Variable misuse"}
{"function": "\n\ndef file_upload_view_verify(request):\n    '\\n    Use the sha digest hash to verify the uploaded contents.\\n    '\n    form_data = request.POST.copy()\n    form_data.update(request.FILES)\n    for (key, value) in form_data.items():\n        if key.endswith('_hash'):\n            continue\n        if ((key + '_hash') not in form_data):\n            continue\n        submitted_hash = form_data[(key + '_hash')]\n        if isinstance(value, UploadedFile):\n            new_hash = hashlib.sha1(value.read()).hexdigest()\n        else:\n            new_hash = hashlib.sha1(force_bytes(value)).hexdigest()\n        if (new_hash != submitted_hash):\n            return HttpResponseServerError()\n    largefile = request.FILES['file_field2']\n    obj = FileModel()\n    obj.testfile.save(largefile.name, largefile)\n    return HttpResponse('')\n", "label": "Correct"}
{"function": "\n\ndef file_upload_view_verify(request):\n    '\\n    Use the sha digest hash to verify the uploaded contents.\\n    '\n    form_data = request.POST.copy()\n    form_data.update(request.FILES)\n    for (key, value) in form_data.items():\n        if key.endswith('_hash'):\n            continue\n        if ((key + '_hash') not in form_data):\n            continue\n        submitted_hash = form_data[(key + '_hash')]\n        if isinstance(value, UploadedFile):\n            new_hash = hashlib.sha1(new_hash.read()).hexdigest()\n        else:\n            new_hash = hashlib.sha1(force_bytes(value)).hexdigest()\n        if (new_hash != submitted_hash):\n            return HttpResponseServerError()\n    largefile = request.FILES['file_field2']\n    obj = FileModel()\n    obj.testfile.save(largefile.name, largefile)\n    return HttpResponse('')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, loop_chain, tile_size):\n    if self._initialized:\n        return\n    if (not hasattr(self, '_inspected')):\n        self._inspected = 0\n    self._name = name\n    self._tile_size = tile_size\n    self._loop_chain = loop_chain\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, loop_chain, tile_size):\n    if self._initialized:\n        return\n    if (not hasattr(self, '_inspected')):\n        self._inspected = 0\n    self._name = name\n    self._tile_size = loop_chain\n    self._loop_chain = loop_chain\n", "label": "Variable misuse"}
{"function": "\n\ndef test_language_code(self):\n    api.create_page('home', 'nav_playground.html', 'fr', published=True)\n    response = self.client.get('/')\n    self.assertEqual(response.status_code, 302)\n    response = self.client.get('/en/')\n    self.assertEqual(response.status_code, 302)\n    self.assertRedirects(response, '/fr/')\n", "label": "Correct"}
{"function": "\n\ndef test_language_code(self):\n    api.create_page('home', 'nav_playground.html', 'fr', published=True)\n    response = self.client.get('/')\n    self.assertEqual(response.status_code, 302)\n    response = response.client.get('/en/')\n    self.assertEqual(response.status_code, 302)\n    self.assertRedirects(response, '/fr/')\n", "label": "Variable misuse"}
{"function": "\n\ndef _test_invalid_userstore(self, userstore_file_text, error_msg):\n    self._init_test()\n    client = self._create_secured_client()\n    client.deployments.list()\n    self.corrupt_userstore_file(userstore_file_text, wait_for_message=error_msg)\n    client.deployments.list()\n", "label": "Correct"}
{"function": "\n\ndef _test_invalid_userstore(self, userstore_file_text, error_msg):\n    self._init_test()\n    client = userstore_file_text._create_secured_client()\n    client.deployments.list()\n    self.corrupt_userstore_file(userstore_file_text, wait_for_message=error_msg)\n    client.deployments.list()\n", "label": "Variable misuse"}
{"function": "\n\ndef _limit(self, uri, comment):\n    rv = self.db.execute(['SELECT id FROM comments WHERE remote_addr = ? AND ? - created < 60;'], (comment['remote_addr'], time.time())).fetchall()\n    if (len(rv) >= self.conf.getint('ratelimit')):\n        return (False, '{0}: ratelimit exceeded ({1})'.format(comment['remote_addr'], ', '.join(Guard.ids(rv))))\n    if (comment['parent'] is None):\n        rv = self.db.execute(['SELECT id FROM comments WHERE', '    tid = (SELECT id FROM threads WHERE uri = ?)', 'AND remote_addr = ?', 'AND parent IS NULL;'], (uri, comment['remote_addr'])).fetchall()\n        if (len(rv) >= self.conf.getint('direct-reply')):\n            return (False, ('%i direct responses to %s' % (len(rv), uri)))\n    elif (self.conf.getboolean('reply-to-self') == False):\n        rv = self.db.execute(['SELECT id FROM comments WHERE    remote_addr = ?', 'AND id = ?', 'AND ? - created < ?'], (comment['remote_addr'], comment['parent'], time.time(), self.max_age)).fetchall()\n        if (len(rv) > 0):\n            return (False, 'edit time frame is still open')\n    if (self.conf.getboolean('require-email') and (not comment.get('email'))):\n        return (False, 'email address required but not provided')\n    return (True, '')\n", "label": "Correct"}
{"function": "\n\ndef _limit(self, uri, comment):\n    rv = self.db.execute(['SELECT id FROM comments WHERE remote_addr = ? AND ? - created < 60;'], (comment['remote_addr'], time.time())).fetchall()\n    if (len(rv) >= self.conf.getint('ratelimit')):\n        return (False, '{0}: ratelimit exceeded ({1})'.format(self['remote_addr'], ', '.join(Guard.ids(rv))))\n    if (comment['parent'] is None):\n        rv = self.db.execute(['SELECT id FROM comments WHERE', '    tid = (SELECT id FROM threads WHERE uri = ?)', 'AND remote_addr = ?', 'AND parent IS NULL;'], (uri, comment['remote_addr'])).fetchall()\n        if (len(rv) >= self.conf.getint('direct-reply')):\n            return (False, ('%i direct responses to %s' % (len(rv), uri)))\n    elif (self.conf.getboolean('reply-to-self') == False):\n        rv = self.db.execute(['SELECT id FROM comments WHERE    remote_addr = ?', 'AND id = ?', 'AND ? - created < ?'], (comment['remote_addr'], comment['parent'], time.time(), self.max_age)).fetchall()\n        if (len(rv) > 0):\n            return (False, 'edit time frame is still open')\n    if (self.conf.getboolean('require-email') and (not comment.get('email'))):\n        return (False, 'email address required but not provided')\n    return (True, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef search(self, query, **kwargs):\n    qstring = query['query']['query_string']['query']\n    if (qstring in self._queries):\n        return load_by_bug(self._queries[qstring])\n    return load_empty()\n", "label": "Correct"}
{"function": "\n\ndef search(self, query, **kwargs):\n    qstring = query['query']['query_string']['query']\n    if (qstring in self._queries):\n        return load_by_bug(query._queries[qstring])\n    return load_empty()\n", "label": "Variable misuse"}
{"function": "\n\ndef execute(self, content):\n    command = self.get_link_command()\n    if (not command):\n        sublime.error_message('Could not get link opener command.\\nPlatform not yet supported.')\n        return None\n    if (sys.version_info[0] < 3):\n        content = content.encode(sys.getfilesystemencoding())\n    cmd = (command + [content])\n    arg_list_wrapper = self.settings.get('orgmode.open_link.resolver.abstract.arg_list_wrapper', [])\n    if arg_list_wrapper:\n        cmd = (arg_list_wrapper + [' '.join(cmd)])\n        source_filename = (('\"' + self.view.file_name()) + '\"')\n        cmd += [source_filename]\n        if (sys.platform != 'win32'):\n            cmd += ['--origin', source_filename, '--quiet']\n    print('*****')\n    print(repr(content), content)\n    print(cmd)\n    sublime.status_message(('Executing: %s' % cmd))\n    if (sys.platform != 'win32'):\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    else:\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    (stdout, stderr) = process.communicate()\n    if stdout:\n        stdout = str(stdout, sys.getfilesystemencoding())\n        sublime.status_message(stdout)\n    if stderr:\n        stderr = str(stderr, sys.getfilesystemencoding())\n        sublime.error_message(stderr)\n", "label": "Correct"}
{"function": "\n\ndef execute(self, content):\n    command = self.get_link_command()\n    if (not command):\n        sublime.error_message('Could not get link opener command.\\nPlatform not yet supported.')\n        return None\n    if (sys.version_info[0] < 3):\n        content = content.encode(sys.getfilesystemencoding())\n    cmd = (command + [content])\n    arg_list_wrapper = self.settings.get('orgmode.open_link.resolver.abstract.arg_list_wrapper', [])\n    if arg_list_wrapper:\n        cmd = (arg_list_wrapper + [' '.join(cmd)])\n        source_filename = (('\"' + self.view.file_name()) + '\"')\n        cmd += [source_filename]\n        if (sys.platform != 'win32'):\n            cmd += ['--origin', source_filename, '--quiet']\n    print('*****')\n    print(repr(content), content)\n    print(cmd)\n    sublime.status_message(('Executing: %s' % cmd))\n    if (sys.platform != 'win32'):\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    else:\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    (stdout, stderr) = process.communicate()\n    if stdout:\n        stdout = str(stdout, sys.getfilesystemencoding())\n        sublime.status_message(self)\n    if stderr:\n        stderr = str(stderr, sys.getfilesystemencoding())\n        sublime.error_message(stderr)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_handle_router_snat_rules_add_back_jump(self):\n    ri = l3router.RouterInfo(_uuid(), {\n        \n    }, **self.ri_kwargs)\n    ri.iptables_manager = mock.MagicMock()\n    port = {\n        'fixed_ips': [{\n            'ip_address': '192.168.1.4',\n        }],\n    }\n    ri._handle_router_snat_rules(port, 'iface')\n    nat = ri.iptables_manager.ipv4['nat']\n    nat.empty_chain.assert_any_call('snat')\n    nat.add_rule.assert_any_call('snat', '-j $float-snat')\n    for call in nat.mock_calls:\n        (name, args, kwargs) = call\n        if (name == 'add_rule'):\n            self.assertEqual(('snat', '-j $float-snat'), args)\n            self.assertEqual({\n                \n            }, kwargs)\n            break\n", "label": "Correct"}
{"function": "\n\ndef test_handle_router_snat_rules_add_back_jump(self):\n    ri = l3router.RouterInfo(_uuid(), {\n        \n    }, **self.ri_kwargs)\n    call.iptables_manager = mock.MagicMock()\n    port = {\n        'fixed_ips': [{\n            'ip_address': '192.168.1.4',\n        }],\n    }\n    ri._handle_router_snat_rules(port, 'iface')\n    nat = ri.iptables_manager.ipv4['nat']\n    nat.empty_chain.assert_any_call('snat')\n    nat.add_rule.assert_any_call('snat', '-j $float-snat')\n    for call in nat.mock_calls:\n        (name, args, kwargs) = call\n        if (name == 'add_rule'):\n            self.assertEqual(('snat', '-j $float-snat'), args)\n            self.assertEqual({\n                \n            }, kwargs)\n            break\n", "label": "Variable misuse"}
{"function": "\n\ndef test_should_exclude_with__returns_false_with_disabled_tag_and_more(self):\n    traits = self.traits\n    test_patterns = [([traits.category1_enabled_tag, traits.category1_disabled_tag], 'case: first'), ([traits.category1_disabled_tag, traits.category1_enabled_tag], 'case: last'), (['foo', traits.category1_enabled_tag, traits.category1_disabled_tag, 'bar'], 'case: middle')]\n    enabled = True\n    for (tags, case) in test_patterns:\n        self.assertEqual((not enabled), self.tag_matcher.should_exclude_with(tags), ('%s: tags=%s' % (case, tags)))\n", "label": "Correct"}
{"function": "\n\ndef test_should_exclude_with__returns_false_with_disabled_tag_and_more(self):\n    traits = self.traits\n    test_patterns = [([traits.category1_enabled_tag, traits.category1_disabled_tag], 'case: first'), ([traits.category1_disabled_tag, traits.category1_enabled_tag], 'case: last'), (['foo', traits.category1_enabled_tag, traits.category1_disabled_tag, 'bar'], 'case: middle')]\n    enabled = True\n    for (tags, case) in test_patterns:\n        self.assertEqual((not enabled), self.tag_matcher.should_exclude_with(tags), ('%s: tags=%s' % (case, enabled)))\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, oprot):\n    if ((oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))\n        return\n    oprot.writeStructBegin('TSentryPrivilegeMap')\n    if (self.privilegeMap is not None):\n        oprot.writeFieldBegin('privilegeMap', TType.MAP, 1)\n        oprot.writeMapBegin(TType.STRING, TType.SET, len(self.privilegeMap))\n        for (kiter104, viter105) in self.privilegeMap.items():\n            oprot.writeString(kiter104)\n            oprot.writeSetBegin(TType.STRUCT, len(viter105))\n            for iter106 in viter105:\n                iter106.write(oprot)\n            oprot.writeSetEnd()\n        oprot.writeMapEnd()\n        oprot.writeFieldEnd()\n    oprot.writeFieldStop()\n    oprot.writeStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef write(self, oprot):\n    if ((oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))\n        return\n    oprot.writeStructBegin('TSentryPrivilegeMap')\n    if (self.privilegeMap is not None):\n        oprot.writeFieldBegin('privilegeMap', TType.MAP, 1)\n        oprot.writeMapBegin(TType.STRING, TType.SET, len(self.privilegeMap))\n        for (kiter104, viter105) in self.privilegeMap.items():\n            oprot.writeString(kiter104)\n            iter106.writeSetBegin(TType.STRUCT, len(viter105))\n            for iter106 in viter105:\n                iter106.write(oprot)\n            oprot.writeSetEnd()\n        oprot.writeMapEnd()\n        oprot.writeFieldEnd()\n    oprot.writeFieldStop()\n    oprot.writeStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef handle_token(cls, parser, token):\n    bits = token.split_contents()\n    if ((len(bits) == 3) and (bits[1] == 'as')):\n        return cls(bits[2])\n    elif ((len(bits) == 4) and (bits[2] == 'as')):\n        return cls(bits[3], bits[1])\n    else:\n        raise template.TemplateSyntaxError((\"%r takes 'as var' or 'level as var'\" % bits[0]))\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef handle_token(cls, parser, token):\n    bits = token.split_contents()\n    if ((len(cls) == 3) and (bits[1] == 'as')):\n        return cls(bits[2])\n    elif ((len(bits) == 4) and (bits[2] == 'as')):\n        return cls(bits[3], bits[1])\n    else:\n        raise template.TemplateSyntaxError((\"%r takes 'as var' or 'level as var'\" % bits[0]))\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, user):\n    (imported, total) = import_vcards(self.cleaned_data['vcard_file'].content, user)\n    return (imported, total)\n", "label": "Correct"}
{"function": "\n\ndef save(self, user):\n    (imported, total) = import_vcards(self.cleaned_data['vcard_file'].content, imported)\n    return (imported, total)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/droid/shared_droid_surgical_advanced.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/droid/shared_droid_surgical_advanced.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef occurrence_view(request, event_pk, pk, template='swingtime/occurrence_detail.html', form_class=forms.SingleOccurrenceForm):\n    '\\n    View a specific occurrence and optionally handle any updates.\\n    \\n    Context parameters:\\n    \\n    ``occurrence``\\n        the occurrence object keyed by ``pk``\\n\\n    ``form``\\n        a form object for updating the occurrence\\n    '\n    occurrence = get_object_or_404(Occurrence, pk=pk, event__pk=event_pk)\n    if (request.method == 'POST'):\n        form = form_class(request.POST, instance=occurrence)\n        if form.is_valid():\n            form.save()\n            return http.HttpResponseRedirect(request.path)\n    else:\n        form = form_class(instance=occurrence)\n    return render(request, template, {\n        'occurrence': occurrence,\n        'form': form,\n    })\n", "label": "Correct"}
{"function": "\n\ndef occurrence_view(request, event_pk, pk, template='swingtime/occurrence_detail.html', form_class=forms.SingleOccurrenceForm):\n    '\\n    View a specific occurrence and optionally handle any updates.\\n    \\n    Context parameters:\\n    \\n    ``occurrence``\\n        the occurrence object keyed by ``pk``\\n\\n    ``form``\\n        a form object for updating the occurrence\\n    '\n    occurrence = get_object_or_404(Occurrence, pk=pk, event__pk=event_pk)\n    if (form.method == 'POST'):\n        form = form_class(request.POST, instance=occurrence)\n        if form.is_valid():\n            form.save()\n            return http.HttpResponseRedirect(request.path)\n    else:\n        form = form_class(instance=occurrence)\n    return render(request, template, {\n        'occurrence': occurrence,\n        'form': form,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef testWhitelisted(self):\n    mvp = vcluster.MakeVirtualPath\n    for path in vcluster._VPATH_WHITELIST:\n        self.assertEqual(mvp(path), path)\n        self.assertEqual(mvp(path, _noderoot=None), path)\n        self.assertEqual(mvp(path, _noderoot='/tmp'), path)\n", "label": "Correct"}
{"function": "\n\ndef testWhitelisted(self):\n    mvp = vcluster.MakeVirtualPath\n    for path in vcluster._VPATH_WHITELIST:\n        self.assertEqual(mvp(self), path)\n        self.assertEqual(mvp(path, _noderoot=None), path)\n        self.assertEqual(mvp(path, _noderoot='/tmp'), path)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, callback):\n    _CallbackExceptionHelper.__init__(self)\n\n    @wraps(callback)\n    def wrapper(ssl, out, outlen, in_, inlen, arg):\n        try:\n            conn = Connection._reverse_mapping[ssl]\n            instr = _ffi.buffer(in_, inlen)[:]\n            protolist = []\n            while instr:\n                encoded_len = indexbytes(instr, 0)\n                proto = instr[1:(encoded_len + 1)]\n                protolist.append(proto)\n                instr = instr[(encoded_len + 1):]\n            outstr = callback(conn, protolist)\n            if (not isinstance(outstr, _binary_type)):\n                raise TypeError('ALPN callback must return a bytestring.')\n            conn._alpn_select_callback_args = [_ffi.new('unsigned char *', len(outstr)), _ffi.new('unsigned char[]', outstr)]\n            outlen[0] = conn._alpn_select_callback_args[0][0]\n            out[0] = conn._alpn_select_callback_args[1]\n            return 0\n        except Exception as e:\n            self._problems.append(e)\n            return 2\n    self.callback = _ffi.callback('int (*)(SSL *, unsigned char **, unsigned char *, const unsigned char *, unsigned int, void *)', wrapper)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, callback):\n    _CallbackExceptionHelper.__init__(callback)\n\n    @wraps(callback)\n    def wrapper(ssl, out, outlen, in_, inlen, arg):\n        try:\n            conn = Connection._reverse_mapping[ssl]\n            instr = _ffi.buffer(in_, inlen)[:]\n            protolist = []\n            while instr:\n                encoded_len = indexbytes(instr, 0)\n                proto = instr[1:(encoded_len + 1)]\n                protolist.append(proto)\n                instr = instr[(encoded_len + 1):]\n            outstr = callback(conn, protolist)\n            if (not isinstance(outstr, _binary_type)):\n                raise TypeError('ALPN callback must return a bytestring.')\n            conn._alpn_select_callback_args = [_ffi.new('unsigned char *', len(outstr)), _ffi.new('unsigned char[]', outstr)]\n            outlen[0] = conn._alpn_select_callback_args[0][0]\n            out[0] = conn._alpn_select_callback_args[1]\n            return 0\n        except Exception as e:\n            self._problems.append(e)\n            return 2\n    self.callback = _ffi.callback('int (*)(SSL *, unsigned char **, unsigned char *, const unsigned char *, unsigned int, void *)', wrapper)\n", "label": "Variable misuse"}
{"function": "\n\ndef depack(self, args):\n    self.is_touch = True\n    self.sx = args['x']\n    self.sy = args['y']\n    self.profile = ['pos']\n    if (('size_w' in args) and ('size_h' in args)):\n        self.shape = ShapeRect()\n        self.shape.width = args['size_w']\n        self.shape.height = args['size_h']\n        self.profile.append('shape')\n    if ('pressure' in args):\n        self.pressure = args['pressure']\n        self.profile.append('pressure')\n    super(MTDMotionEvent, self).depack(args)\n", "label": "Correct"}
{"function": "\n\ndef depack(self, args):\n    self.is_touch = True\n    self.sx = args['x']\n    self.sy = args['y']\n    self.profile = ['pos']\n    if (('size_w' in args) and ('size_h' in args)):\n        self.shape = ShapeRect()\n        self.shape.width = args['size_w']\n        self.shape.height = args['size_h']\n        self.profile.append('shape')\n    if ('pressure' in args):\n        self.pressure = args['pressure']\n        self.profile.append('pressure')\n    super(MTDMotionEvent, args).depack(args)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_registration(self):\n    resp = self.client.post(reverse('users_register'), self.user_data)\n    self.assertRedirects(resp, reverse('users_registration_complete'))\n", "label": "Correct"}
{"function": "\n\ndef test_registration(self):\n    resp = self.client.post(reverse('users_register'), self.user_data)\n    resp.assertRedirects(resp, reverse('users_registration_complete'))\n", "label": "Variable misuse"}
{"function": "\n\n@age.setter\ndef age(self, value):\n    'When assigning to this attribute it must be an RDFDatetime.'\n    self._age = RDFDatetime(value, age=0)\n", "label": "Correct"}
{"function": "\n\n@age.setter\ndef age(self, value):\n    'When assigning to this attribute it must be an RDFDatetime.'\n    value._age = RDFDatetime(value, age=0)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_multiple_close(self):\n    d = self.do_create()\n    d.cleanup()\n    d.cleanup()\n    d.cleanup()\n", "label": "Correct"}
{"function": "\n\ndef test_multiple_close(self):\n    d = self.do_create()\n    d.cleanup()\n    d.cleanup()\n    self.cleanup()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_rule_with_tags(self):\n    post_resp = self.__do_post(TestRuleController.RULE_1)\n    rule_id = self.__get_rule_id(post_resp)\n    get_resp = self.__do_get_one(rule_id)\n    self.assertEqual(get_resp.status_int, http_client.OK)\n    self.assertEqual(self.__get_rule_id(get_resp), rule_id)\n    self.assertEqual(get_resp.json['tags'], TestRuleController.RULE_1['tags'])\n    self.__do_delete(rule_id)\n", "label": "Correct"}
{"function": "\n\ndef test_rule_with_tags(self):\n    post_resp = self.__do_post(TestRuleController.RULE_1)\n    rule_id = self.__get_rule_id(post_resp)\n    get_resp = self.__do_get_one(rule_id)\n    self.assertEqual(get_resp.status_int, http_client.OK)\n    self.assertEqual(self.__get_rule_id(post_resp), rule_id)\n    self.assertEqual(get_resp.json['tags'], TestRuleController.RULE_1['tags'])\n    self.__do_delete(rule_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _BuildPodBody(self):\n    '\\n    Builds a JSON which will be passed as a body of POST request\\n    to Kuberneres API in order to create a POD.\\n    '\n    container = self._BuildContainerBody()\n    volumes = self._BuildVolumesBody()\n    template = {\n        'kind': 'Pod',\n        'apiVersion': 'v1',\n        'metadata': {\n            'name': self.name,\n            'labels': {\n                SELECTOR_PREFIX: self.name,\n            },\n        },\n        'spec': {\n            'volumes': volumes,\n            'containers': [container],\n            'dnsPolicy': 'ClusterFirst',\n        },\n    }\n    return json.dumps(template)\n", "label": "Correct"}
{"function": "\n\ndef _BuildPodBody(self):\n    '\\n    Builds a JSON which will be passed as a body of POST request\\n    to Kuberneres API in order to create a POD.\\n    '\n    container = template._BuildContainerBody()\n    volumes = self._BuildVolumesBody()\n    template = {\n        'kind': 'Pod',\n        'apiVersion': 'v1',\n        'metadata': {\n            'name': self.name,\n            'labels': {\n                SELECTOR_PREFIX: self.name,\n            },\n        },\n        'spec': {\n            'volumes': volumes,\n            'containers': [container],\n            'dnsPolicy': 'ClusterFirst',\n        },\n    }\n    return json.dumps(template)\n", "label": "Variable misuse"}
{"function": "\n\ndef send(self, message, flags=0, copy=False, track=False):\n    zmq_msg = ffi.new('zmq_msg_t*')\n    c_message = ffi.new('char[]', message)\n    C.zmq_msg_init_size(zmq_msg, len(message))\n    C.memcpy(C.zmq_msg_data(zmq_msg), c_message, len(message))\n    if (zmq_version == 2):\n        ret = C.zmq_send(self.zmq_socket, zmq_msg, flags)\n    else:\n        ret = C.zmq_sendmsg(self.zmq_socket, zmq_msg, flags)\n    C.zmq_msg_close(zmq_msg)\n    if (ret < 0):\n        self.last_errno = C.zmq_errno()\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef send(self, message, flags=0, copy=False, track=False):\n    zmq_msg = ffi.new('zmq_msg_t*')\n    c_message = ffi.new('char[]', message)\n    C.zmq_msg_init_size(zmq_msg, len(message))\n    C.memcpy(C.zmq_msg_data(message), c_message, len(message))\n    if (zmq_version == 2):\n        ret = C.zmq_send(self.zmq_socket, zmq_msg, flags)\n    else:\n        ret = C.zmq_sendmsg(self.zmq_socket, zmq_msg, flags)\n    C.zmq_msg_close(zmq_msg)\n    if (ret < 0):\n        self.last_errno = C.zmq_errno()\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(build_request.BuildRequest, '_get_by_instance_uuid_from_db')\ndef test_get_by_instance_uuid_instance_version_too_new(self, get_by_uuid):\n    fake_req = fake_build_request.fake_db_req()\n    instance = fake_instance.fake_instance_obj(self.context, objects.Instance, uuid=fake_req['instance_uuid'])\n    instance.VERSION = '99'\n    fake_req['instance'] = jsonutils.dumps(instance.obj_to_primitive)\n    get_by_uuid.return_value = fake_req\n    self.assertRaises(exception.BuildRequestNotFound, build_request.BuildRequest.get_by_instance_uuid, self.context, fake_req['instance_uuid'])\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(build_request.BuildRequest, '_get_by_instance_uuid_from_db')\ndef test_get_by_instance_uuid_instance_version_too_new(self, get_by_uuid):\n    fake_req = fake_build_request.fake_db_req()\n    instance = fake_instance.fake_instance_obj(self.context, objects.Instance, uuid=fake_req['instance_uuid'])\n    instance.VERSION = '99'\n    fake_req['instance'] = jsonutils.dumps(instance.obj_to_primitive)\n    get_by_uuid.return_value = fake_req\n    self.assertRaises(exception.BuildRequestNotFound, build_request.BuildRequest.get_by_instance_uuid, instance.context, fake_req['instance_uuid'])\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/attachment/weapon/shared_blacksun_light_weapon_s06.iff'\n    result.attribute_template_id = 8\n    result.stfName('item_n', 'ship_attachment')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/attachment/weapon/shared_blacksun_light_weapon_s06.iff'\n    kernel.attribute_template_id = 8\n    result.stfName('item_n', 'ship_attachment')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef get_next_event(self, *event_types, **kwargs):\n    kwargs['once'] = True\n    result = AsyncResult()\n\n    @self.subscribe(*event_types, **kwargs)\n    def handler(interface, event):\n        result.set(event.body)\n    return AsyncResultWrapper(self.container, handler, result)\n", "label": "Correct"}
{"function": "\n\ndef get_next_event(self, *event_types, **kwargs):\n    event_types['once'] = True\n    result = AsyncResult()\n\n    @self.subscribe(*event_types, **kwargs)\n    def handler(interface, event):\n        result.set(event.body)\n    return AsyncResultWrapper(self.container, handler, result)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_absolute_url(self, obj):\n    comment_id = self.context['request'].parser_context['kwargs']['comment_id']\n    return absolute_reverse('comments:report-detail', kwargs={\n        'comment_id': comment_id,\n        'user_id': obj._id,\n    })\n", "label": "Correct"}
{"function": "\n\ndef get_absolute_url(self, obj):\n    comment_id = self.context['request'].parser_context['kwargs']['comment_id']\n    return absolute_reverse('comments:report-detail', kwargs={\n        'comment_id': comment_id,\n        'user_id': comment_id._id,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef GetBlendMethod(self):\n    'Get the blend method'\n    currentMethod = self.component.PropertyList.Find('SourceBlendMode').Data\n    for (method, idx) in self.kBlendMethods.iteritems():\n        if (currentMethod == idx):\n            return method\n", "label": "Correct"}
{"function": "\n\ndef GetBlendMethod(self):\n    'Get the blend method'\n    currentMethod = self.component.PropertyList.Find('SourceBlendMode').Data\n    for (method, idx) in self.kBlendMethods.iteritems():\n        if (currentMethod == idx):\n            return currentMethod\n", "label": "Variable misuse"}
{"function": "\n\ndef anno(self, node):\n    if ((node.type is None) and (not getattr(node, 'escapes', False))):\n        return\n    if isinstance(node.type, (types.function, types.Type)):\n        return\n    self.write(' [')\n    if (node.type is not None):\n        self.visit(node.type)\n    if ((node.type is not None) and getattr(node, 'escapes', False)):\n        self.write(':')\n    if getattr(node, 'escapes', False):\n        self.write('E')\n    self.write(']')\n", "label": "Correct"}
{"function": "\n\ndef anno(self, node):\n    if ((node.type is None) and (not getattr(node, 'escapes', False))):\n        return\n    if isinstance(self.type, (types.function, types.Type)):\n        return\n    self.write(' [')\n    if (node.type is not None):\n        self.visit(node.type)\n    if ((node.type is not None) and getattr(node, 'escapes', False)):\n        self.write(':')\n    if getattr(node, 'escapes', False):\n        self.write('E')\n    self.write(']')\n", "label": "Variable misuse"}
{"function": "\n\n@log_repo_action\ndef pull(repo, args=[]):\n    '\\n    Pull changes from the backend\\n\\n    Parameters\\n    ----------\\n\\n    repo: Repository object\\n    args: Arguments to git command\\n    '\n    return generic_repo_cmd(repo, 'pull', args)\n", "label": "Correct"}
{"function": "\n\n@log_repo_action\ndef pull(repo, args=[]):\n    '\\n    Pull changes from the backend\\n\\n    Parameters\\n    ----------\\n\\n    repo: Repository object\\n    args: Arguments to git command\\n    '\n    return generic_repo_cmd(repo, 'pull', repo)\n", "label": "Variable misuse"}
{"function": "\n\ndef _read_track_origin(self, group):\n    self.track_origin = group.attrs['track_origin'].decode('ascii')\n    if ('track_n_scat' in group.attrs):\n        self.track_n_scat = group.attrs['track_n_scat']\n    else:\n        self.track_n_scat = 0\n", "label": "Correct"}
{"function": "\n\ndef _read_track_origin(self, group):\n    self.track_origin = group.attrs['track_origin'].decode('ascii')\n    if ('track_n_scat' in group.attrs):\n        self.track_n_scat = group.attrs['track_n_scat']\n    else:\n        group.track_n_scat = 0\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef size(self):\n    size = 4\n    size += AMF0String.size(self.target_uri)\n    size += AMF0String.size(self.response_uri)\n    size += AMF0Value.size(self.value)\n    return size\n", "label": "Correct"}
{"function": "\n\n@property\ndef size(self):\n    size = 4\n    size += AMF0String.size(self.target_uri)\n    size += AMF0String.size(size.response_uri)\n    size += AMF0Value.size(self.value)\n    return size\n", "label": "Variable misuse"}
{"function": "\n\ndef watch(self, actor, *actors, **kwargs):\n    return self.__cell.watch(actor, *actors, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef watch(self, actor, *actors, **kwargs):\n    return self.__cell.watch(kwargs, *actors, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_NVARCHAR(self, type_, **kw):\n    if type_.length:\n        return self._extend_string(type_, {\n            'national': True,\n        }, ('VARCHAR(%(length)s)' % {\n            'length': type_.length,\n        }))\n    else:\n        raise exc.CompileError(('NVARCHAR requires a length on dialect %s' % self.dialect.name))\n", "label": "Correct"}
{"function": "\n\ndef visit_NVARCHAR(self, type_, **kw):\n    if type_.length:\n        return self._extend_string(self, {\n            'national': True,\n        }, ('VARCHAR(%(length)s)' % {\n            'length': type_.length,\n        }))\n    else:\n        raise exc.CompileError(('NVARCHAR requires a length on dialect %s' % self.dialect.name))\n", "label": "Variable misuse"}
{"function": "\n\n@version.setter\ndef version(self, value):\n    self._element.version_text = value\n", "label": "Correct"}
{"function": "\n\n@version.setter\ndef version(self, value):\n    value._element.version_text = value\n", "label": "Variable misuse"}
{"function": "\n\ndef to_ctype(self, parakeet_type):\n    if isinstance(parakeet_type, (NoneT, ScalarT)):\n        return type_mappings.to_ctype(parakeet_type)\n    elif isinstance(parakeet_type, TupleT):\n        return self.struct_type_from_fields(parakeet_type.elt_types)\n    elif isinstance(parakeet_type, PtrT):\n        return self.ptr_struct_type(parakeet_type.elt_type)\n    elif isinstance(parakeet_type, ArrayT):\n        elt_t = parakeet_type.elt_type\n        rank = parakeet_type.rank\n        return self.array_struct_type(elt_t, rank)\n    elif isinstance(parakeet_type, SliceT):\n        return self.slice_struct_type()\n    elif isinstance(parakeet_type, ClosureT):\n        return self.struct_type_from_fields(parakeet_type.arg_types)\n    elif isinstance(parakeet_type, TypeValueT):\n        return 'int'\n    else:\n        assert False, (\"Don't know how to make C type for %s\" % parakeet_type)\n", "label": "Correct"}
{"function": "\n\ndef to_ctype(self, parakeet_type):\n    if isinstance(parakeet_type, (NoneT, ScalarT)):\n        return type_mappings.to_ctype(parakeet_type)\n    elif isinstance(parakeet_type, TupleT):\n        return self.struct_type_from_fields(parakeet_type.elt_types)\n    elif isinstance(parakeet_type, PtrT):\n        return self.ptr_struct_type(parakeet_type.elt_type)\n    elif isinstance(parakeet_type, ArrayT):\n        elt_t = parakeet_type.elt_type\n        rank = parakeet_type.rank\n        return self.array_struct_type(elt_t, rank)\n    elif isinstance(parakeet_type, SliceT):\n        return self.slice_struct_type()\n    elif isinstance(parakeet_type, ClosureT):\n        return rank.struct_type_from_fields(parakeet_type.arg_types)\n    elif isinstance(parakeet_type, TypeValueT):\n        return 'int'\n    else:\n        assert False, (\"Don't know how to make C type for %s\" % parakeet_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef detect(text):\n    init_factory()\n    detector = _factory.create()\n    detector.append(text)\n    return detector.detect()\n", "label": "Correct"}
{"function": "\n\ndef detect(text):\n    init_factory()\n    detector = _factory.create()\n    text.append(text)\n    return detector.detect()\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(iscsi_deploy, '_save_disk_layout', autospec=True)\n@mock.patch.object(iscsi_deploy, 'LOG', autospec=True)\n@mock.patch.object(iscsi_deploy, 'get_deploy_info', autospec=True)\n@mock.patch.object(iscsi_deploy, 'InstanceImageCache', autospec=True)\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\n@mock.patch.object(deploy_utils, 'deploy_partition_image', autospec=True)\ndef test_continue_deploy(self, deploy_mock, power_mock, mock_image_cache, mock_deploy_info, mock_log, mock_disk_layout):\n    kwargs = {\n        'address': '123456',\n        'iqn': 'aaa-bbb',\n        'key': 'fake-56789',\n    }\n    self.node.provision_state = states.DEPLOYWAIT\n    self.node.target_provision_state = states.ACTIVE\n    self.node.save()\n    mock_deploy_info.return_value = {\n        'address': '123456',\n        'boot_option': 'netboot',\n        'configdrive': \"I've got the power\",\n        'ephemeral_format': None,\n        'ephemeral_mb': 0,\n        'image_path': '/var/lib/ironic/images/1be26c0b-03f2-4d2e-ae87-c02d7f33c123/disk',\n        'iqn': 'aaa-bbb',\n        'lun': '1',\n        'node_uuid': '1be26c0b-03f2-4d2e-ae87-c02d7f33c123',\n        'port': '3260',\n        'preserve_ephemeral': True,\n        'root_mb': 102400,\n        'swap_mb': 0,\n    }\n    log_params = mock_deploy_info.return_value.copy()\n    log_params['configdrive'] = '***'\n    expected_dict = {\n        'node': self.node.uuid,\n        'params': log_params,\n    }\n    uuid_dict_returned = {\n        'root uuid': '12345678-87654321',\n    }\n    deploy_mock.return_value = uuid_dict_returned\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        mock_log.isEnabledFor.return_value = True\n        retval = iscsi_deploy.continue_deploy(task, **kwargs)\n        mock_log.debug.assert_called_once_with(mock.ANY, expected_dict)\n        self.assertEqual(states.DEPLOYWAIT, task.node.provision_state)\n        self.assertEqual(states.ACTIVE, task.node.target_provision_state)\n        self.assertIsNone(task.node.last_error)\n        mock_image_cache.assert_called_once_with()\n        mock_image_cache.return_value.clean_up.assert_called_once_with()\n        self.assertEqual(uuid_dict_returned, retval)\n        mock_disk_layout.assert_called_once_with(task.node, mock.ANY)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(iscsi_deploy, '_save_disk_layout', autospec=True)\n@mock.patch.object(iscsi_deploy, 'LOG', autospec=True)\n@mock.patch.object(iscsi_deploy, 'get_deploy_info', autospec=True)\n@mock.patch.object(iscsi_deploy, 'InstanceImageCache', autospec=True)\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\n@mock.patch.object(deploy_utils, 'deploy_partition_image', autospec=True)\ndef test_continue_deploy(self, deploy_mock, power_mock, mock_image_cache, mock_deploy_info, mock_log, mock_disk_layout):\n    kwargs = {\n        'address': '123456',\n        'iqn': 'aaa-bbb',\n        'key': 'fake-56789',\n    }\n    self.node.provision_state = states.DEPLOYWAIT\n    self.node.target_provision_state = states.ACTIVE\n    self.node.save()\n    mock_deploy_info.return_value = {\n        'address': '123456',\n        'boot_option': 'netboot',\n        'configdrive': \"I've got the power\",\n        'ephemeral_format': None,\n        'ephemeral_mb': 0,\n        'image_path': '/var/lib/ironic/images/1be26c0b-03f2-4d2e-ae87-c02d7f33c123/disk',\n        'iqn': 'aaa-bbb',\n        'lun': '1',\n        'node_uuid': '1be26c0b-03f2-4d2e-ae87-c02d7f33c123',\n        'port': '3260',\n        'preserve_ephemeral': True,\n        'root_mb': 102400,\n        'swap_mb': 0,\n    }\n    log_params = mock_deploy_info.return_value.copy()\n    log_params['configdrive'] = '***'\n    expected_dict = {\n        'node': self.node.uuid,\n        'params': log_params,\n    }\n    uuid_dict_returned = {\n        'root uuid': '12345678-87654321',\n    }\n    deploy_mock.return_value = uuid_dict_returned\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        mock_log.isEnabledFor.return_value = True\n        retval = iscsi_deploy.continue_deploy(task, **kwargs)\n        mock_log.debug.assert_called_once_with(mock.ANY, expected_dict)\n        self.assertEqual(states.DEPLOYWAIT, task.node.provision_state)\n        mock_log.assertEqual(states.ACTIVE, task.node.target_provision_state)\n        self.assertIsNone(task.node.last_error)\n        mock_image_cache.assert_called_once_with()\n        mock_image_cache.return_value.clean_up.assert_called_once_with()\n        self.assertEqual(uuid_dict_returned, retval)\n        mock_disk_layout.assert_called_once_with(task.node, mock.ANY)\n", "label": "Variable misuse"}
{"function": "\n\n@webob.dec.wsgify\ndef process_request(self, req):\n    if (req.path != self._path):\n        return None\n    results = [ext.obj.healthcheck(req.server_port) for ext in self._backends]\n    healthy = self._are_results_healthy(results)\n    if (req.method == 'HEAD'):\n        functor = self._make_head_response\n        status = self.HEAD_HEALTHY_TO_STATUS_CODES[healthy]\n    else:\n        status = self.HEALTHY_TO_STATUS_CODES[healthy]\n        accept_type = req.accept.best_match(self._accept_order)\n        if (not accept_type):\n            accept_type = self._default_accept\n        functor = self._accept_to_functor[accept_type]\n    (body, content_type) = functor(results, healthy)\n    return webob.response.Response(status=status, body=body, content_type=content_type)\n", "label": "Correct"}
{"function": "\n\n@webob.dec.wsgify\ndef process_request(self, req):\n    if (req.path != self._path):\n        return None\n    results = [ext.obj.healthcheck(req.server_port) for ext in self._backends]\n    healthy = self._are_results_healthy(results)\n    if (content_type.method == 'HEAD'):\n        functor = self._make_head_response\n        status = self.HEAD_HEALTHY_TO_STATUS_CODES[healthy]\n    else:\n        status = self.HEALTHY_TO_STATUS_CODES[healthy]\n        accept_type = req.accept.best_match(self._accept_order)\n        if (not accept_type):\n            accept_type = self._default_accept\n        functor = self._accept_to_functor[accept_type]\n    (body, content_type) = functor(results, healthy)\n    return webob.response.Response(status=status, body=body, content_type=content_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef _convert_to_array_of_opt_val(optvals):\n    'Wraps the given array into a DataObject.'\n    array_of_optv = DataObject()\n    array_of_optv.OptionValue = optvals\n    return array_of_optv\n", "label": "Correct"}
{"function": "\n\ndef _convert_to_array_of_opt_val(optvals):\n    'Wraps the given array into a DataObject.'\n    array_of_optv = DataObject()\n    array_of_optv.OptionValue = array_of_optv\n    return array_of_optv\n", "label": "Variable misuse"}
{"function": "\n\ndef test_minimum_specific_energy_scalar(tmpdir):\n    input_file = tmpdir.join(random_id()).strpath\n    output_file = tmpdir.join(random_id()).strpath\n    model = get_test_model_noimaging()\n    model.add_density_grid(density, dust_file)\n    model.set_minimum_specific_energy(2.0)\n    model.write(input_file)\n    out = model.run(output_file)\n    t = out.get_physical_grid('specific_energy')\n    assert_array_almost_equal_nulp(t[0][(0, 0, 0)], 2.0, 10)\n", "label": "Correct"}
{"function": "\n\ndef test_minimum_specific_energy_scalar(tmpdir):\n    input_file = tmpdir.join(random_id()).strpath\n    output_file = tmpdir.join(random_id()).strpath\n    model = get_test_model_noimaging()\n    out.add_density_grid(density, dust_file)\n    model.set_minimum_specific_energy(2.0)\n    model.write(input_file)\n    out = model.run(output_file)\n    t = out.get_physical_grid('specific_energy')\n    assert_array_almost_equal_nulp(t[0][(0, 0, 0)], 2.0, 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef hvals(self, name):\n    'Return the list of values within hash ``name``'\n    return self.execute_command('HVALS', name)\n", "label": "Correct"}
{"function": "\n\ndef hvals(self, name):\n    'Return the list of values within hash ``name``'\n    return name.execute_command('HVALS', name)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_some_incompatible(self):\n    red = self.make_target('red', RedTarget)\n    blue = self.make_target('blue', BlueTarget)\n    with self.mutex_group(targets=[red, blue]) as (red_viewer, blue_viewer, green_viewer):\n        self.assert_incompatible_activations(red_viewer)\n        self.assert_incompatible_activations(blue_viewer)\n        green_viewer.execute()\n        self.assertIsNone(green_viewer.executed)\n", "label": "Correct"}
{"function": "\n\ndef test_some_incompatible(self):\n    red = self.make_target('red', RedTarget)\n    blue = self.make_target('blue', BlueTarget)\n    with self.mutex_group(targets=[red, blue]) as (red_viewer, blue_viewer, green_viewer):\n        self.assert_incompatible_activations(red)\n        self.assert_incompatible_activations(blue_viewer)\n        green_viewer.execute()\n        self.assertIsNone(green_viewer.executed)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_segm_id(self, example_word):\n    return example_word.split('(')[1].split(',')[0]\n", "label": "Correct"}
{"function": "\n\ndef get_segm_id(self, example_word):\n    return self.split('(')[1].split(',')[0]\n", "label": "Variable misuse"}
