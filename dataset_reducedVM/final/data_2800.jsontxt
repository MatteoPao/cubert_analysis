{"function": "\n\ndef test_s3_domain_with_default_root_object(self):\n    cmdline = ((self.prefix + '--origin-domain-name foo.s3.amazonaws.com ') + '--default-root-object index.html')\n    result = {\n        'DistributionConfig': {\n            'Origins': {\n                'Quantity': 1,\n                'Items': [{\n                    'S3OriginConfig': mock.ANY,\n                    'DomainName': 'foo.s3.amazonaws.com',\n                    'Id': mock.ANY,\n                    'OriginPath': '',\n                }],\n            },\n            'CallerReference': mock.ANY,\n            'Comment': '',\n            'Enabled': True,\n            'DefaultCacheBehavior': mock.ANY,\n            'DefaultRootObject': 'index.html',\n        },\n    }\n    self.run_cmd(cmdline)\n    self.assertEqual(self.last_kwargs, result)\n", "label": "Correct"}
{"function": "\n\ndef test_s3_domain_with_default_root_object(self):\n    cmdline = ((self.prefix + '--origin-domain-name foo.s3.amazonaws.com ') + '--default-root-object index.html')\n    result = {\n        'DistributionConfig': {\n            'Origins': {\n                'Quantity': 1,\n                'Items': [{\n                    'S3OriginConfig': mock.ANY,\n                    'DomainName': 'foo.s3.amazonaws.com',\n                    'Id': mock.ANY,\n                    'OriginPath': '',\n                }],\n            },\n            'CallerReference': mock.ANY,\n            'Comment': '',\n            'Enabled': True,\n            'DefaultCacheBehavior': mock.ANY,\n            'DefaultRootObject': 'index.html',\n        },\n    }\n    self.run_cmd(cmdline)\n    self.assertEqual(result.last_kwargs, result)\n", "label": "Variable misuse"}
{"function": "\n\ndef pages_dynamic_tree_menu(context, page, url='/'):\n    '\\n    Render a \"dynamic\" tree menu, with all nodes expanded which are either\\n    ancestors or the current page itself.\\n\\n    Override ``pages/dynamic_tree_menu.html`` if you want to change the\\n    design.\\n\\n    :param page: the current page\\n    :param url: not used anymore\\n    '\n    lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\n    page = get_page_from_string_or_id(page, lang)\n    children = None\n    if (page and ('current_page' in context)):\n        current_page = context['current_page']\n        if ((page.tree_id == current_page.tree_id) and (page.lft <= current_page.lft) and (page.rght >= current_page.rght)):\n            children = page.get_children_for_frontend()\n    context.update({\n        'children': children,\n        'page': page,\n    })\n    return context\n", "label": "Correct"}
{"function": "\n\ndef pages_dynamic_tree_menu(context, page, url='/'):\n    '\\n    Render a \"dynamic\" tree menu, with all nodes expanded which are either\\n    ancestors or the current page itself.\\n\\n    Override ``pages/dynamic_tree_menu.html`` if you want to change the\\n    design.\\n\\n    :param page: the current page\\n    :param url: not used anymore\\n    '\n    lang = context.get('lang', pages_settings.PAGE_DEFAULT_LANGUAGE)\n    page = get_page_from_string_or_id(page, lang)\n    children = None\n    if (page and ('current_page' in context)):\n        current_page = children['current_page']\n        if ((page.tree_id == current_page.tree_id) and (page.lft <= current_page.lft) and (page.rght >= current_page.rght)):\n            children = page.get_children_for_frontend()\n    context.update({\n        'children': children,\n        'page': page,\n    })\n    return context\n", "label": "Variable misuse"}
{"function": "\n\ndef remove(path, recursive=False, use_sudo=False):\n    '\\n    Remove a file or directory\\n    '\n    func = ((use_sudo and run_as_root) or run)\n    options = ('-r ' if recursive else '')\n    func('/bin/rm {0}{1}'.format(options, quote(path)))\n", "label": "Correct"}
{"function": "\n\ndef remove(path, recursive=False, use_sudo=False):\n    '\\n    Remove a file or directory\\n    '\n    func = ((recursive and run_as_root) or run)\n    options = ('-r ' if recursive else '')\n    func('/bin/rm {0}{1}'.format(options, quote(path)))\n", "label": "Variable misuse"}
{"function": "\n\ndef marshal_dump(code, f):\n    if isinstance(f, file):\n        marshal.dump(code, f)\n    else:\n        f.write(marshal.dumps(code))\n", "label": "Correct"}
{"function": "\n\ndef marshal_dump(code, f):\n    if isinstance(f, file):\n        marshal.dump(f, f)\n    else:\n        f.write(marshal.dumps(code))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_show_body(self):\n    client = Mock()\n    client.indices.get_settings.return_value = testvars.settings_one\n    client.cluster.state.return_value = testvars.clu_state_one\n    client.indices.stats.return_value = testvars.stats_one\n    ilo = curator.IndexList(client)\n    ao = curator.Alias(name='alias')\n    ao.remove(ilo)\n    ao.add(ilo)\n    body = ao.body()\n    self.assertEqual(testvars.alias_one_body['actions'][0], body['actions'][0])\n    self.assertEqual(testvars.alias_one_body['actions'][1], body['actions'][1])\n", "label": "Correct"}
{"function": "\n\ndef test_show_body(self):\n    client = Mock()\n    client.indices.get_settings.return_value = testvars.settings_one\n    client.cluster.state.return_value = testvars.clu_state_one\n    client.indices.stats.return_value = testvars.stats_one\n    ilo = curator.IndexList(client)\n    ao = curator.Alias(name='alias')\n    ao.remove(ilo)\n    ao.add(ilo)\n    body = ao.body()\n    self.assertEqual(testvars.alias_one_body['actions'][0], client['actions'][0])\n    self.assertEqual(testvars.alias_one_body['actions'][1], body['actions'][1])\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('SoftLayer.API.BaseClient.iter_call')\ndef test_iterate(self, _iter_call):\n    self.client['SERVICE'].METHOD(iter=True)\n    _iter_call.assert_called_with('SERVICE', 'METHOD')\n", "label": "Correct"}
{"function": "\n\n@mock.patch('SoftLayer.API.BaseClient.iter_call')\ndef test_iterate(self, _iter_call):\n    self.client['SERVICE'].METHOD(iter=True)\n    self.assert_called_with('SERVICE', 'METHOD')\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, *args, **kwargs):\n    try:\n        self._call(*args, **kwargs)\n    except Exception as err:\n        stats.incr('callback-failure', 1)\n        logging.exception('Callback Failed: %s', err)\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, *args, **kwargs):\n    try:\n        self._call(*err, **kwargs)\n    except Exception as err:\n        stats.incr('callback-failure', 1)\n        logging.exception('Callback Failed: %s', err)\n", "label": "Variable misuse"}
{"function": "\n\n@register.filter\ndef lookup(h, key):\n    try:\n        return h[key]\n    except KeyError:\n        return ''\n", "label": "Correct"}
{"function": "\n\n@register.filter\ndef lookup(h, key):\n    try:\n        return h[h]\n    except KeyError:\n        return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef __add__(self, other):\n    return self.build('add', self, other)\n", "label": "Correct"}
{"function": "\n\ndef __add__(self, other):\n    return self.build('add', self, self)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef read(cls, handle):\n    self = cls()\n    self._read_luminosity(handle)\n    self.name = handle.attrs['name'].decode('utf-8')\n    self.peeloff = str2bool(handle.attrs['peeloff'])\n    if (handle.attrs['spectrum'] == b'spectrum'):\n        self.spectrum = Table(np.array(handle['spectrum']))\n    elif (handle.attrs['spectrum'] == b'temperature'):\n        self.temperature = handle.attrs['temperature']\n    elif (handle.attrs['spectrum'] == b'lte'):\n        pass\n    else:\n        raise ValueError(('Unexpected value for `spectrum`: %s' % handle.attrs['spectrum']))\n    return self\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef read(cls, handle):\n    self = cls()\n    self._read_luminosity(handle)\n    self.name = handle.attrs['name'].decode('utf-8')\n    handle.peeloff = str2bool(handle.attrs['peeloff'])\n    if (handle.attrs['spectrum'] == b'spectrum'):\n        self.spectrum = Table(np.array(handle['spectrum']))\n    elif (handle.attrs['spectrum'] == b'temperature'):\n        self.temperature = handle.attrs['temperature']\n    elif (handle.attrs['spectrum'] == b'lte'):\n        pass\n    else:\n        raise ValueError(('Unexpected value for `spectrum`: %s' % handle.attrs['spectrum']))\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, context):\n    category = resolve(self.category, context)\n    if isinstance(category, CategoryBase):\n        cat = category\n    else:\n        cat = get_category(category, self.model)\n    try:\n        if (cat is not None):\n            context[self.varname] = drilldown_tree_for_node(cat)\n        else:\n            context[self.varname] = []\n    except:\n        context[self.varname] = []\n    return ''\n", "label": "Correct"}
{"function": "\n\ndef render(self, context):\n    category = resolve(self.category, context)\n    if isinstance(category, CategoryBase):\n        cat = category\n    else:\n        cat = get_category(category, self.model)\n    try:\n        if (category is not None):\n            context[self.varname] = drilldown_tree_for_node(cat)\n        else:\n            context[self.varname] = []\n    except:\n        context[self.varname] = []\n    return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, manufacturer, data):\n    self.manufacturer = manufacturer\n    self.data = list(data)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, manufacturer, data):\n    self.manufacturer = manufacturer\n    self.data = list(manufacturer)\n", "label": "Variable misuse"}
{"function": "\n\ndef process_response(self, request, response):\n    from django.conf import settings\n    from rest_framework.exceptions import PermissionDenied\n    from .access_control import upload_prefix_for_request\n    cookie_name = getattr(settings, 'UPLOAD_PREFIX_COOKIE_NAME', 'upload_prefix')\n    try:\n        response.set_cookie(cookie_name, upload_prefix_for_request(request))\n    except PermissionDenied:\n        response.delete_cookie(cookie_name)\n    return response\n", "label": "Correct"}
{"function": "\n\ndef process_response(self, request, response):\n    from django.conf import settings\n    from rest_framework.exceptions import PermissionDenied\n    from .access_control import upload_prefix_for_request\n    cookie_name = getattr(settings, 'UPLOAD_PREFIX_COOKIE_NAME', 'upload_prefix')\n    try:\n        response.set_cookie(cookie_name, upload_prefix_for_request(cookie_name))\n    except PermissionDenied:\n        response.delete_cookie(cookie_name)\n    return response\n", "label": "Variable misuse"}
{"function": "\n\ndef createLineSet(self, indices, inputlist, materialid):\n    'Create a set of lines for use in this geometry instance.\\n\\n        :param numpy.array indices:\\n          unshaped numpy array that contains the indices for\\n          the inputs referenced in inputlist\\n        :param collada.source.InputList inputlist:\\n          The inputs for this primitive\\n        :param str materialid:\\n          A string containing a symbol that will get used to bind this lineset\\n          to a material when instantiating into a scene\\n\\n        :rtype: :class:`collada.lineset.LineSet`\\n        '\n    inputdict = primitive.Primitive._getInputsFromList(self.collada, self.sourceById, inputlist.getList())\n    return lineset.LineSet(inputdict, materialid, indices)\n", "label": "Correct"}
{"function": "\n\ndef createLineSet(self, indices, inputlist, materialid):\n    'Create a set of lines for use in this geometry instance.\\n\\n        :param numpy.array indices:\\n          unshaped numpy array that contains the indices for\\n          the inputs referenced in inputlist\\n        :param collada.source.InputList inputlist:\\n          The inputs for this primitive\\n        :param str materialid:\\n          A string containing a symbol that will get used to bind this lineset\\n          to a material when instantiating into a scene\\n\\n        :rtype: :class:`collada.lineset.LineSet`\\n        '\n    inputdict = primitive.Primitive._getInputsFromList(self.collada, inputlist.sourceById, inputlist.getList())\n    return lineset.LineSet(inputdict, materialid, indices)\n", "label": "Variable misuse"}
{"function": "\n\ndef stepSlice(self, offset):\n    ' Move the selected structure one slice up or down\\n        :param offset: +1 or -1\\n        :return:\\n        '\n    volumeId = self.volumeSelector.currentNodeId\n    if (volumeId == ''):\n        self.showUnselectedVolumeWarningMessage()\n        return\n    selectedStructure = self.getCurrentSelectedStructure()\n    if (selectedStructure == self.logic.NONE):\n        self.showUnselectedStructureWarningMessage()\n        return\n    if (selectedStructure == self.logic.BOTH):\n        self.logic.stepSlice(volumeId, self.logic.AORTA, offset)\n        newSlice = self.logic.stepSlice(volumeId, self.logic.PA, offset)\n    else:\n        newSlice = self.logic.stepSlice(volumeId, selectedStructure, offset)\n    self.moveRedWindowToSlice(newSlice)\n", "label": "Correct"}
{"function": "\n\ndef stepSlice(self, offset):\n    ' Move the selected structure one slice up or down\\n        :param offset: +1 or -1\\n        :return:\\n        '\n    volumeId = self.volumeSelector.currentNodeId\n    if (volumeId == ''):\n        self.showUnselectedVolumeWarningMessage()\n        return\n    selectedStructure = selectedStructure.getCurrentSelectedStructure()\n    if (selectedStructure == self.logic.NONE):\n        self.showUnselectedStructureWarningMessage()\n        return\n    if (selectedStructure == self.logic.BOTH):\n        self.logic.stepSlice(volumeId, self.logic.AORTA, offset)\n        newSlice = self.logic.stepSlice(volumeId, self.logic.PA, offset)\n    else:\n        newSlice = self.logic.stepSlice(volumeId, selectedStructure, offset)\n    self.moveRedWindowToSlice(newSlice)\n", "label": "Variable misuse"}
{"function": "\n\n@testhelp.context('sysmodel')\ndef testScripts(self):\n    '\\n        Make sure we can attach scripts to groups correctly\\n        '\n\n    def _checkScripts(grp):\n        scripts = grp.troveInfo.scripts\n        for scriptType in scriptTypes:\n            script = getattr(scripts, scriptType).script()\n            self.assertEquals(script, ('# %s' % scriptType))\n    self.addComponent('foo:runtime=1.0')\n    self.addComponent('foo:lib=1.0')\n    self.addCollection('foo=1.0', ['foo:runtime', 'foo:lib'])\n    recipe = []\n    scriptTypes = ('postInstall', 'preRollback', 'postRollback', 'preUpdate', 'postUpdate')\n    for scriptType in scriptTypes:\n        recipe.append(('%s = r.Script(contents=\"# %s\")' % (2 * (scriptType,))))\n    recipe.append(('scripts = r.Scripts(%s)' % ', '.join([' = '.join((x, x)) for x in scriptTypes])))\n    recipe.append('foo = world.find(\"foo\")')\n    recipe.append('groupInner = foo.createGroup(\"group-inner\", scripts=scripts)')\n    recipe.append('r.Group(groupInner, scripts=scripts)')\n    grp = self._build(*recipe)\n    repos = self.openRepository()\n    igrp = repos.getTrove('group-inner', grp.getVersion(), grp.getFlavor())\n    for g in (grp, igrp):\n        _checkScripts(g)\n    grp = self._build(\"grp = world['group-test']\", \"foo = world['foo']\", \"r.name = 'group-bar'\", 'scripts = grp.scripts()', 'r.Group(foo, scripts = scripts)')\n    _checkScripts(grp)\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test', 'foo')\", 'scripts = grp.scripts()', 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Multiple troves in trove set for scripts()')\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test')\", \"scripts = (grp - grp['group-test']).scripts()\", 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Empty trove set for scripts()')\n", "label": "Correct"}
{"function": "\n\n@testhelp.context('sysmodel')\ndef testScripts(self):\n    '\\n        Make sure we can attach scripts to groups correctly\\n        '\n\n    def _checkScripts(grp):\n        scripts = grp.troveInfo.scripts\n        for scriptType in scriptTypes:\n            script = getattr(scripts, scriptType).script()\n            self.assertEquals(script, ('# %s' % scriptType))\n    self.addComponent('foo:runtime=1.0')\n    self.addComponent('foo:lib=1.0')\n    self.addCollection('foo=1.0', ['foo:runtime', 'foo:lib'])\n    recipe = []\n    scriptTypes = ('postInstall', 'preRollback', 'postRollback', 'preUpdate', 'postUpdate')\n    for scriptType in scriptTypes:\n        recipe.append(('%s = r.Script(contents=\"# %s\")' % (2 * (scriptType,))))\n    igrp.append(('scripts = r.Scripts(%s)' % ', '.join([' = '.join((x, x)) for x in scriptTypes])))\n    recipe.append('foo = world.find(\"foo\")')\n    recipe.append('groupInner = foo.createGroup(\"group-inner\", scripts=scripts)')\n    recipe.append('r.Group(groupInner, scripts=scripts)')\n    grp = self._build(*recipe)\n    repos = self.openRepository()\n    igrp = repos.getTrove('group-inner', grp.getVersion(), grp.getFlavor())\n    for g in (grp, igrp):\n        _checkScripts(g)\n    grp = self._build(\"grp = world['group-test']\", \"foo = world['foo']\", \"r.name = 'group-bar'\", 'scripts = grp.scripts()', 'r.Group(foo, scripts = scripts)')\n    _checkScripts(grp)\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test', 'foo')\", 'scripts = grp.scripts()', 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Multiple troves in trove set for scripts()')\n    e = self.assertRaises(cook.CookError, self._build, \"grp = world.find('group-test')\", \"scripts = (grp - grp['group-test']).scripts()\", 'r.Group(grp, scripts = scripts)')\n    self.assertEquals(str(e), 'Empty trove set for scripts()')\n", "label": "Variable misuse"}
{"function": "\n\ndef normalize_diff_filename(self, filename):\n    \"Normalize filenames in diffs.\\n\\n        The default behavior of stripping off leading slashes doesn't work for\\n        Perforce (because depot paths start with //), so this overrides it to\\n        just return the filename un-molested.\\n        \"\n    return filename\n", "label": "Correct"}
{"function": "\n\ndef normalize_diff_filename(self, filename):\n    \"Normalize filenames in diffs.\\n\\n        The default behavior of stripping off leading slashes doesn't work for\\n        Perforce (because depot paths start with //), so this overrides it to\\n        just return the filename un-molested.\\n        \"\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_chair_metal_s1.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_chair_metal_s1.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_content_url_encoding_safe(self):\n    s = Site(self.SITE_PATH, config=self.config)\n    s.load()\n    path = '\".jpg/abc'\n    print(s.content_url(path, ''))\n    print(('/' + quote(path, '')))\n    assert (s.content_url(path, '') == ('/' + quote(path, '')))\n", "label": "Correct"}
{"function": "\n\ndef test_content_url_encoding_safe(self):\n    s = Site(self.SITE_PATH, config=self.config)\n    s.load()\n    path = '\".jpg/abc'\n    print(self.content_url(path, ''))\n    print(('/' + quote(path, '')))\n    assert (s.content_url(path, '') == ('/' + quote(path, '')))\n", "label": "Variable misuse"}
{"function": "\n\ndef post_undelete(self, *args, **kwargs):\n    self.post_undelete_called = True\n", "label": "Correct"}
{"function": "\n\ndef post_undelete(self, *args, **kwargs):\n    kwargs.post_undelete_called = True\n", "label": "Variable misuse"}
{"function": "\n\ndef timecolon(data):\n    match = re.search('(\\\\d+:\\\\d+:\\\\d+):(\\\\d+)', data)\n    return ('%s,%s' % (match.group(1), match.group(2)))\n", "label": "Correct"}
{"function": "\n\ndef timecolon(data):\n    match = re.search('(\\\\d+:\\\\d+:\\\\d+):(\\\\d+)', data)\n    return ('%s,%s' % (data.group(1), match.group(2)))\n", "label": "Variable misuse"}
{"function": "\n\ndef getUpdatedBatchJob(self, maxWait):\n    while True:\n        try:\n            (jobID, status, wallTime) = self.updatedJobsQueue.get(timeout=maxWait)\n        except Empty:\n            return None\n        try:\n            self.runningJobs.remove(jobID)\n        except KeyError:\n            pass\n        else:\n            return (jobID, status, wallTime)\n", "label": "Correct"}
{"function": "\n\ndef getUpdatedBatchJob(self, maxWait):\n    while True:\n        try:\n            (jobID, status, wallTime) = self.updatedJobsQueue.get(timeout=maxWait)\n        except Empty:\n            return None\n        try:\n            self.runningJobs.remove(jobID)\n        except KeyError:\n            pass\n        else:\n            return (status, status, wallTime)\n", "label": "Variable misuse"}
{"function": "\n\ndef package_private_devel_path(self, package):\n    'The path to the linked devel space for a given package.'\n    return os.path.join(self.private_devel_path, package.name)\n", "label": "Correct"}
{"function": "\n\ndef package_private_devel_path(self, package):\n    'The path to the linked devel space for a given package.'\n    return os.path.join(self.private_devel_path, self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_getset_owner(self):\n    m = meta.Metadata()\n    o = m.get_owner('files/one')\n    m.set_owner('files/one', *o)\n", "label": "Correct"}
{"function": "\n\ndef test_getset_owner(self):\n    m = meta.Metadata()\n    o = o.get_owner('files/one')\n    m.set_owner('files/one', *o)\n", "label": "Variable misuse"}
{"function": "\n\ndef indent(string, prefix='    '):\n    '\\n    Indent every line of this string.\\n    '\n    return ''.join((('%s%s\\n' % (prefix, s)) for s in string.split('\\n')))\n", "label": "Correct"}
{"function": "\n\ndef indent(string, prefix='    '):\n    '\\n    Indent every line of this string.\\n    '\n    return ''.join((('%s%s\\n' % (s, s)) for s in string.split('\\n')))\n", "label": "Variable misuse"}
{"function": "\n\ndef stories(self, task, params={\n    \n}, **options):\n    'Returns a compact representation of all of the stories on the task.\\n\\n        Parameters\\n        ----------\\n        task : {Id} The task containing the stories to get.\\n        [params] : {Object} Parameters for the request\\n        '\n    path = ('/tasks/%s/stories' % task)\n    return self.client.get_collection(path, params, **options)\n", "label": "Correct"}
{"function": "\n\ndef stories(self, task, params={\n    \n}, **options):\n    'Returns a compact representation of all of the stories on the task.\\n\\n        Parameters\\n        ----------\\n        task : {Id} The task containing the stories to get.\\n        [params] : {Object} Parameters for the request\\n        '\n    path = ('/tasks/%s/stories' % task)\n    return self.client.get_collection(self, params, **options)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_context_types_value(context_id, source, filter_func, codebase):\n    query = CodeElementLink.objects.filter(code_element__kind__is_type=True).filter(index=0).filter(code_element__codebase=codebase).filter(code_reference__source=source)\n    query = filter_func(query, context_id)\n    context_types = []\n    pk_set = set()\n    for link in query.all():\n        code_element = link.code_element\n        if (code_element.pk not in pk_set):\n            context_types.append(code_element)\n            pk_set.add(code_element.pk)\n    return context_types\n", "label": "Correct"}
{"function": "\n\ndef get_context_types_value(context_id, source, filter_func, codebase):\n    query = CodeElementLink.objects.filter(code_element__kind__is_type=True).filter(index=0).filter(code_element__codebase=query).filter(code_reference__source=source)\n    query = filter_func(query, context_id)\n    context_types = []\n    pk_set = set()\n    for link in query.all():\n        code_element = link.code_element\n        if (code_element.pk not in pk_set):\n            context_types.append(code_element)\n            pk_set.add(code_element.pk)\n    return context_types\n", "label": "Variable misuse"}
{"function": "\n\ndef _validate_simple_authn(self, username, credentials):\n    '\\n        When the login() method is called, this method is used with the \\n        username and credentials (e.g., password, IP address, etc.). This\\n        method will only check the SimpleAuthn instances.\\n        '\n    try:\n        (login, role_name, user_auths) = self._db.retrieve_role_and_user_auths(username)\n    except DbUserNotFoundError:\n        return self._process_invalid()\n    errors = False\n    for user_auth in user_auths:\n        if user_auth.is_simple_authn():\n            try:\n                authenticated = user_auth.authenticate(login, credentials)\n            except:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: ERROR' % (login, user_auth)))\n                log.log_exc(LoginManager, log.level.Warning)\n                errors = True\n                traceback.print_exc()\n                continue\n            if authenticated:\n                log.log(LoginManager, log.level.Debug, ('Username: %s with user_auth %s: SUCCESS' % (login, user_auth)))\n                return ValidDatabaseSessionId(login, role_name)\n            else:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: FAIL' % (login, user_auth)))\n    if errors:\n        raise LoginErrors.LoginError('Error checking credentials. Contact administrators!')\n    return self._process_invalid()\n", "label": "Correct"}
{"function": "\n\ndef _validate_simple_authn(self, username, credentials):\n    '\\n        When the login() method is called, this method is used with the \\n        username and credentials (e.g., password, IP address, etc.). This\\n        method will only check the SimpleAuthn instances.\\n        '\n    try:\n        (login, role_name, user_auths) = self._db.retrieve_role_and_user_auths(username)\n    except DbUserNotFoundError:\n        return self._process_invalid()\n    errors = False\n    for user_auth in user_auths:\n        if user_auth.is_simple_authn():\n            try:\n                authenticated = user_auth.authenticate(login, credentials)\n            except:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: ERROR' % (login, user_auth)))\n                log.log_exc(LoginManager, log.level.Warning)\n                errors = True\n                traceback.print_exc()\n                continue\n            if authenticated:\n                log.log(LoginManager, log.level.Debug, ('Username: %s with user_auth %s: SUCCESS' % (login, user_auth)))\n                return ValidDatabaseSessionId(login, role_name)\n            else:\n                log.log(LoginManager, log.level.Warning, ('Username: %s with user_auth %s: FAIL' % (credentials, user_auth)))\n    if errors:\n        raise LoginErrors.LoginError('Error checking credentials. Contact administrators!')\n    return self._process_invalid()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_elemwise_thats_also_a_column():\n    t = symbol('t', 'var * {x: int, time: datetime, y: int}')\n    expr = t[(t.x > 0)].time.truncate(months=1)\n    expected = t[['time', 'x']]\n    result = lean_projection(expr)\n    assert result._child._child._child.isidentical(t[['time', 'x']])\n", "label": "Correct"}
{"function": "\n\ndef test_elemwise_thats_also_a_column():\n    t = symbol('t', 'var * {x: int, time: datetime, y: int}')\n    expr = t[(result.x > 0)].time.truncate(months=1)\n    expected = t[['time', 'x']]\n    result = lean_projection(expr)\n    assert result._child._child._child.isidentical(t[['time', 'x']])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list(self):\n    lists = {('l%s' % i): list(string.ascii_lowercase[:i]) for i in range(1, 10)}\n    self.collections_common_tests(lists, 'l')\n", "label": "Correct"}
{"function": "\n\ndef test_list(self):\n    lists = {('l%s' % i): list(string.ascii_lowercase[:i]) for i in range(1, 10)}\n    lists.collections_common_tests(lists, 'l')\n", "label": "Variable misuse"}
{"function": "\n\ndef fit_transform(self, X, y):\n    'Fit and transform.'\n    self.fit(X, y)\n    return self.transform(X)\n", "label": "Correct"}
{"function": "\n\ndef fit_transform(self, X, y):\n    'Fit and transform.'\n    self.fit(X, y)\n    return self.transform(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef make_ProfileConnectionV4(cid, name, networkUri, profileTemplateConnection, connectionBoot=None, functionType='Ethernet', mac=None, macType='Virtual', portId='Auto', requestedMbps=None, wwnn=None, wwpn=None, wwpnType='Virtual'):\n    \" Create a ProfileConnectionV4 dictionary\\n\\n    Args:\\n        connectionBoot:\\n            ConnectionBoot dictionary that descirbes server boot management.\\n        functionType:\\n            The function of the connection, either 'Ethernet' or 'FibreChannel'\\n        cid:\\n            A unique identifier for this connection. When creating or editing a\\n            profile, an id is automatically assigned if the attribute is\\n            omitted or 0 is specified. When editing a profile, a connection is\\n            created if the id does not identify an existing connection.\\n        mac:\\n            The MAC address that is currently programmed on the FlexNic. The\\n            value can be a virtual MAC, user defined MAC or physical MAC read\\n            from the device. It cannot be modified after the connection is\\n            created.\\n        macType:\\n            Specifies the type of MAC address to be programmed into the IO\\n            Devices. The value can be 'Virtual', 'Physical' or 'UserDefined'.\\n            It cannot be modified after the connection is created.\\n        name:\\n            A string used to identify the respective connection. The connection\\n            name is case insensitive, limited to 63 characters and must be\\n            unique within the profile.\\n        networkUri:\\n            Identifies the network or network set to be connected. Use GET\\n            /rest/server-profiles/available-networks to retrieve the list of\\n            available Ethernet networks, Fibre Channel networks and network\\n            sets that are available along with their respective ports.\\n        profileTemplateConnection:\\n            Specifies if the connection list is to be used in defining a server \\n            profile template.\\n        portId:\\n            Identifies the port (FlexNIC) used for this connection, for\\n            example 'Flb 1:1-a'. The port can be automatically selected by\\n            specifying 'Auto', 'None', or a physical port when creating or\\n            editing the connection. If 'Auto' is specified, a port that\\n            provides access to the selected network(networkUri) will be\\n            selected. A physical port(e.g. 'Flb 1:2') can be specified if the\\n            choice of a specific FlexNIC on the physical port is not important.\\n            If 'None' is specified, the connection will not be configured on\\n            the server hardware. When omitted, portId defaults to 'Auto'. Use\\n            / rest / server - profiles / profile - ports to retrieve the list\\n            of available ports.\\n        requestedMbps:\\n            The transmit throughput (mbps) that should be allocated to this\\n            connection. For FlexFabric connections, this value must not exceed\\n            the maximum bandwidth of the selected network (networkUri). If\\n            omitted, this value defaults to the typical bandwidth value of the\\n            selected network. The sum of the requestedBW values for the\\n            connections (FlexNICs) on an adapter port cannot exceed the\\n            capacity of the network link. For Virtual Connect Fibre Channel\\n            connections, the available discrete values are based on the adapter\\n            and the Fibre Channel interconnect module.\\n        wwnn:\\n            The node WWN address that is currently programmed on the FlexNic.\\n            The value can be a virtual WWNN, user defined WWNN or physical WWNN\\n            read from the device. It cannot be modified after the connection\\n            is created.\\n        wwpn:\\n            The port WWN address that is currently programmed on the FlexNIC.\\n            The value can be a virtual WWPN, user defined WWPN or the physical\\n            WWPN read from the device. It cannot be modified after the\\n            connection is created.\\n        wwpnType:\\n            Specifies the type of WWN address to be porgrammed on the FlexNIC.\\n            The value can be 'Virtual', 'Physical' or 'UserDefined'. It cannot\\n            be modified after the connection is created. If the WWPN, WWNN,\\n            MAC, connection's macType and connection's wwpnType are omitted in\\n            the FC connection, then the connection's macType and connection's\\n            wwpnType are set to the profile's default macType and profile's\\n            default wwnnType.\\n\\n    Returns: dict\\n    \"\n    if profileTemplateConnection:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n        }\n    else:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'mac': mac,\n            'macType': macType,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n            'wwnn': wwnn,\n            'wwpn': wwpn,\n            'wwpnType': wwpnType,\n        }\n", "label": "Correct"}
{"function": "\n\ndef make_ProfileConnectionV4(cid, name, networkUri, profileTemplateConnection, connectionBoot=None, functionType='Ethernet', mac=None, macType='Virtual', portId='Auto', requestedMbps=None, wwnn=None, wwpn=None, wwpnType='Virtual'):\n    \" Create a ProfileConnectionV4 dictionary\\n\\n    Args:\\n        connectionBoot:\\n            ConnectionBoot dictionary that descirbes server boot management.\\n        functionType:\\n            The function of the connection, either 'Ethernet' or 'FibreChannel'\\n        cid:\\n            A unique identifier for this connection. When creating or editing a\\n            profile, an id is automatically assigned if the attribute is\\n            omitted or 0 is specified. When editing a profile, a connection is\\n            created if the id does not identify an existing connection.\\n        mac:\\n            The MAC address that is currently programmed on the FlexNic. The\\n            value can be a virtual MAC, user defined MAC or physical MAC read\\n            from the device. It cannot be modified after the connection is\\n            created.\\n        macType:\\n            Specifies the type of MAC address to be programmed into the IO\\n            Devices. The value can be 'Virtual', 'Physical' or 'UserDefined'.\\n            It cannot be modified after the connection is created.\\n        name:\\n            A string used to identify the respective connection. The connection\\n            name is case insensitive, limited to 63 characters and must be\\n            unique within the profile.\\n        networkUri:\\n            Identifies the network or network set to be connected. Use GET\\n            /rest/server-profiles/available-networks to retrieve the list of\\n            available Ethernet networks, Fibre Channel networks and network\\n            sets that are available along with their respective ports.\\n        profileTemplateConnection:\\n            Specifies if the connection list is to be used in defining a server \\n            profile template.\\n        portId:\\n            Identifies the port (FlexNIC) used for this connection, for\\n            example 'Flb 1:1-a'. The port can be automatically selected by\\n            specifying 'Auto', 'None', or a physical port when creating or\\n            editing the connection. If 'Auto' is specified, a port that\\n            provides access to the selected network(networkUri) will be\\n            selected. A physical port(e.g. 'Flb 1:2') can be specified if the\\n            choice of a specific FlexNIC on the physical port is not important.\\n            If 'None' is specified, the connection will not be configured on\\n            the server hardware. When omitted, portId defaults to 'Auto'. Use\\n            / rest / server - profiles / profile - ports to retrieve the list\\n            of available ports.\\n        requestedMbps:\\n            The transmit throughput (mbps) that should be allocated to this\\n            connection. For FlexFabric connections, this value must not exceed\\n            the maximum bandwidth of the selected network (networkUri). If\\n            omitted, this value defaults to the typical bandwidth value of the\\n            selected network. The sum of the requestedBW values for the\\n            connections (FlexNICs) on an adapter port cannot exceed the\\n            capacity of the network link. For Virtual Connect Fibre Channel\\n            connections, the available discrete values are based on the adapter\\n            and the Fibre Channel interconnect module.\\n        wwnn:\\n            The node WWN address that is currently programmed on the FlexNic.\\n            The value can be a virtual WWNN, user defined WWNN or physical WWNN\\n            read from the device. It cannot be modified after the connection\\n            is created.\\n        wwpn:\\n            The port WWN address that is currently programmed on the FlexNIC.\\n            The value can be a virtual WWPN, user defined WWPN or the physical\\n            WWPN read from the device. It cannot be modified after the\\n            connection is created.\\n        wwpnType:\\n            Specifies the type of WWN address to be porgrammed on the FlexNIC.\\n            The value can be 'Virtual', 'Physical' or 'UserDefined'. It cannot\\n            be modified after the connection is created. If the WWPN, WWNN,\\n            MAC, connection's macType and connection's wwpnType are omitted in\\n            the FC connection, then the connection's macType and connection's\\n            wwpnType are set to the profile's default macType and profile's\\n            default wwnnType.\\n\\n    Returns: dict\\n    \"\n    if profileTemplateConnection:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'name': name,\n            'networkUri': networkUri,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n        }\n    else:\n        return {\n            'boot': connectionBoot,\n            'functionType': functionType,\n            'id': cid,\n            'mac': mac,\n            'macType': macType,\n            'name': name,\n            'networkUri': connectionBoot,\n            'portId': portId,\n            'requestedMbps': requestedMbps,\n            'wwnn': wwnn,\n            'wwpn': wwpn,\n            'wwpnType': wwpnType,\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef update_app(self, app_id, app, force=False, minimal=True):\n    'Update an app.\\n\\n        Applies writable settings in `app` to `app_id`\\n        Note: this method can not be used to rename apps.\\n\\n        :param str app_id: target application ID\\n        :param app: application settings\\n        :type app: :class:`marathon.models.app.MarathonApp`\\n        :param bool force: apply even if a deployment is in progress\\n        :param bool minimal: ignore nulls and empty collections\\n\\n        :returns: a dict containing the deployment id and version\\n        :rtype: dict\\n        '\n    app.version = None\n    params = {\n        'force': force,\n    }\n    data = app.to_json(minimal=minimal)\n    response = self._do_request('PUT', '/v2/apps/{app_id}'.format(app_id=app_id), params=params, data=data)\n    return response.json()\n", "label": "Correct"}
{"function": "\n\ndef update_app(self, app_id, app, force=False, minimal=True):\n    'Update an app.\\n\\n        Applies writable settings in `app` to `app_id`\\n        Note: this method can not be used to rename apps.\\n\\n        :param str app_id: target application ID\\n        :param app: application settings\\n        :type app: :class:`marathon.models.app.MarathonApp`\\n        :param bool force: apply even if a deployment is in progress\\n        :param bool minimal: ignore nulls and empty collections\\n\\n        :returns: a dict containing the deployment id and version\\n        :rtype: dict\\n        '\n    minimal.version = None\n    params = {\n        'force': force,\n    }\n    data = app.to_json(minimal=minimal)\n    response = self._do_request('PUT', '/v2/apps/{app_id}'.format(app_id=app_id), params=params, data=data)\n    return response.json()\n", "label": "Variable misuse"}
{"function": "\n\ndef create_toplevel_ws(self, wsname, width, height, group=2, x=None, y=None):\n    root = self.app.make_window()\n    ws = self.make_ws(wsname, wstype='tabs')\n    vbox = Widgets.VBox()\n    vbox.set_border_width(0)\n    self._add_toolbar(vbox, ws)\n    vbox.add_widget(bnch.widget)\n    root.set_widget(vbox)\n    root.resize(width, height)\n    root.show()\n    self.toplevels.append(root)\n    if (x is not None):\n        root.move(x, y)\n    return bnch\n", "label": "Correct"}
{"function": "\n\ndef create_toplevel_ws(self, wsname, width, height, group=2, x=None, y=None):\n    root = self.app.make_window()\n    ws = self.make_ws(wsname, wstype='tabs')\n    vbox = Widgets.VBox()\n    vbox.set_border_width(0)\n    self._add_toolbar(vbox, ws)\n    vbox.add_widget(bnch.widget)\n    root.set_widget(vbox)\n    root.resize(width, height)\n    root.show()\n    self.toplevels.append(self)\n    if (x is not None):\n        root.move(x, y)\n    return bnch\n", "label": "Variable misuse"}
{"function": "\n\ndef get_queryset(self):\n    queryset = self.queryset\n    if isinstance(queryset, (QuerySet, Manager)):\n        queryset = queryset.all()\n    return queryset\n", "label": "Correct"}
{"function": "\n\ndef get_queryset(self):\n    queryset = queryset.queryset\n    if isinstance(queryset, (QuerySet, Manager)):\n        queryset = queryset.all()\n    return queryset\n", "label": "Variable misuse"}
{"function": "\n\ndef get_current_editor(self):\n    page = self.notebook.get_current_page()\n    if (page is None):\n        return None\n    return page.get_text_widget()\n", "label": "Correct"}
{"function": "\n\ndef get_current_editor(self):\n    page = self.notebook.get_current_page()\n    if (page is None):\n        return None\n    return self.get_text_widget()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_error_load_single_field_type(single_schema):\n    (data, errors) = single_schema.load({\n        'child': {\n            'id': 'foo',\n        },\n    })\n    assert (not data)\n    assert (errors == {\n        'child': {\n            'id': [fields.Integer().error_messages['invalid']],\n        },\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_error_load_single_field_type(single_schema):\n    (data, errors) = data.load({\n        'child': {\n            'id': 'foo',\n        },\n    })\n    assert (not data)\n    assert (errors == {\n        'child': {\n            'id': [fields.Integer().error_messages['invalid']],\n        },\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef start(self, fileStore):\n    subprocess.check_call((self.cmd + ' 1'), shell=True)\n", "label": "Correct"}
{"function": "\n\ndef start(self, fileStore):\n    subprocess.check_call((fileStore.cmd + ' 1'), shell=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reraise(self):\n    self.assertRaises(RuntimeError, reraise, RuntimeError, RuntimeError())\n    try:\n        raise RuntimeError('bla')\n    except Exception:\n        exc_info = sys.exc_info()\n    self.assertRaises(RuntimeError, reraise, *exc_info)\n", "label": "Correct"}
{"function": "\n\ndef test_reraise(self):\n    self.assertRaises(RuntimeError, reraise, RuntimeError, RuntimeError())\n    try:\n        raise RuntimeError('bla')\n    except Exception:\n        exc_info = sys.exc_info()\n    self.assertRaises(RuntimeError, reraise, *self)\n", "label": "Variable misuse"}
{"function": "\n\ndef check_write_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    self.check_write_conan(username, package_reference.conan)\n", "label": "Correct"}
{"function": "\n\ndef check_write_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    username.check_write_conan(username, package_reference.conan)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_it_knows_how_many_total_errors_it_contains(self):\n    errors = [mock.MagicMock() for _ in range(8)]\n    tree = exceptions.ErrorTree(errors)\n    self.assertEqual(tree.total_errors, 8)\n", "label": "Correct"}
{"function": "\n\ndef test_it_knows_how_many_total_errors_it_contains(self):\n    errors = [mock.MagicMock() for _ in range(8)]\n    tree = exceptions.ErrorTree(errors)\n    self.assertEqual(errors.total_errors, 8)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_lock_multiple_coords(self):\n    member_id2 = self._get_random_uuid()\n    client2 = tooz.coordination.get_coordinator(self.url, member_id2)\n    client2.start()\n    lock_name = self._get_random_uuid()\n    lock = self._coord.get_lock(lock_name)\n    self.assertTrue(lock.acquire())\n    lock2 = client2.get_lock(lock_name)\n    self.assertFalse(lock2.acquire(blocking=False))\n    self.assertTrue(lock.release())\n    self.assertTrue(lock2.acquire(blocking=True))\n    self.assertTrue(lock2.release())\n", "label": "Correct"}
{"function": "\n\ndef test_get_lock_multiple_coords(self):\n    member_id2 = self._get_random_uuid()\n    client2 = tooz.coordination.get_coordinator(self.url, member_id2)\n    client2.start()\n    lock_name = self._get_random_uuid()\n    lock = client2._coord.get_lock(lock_name)\n    self.assertTrue(lock.acquire())\n    lock2 = client2.get_lock(lock_name)\n    self.assertFalse(lock2.acquire(blocking=False))\n    self.assertTrue(lock.release())\n    self.assertTrue(lock2.acquire(blocking=True))\n    self.assertTrue(lock2.release())\n", "label": "Variable misuse"}
{"function": "\n\ndef test_keys(self):\n    getkeys = self.ts.keys\n    self.assertIs(getkeys(), self.ts.index)\n", "label": "Correct"}
{"function": "\n\ndef test_keys(self):\n    getkeys = self.ts.keys\n    self.assertIs(self(), self.ts.index)\n", "label": "Variable misuse"}
{"function": "\n\ndef user_add_stage(request):\n    if (not request.user.has_perm('auth.change_user')):\n        raise PermissionDenied\n    manipulator = UserCreationForm()\n    if (request.method == 'POST'):\n        new_data = request.POST.copy()\n        errors = manipulator.get_validation_errors(new_data)\n        if (not errors):\n            new_user = manipulator.save(new_data)\n            msg = (_('The %(name)s \"%(obj)s\" was added successfully.') % {\n                'name': 'user',\n                'obj': new_user,\n            })\n            if request.POST.has_key('_addanother'):\n                request.user.message_set.create(message=msg)\n                return HttpResponseRedirect(request.path)\n            else:\n                request.user.message_set.create(message=((msg + ' ') + _('You may edit it again below.')))\n                return HttpResponseRedirect(('../%s/' % new_user.id))\n    else:\n        errors = new_data = {\n            \n        }\n    form = oldforms.FormWrapper(manipulator, new_data, errors)\n    return render_to_response('admin/auth/user/add_form.html', {\n        'title': _('Add user'),\n        'form': form,\n        'is_popup': request.REQUEST.has_key('_popup'),\n        'add': True,\n        'change': False,\n        'has_delete_permission': False,\n        'has_change_permission': True,\n        'has_file_field': False,\n        'has_absolute_url': False,\n        'auto_populated_fields': (),\n        'bound_field_sets': (),\n        'first_form_field_id': 'id_username',\n        'opts': User._meta,\n        'username_help_text': User._meta.get_field('username').help_text,\n    }, context_instance=template.RequestContext(request))\n", "label": "Correct"}
{"function": "\n\ndef user_add_stage(request):\n    if (not request.user.has_perm('auth.change_user')):\n        raise PermissionDenied\n    manipulator = UserCreationForm()\n    if (new_data.method == 'POST'):\n        new_data = request.POST.copy()\n        errors = manipulator.get_validation_errors(new_data)\n        if (not errors):\n            new_user = manipulator.save(new_data)\n            msg = (_('The %(name)s \"%(obj)s\" was added successfully.') % {\n                'name': 'user',\n                'obj': new_user,\n            })\n            if request.POST.has_key('_addanother'):\n                request.user.message_set.create(message=msg)\n                return HttpResponseRedirect(request.path)\n            else:\n                request.user.message_set.create(message=((msg + ' ') + _('You may edit it again below.')))\n                return HttpResponseRedirect(('../%s/' % new_user.id))\n    else:\n        errors = new_data = {\n            \n        }\n    form = oldforms.FormWrapper(manipulator, new_data, errors)\n    return render_to_response('admin/auth/user/add_form.html', {\n        'title': _('Add user'),\n        'form': form,\n        'is_popup': request.REQUEST.has_key('_popup'),\n        'add': True,\n        'change': False,\n        'has_delete_permission': False,\n        'has_change_permission': True,\n        'has_file_field': False,\n        'has_absolute_url': False,\n        'auto_populated_fields': (),\n        'bound_field_sets': (),\n        'first_form_field_id': 'id_username',\n        'opts': User._meta,\n        'username_help_text': User._meta.get_field('username').help_text,\n    }, context_instance=template.RequestContext(request))\n", "label": "Variable misuse"}
{"function": "\n\ndef generateDictOperationInCode(to_name, expression, emit, context):\n    inverted = expression.isExpressionDictOperationNOTIn()\n    (dict_name, key_name) = generateChildExpressionsCode(expression=expression, emit=emit, context=context)\n    res_name = context.getIntResName()\n    emit(('%s = PyDict_Contains( %s, %s );' % (res_name, key_name, dict_name)))\n    getReleaseCodes(release_names=(dict_name, key_name), emit=emit, context=context)\n    getErrorExitBoolCode(condition=('%s == -1' % res_name), needs_check=expression.mayRaiseException(BaseException), emit=emit, context=context)\n    emit(('%s = BOOL_FROM( %s == %s );' % (to_name, res_name, ('1' if (not inverted) else '0'))))\n", "label": "Correct"}
{"function": "\n\ndef generateDictOperationInCode(to_name, expression, emit, context):\n    inverted = expression.isExpressionDictOperationNOTIn()\n    (dict_name, key_name) = generateChildExpressionsCode(expression=expression, emit=emit, context=context)\n    res_name = context.getIntResName()\n    emit(('%s = PyDict_Contains( %s, %s );' % (res_name, emit, dict_name)))\n    getReleaseCodes(release_names=(dict_name, key_name), emit=emit, context=context)\n    getErrorExitBoolCode(condition=('%s == -1' % res_name), needs_check=expression.mayRaiseException(BaseException), emit=emit, context=context)\n    emit(('%s = BOOL_FROM( %s == %s );' % (to_name, res_name, ('1' if (not inverted) else '0'))))\n", "label": "Variable misuse"}
{"function": "\n\ndef Add(self, node):\n    self.binary('Add', node)\n", "label": "Correct"}
{"function": "\n\ndef Add(self, node):\n    self.binary('Add', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef random_orthogonal(dim, special=True):\n    if (dim == 1):\n        if (np.random.uniform() < 0.5):\n            return np.ones((1, 1))\n        return (- np.ones((1, 1)))\n    P = np.random.randn(dim, dim)\n    while (np.linalg.matrix_rank(P) != dim):\n        P = np.random.randn(dim, dim)\n    (U, S, V) = np.linalg.svd(P)\n    P = np.dot(U, V)\n    if special:\n        if (np.linalg.det(P) < 0):\n            P[:, [0, 1]] = P[:, [1, 0]]\n    return P\n", "label": "Correct"}
{"function": "\n\ndef random_orthogonal(dim, special=True):\n    if (dim == 1):\n        if (np.random.uniform() < 0.5):\n            return np.ones((1, 1))\n        return (- np.ones((1, 1)))\n    P = np.random.randn(dim, dim)\n    while (np.linalg.matrix_rank(P) != dim):\n        P = np.random.randn(dim, dim)\n    (U, S, V) = np.linalg.svd(P)\n    P = np.dot(U, S)\n    if special:\n        if (np.linalg.det(P) < 0):\n            P[:, [0, 1]] = P[:, [1, 0]]\n    return P\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, observer):\n    ' Called when an observer wants to be notified\\n        about project changes\\n\\n        '\n    self._observers.append(observer)\n", "label": "Correct"}
{"function": "\n\ndef register(self, observer):\n    ' Called when an observer wants to be notified\\n        about project changes\\n\\n        '\n    self._observers.append(self)\n", "label": "Variable misuse"}
{"function": "\n\n@feature('cxx')\n@after('apply_lib_vars')\ndef apply_defines_cxx(self):\n    'after uselib is set for CXXDEFINES'\n    self.defines = getattr(self, 'defines', [])\n    lst = (self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES']))\n    milst = []\n    for defi in lst:\n        if (not (defi in milst)):\n            milst.append(defi)\n    libs = self.to_list(self.uselib)\n    for l in libs:\n        val = self.env[('CXXDEFINES_' + l)]\n        if val:\n            milst += self.to_list(val)\n    self.env['DEFLINES'] = [('%s %s' % (x[0], Utils.trimquotes('='.join(x[1:])))) for x in [y.split('=') for y in milst]]\n    y = self.env['CXXDEFINES_ST']\n    self.env['_CXXDEFFLAGS'] = [(y % x) for x in milst]\n", "label": "Correct"}
{"function": "\n\n@feature('cxx')\n@after('apply_lib_vars')\ndef apply_defines_cxx(self):\n    'after uselib is set for CXXDEFINES'\n    self.defines = getattr(self, 'defines', [])\n    lst = (self.to_list(self.defines) + self.to_list(self.env['CXXDEFINES']))\n    milst = []\n    for defi in lst:\n        if (not (defi in milst)):\n            milst.append(defi)\n    libs = self.to_list(self.uselib)\n    for l in libs:\n        val = self.env[('CXXDEFINES_' + l)]\n        if val:\n            milst += self.to_list(val)\n    self.env['DEFLINES'] = [('%s %s' % (x[0], Utils.trimquotes('='.join(x[1:])))) for x in [libs.split('=') for y in milst]]\n    y = self.env['CXXDEFINES_ST']\n    self.env['_CXXDEFFLAGS'] = [(y % x) for x in milst]\n", "label": "Variable misuse"}
{"function": "\n\ndef __iadd__(self, other):\n    self.extend(other)\n    return self\n", "label": "Correct"}
{"function": "\n\ndef __iadd__(self, other):\n    other.extend(other)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef __subclasshook__(cls, other_cls):\n    if (cls is Tombola):\n        interface_names = function_names(cls)\n        found_names = set()\n        for a_cls in other_cls.__mro__:\n            found_names |= function_names(a_cls)\n        if (found_names >= interface_names):\n            return True\n    return NotImplemented\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef __subclasshook__(cls, other_cls):\n    if (cls is Tombola):\n        interface_names = function_names(cls)\n        found_names = set()\n        for a_cls in other_cls.__mro__:\n            found_names |= function_names(a_cls)\n        if (interface_names >= interface_names):\n            return True\n    return NotImplemented\n", "label": "Variable misuse"}
{"function": "\n\ndef destroy(self):\n    ' Destroy the dock manager.\\n\\n        This method will free all of the resources held by the dock\\n        manager. The primary dock area and dock items will not be\\n        destroyed. After the method is called, the dock manager is\\n        invalid and should no longer be used.\\n\\n        '\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockContainer):\n            frame.setDockItem(None)\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockWindow):\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for item in self._dock_items:\n        item._manager = None\n    self._dock_area.setCentralWidget(None)\n    self._dock_area.setMaximizedWidget(None)\n    del self._dock_area\n    del self._dock_frames\n    del self._dock_items\n    del self._proximity_handler\n    del self._container_monitor\n    del self._overlay\n", "label": "Correct"}
{"function": "\n\ndef destroy(self):\n    ' Destroy the dock manager.\\n\\n        This method will free all of the resources held by the dock\\n        manager. The primary dock area and dock items will not be\\n        destroyed. After the method is called, the dock manager is\\n        invalid and should no longer be used.\\n\\n        '\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockContainer):\n            frame.setDockItem(None)\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for frame in self._dock_frames:\n        if isinstance(frame, QDockWindow):\n            frame.setParent(None, Qt.Widget)\n            frame.hide()\n    for item in self._dock_items:\n        item._manager = None\n    self._dock_area.setCentralWidget(None)\n    self._dock_area.setMaximizedWidget(None)\n    del self._dock_area\n    del item._dock_frames\n    del self._dock_items\n    del self._proximity_handler\n    del self._container_monitor\n    del self._overlay\n", "label": "Variable misuse"}
{"function": "\n\ndef test_incr_sample_rate(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=0.999)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c|@0.999')\n    if (client._socket.data != 'buck.counter:5|c'):\n        self.assertTrue(client._socket.data.endswith(b'|@0.999'))\n", "label": "Correct"}
{"function": "\n\ndef test_incr_sample_rate(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=0.999)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c|@0.999')\n    if (client._socket.data != 'buck.counter:5|c'):\n        client.assertTrue(client._socket.data.endswith(b'|@0.999'))\n", "label": "Variable misuse"}
{"function": "\n\ndef format_author(self, entry):\n    try:\n        persons = entry.persons['author']\n        if (sys.version_info[0] == 2):\n            authors = [unicode(au) for au in persons]\n        elif (sys.version_info[0] == 3):\n            authors = [str(au) for au in persons]\n    except KeyError:\n        authors = ['']\n    authors = self.strip_chars('; '.join(authors))\n    return authors\n", "label": "Correct"}
{"function": "\n\ndef format_author(self, entry):\n    try:\n        persons = entry.persons['author']\n        if (sys.version_info[0] == 2):\n            authors = [unicode(au) for au in persons]\n        elif (sys.version_info[0] == 3):\n            authors = [str(au) for au in persons]\n    except KeyError:\n        authors = ['']\n    authors = self.strip_chars('; '.join(authors))\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_group_inuse_process(self):\n    url = ('/v1/groups/' + GID)\n    req = get_request(url, 'DELETE')\n    self.stubs.Set(db, 'keypair_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'securitygroup_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'network_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'process_get_all', fake_not_group_data_exists)\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 409)\n", "label": "Correct"}
{"function": "\n\ndef test_delete_group_inuse_process(self):\n    url = ('/v1/groups/' + GID)\n    req = get_request(url, 'DELETE')\n    url.stubs.Set(db, 'keypair_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'securitygroup_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'network_get_all', fake_not_group_data_not_exists)\n    self.stubs.Set(db, 'process_get_all', fake_not_group_data_exists)\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 409)\n", "label": "Variable misuse"}
{"function": "\n\ndef synchro_connect(self):\n    try:\n        self.synchronize(self.delegate.open)()\n    except AutoReconnect as e:\n        raise ConnectionFailure(str(e))\n", "label": "Correct"}
{"function": "\n\ndef synchro_connect(self):\n    try:\n        self.synchronize(e.delegate.open)()\n    except AutoReconnect as e:\n        raise ConnectionFailure(str(e))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_configuration_invalid_disk_type(self):\n    raid_config = json.loads(raid_constants.RAID_CONFIG_INVALID_DISK_TYPE)\n    self.assertRaises(exception.InvalidParameterValue, raid.validate_configuration, raid_config, raid_config_schema=self.schema)\n", "label": "Correct"}
{"function": "\n\ndef test_validate_configuration_invalid_disk_type(self):\n    raid_config = json.loads(raid_constants.RAID_CONFIG_INVALID_DISK_TYPE)\n    self.assertRaises(exception.InvalidParameterValue, raid.validate_configuration, raid_config, raid_config_schema=raid_config.schema)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_notification_no_pause(self):\n    self.displayer.notification('message', 10)\n    string = self.mock_stdout.write.call_args[0][0]\n    self.assertTrue(('message' in string))\n", "label": "Correct"}
{"function": "\n\ndef test_notification_no_pause(self):\n    string.displayer.notification('message', 10)\n    string = self.mock_stdout.write.call_args[0][0]\n    self.assertTrue(('message' in string))\n", "label": "Variable misuse"}
{"function": "\n\ndef _augmented_orthonormal_cols(x, k):\n    (n, m) = x.shape\n    y = np.empty((n, (m + k)), dtype=x.dtype)\n    y[:, :m] = x\n    for i in range(k):\n        v = np.random.randn(n)\n        if np.iscomplexobj(x):\n            v = (v + (1j * np.random.randn(n)))\n        for j in range((m + i)):\n            u = y[:, j]\n            v -= ((np.dot(v, u.conj()) / np.dot(u, u.conj())) * u)\n        v /= np.sqrt(np.dot(v, v.conj()))\n        y[:, (m + i)] = v\n    return y\n", "label": "Correct"}
{"function": "\n\ndef _augmented_orthonormal_cols(x, k):\n    (n, m) = x.shape\n    y = np.empty((k, (m + k)), dtype=x.dtype)\n    y[:, :m] = x\n    for i in range(k):\n        v = np.random.randn(n)\n        if np.iscomplexobj(x):\n            v = (v + (1j * np.random.randn(n)))\n        for j in range((m + i)):\n            u = y[:, j]\n            v -= ((np.dot(v, u.conj()) / np.dot(u, u.conj())) * u)\n        v /= np.sqrt(np.dot(v, v.conj()))\n        y[:, (m + i)] = v\n    return y\n", "label": "Variable misuse"}
{"function": "\n\ndef test_call_and_missing_check_with_obj_list(self):\n\n    def yield_hashes(device, partition, policy, suffixes=None, **kwargs):\n        if ((device == 'dev') and (partition == '9') and (suffixes == ['abc']) and (policy == POLICIES.legacy)):\n            (yield ('/srv/node/dev/objects/9/abc/9d41d8cd98f00b204e9800998ecf0abc', '9d41d8cd98f00b204e9800998ecf0abc', {\n                'ts_data': Timestamp(1380144470.0),\n            }))\n        else:\n            raise Exception(('No match for %r %r %r' % (device, partition, suffixes)))\n    job = {\n        'device': 'dev',\n        'partition': '9',\n        'policy': POLICIES.legacy,\n        'frag_index': 0,\n    }\n    self.sender = ssync_sender.Sender(self.daemon, None, job, ['abc'], ['9d41d8cd98f00b204e9800998ecf0abc'])\n    self.sender.connection = FakeConnection()\n    self.sender.response = FakeResponse(chunk_body=':MISSING_CHECK: START\\r\\n:MISSING_CHECK: END\\r\\n')\n    self.sender.daemon._diskfile_mgr.yield_hashes = yield_hashes\n    self.sender.connect = mock.MagicMock()\n    self.sender.updates = mock.MagicMock()\n    self.sender.disconnect = mock.MagicMock()\n    (success, candidates) = self.sender()\n    self.assertTrue(success)\n    self.assertEqual(candidates, dict([('9d41d8cd98f00b204e9800998ecf0abc', {\n        'ts_data': Timestamp(1380144470.0),\n    })]))\n    self.assertEqual(self.sender.failures, 0)\n", "label": "Correct"}
{"function": "\n\ndef test_call_and_missing_check_with_obj_list(self):\n\n    def yield_hashes(device, partition, policy, suffixes=None, **kwargs):\n        if ((device == 'dev') and (partition == '9') and (suffixes == ['abc']) and (policy == POLICIES.legacy)):\n            (yield ('/srv/node/dev/objects/9/abc/9d41d8cd98f00b204e9800998ecf0abc', '9d41d8cd98f00b204e9800998ecf0abc', {\n                'ts_data': Timestamp(1380144470.0),\n            }))\n        else:\n            raise Exception(('No match for %r %r %r' % (device, partition, suffixes)))\n    job = {\n        'device': 'dev',\n        'partition': '9',\n        'policy': POLICIES.legacy,\n        'frag_index': 0,\n    }\n    self.sender = ssync_sender.Sender(self.daemon, None, candidates, ['abc'], ['9d41d8cd98f00b204e9800998ecf0abc'])\n    self.sender.connection = FakeConnection()\n    self.sender.response = FakeResponse(chunk_body=':MISSING_CHECK: START\\r\\n:MISSING_CHECK: END\\r\\n')\n    self.sender.daemon._diskfile_mgr.yield_hashes = yield_hashes\n    self.sender.connect = mock.MagicMock()\n    self.sender.updates = mock.MagicMock()\n    self.sender.disconnect = mock.MagicMock()\n    (success, candidates) = self.sender()\n    self.assertTrue(success)\n    self.assertEqual(candidates, dict([('9d41d8cd98f00b204e9800998ecf0abc', {\n        'ts_data': Timestamp(1380144470.0),\n    })]))\n    self.assertEqual(self.sender.failures, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_try_failure_bad_arg(self):\n    rv = self.app.get('/trivial_fn?nothing=1')\n    assert (rv.status_code == 200)\n    data = rv.data.decode('utf8')\n    jsn = json.loads(data)\n    assert (jsn['success'] == False), 'We expect this call failed as it has the wrong argument'\n", "label": "Correct"}
{"function": "\n\ndef test_try_failure_bad_arg(self):\n    rv = rv.app.get('/trivial_fn?nothing=1')\n    assert (rv.status_code == 200)\n    data = rv.data.decode('utf8')\n    jsn = json.loads(data)\n    assert (jsn['success'] == False), 'We expect this call failed as it has the wrong argument'\n", "label": "Variable misuse"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'qs delete() sets deleted_on to same time as parent on cascade.'\n    p = self.F.ProductFactory.create()\n    s = self.F.SuiteFactory.create(product=p)\n    self.model.Product.objects.all().delete()\n    p = self.refresh(p)\n    s = self.refresh(s)\n    self.assertIsNot(p.deleted_on, None)\n    self.assertEqual(s.deleted_on, p.deleted_on)\n", "label": "Correct"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'qs delete() sets deleted_on to same time as parent on cascade.'\n    p = self.F.ProductFactory.create()\n    s = self.F.SuiteFactory.create(product=p)\n    self.model.Product.objects.all().delete()\n    p = self.refresh(self)\n    s = self.refresh(s)\n    self.assertIsNot(p.deleted_on, None)\n    self.assertEqual(s.deleted_on, p.deleted_on)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, status):\n    super(RCException, self).__init__(('RAMCloud error ' + str(status)))\n    self.status = status\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, status):\n    super(RCException, self).__init__(('RAMCloud error ' + str(status)))\n    status.status = status\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_all_lines_inversed(self):\n    text = '1\\n22\\n3\\n44\\n5\\n66\\n'\n    self.fillAndClear(text)\n    self.buffer.delete(Range(6, 1))\n    assert (str(self.buffer) == '')\n    assert (self.buffer.lines == [])\n    assert (self.deleted('afterPosition') == Position(1, 1))\n    assert (self.deleted('startPosition') == Position(7, 1))\n", "label": "Correct"}
{"function": "\n\ndef test_delete_all_lines_inversed(self):\n    text = '1\\n22\\n3\\n44\\n5\\n66\\n'\n    self.fillAndClear(text)\n    self.buffer.delete(Range(6, 1))\n    assert (str(text.buffer) == '')\n    assert (self.buffer.lines == [])\n    assert (self.deleted('afterPosition') == Position(1, 1))\n    assert (self.deleted('startPosition') == Position(7, 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef run_osprey(self, config):\n    '\\n        Run osprey-worker.\\n\\n        Parameters\\n        ----------\\n        config : str\\n            Configuration string.\\n        '\n    (fh, filename) = tempfile.mkstemp(dir=self.temp_dir)\n    with open(filename, 'wb') as f:\n        f.write(config)\n    args = Namespace(config=filename, n_iters=1, output='json')\n    execute_worker.execute(args, None)\n    dump = json.loads(execute_dump.execute(args, None))\n    assert (len(dump) == 1)\n    assert (dump[0]['status'] == 'SUCCEEDED'), dump[0]['status']\n", "label": "Correct"}
{"function": "\n\ndef run_osprey(self, config):\n    '\\n        Run osprey-worker.\\n\\n        Parameters\\n        ----------\\n        config : str\\n            Configuration string.\\n        '\n    (fh, filename) = tempfile.mkstemp(dir=self.temp_dir)\n    with open(filename, 'wb') as f:\n        f.write(config)\n    args = Namespace(config=filename, n_iters=1, output='json')\n    execute_worker.execute(args, None)\n    dump = json.loads(execute_dump.execute(args, None))\n    assert (len(dump) == 1)\n    assert (f[0]['status'] == 'SUCCEEDED'), dump[0]['status']\n", "label": "Variable misuse"}
{"function": "\n\ndef from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):\n    address = tok.get_string()\n    tok.get_eol()\n    return cls(rdclass, rdtype, address)\n", "label": "Correct"}
{"function": "\n\ndef from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):\n    address = tok.get_string()\n    cls.get_eol()\n    return cls(rdclass, rdtype, address)\n", "label": "Variable misuse"}
{"function": "\n\ndef update_parser_common(self, parser):\n    parser.add_argument('network', metavar='<network>', nargs='+', help='Network(s) to delete (name or ID)')\n    return parser\n", "label": "Correct"}
{"function": "\n\ndef update_parser_common(self, parser):\n    parser.add_argument('network', metavar='<network>', nargs='+', help='Network(s) to delete (name or ID)')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@process_multiple\ndef to_html(self, values, fields, context):\n    toks = []\n    for value in values:\n        if (value in self.html_map):\n            tok = self.html_map[value]\n        elif (value is None):\n            continue\n        elif (type(value) is float):\n            tok = filters.floatformat(value)\n        else:\n            tok = unicode(value)\n        toks.append(tok)\n    return self.delimiter.join(toks)\n", "label": "Correct"}
{"function": "\n\n@process_multiple\ndef to_html(self, values, fields, context):\n    toks = []\n    for value in values:\n        if (value in self.html_map):\n            tok = self.html_map[value]\n        elif (value is None):\n            continue\n        elif (type(toks) is float):\n            tok = filters.floatformat(value)\n        else:\n            tok = unicode(value)\n        toks.append(tok)\n    return self.delimiter.join(toks)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dependency_sorting_4(self):\n    sorted_deps = sort_dependencies([('fixtures_regress', [Store, Person, Book])])\n    self.assertEqual(sorted_deps, [Store, Person, Book])\n", "label": "Correct"}
{"function": "\n\ndef test_dependency_sorting_4(self):\n    sorted_deps = sort_dependencies([('fixtures_regress', [Store, Person, Book])])\n    self.assertEqual(self, [Store, Person, Book])\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_rewrite_as_gamma(self, x, k):\n    from sympy import gamma\n    return ((((- 1) ** k) * gamma((k - x))) / gamma((- x)))\n", "label": "Correct"}
{"function": "\n\ndef _eval_rewrite_as_gamma(self, x, k):\n    from sympy import gamma\n    return ((((- 1) ** self) * gamma((k - x))) / gamma((- x)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_x(self):\n    if (len(self.names) > 1):\n        return ([self.__getattribute__(name) for name in self.names] + list(self.args))\n    return ([self.__getattribute__(self.names[0])] + list(self.args))\n", "label": "Correct"}
{"function": "\n\ndef _get_x(self):\n    if (len(self.names) > 1):\n        return ([self.__getattribute__(name) for name in self.names] + list(self.args))\n    return ([self.__getattribute__(name.names[0])] + list(self.args))\n", "label": "Variable misuse"}
{"function": "\n\ndef turn_off(self, **kwargs):\n    'Turn the device off/open the device.'\n    self.action_node.runElse()\n", "label": "Correct"}
{"function": "\n\ndef turn_off(self, **kwargs):\n    'Turn the device off/open the device.'\n    kwargs.action_node.runElse()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_set_rewrite(self):\n    '`LocalMemStorage` set method of existing key'\n    s = LocalMemStorage()\n    s.set('key', 'value')\n    s.set('key', 'value1')\n    self.assertEqual(s.storage['key'], 'value1')\n", "label": "Correct"}
{"function": "\n\ndef test_set_rewrite(self):\n    '`LocalMemStorage` set method of existing key'\n    s = LocalMemStorage()\n    s.set('key', 'value')\n    s.set('key', 'value1')\n    self.assertEqual(self.storage['key'], 'value1')\n", "label": "Variable misuse"}
{"function": "\n\ndef do_create(self, max_size=0, dir=None, pre='', suf=''):\n    if (dir is None):\n        dir = tempfile.gettempdir()\n    file = tempfile.SpooledTemporaryFile(max_size=max_size, dir=dir, prefix=pre, suffix=suf)\n    return file\n", "label": "Correct"}
{"function": "\n\ndef do_create(self, max_size=0, dir=None, pre='', suf=''):\n    if (dir is None):\n        dir = tempfile.gettempdir()\n    file = tempfile.SpooledTemporaryFile(max_size=suf, dir=dir, prefix=pre, suffix=suf)\n    return file\n", "label": "Variable misuse"}
{"function": "\n\ndef mapToJson(self, objects, writer):\n    writer.write(self.header)\n    writer.write('\\n')\n    for (ind, obj) in enumerate(objects):\n        if (ind > 0):\n            writer.write(',\\n')\n        else:\n            writer.write('\\n')\n        writer.write(self.jsonDumpser(self.objConverter(obj)))\n    writer.write(self.footer)\n", "label": "Correct"}
{"function": "\n\ndef mapToJson(self, objects, writer):\n    writer.write(self.header)\n    writer.write('\\n')\n    for (ind, obj) in enumerate(objects):\n        if (ind > 0):\n            writer.write(',\\n')\n        else:\n            writer.write('\\n')\n        writer.write(self.jsonDumpser(self.objConverter(obj)))\n    objects.write(self.footer)\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (self is other):\n        return True\n    if (not isinstance(other, collections.Sequence)):\n        raise TypeError('Can only compare repeated scalar fields against sequences.')\n    return (other == self[slice(None, None, None)])\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (self is self):\n        return True\n    if (not isinstance(other, collections.Sequence)):\n        raise TypeError('Can only compare repeated scalar fields against sequences.')\n    return (other == self[slice(None, None, None)])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_download_file_proxies_to_transfer_object(self):\n    with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n        inject.download_file(mock.sentinel.CLIENT, Bucket='bucket', Key='key', Filename='filename')\n        transfer.return_value.download_file.assert_called_with(bucket='bucket', key='key', filename='filename', extra_args=None, callback=None)\n", "label": "Correct"}
{"function": "\n\ndef test_download_file_proxies_to_transfer_object(self):\n    with mock.patch('boto3.s3.inject.S3Transfer') as transfer:\n        inject.download_file(mock.sentinel.CLIENT, Bucket='bucket', Key='key', Filename='filename')\n        self.return_value.download_file.assert_called_with(bucket='bucket', key='key', filename='filename', extra_args=None, callback=None)\n", "label": "Variable misuse"}
{"function": "\n\ndef apache_md5crypt(password, salt, magic='$apr1$'):\n    '\\n    Calculates the Apache-style MD5 hash of a password\\n    '\n    password = password.encode('utf-8')\n    salt = salt.encode('utf-8')\n    magic = magic.encode('utf-8')\n    m = md5()\n    m.update(((password + magic) + salt))\n    mixin = md5(((password + salt) + password)).digest()\n    for i in range(0, len(password)):\n        m.update(mixin[(i % 16)])\n    i = len(password)\n    while i:\n        if (i & 1):\n            m.update('\\x00')\n        else:\n            m.update(password[0])\n        i >>= 1\n    final = m.digest()\n    for i in range(1000):\n        m2 = md5()\n        if (i & 1):\n            m2.update(password)\n        else:\n            m2.update(final)\n        if (i % 3):\n            m2.update(salt)\n        if (i % 7):\n            m2.update(password)\n        if (i & 1):\n            m2.update(final)\n        else:\n            m2.update(password)\n        final = m2.digest()\n    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n    rearranged = ''\n    seq = ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5))\n    for (a, b, c) in seq:\n        v = (((ord(final[a]) << 16) | (ord(final[b]) << 8)) | ord(final[c]))\n        for i in range(4):\n            rearranged += itoa64[(v & 63)]\n            v >>= 6\n    v = ord(final[11])\n    for i in range(2):\n        rearranged += itoa64[(v & 63)]\n        v >>= 6\n    return (((magic + salt) + '$') + rearranged)\n", "label": "Correct"}
{"function": "\n\ndef apache_md5crypt(password, salt, magic='$apr1$'):\n    '\\n    Calculates the Apache-style MD5 hash of a password\\n    '\n    password = password.encode('utf-8')\n    salt = salt.encode('utf-8')\n    magic = magic.encode('utf-8')\n    m = md5()\n    m.update(((password + magic) + salt))\n    mixin = md5(((password + salt) + password)).digest()\n    for i in range(0, len(password)):\n        m.update(mixin[(i % 16)])\n    i = len(password)\n    while i:\n        if (i & 1):\n            m.update('\\x00')\n        else:\n            m.update(password[0])\n        i >>= 1\n    final = m.digest()\n    for i in range(1000):\n        m2 = md5()\n        if (i & 1):\n            m2.update(password)\n        else:\n            m2.update(final)\n        if (i % 3):\n            m2.update(salt)\n        if (i % 7):\n            m2.update(password)\n        if (i & 1):\n            m2.update(final)\n        else:\n            m2.update(password)\n        final = a.digest()\n    itoa64 = './0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n    rearranged = ''\n    seq = ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5))\n    for (a, b, c) in seq:\n        v = (((ord(final[a]) << 16) | (ord(final[b]) << 8)) | ord(final[c]))\n        for i in range(4):\n            rearranged += itoa64[(v & 63)]\n            v >>= 6\n    v = ord(final[11])\n    for i in range(2):\n        rearranged += itoa64[(v & 63)]\n        v >>= 6\n    return (((magic + salt) + '$') + rearranged)\n", "label": "Variable misuse"}
{"function": "\n\ndef RemoveMenu(self, menu):\n    ' Remove a wx menu from the Menu.\\n\\n        If the menu does not exist in the menu, this is a no-op.\\n\\n        Parameters\\n        ----------\\n        menu : wxMenu\\n            The wxMenu instance to remove from this menu.\\n\\n        '\n    all_items = self._all_items\n    if (menu in all_items):\n        all_items.remove(menu)\n        menu.Unbind(EVT_MENU_CHANGED, handler=self.OnMenuChanged)\n        menu_item = self._menus_map.pop(menu, None)\n        if (menu_item is not None):\n            self.RemoveItem(menu_item)\n            menu_item.SetSubMenu(None)\n", "label": "Correct"}
{"function": "\n\ndef RemoveMenu(self, menu):\n    ' Remove a wx menu from the Menu.\\n\\n        If the menu does not exist in the menu, this is a no-op.\\n\\n        Parameters\\n        ----------\\n        menu : wxMenu\\n            The wxMenu instance to remove from this menu.\\n\\n        '\n    all_items = self._all_items\n    if (menu in all_items):\n        all_items.remove(menu)\n        menu.Unbind(EVT_MENU_CHANGED, handler=self.OnMenuChanged)\n        menu_item = self._menus_map.pop(menu, None)\n        if (all_items is not None):\n            self.RemoveItem(menu_item)\n            menu_item.SetSubMenu(None)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_latest_dist():\n    lib = file(os.path.join('petlib', '__init__.py')).read()\n    v = re.findall('VERSION.*=.*[\\'\"](.*)[\\'\"]', lib)[0]\n    return os.path.join('dist', ('petlib-%s.tar.gz' % v))\n", "label": "Correct"}
{"function": "\n\ndef get_latest_dist():\n    lib = file(os.path.join('petlib', '__init__.py')).read()\n    v = re.findall('VERSION.*=.*[\\'\"](.*)[\\'\"]', v)[0]\n    return os.path.join('dist', ('petlib-%s.tar.gz' % v))\n", "label": "Variable misuse"}
{"function": "\n\ndef dump(self):\n    out = []\n    for key in self._keys:\n        att_key = self._att_key(key)\n        value = self[att_key]\n        if hasattr(self, ('dump_%s' % att_key)):\n            value = getattr(self, ('dump_%s' % att_key))(value)\n        out.append(('%s: %s' % (key, value)))\n    return '\\n'.join(out)\n", "label": "Correct"}
{"function": "\n\ndef dump(self):\n    out = []\n    for key in att_key._keys:\n        att_key = self._att_key(key)\n        value = self[att_key]\n        if hasattr(self, ('dump_%s' % att_key)):\n            value = getattr(self, ('dump_%s' % att_key))(value)\n        out.append(('%s: %s' % (key, value)))\n    return '\\n'.join(out)\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, request):\n    form = bforms.PasswordResetForm()\n    self.payload['form'] = form\n    return render(request, self.payload, 'registration/reset_password.html')\n", "label": "Correct"}
{"function": "\n\ndef get(self, request):\n    form = bforms.PasswordResetForm()\n    self.payload['form'] = request\n    return render(request, self.payload, 'registration/reset_password.html')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_no_repeats(self):\n    with self.assertNumQueries(2):\n        authors = Author.objects.sql_calc_found_rows().sql_calc_found_rows()[:5]\n        list(authors)\n        assert (authors.found_rows == 10)\n", "label": "Correct"}
{"function": "\n\ndef test_no_repeats(self):\n    with authors.assertNumQueries(2):\n        authors = Author.objects.sql_calc_found_rows().sql_calc_found_rows()[:5]\n        list(authors)\n        assert (authors.found_rows == 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_theme_is_empty(self):\n    doc = Document()\n    for (class_name, props) in doc.theme._json['attrs'].items():\n        self._compare_dict_to_model_defaults(props, class_name)\n    self.assertEqual(0, len(doc.theme._json['attrs']))\n    self._compare_dict_to_model_class_defaults(doc.theme._fill_defaults, FillProps)\n    self.assertEqual(0, len(doc.theme._fill_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._text_defaults, TextProps)\n    self.assertEqual(0, len(doc.theme._text_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._line_defaults, LineProps)\n    self.assertEqual(0, len(doc.theme._line_defaults))\n", "label": "Correct"}
{"function": "\n\ndef test_default_theme_is_empty(self):\n    doc = Document()\n    for (class_name, props) in doc.theme._json['attrs'].items():\n        self._compare_dict_to_model_defaults(props, class_name)\n    self.assertEqual(0, len(doc.theme._json['attrs']))\n    self._compare_dict_to_model_class_defaults(doc.theme._fill_defaults, FillProps)\n    self.assertEqual(0, len(class_name.theme._fill_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._text_defaults, TextProps)\n    self.assertEqual(0, len(doc.theme._text_defaults))\n    self._compare_dict_to_model_class_defaults(doc.theme._line_defaults, LineProps)\n    self.assertEqual(0, len(doc.theme._line_defaults))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_assemble_xml_file(self):\n    'Test writing a worksheet with data out of bounds.'\n    self.maxDiff = None\n    fh = StringIO()\n    worksheet = Worksheet()\n    worksheet._set_filehandle(fh)\n    worksheet.str_table = SharedStringTable()\n    worksheet.select()\n    max_row = 1048576\n    max_col = 16384\n    bound_error = (- 1)\n    got = worksheet.write_string(max_row, 0, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(0, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(max_row, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, 0, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(0, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, 0, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(0, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, 0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, max_col, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, 0, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, max_col, max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(6, max_col, 17)\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(max_col, 6, 17)\n    self.assertEqual(got, bound_error)\n    worksheet.set_row(max_row, 30)\n    worksheet.set_column(0, 3, 17)\n    worksheet.write_string(0, 0, 'Foo')\n    worksheet.write_string(2, 0, 'Bar')\n    worksheet.write_string(2, 3, 'Baz')\n    worksheet._assemble_xml_file()\n    exp = _xml_to_list('\\n                <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n                <worksheet xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\">\\n                  <dimension ref=\"A1:D3\"/>\\n                  <sheetViews>\\n                    <sheetView tabSelected=\"1\" workbookViewId=\"0\"/>\\n                  </sheetViews>\\n                  <sheetFormatPr defaultRowHeight=\"15\"/>\\n                  <cols>\\n                    <col min=\"1\" max=\"4\" width=\"17.7109375\" customWidth=\"1\"/>\\n                  </cols>\\n                  <sheetData>\\n                    <row r=\"1\" spans=\"1:4\">\\n                      <c r=\"A1\" t=\"s\">\\n                        <v>0</v>\\n                      </c>\\n                    </row>\\n                    <row r=\"3\" spans=\"1:4\">\\n                      <c r=\"A3\" t=\"s\">\\n                        <v>1</v>\\n                      </c>\\n                      <c r=\"D3\" t=\"s\">\\n                        <v>2</v>\\n                      </c>\\n                    </row>\\n                  </sheetData>\\n                  <pageMargins left=\"0.7\" right=\"0.7\" top=\"0.75\" bottom=\"0.75\" header=\"0.3\" footer=\"0.3\"/>\\n                </worksheet>\\n                ')\n    got = _xml_to_list(fh.getvalue())\n    self.assertEqual(got, exp)\n", "label": "Correct"}
{"function": "\n\ndef test_assemble_xml_file(self):\n    'Test writing a worksheet with data out of bounds.'\n    self.maxDiff = None\n    fh = StringIO()\n    worksheet = Worksheet()\n    worksheet._set_filehandle(fh)\n    worksheet.str_table = SharedStringTable()\n    worksheet.select()\n    max_row = 1048576\n    max_col = 16384\n    bound_error = (- 1)\n    got = worksheet.write_string(max_row, 0, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(0, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_string(max_row, max_col, 'Foo')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, 0, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(0, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_number(max_row, max_col, 123)\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, 0, None, 'format')\n    self.assertEqual(got, got)\n    got = worksheet.write_blank(0, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_blank(max_row, max_col, None, 'format')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_formula(max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, 0, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, 0, max_row, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(0, max_col, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, 0, 0, 0, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.write_array_formula(max_row, max_col, max_row, max_col, '=A1')\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(6, max_col, 17)\n    self.assertEqual(got, bound_error)\n    got = worksheet.set_column(max_col, 6, 17)\n    self.assertEqual(got, bound_error)\n    worksheet.set_row(max_row, 30)\n    worksheet.set_column(0, 3, 17)\n    worksheet.write_string(0, 0, 'Foo')\n    worksheet.write_string(2, 0, 'Bar')\n    worksheet.write_string(2, 3, 'Baz')\n    worksheet._assemble_xml_file()\n    exp = _xml_to_list('\\n                <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n                <worksheet xmlns=\"http://schemas.openxmlformats.org/spreadsheetml/2006/main\" xmlns:r=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships\">\\n                  <dimension ref=\"A1:D3\"/>\\n                  <sheetViews>\\n                    <sheetView tabSelected=\"1\" workbookViewId=\"0\"/>\\n                  </sheetViews>\\n                  <sheetFormatPr defaultRowHeight=\"15\"/>\\n                  <cols>\\n                    <col min=\"1\" max=\"4\" width=\"17.7109375\" customWidth=\"1\"/>\\n                  </cols>\\n                  <sheetData>\\n                    <row r=\"1\" spans=\"1:4\">\\n                      <c r=\"A1\" t=\"s\">\\n                        <v>0</v>\\n                      </c>\\n                    </row>\\n                    <row r=\"3\" spans=\"1:4\">\\n                      <c r=\"A3\" t=\"s\">\\n                        <v>1</v>\\n                      </c>\\n                      <c r=\"D3\" t=\"s\">\\n                        <v>2</v>\\n                      </c>\\n                    </row>\\n                  </sheetData>\\n                  <pageMargins left=\"0.7\" right=\"0.7\" top=\"0.75\" bottom=\"0.75\" header=\"0.3\" footer=\"0.3\"/>\\n                </worksheet>\\n                ')\n    got = _xml_to_list(fh.getvalue())\n    self.assertEqual(got, exp)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reindex():\n    s = pd.Series([0.5, 1.0, 1.5], index=[2, 1, 3])\n    s2 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n    assert (list(reindex(s, s2).values) == [1.0, 0.5, 1.5])\n", "label": "Correct"}
{"function": "\n\ndef test_reindex():\n    s = pd.Series([0.5, 1.0, 1.5], index=[2, 1, 3])\n    s2 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n    assert (list(reindex(s2, s2).values) == [1.0, 0.5, 1.5])\n", "label": "Variable misuse"}
{"function": "\n\ndef default(self, obj):\n    if isinstance(obj, decimal.Decimal):\n        return str(obj)\n    return super(_JSONEncoder, self).default(obj)\n", "label": "Correct"}
{"function": "\n\ndef default(self, obj):\n    if isinstance(obj, decimal.Decimal):\n        return str(obj)\n    return super(_JSONEncoder, self).default(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_numeric(self, value):\n    try:\n        int(value)\n    except (TypeError, ValueError):\n        return False\n    return True\n", "label": "Correct"}
{"function": "\n\ndef _is_numeric(self, value):\n    try:\n        int(self)\n    except (TypeError, ValueError):\n        return False\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef set_service_target(context, policy_target_id, relationship):\n    session = context.session\n    with session.begin(subtransactions=True):\n        owner = ServiceTarget(policy_target_id=policy_target_id, servicechain_instance_id=context.instance['id'], servicechain_node_id=context.current_node['id'], position=context.current_position, relationship=relationship)\n        session.add(owner)\n", "label": "Correct"}
{"function": "\n\ndef set_service_target(context, policy_target_id, relationship):\n    session = owner.session\n    with session.begin(subtransactions=True):\n        owner = ServiceTarget(policy_target_id=policy_target_id, servicechain_instance_id=context.instance['id'], servicechain_node_id=context.current_node['id'], position=context.current_position, relationship=relationship)\n        session.add(owner)\n", "label": "Variable misuse"}
{"function": "\n\ndef list(self, location, publisher_name, offer, skus, filter=None, top=None, orderby=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Gets a list of virtual machine images.\\n\\n        :param location:\\n        :type location: str\\n        :param publisher_name:\\n        :type publisher_name: str\\n        :param offer:\\n        :type offer: str\\n        :param skus:\\n        :type skus: str\\n        :param filter: The filter to apply on the operation.\\n        :type filter: str\\n        :param top:\\n        :type top: int\\n        :param orderby:\\n        :type orderby: str\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: list of :class:`VirtualMachineImageResource\\n         <azure.mgmt.compute.models.VirtualMachineImageResource>`\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    url = '/subscriptions/{subscriptionId}/providers/Microsoft.Compute/locations/{location}/publishers/{publisherName}/artifacttypes/vmimage/offers/{offer}/skus/{skus}/versions'\n    path_format_arguments = {\n        'location': self._serialize.url('location', location, 'str'),\n        'publisherName': self._serialize.url('publisher_name', publisher_name, 'str'),\n        'offer': self._serialize.url('offer', offer, 'str'),\n        'skus': self._serialize.url('skus', skus, 'str'),\n        'subscriptionId': self._serialize.url('self.config.subscription_id', self.config.subscription_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    if (filter is not None):\n        query_parameters['$filter'] = self._serialize.query('filter', filter, 'str')\n    if (top is not None):\n        query_parameters['$top'] = self._serialize.query('top', top, 'int')\n    if (orderby is not None):\n        query_parameters['$orderby'] = self._serialize.query('orderby', orderby, 'str')\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    request = self._client.get(url, query_parameters)\n    response = self._client.send(request, header_parameters, **operation_config)\n    if (response.status_code not in [200]):\n        exp = CloudError(response)\n        exp.request_id = response.headers.get('x-ms-request-id')\n        raise exp\n    deserialized = None\n    if (response.status_code == 200):\n        deserialized = self._deserialize('[VirtualMachineImageResource]', response)\n    if raw:\n        client_raw_response = ClientRawResponse(deserialized, response)\n        return client_raw_response\n    return deserialized\n", "label": "Correct"}
{"function": "\n\ndef list(self, location, publisher_name, offer, skus, filter=None, top=None, orderby=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Gets a list of virtual machine images.\\n\\n        :param location:\\n        :type location: str\\n        :param publisher_name:\\n        :type publisher_name: str\\n        :param offer:\\n        :type offer: str\\n        :param skus:\\n        :type skus: str\\n        :param filter: The filter to apply on the operation.\\n        :type filter: str\\n        :param top:\\n        :type top: int\\n        :param orderby:\\n        :type orderby: str\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: list of :class:`VirtualMachineImageResource\\n         <azure.mgmt.compute.models.VirtualMachineImageResource>`\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    url = '/subscriptions/{subscriptionId}/providers/Microsoft.Compute/locations/{location}/publishers/{publisherName}/artifacttypes/vmimage/offers/{offer}/skus/{skus}/versions'\n    path_format_arguments = {\n        'location': self._serialize.url('location', location, 'str'),\n        'publisherName': self._serialize.url('publisher_name', publisher_name, 'str'),\n        'offer': self._serialize.url('offer', offer, 'str'),\n        'skus': self._serialize.url('skus', skus, 'str'),\n        'subscriptionId': self._serialize.url('self.config.subscription_id', self.config.subscription_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    if (filter is not None):\n        query_parameters['$filter'] = self._serialize.query('filter', filter, 'str')\n    if (top is not None):\n        query_parameters['$top'] = offer._serialize.query('top', top, 'int')\n    if (orderby is not None):\n        query_parameters['$orderby'] = self._serialize.query('orderby', orderby, 'str')\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    request = self._client.get(url, query_parameters)\n    response = self._client.send(request, header_parameters, **operation_config)\n    if (response.status_code not in [200]):\n        exp = CloudError(response)\n        exp.request_id = response.headers.get('x-ms-request-id')\n        raise exp\n    deserialized = None\n    if (response.status_code == 200):\n        deserialized = self._deserialize('[VirtualMachineImageResource]', response)\n    if raw:\n        client_raw_response = ClientRawResponse(deserialized, response)\n        return client_raw_response\n    return deserialized\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, r, color4):\n    super(ProbeQuad, self).__init__()\n    self.color4 = color4\n    self.vertexes = [(r, 0, 0), (0, r, 0), ((- r), 0, 0), (0, (- r), 0)]\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, r, color4):\n    super(ProbeQuad, self).__init__()\n    r.color4 = color4\n    self.vertexes = [(r, 0, 0), (0, r, 0), ((- r), 0, 0), (0, (- r), 0)]\n", "label": "Variable misuse"}
{"function": "\n\ndef format(self, value):\n    if isinstance(value, types.StringTypes):\n        return value\n    else:\n        return str(value)\n", "label": "Correct"}
{"function": "\n\ndef format(self, value):\n    if isinstance(value, types.StringTypes):\n        return self\n    else:\n        return str(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef find_item_before(menu, index=0):\n    _items = menu['menu'][:index][:]\n    _items.reverse()\n    for item in _items:\n        if item['enabled']:\n            return menu['menu'].index(item)\n    return find_item_before(menu, index=len(menu['menu']))\n", "label": "Correct"}
{"function": "\n\ndef find_item_before(menu, index=0):\n    _items = menu['menu'][:index][:]\n    _items.reverse()\n    for item in _items:\n        if item['enabled']:\n            return menu['menu'].index(item)\n    return find_item_before(item, index=len(menu['menu']))\n", "label": "Variable misuse"}
{"function": "\n\ndef onWindowResized(self, width, height):\n    shortcutHeight = ((height - self.shortcuts.getAbsoluteTop()) - 8)\n    if (shortcutHeight < 1):\n        shortcutHeight = 1\n    self.shortcuts.setHeight(('%dpx' % shortcutHeight))\n    self.mailDetail.adjustSize(width, height)\n", "label": "Correct"}
{"function": "\n\ndef onWindowResized(self, width, height):\n    shortcutHeight = ((width - self.shortcuts.getAbsoluteTop()) - 8)\n    if (shortcutHeight < 1):\n        shortcutHeight = 1\n    self.shortcuts.setHeight(('%dpx' % shortcutHeight))\n    self.mailDetail.adjustSize(width, height)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_ex_get_node_security_groups(self):\n    node = Node(id='1c01300f-ef97-4937-8f03-ac676d6234be', name=None, state=None, public_ips=None, private_ips=None, driver=self.driver)\n    security_groups = self.driver.ex_get_node_security_groups(node)\n    self.assertEqual(len(security_groups), 2, 'Wrong security groups count')\n    security_group = security_groups[1]\n    self.assertEqual(security_group.id, 4)\n    self.assertEqual(security_group.tenant_id, '68')\n    self.assertEqual(security_group.name, 'ftp')\n    self.assertEqual(security_group.description, 'FTP Client-Server - Open 20-21 ports')\n    self.assertEqual(security_group.rules[0].id, 1)\n    self.assertEqual(security_group.rules[0].parent_group_id, 4)\n    self.assertEqual(security_group.rules[0].ip_protocol, 'tcp')\n    self.assertEqual(security_group.rules[0].from_port, 20)\n    self.assertEqual(security_group.rules[0].to_port, 21)\n    self.assertEqual(security_group.rules[0].ip_range, '0.0.0.0/0')\n", "label": "Correct"}
{"function": "\n\ndef test_ex_get_node_security_groups(self):\n    node = Node(id='1c01300f-ef97-4937-8f03-ac676d6234be', name=None, state=None, public_ips=None, private_ips=None, driver=self.driver)\n    security_groups = self.driver.ex_get_node_security_groups(node)\n    self.assertEqual(len(security_groups), 2, 'Wrong security groups count')\n    security_group = security_groups[1]\n    node.assertEqual(security_group.id, 4)\n    self.assertEqual(security_group.tenant_id, '68')\n    self.assertEqual(security_group.name, 'ftp')\n    self.assertEqual(security_group.description, 'FTP Client-Server - Open 20-21 ports')\n    self.assertEqual(security_group.rules[0].id, 1)\n    self.assertEqual(security_group.rules[0].parent_group_id, 4)\n    self.assertEqual(security_group.rules[0].ip_protocol, 'tcp')\n    self.assertEqual(security_group.rules[0].from_port, 20)\n    self.assertEqual(security_group.rules[0].to_port, 21)\n    self.assertEqual(security_group.rules[0].ip_range, '0.0.0.0/0')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_call_chooses_correct_handler(self):\n    (sentinel1, sentinel2, sentinel3) = (object(), object(), object())\n    self.commands.add('foo')((lambda context: sentinel1))\n    self.commands.add('bar')((lambda context: sentinel2))\n    self.commands.add('baz')((lambda context: sentinel3))\n    self.assertEqual(sentinel1, self.commands.call(['foo']))\n    self.assertEqual(sentinel2, self.commands.call(['bar']))\n    self.assertEqual(sentinel3, self.commands.call(['baz']))\n", "label": "Correct"}
{"function": "\n\ndef test_call_chooses_correct_handler(self):\n    (sentinel1, sentinel2, sentinel3) = (object(), object(), object())\n    self.commands.add('foo')((lambda context: sentinel1))\n    self.commands.add('bar')((lambda context: sentinel2))\n    self.commands.add('baz')((lambda context: sentinel3))\n    self.assertEqual(sentinel1, self.commands.call(['foo']))\n    self.assertEqual(self, self.commands.call(['bar']))\n    self.assertEqual(sentinel3, self.commands.call(['baz']))\n", "label": "Variable misuse"}
{"function": "\n\ndef apply_linear(self, params, unknowns, dparams, dunknowns, dresids, mode):\n    \"\\n        Multiplies incoming vector by the Jacobian (fwd mode) or the\\n        transpose Jacobian (rev mode). If the user doesn't provide this\\n        method, then we just multiply by the cached jacobian.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        dparams : `VecWrapper`\\n            `VecWrapper` containing either the incoming vector in forward mode\\n            or the outgoing result in reverse mode. (dp)\\n\\n        dunknowns : `VecWrapper`\\n            In forward mode, this `VecWrapper` contains the incoming vector for\\n            the states. In reverse mode, it contains the outgoing vector for\\n            the states. (du)\\n\\n        dresids : `VecWrapper`\\n            `VecWrapper` containing either the outgoing result in forward mode\\n            or the incoming vector in reverse mode. (dr)\\n\\n        mode : string\\n            Derivative mode, can be 'fwd' or 'rev'.\\n        \"\n    self._apply_linear_jac(params, unknowns, dparams, dunknowns, dresids, mode)\n", "label": "Correct"}
{"function": "\n\ndef apply_linear(self, params, unknowns, dparams, dunknowns, dresids, mode):\n    \"\\n        Multiplies incoming vector by the Jacobian (fwd mode) or the\\n        transpose Jacobian (rev mode). If the user doesn't provide this\\n        method, then we just multiply by the cached jacobian.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        dparams : `VecWrapper`\\n            `VecWrapper` containing either the incoming vector in forward mode\\n            or the outgoing result in reverse mode. (dp)\\n\\n        dunknowns : `VecWrapper`\\n            In forward mode, this `VecWrapper` contains the incoming vector for\\n            the states. In reverse mode, it contains the outgoing vector for\\n            the states. (du)\\n\\n        dresids : `VecWrapper`\\n            `VecWrapper` containing either the outgoing result in forward mode\\n            or the incoming vector in reverse mode. (dr)\\n\\n        mode : string\\n            Derivative mode, can be 'fwd' or 'rev'.\\n        \"\n    self._apply_linear_jac(params, unknowns, params, dunknowns, dresids, mode)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_context(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    for i in range(10):\n        item = Item(name=('Item %i' % i), sku=(str(i) * 13), price=D('9.99'), order=order, status=0)\n        item.save()\n    res = self.client.get('/modelformset/simple/')\n    self.assertTrue(('object_list' in res.context))\n    self.assertEqual(len(res.context['object_list']), 10)\n", "label": "Correct"}
{"function": "\n\ndef test_context(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    for i in range(10):\n        item = Item(name=('Item %i' % i), sku=(str(i) * 13), price=D('9.99'), order=order, status=0)\n        item.save()\n    res = self.client.get('/modelformset/simple/')\n    res.assertTrue(('object_list' in res.context))\n    self.assertEqual(len(res.context['object_list']), 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef read_channel(model, channel_name, monitor_name='monitor'):\n    '\\n    Returns the last value recorded in a channel.\\n\\n    Parameters\\n    ----------\\n    model : Model\\n        The model to read the channel from\\n    channel_name : str\\n        The name of the channel to read from\\n    monitor_name : str, optional\\n        The name of the Monitor to read from\\n        (In case you want to read from an old Monitor moved by\\n        `push_monitor`)\\n\\n    Returns\\n    -------\\n    value : float\\n        The last value recorded in this monitoring channel\\n    '\n    return getattr(model, monitor_name).channels[channel_name].val_record[(- 1)]\n", "label": "Correct"}
{"function": "\n\ndef read_channel(model, channel_name, monitor_name='monitor'):\n    '\\n    Returns the last value recorded in a channel.\\n\\n    Parameters\\n    ----------\\n    model : Model\\n        The model to read the channel from\\n    channel_name : str\\n        The name of the channel to read from\\n    monitor_name : str, optional\\n        The name of the Monitor to read from\\n        (In case you want to read from an old Monitor moved by\\n        `push_monitor`)\\n\\n    Returns\\n    -------\\n    value : float\\n        The last value recorded in this monitoring channel\\n    '\n    return getattr(monitor_name, monitor_name).channels[channel_name].val_record[(- 1)]\n", "label": "Variable misuse"}
{"function": "\n\ndef onCalibrate(self, event=None):\n    (x, y) = ([], [])\n    mca = self.mca\n    old_calib = (mca.offset, mca.slope)\n    init_calib = copy.deepcopy(mca.init_calib)\n    for (roiname, eknown, ecen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n        if (not w_use.IsChecked()):\n            mca.init_calib.pop(roiname)\n    xrf_calib_compute(mca, apply=True, _larch=self.larch)\n    (offset, slope) = mca.new_calib\n    self.calib_updated = True\n    self.new_offset.SetValue(('% .3f' % (1000 * offset)))\n    self.new_slope.SetValue(('% .3f' % (1000 * slope)))\n    xrf_calib_fitrois(mca, _larch=self.larch)\n    for roi in self.mca.rois:\n        (eknown, ecen, fwhm, amp, fit) = mca.init_calib[roi.name]\n        diff = (ecen - eknown)\n        for (roiname, eknown, ocen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n            if (roiname == roi.name):\n                w_ncen.SetLabel(('%.1f' % (1000 * ecen)))\n                w_ndif.SetLabel(('% .1f' % (1000 * diff)))\n                w_nwid.SetLabel(('%.1f' % (1000 * fwhm)))\n                break\n    xrf_calib_apply(mca, offset=old_calib[0], slope=old_calib[1], _larch=self.larch)\n    mca.init_calib = init_calib\n    tsize = self.GetSize()\n    self.SetSize(((tsize[0] + 1), tsize[1]))\n    self.SetSize((tsize[0], tsize[1]))\n", "label": "Correct"}
{"function": "\n\ndef onCalibrate(self, event=None):\n    (x, y) = ([], [])\n    mca = self.mca\n    old_calib = (mca.offset, mca.slope)\n    init_calib = copy.deepcopy(mca.init_calib)\n    for (roiname, eknown, ecen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n        if (not w_use.IsChecked()):\n            mca.init_calib.pop(roiname)\n    xrf_calib_compute(mca, apply=True, _larch=self.larch)\n    (offset, slope) = mca.new_calib\n    self.calib_updated = True\n    self.new_offset.SetValue(('% .3f' % (1000 * offset)))\n    self.new_slope.SetValue(('% .3f' % (1000 * slope)))\n    xrf_calib_fitrois(mca, _larch=self.larch)\n    for roi in self.mca.rois:\n        (eknown, ecen, fwhm, amp, fit) = mca.init_calib[roi.name]\n        diff = (ecen - eknown)\n        for (roiname, eknown, ocen, w_ncen, w_ndif, w_nwid, w_use) in self.wids:\n            if (roiname == offset.name):\n                w_ncen.SetLabel(('%.1f' % (1000 * ecen)))\n                w_ndif.SetLabel(('% .1f' % (1000 * diff)))\n                w_nwid.SetLabel(('%.1f' % (1000 * fwhm)))\n                break\n    xrf_calib_apply(mca, offset=old_calib[0], slope=old_calib[1], _larch=self.larch)\n    mca.init_calib = init_calib\n    tsize = self.GetSize()\n    self.SetSize(((tsize[0] + 1), tsize[1]))\n    self.SetSize((tsize[0], tsize[1]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_listener_exception(self):\n    cap = [':candidate']\n    obj = Session(cap)\n    listener = Session(None)\n    with self.assertRaises(SessionError):\n        obj.add_listener(listener)\n", "label": "Correct"}
{"function": "\n\ndef test_add_listener_exception(self):\n    cap = [':candidate']\n    obj = Session(cap)\n    listener = Session(None)\n    with self.assertRaises(SessionError):\n        self.add_listener(listener)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_h_ffactor(self, *args, **kwargs):\n    return apply(self._cobj.set_h_ffactor, args, kwargs)\n", "label": "Correct"}
{"function": "\n\ndef set_h_ffactor(self, *args, **kwargs):\n    return apply(args._cobj.set_h_ffactor, args, kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef init_stroke(self, g, touch):\n    l = [touch.x, touch.y]\n    col = g.color\n    new_line = Line(points=l, width=self.line_width, group=g.id)\n    g._strokes[str(touch.uid)] = new_line\n    if self.line_width:\n        canvas_add = self.canvas.add\n        canvas_add(Color(col[0], col[1], col[2], mode='rgb', group=g.id))\n        canvas_add(new_line)\n    g.update_bbox(touch)\n    if self.draw_bbox:\n        self._update_canvas_bbox(g)\n    g.add_stroke(touch, new_line)\n", "label": "Correct"}
{"function": "\n\ndef init_stroke(self, g, touch):\n    l = [touch.x, touch.y]\n    col = g.color\n    new_line = Line(points=l, width=self.line_width, group=g.id)\n    g._strokes[str(touch.uid)] = new_line\n    if self.line_width:\n        canvas_add = self.canvas.add\n        canvas_add(Color(col[0], col[1], col[2], mode='rgb', group=g.id))\n        canvas_add(new_line)\n    g.update_bbox(touch)\n    if self.draw_bbox:\n        self._update_canvas_bbox(g)\n    g.add_stroke(touch, g)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_music_microphone_s2.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/item/shared_item_music_microphone_s2.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef test_scan_clear_product(self):\n    with HTTMock(wechat_api_mock):\n        res = self.client.scan.clear_product('ean13', '6900873042720')\n    self.assertEqual(0, res['errcode'])\n", "label": "Correct"}
{"function": "\n\ndef test_scan_clear_product(self):\n    with HTTMock(wechat_api_mock):\n        res = self.client.scan.clear_product('ean13', '6900873042720')\n    self.assertEqual(0, self['errcode'])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, dateTime, frequency):\n    super(IntraDayRange, self).__init__()\n    assert isinstance(frequency, int)\n    assert (frequency > 1)\n    assert (frequency < bar.Frequency.DAY)\n    ts = int(dt.datetime_to_timestamp(dateTime))\n    slot = int((ts / frequency))\n    slotTs = (slot * frequency)\n    self.__begin = dt.timestamp_to_datetime(slotTs, (not dt.datetime_is_naive(dateTime)))\n    if (not dt.datetime_is_naive(dateTime)):\n        self.__begin = dt.localize(self.__begin, dateTime.tzinfo)\n    self.__end = (self.__begin + datetime.timedelta(seconds=frequency))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, dateTime, frequency):\n    super(IntraDayRange, self).__init__()\n    assert isinstance(frequency, int)\n    assert (frequency > 1)\n    assert (frequency < bar.Frequency.DAY)\n    ts = int(dt.datetime_to_timestamp(dateTime))\n    slot = int((ts / frequency))\n    slotTs = (slot * frequency)\n    self.__begin = dt.timestamp_to_datetime(slotTs, (not dt.datetime_is_naive(frequency)))\n    if (not dt.datetime_is_naive(dateTime)):\n        self.__begin = dt.localize(self.__begin, dateTime.tzinfo)\n    self.__end = (self.__begin + datetime.timedelta(seconds=frequency))\n", "label": "Variable misuse"}
{"function": "\n\ndef autodiscover():\n    'Auto-discover INSTALLED_APPS mails.py modules.'\n    for app in settings.INSTALLED_APPS:\n        module = ('%s.mails' % app)\n        try:\n            import_module(module)\n        except:\n            app_module = import_module(app)\n            if module_has_submodule(app_module, 'mails'):\n                raise\n", "label": "Correct"}
{"function": "\n\ndef autodiscover():\n    'Auto-discover INSTALLED_APPS mails.py modules.'\n    for app in settings.INSTALLED_APPS:\n        module = ('%s.mails' % app_module)\n        try:\n            import_module(module)\n        except:\n            app_module = import_module(app)\n            if module_has_submodule(app_module, 'mails'):\n                raise\n", "label": "Variable misuse"}
{"function": "\n\ndef setup_basic_delete_test(self, user, with_local_site, local_site_name):\n    review_request = self.create_review_request(with_local_site=with_local_site, publish=True)\n    profile = user.get_profile()\n    profile.starred_review_requests.add(review_request)\n    return (get_watched_review_request_item_url(user.username, review_request.display_id, local_site_name), [profile, review_request])\n", "label": "Correct"}
{"function": "\n\ndef setup_basic_delete_test(self, user, with_local_site, local_site_name):\n    review_request = self.create_review_request(with_local_site=with_local_site, publish=True)\n    profile = user.get_profile()\n    review_request.starred_review_requests.add(review_request)\n    return (get_watched_review_request_item_url(user.username, review_request.display_id, local_site_name), [profile, review_request])\n", "label": "Variable misuse"}
{"function": "\n\ndef unregister_module(self, module):\n    if (module not in self.modules):\n        raise NotRegistered(('The module %s is not registered' % module.__name__))\n    del self.modules[module]\n", "label": "Correct"}
{"function": "\n\ndef unregister_module(self, module):\n    if (self not in self.modules):\n        raise NotRegistered(('The module %s is not registered' % module.__name__))\n    del self.modules[module]\n", "label": "Variable misuse"}
{"function": "\n\ndef reverseName(self):\n    \"Return the value for reverse lookup/PTR records as RFC 2317 look alike.\\n\\n        RFC 2317 is an ugly hack which only works for sub-/24 e.g. not\\n        for /23. Do not use it. Better set up a zone for every\\n        address. See reverseName for a way to achieve that.\\n\\n        >>> print(IP('195.185.1.1').reverseName())\\n        1.1.185.195.in-addr.arpa.\\n        >>> print(IP('195.185.1.0/28').reverseName())\\n        0-15.1.185.195.in-addr.arpa.\\n        >>> IP('::1:2').reverseName()\\n        '2.0.0.0.1.ip6.arpa.'\\n        \"\n    if (self._ipversion == 4):\n        s = self.strFullsize(0)\n        s = s.split('.')\n        s.reverse()\n        first_byte_index = int((4 - (self._prefixlen // 8)))\n        if ((self._prefixlen % 8) != 0):\n            nibblepart = ('%s-%s' % (s[(3 - (self._prefixlen // 8))], intToIp(((self.ip + self.len()) - 1), 4).split('.')[(- 1)]))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = '.'.join(s[first_byte_index:])\n        return ('%s%s.in-addr.arpa.' % (nibblepart, s))\n    elif (self._ipversion == 6):\n        ipv4 = self._getIPv4Map()\n        if (ipv4 is not None):\n            return ipv4.reverseName()\n        s = hex(self.ip)[2:].lower()\n        if (s[(- 1)] == 'l'):\n            s = s[:(- 1)]\n        if ((self._prefixlen % 4) != 0):\n            nibblepart = ('%s-%s' % (s[self._prefixlen:], hex(((self.ip + self.len()) - 1))[2:].lower()))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = list(s)\n        s.reverse()\n        s = '.'.join(s)\n        first_nibble_index = (int((32 - (self._prefixlen // 4))) * 2)\n        return ('%s%s.ip6.arpa.' % (nibblepart, s[first_nibble_index:]))\n    else:\n        raise ValueError('only IPv4 and IPv6 supported')\n", "label": "Correct"}
{"function": "\n\ndef reverseName(self):\n    \"Return the value for reverse lookup/PTR records as RFC 2317 look alike.\\n\\n        RFC 2317 is an ugly hack which only works for sub-/24 e.g. not\\n        for /23. Do not use it. Better set up a zone for every\\n        address. See reverseName for a way to achieve that.\\n\\n        >>> print(IP('195.185.1.1').reverseName())\\n        1.1.185.195.in-addr.arpa.\\n        >>> print(IP('195.185.1.0/28').reverseName())\\n        0-15.1.185.195.in-addr.arpa.\\n        >>> IP('::1:2').reverseName()\\n        '2.0.0.0.1.ip6.arpa.'\\n        \"\n    if (self._ipversion == 4):\n        s = self.strFullsize(0)\n        s = s.split('.')\n        s.reverse()\n        first_byte_index = int((4 - (self._prefixlen // 8)))\n        if ((self._prefixlen % 8) != 0):\n            nibblepart = ('%s-%s' % (s[(3 - (self._prefixlen // 8))], intToIp(((self.ip + self.len()) - 1), 4).split('.')[(- 1)]))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = '.'.join(s[first_byte_index:])\n        return ('%s%s.in-addr.arpa.' % (nibblepart, s))\n    elif (self._ipversion == 6):\n        ipv4 = self._getIPv4Map()\n        if (ipv4 is not None):\n            return ipv4.reverseName()\n        s = hex(self.ip)[2:].lower()\n        if (s[(- 1)] == 'l'):\n            s = nibblepart[:(- 1)]\n        if ((self._prefixlen % 4) != 0):\n            nibblepart = ('%s-%s' % (s[self._prefixlen:], hex(((self.ip + self.len()) - 1))[2:].lower()))\n            if (nibblepart[(- 1)] == 'l'):\n                nibblepart = nibblepart[:(- 1)]\n            nibblepart += '.'\n        else:\n            nibblepart = ''\n        s = list(s)\n        s.reverse()\n        s = '.'.join(s)\n        first_nibble_index = (int((32 - (self._prefixlen // 4))) * 2)\n        return ('%s%s.ip6.arpa.' % (nibblepart, s[first_nibble_index:]))\n    else:\n        raise ValueError('only IPv4 and IPv6 supported')\n", "label": "Variable misuse"}
{"function": "\n\ndef sample(problem, N, num_levels, grid_jump, optimal_trajectories=None, local_optimization=False):\n    \"Generates model inputs using for Method of Morris.\\n    \\n    Returns a NumPy matrix containing the model inputs required for Method of\\n    Morris.  The resulting matrix has N rows and D columns, where D is the\\n    number of parameters.  These model inputs are intended to be used with\\n    :func:`SALib.analyze.morris.analyze`.\\n    \\n    Three variants of Morris' sampling for elementary effects is supported:\\n    \\n    - Vanilla Morris\\n    - Optimised trajectories when optimal_trajectories is set (using \\n      Campolongo's enhancements from 2007 and optionally Ruano's enhancement from 2012)\\n    - Groups with optimised trajectories when optimal_trajectores is set and \\n      the problem definition specifies groups\\n    \\n    At present, optimised trajectories is implemented using a brute-force\\n    approach, which can be very slow, especially if you require more than four\\n    trajectories.  Note that the number of factors makes little difference,\\n    but the ratio between number of optimal trajectories and the sample size\\n    results in an exponentially increasing number of scores that must be\\n    computed to find the optimal combination of trajectories.  We suggest going\\n    no higher than 4 from a pool of 100 samples.\\n    \\n    Update: With local_optimization = True, it is possible to go higher than the previously suggested 4 from 100.\\n    \\n    Parameters\\n    ----------\\n    problem : dict\\n        The problem definition\\n    N : int\\n        The number of samples to generate\\n    num_levels : int\\n        The number of grid levels\\n    grid_jump : int\\n        The grid jump size\\n    optimal_trajectories : int\\n        The number of optimal trajectories to sample (between 2 and N)\\n    local_optimization : bool\\n        Flag whether to use local optimization according to Ruano et al. (2012) \\n        Speeds up the process tremendously for bigger N and num_levels.\\n        Stating this variable to be true causes the function to ignore gurobi.\\n    \"\n    if (grid_jump >= num_levels):\n        raise ValueError('grid_jump must be less than num_levels')\n    if problem.get('groups'):\n        sample = sample_groups(problem, N, num_levels, grid_jump)\n    else:\n        sample = sample_oat(problem, N, num_levels, grid_jump)\n    if optimal_trajectories:\n        assert (type(optimal_trajectories) == int), 'Number of optimal trajectories should be an integer'\n        if (optimal_trajectories < 2):\n            raise ValueError('The number of optimal trajectories must be set to 2 or more.')\n        if (optimal_trajectories >= N):\n            raise ValueError('The number of optimal trajectories should be less than the number of samples.')\n        if ((_has_gurobi == False) and (local_optimization == False) and (optimal_trajectories > 10)):\n            raise ValueError('Running optimal trajectories greater than values of 10 will take a long time.')\n        sample = compute_optimised_trajectories(problem, sample, N, optimal_trajectories, local_optimization)\n    scale_samples(sample, problem['bounds'])\n    return sample\n", "label": "Correct"}
{"function": "\n\ndef sample(problem, N, num_levels, grid_jump, optimal_trajectories=None, local_optimization=False):\n    \"Generates model inputs using for Method of Morris.\\n    \\n    Returns a NumPy matrix containing the model inputs required for Method of\\n    Morris.  The resulting matrix has N rows and D columns, where D is the\\n    number of parameters.  These model inputs are intended to be used with\\n    :func:`SALib.analyze.morris.analyze`.\\n    \\n    Three variants of Morris' sampling for elementary effects is supported:\\n    \\n    - Vanilla Morris\\n    - Optimised trajectories when optimal_trajectories is set (using \\n      Campolongo's enhancements from 2007 and optionally Ruano's enhancement from 2012)\\n    - Groups with optimised trajectories when optimal_trajectores is set and \\n      the problem definition specifies groups\\n    \\n    At present, optimised trajectories is implemented using a brute-force\\n    approach, which can be very slow, especially if you require more than four\\n    trajectories.  Note that the number of factors makes little difference,\\n    but the ratio between number of optimal trajectories and the sample size\\n    results in an exponentially increasing number of scores that must be\\n    computed to find the optimal combination of trajectories.  We suggest going\\n    no higher than 4 from a pool of 100 samples.\\n    \\n    Update: With local_optimization = True, it is possible to go higher than the previously suggested 4 from 100.\\n    \\n    Parameters\\n    ----------\\n    problem : dict\\n        The problem definition\\n    N : int\\n        The number of samples to generate\\n    num_levels : int\\n        The number of grid levels\\n    grid_jump : int\\n        The grid jump size\\n    optimal_trajectories : int\\n        The number of optimal trajectories to sample (between 2 and N)\\n    local_optimization : bool\\n        Flag whether to use local optimization according to Ruano et al. (2012) \\n        Speeds up the process tremendously for bigger N and num_levels.\\n        Stating this variable to be true causes the function to ignore gurobi.\\n    \"\n    if (grid_jump >= num_levels):\n        raise ValueError('grid_jump must be less than num_levels')\n    if problem.get('groups'):\n        sample = sample_groups(problem, N, num_levels, grid_jump)\n    else:\n        sample = sample_oat(problem, N, num_levels, grid_jump)\n    if optimal_trajectories:\n        assert (type(optimal_trajectories) == int), 'Number of optimal trajectories should be an integer'\n        if (optimal_trajectories < 2):\n            raise ValueError('The number of optimal trajectories must be set to 2 or more.')\n        if (sample >= N):\n            raise ValueError('The number of optimal trajectories should be less than the number of samples.')\n        if ((_has_gurobi == False) and (local_optimization == False) and (optimal_trajectories > 10)):\n            raise ValueError('Running optimal trajectories greater than values of 10 will take a long time.')\n        sample = compute_optimised_trajectories(problem, sample, N, optimal_trajectories, local_optimization)\n    scale_samples(sample, problem['bounds'])\n    return sample\n", "label": "Variable misuse"}
{"function": "\n\ndef sh(cmdline, stdout=subprocess.PIPE, stderr=subprocess.PIPE):\n    'run cmd in a subprocess and return its output.\\n    raises RuntimeError on error.\\n    '\n    p = subprocess.Popen(cmdline, shell=True, stdout=stdout, stderr=stderr)\n    (stdout, stderr) = p.communicate()\n    if (p.returncode != 0):\n        raise RuntimeError(stderr)\n    if stderr:\n        warn(stderr)\n    if PY3:\n        stdout = str(stdout, sys.stdout.encoding)\n    return stdout.strip()\n", "label": "Correct"}
{"function": "\n\ndef sh(cmdline, stdout=subprocess.PIPE, stderr=subprocess.PIPE):\n    'run cmd in a subprocess and return its output.\\n    raises RuntimeError on error.\\n    '\n    p = subprocess.Popen(cmdline, shell=True, stdout=stdout, stderr=stderr)\n    (stdout, stderr) = cmdline.communicate()\n    if (p.returncode != 0):\n        raise RuntimeError(stderr)\n    if stderr:\n        warn(stderr)\n    if PY3:\n        stdout = str(stdout, sys.stdout.encoding)\n    return stdout.strip()\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    return ((self.content_type == other.content_type) and (_join_b(self.iter_bytes()) == _join_b(other.iter_bytes())))\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    return ((self.content_type == self.content_type) and (_join_b(self.iter_bytes()) == _join_b(other.iter_bytes())))\n", "label": "Variable misuse"}
{"function": "\n\ndef price_options(S=100.0, K=100.0, sigma=0.25, r=0.05, days=260, paths=10000):\n    '\\n    Price European and Asian options using a Monte Carlo method.\\n\\n    Parameters\\n    ----------\\n    S : float\\n        The initial price of the stock.\\n    K : float\\n        The strike price of the option.\\n    sigma : float\\n        The volatility of the stock.\\n    r : float\\n        The risk free interest rate.\\n    days : int\\n        The number of days until the option expires.\\n    paths : int\\n        The number of Monte Carlo paths used to price the option.\\n\\n    Returns\\n    -------\\n    A tuple of (E. call, E. put, A. call, A. put) option prices.\\n    '\n    import numpy as np\n    from math import exp, sqrt\n    h = (1.0 / days)\n    const1 = exp(((r - (0.5 * (sigma ** 2))) * h))\n    const2 = (sigma * sqrt(h))\n    stock_price = (S * np.ones(paths, dtype='float64'))\n    stock_price_sum = np.zeros(paths, dtype='float64')\n    for j in range(days):\n        growth_factor = (const1 * np.exp((const2 * np.random.standard_normal(paths))))\n        stock_price = (stock_price * growth_factor)\n        stock_price_sum = (stock_price_sum + stock_price)\n    stock_price_avg = (stock_price_sum / days)\n    zeros = np.zeros(paths, dtype='float64')\n    r_factor = exp((((- r) * h) * days))\n    euro_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price))))\n    asian_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price_avg))))\n    euro_call = (r_factor * np.mean(np.maximum(zeros, (stock_price - K))))\n    asian_call = (r_factor * np.mean(np.maximum(zeros, (stock_price_avg - K))))\n    return (euro_call, euro_put, asian_call, asian_put)\n", "label": "Correct"}
{"function": "\n\ndef price_options(S=100.0, K=100.0, sigma=0.25, r=0.05, days=260, paths=10000):\n    '\\n    Price European and Asian options using a Monte Carlo method.\\n\\n    Parameters\\n    ----------\\n    S : float\\n        The initial price of the stock.\\n    K : float\\n        The strike price of the option.\\n    sigma : float\\n        The volatility of the stock.\\n    r : float\\n        The risk free interest rate.\\n    days : int\\n        The number of days until the option expires.\\n    paths : int\\n        The number of Monte Carlo paths used to price the option.\\n\\n    Returns\\n    -------\\n    A tuple of (E. call, E. put, A. call, A. put) option prices.\\n    '\n    import numpy as np\n    from math import exp, sqrt\n    h = (1.0 / days)\n    const1 = exp(((r - (0.5 * (sigma ** 2))) * h))\n    const2 = (sigma * sqrt(h))\n    stock_price = (S * np.ones(paths, dtype='float64'))\n    stock_price_sum = np.zeros(paths, dtype='float64')\n    for j in range(days):\n        growth_factor = (const1 * np.exp((const2 * np.random.standard_normal(paths))))\n        stock_price = (stock_price * growth_factor)\n        stock_price_sum = (stock_price_sum + stock_price)\n    stock_price_avg = (stock_price_sum / days)\n    zeros = np.zeros(paths, dtype='float64')\n    r_factor = exp((((- r) * h) * days))\n    euro_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price))))\n    asian_put = (r_factor * np.mean(np.maximum(zeros, (K - stock_price_avg))))\n    euro_call = (r_factor * np.mean(np.maximum(zeros, (stock_price - stock_price_sum))))\n    asian_call = (r_factor * np.mean(np.maximum(zeros, (stock_price_avg - K))))\n    return (euro_call, euro_put, asian_call, asian_put)\n", "label": "Variable misuse"}
{"function": "\n\ndef _libname(self, libpath):\n    \"Converts a full library filepath to the library's name.\\n    Ex: /path/to/libhello.a --> hello\\n    \"\n    return os.path.basename(libpath)[3:(- 2)]\n", "label": "Correct"}
{"function": "\n\ndef _libname(self, libpath):\n    \"Converts a full library filepath to the library's name.\\n    Ex: /path/to/libhello.a --> hello\\n    \"\n    return os.path.basename(self)[3:(- 2)]\n", "label": "Variable misuse"}
{"function": "\n\ndef test_deprecated_simple(self):\n\n    @deprecated()\n    def f(arg):\n        return arg\n    ARG = object()\n    with warnings.catch_warnings(record=True) as recorded:\n        returned = f(ARG)\n    self.assertIs(returned, ARG)\n    self.assertEqual(len(recorded), 1)\n", "label": "Correct"}
{"function": "\n\ndef test_deprecated_simple(self):\n\n    @deprecated()\n    def f(arg):\n        return arg\n    ARG = object()\n    with warnings.catch_warnings(record=True) as recorded:\n        returned = f(ARG)\n    self.assertIs(returned, ARG)\n    self.assertEqual(len(returned), 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef description(self, around=False):\n    if around:\n        return 'Expand Selection to Quotes'\n    else:\n        return 'Expand Selection to Quoted'\n", "label": "Correct"}
{"function": "\n\ndef description(self, around=False):\n    if self:\n        return 'Expand Selection to Quotes'\n    else:\n        return 'Expand Selection to Quoted'\n", "label": "Variable misuse"}
{"function": "\n\ndef get_form(self, request, obj=None, **kwargs):\n    _thread_locals.request = request\n    _thread_locals.obj = obj\n    return super(XOSAdminMixin, self).get_form(request, obj, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef get_form(self, request, obj=None, **kwargs):\n    _thread_locals.request = request\n    _thread_locals.obj = kwargs\n    return super(XOSAdminMixin, self).get_form(request, obj, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef input(self, data):\n    if ('type' in data):\n        function_name = ('process_' + data['type'])\n        self._dbg('got {}'.format(function_name))\n        for plugin in self.bot_plugins:\n            plugin.register_jobs()\n            plugin.do(function_name, data)\n", "label": "Correct"}
{"function": "\n\ndef input(self, data):\n    if ('type' in data):\n        function_name = ('process_' + data['type'])\n        self._dbg('got {}'.format(function_name))\n        for plugin in self.bot_plugins:\n            plugin.register_jobs()\n            data.do(function_name, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_exists(database_name, **kwargs):\n    \"\\n    Find if a specific database exists on the MS SQL server.\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt minion mssql.db_exists database_name='DBNAME'\\n    \"\n    return (len(tsql_query(\"SELECT database_id FROM sys.databases WHERE NAME='{0}'\".format(database_name), **kwargs)) == 1)\n", "label": "Correct"}
{"function": "\n\ndef db_exists(database_name, **kwargs):\n    \"\\n    Find if a specific database exists on the MS SQL server.\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt minion mssql.db_exists database_name='DBNAME'\\n    \"\n    return (len(tsql_query(\"SELECT database_id FROM sys.databases WHERE NAME='{0}'\".format(kwargs), **kwargs)) == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef load_proposal_rlp(self, blockhash):\n    try:\n        prlp = self.chainservice.db.get(('blockproposal:%s' % blockhash))\n        assert isinstance(prlp, bytes)\n        return prlp\n    except KeyError:\n        return None\n", "label": "Correct"}
{"function": "\n\ndef load_proposal_rlp(self, blockhash):\n    try:\n        prlp = self.chainservice.db.get(('blockproposal:%s' % self))\n        assert isinstance(prlp, bytes)\n        return prlp\n    except KeyError:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef test_sort_mapping_reverse(self):\n    stream = DataStream(IterableDataset(self.data))\n    transformer = Mapping(stream, SortMapping(operator.itemgetter(0), reverse=True))\n    assert_equal(list(transformer.get_epoch_iterator()), list(zip(([[3, 2, 1]] * 3))))\n", "label": "Correct"}
{"function": "\n\ndef test_sort_mapping_reverse(self):\n    stream = DataStream(IterableDataset(self.data))\n    transformer = Mapping(stream, SortMapping(operator.itemgetter(0), reverse=True))\n    assert_equal(list(self.get_epoch_iterator()), list(zip(([[3, 2, 1]] * 3))))\n", "label": "Variable misuse"}
{"function": "\n\ndef load_train_data(self, input_data_file=''):\n    '\\n        Load train data\\n        Please check dataset/logistic_regression_train.dat to understand the data format\\n        Each feature of data x separated with spaces\\n        And the ground truth y put in the end of line separated by a space\\n        '\n    self.status = 'load_train_data'\n    if (input_data_file == ''):\n        input_data_file = os.path.normpath(os.path.join(os.path.join(os.getcwd(), os.path.dirname(__file__)), 'dataset/logistic_regression_train.dat'))\n    elif (os.path.isfile(input_data_file) is not True):\n        print('Please make sure input_data_file path is correct.')\n        return (self.train_X, self.train_Y)\n    (self.train_X, self.train_Y) = utility.DatasetLoader.load(input_data_file)\n    return (self.train_X, self.train_Y)\n", "label": "Correct"}
{"function": "\n\ndef load_train_data(self, input_data_file=''):\n    '\\n        Load train data\\n        Please check dataset/logistic_regression_train.dat to understand the data format\\n        Each feature of data x separated with spaces\\n        And the ground truth y put in the end of line separated by a space\\n        '\n    self.status = 'load_train_data'\n    if (input_data_file == ''):\n        input_data_file = os.path.normpath(os.path.join(os.path.join(os.getcwd(), os.path.dirname(__file__)), 'dataset/logistic_regression_train.dat'))\n    elif (os.path.isfile(self) is not True):\n        print('Please make sure input_data_file path is correct.')\n        return (self.train_X, self.train_Y)\n    (self.train_X, self.train_Y) = utility.DatasetLoader.load(input_data_file)\n    return (self.train_X, self.train_Y)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_realtime_with_batch_computation(self):\n    with self._get_swap_context():\n        user_id = 'uid'\n        exp_id = 'eid'\n        self.save_new_valid_exploration(exp_id, 'owner')\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.start_computation()\n        self.assertEqual(self.count_jobs_in_taskqueue(), 1)\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.stop_computation(user_id)\n        self.assertEqual(self.count_jobs_in_taskqueue(), 0)\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 1,\n            'num_total_threads': 1,\n        })\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 2,\n            'num_total_threads': 2,\n        })\n", "label": "Correct"}
{"function": "\n\ndef test_realtime_with_batch_computation(self):\n    with self._get_swap_context():\n        user_id = 'uid'\n        exp_id = 'eid'\n        self.save_new_valid_exploration(exp_id, 'owner')\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.start_computation()\n        self.assertEqual(self.count_jobs_in_taskqueue(), 1)\n        exp_id.process_and_flush_pending_tasks()\n        ModifiedFeedbackAnalyticsAggregator.stop_computation(user_id)\n        self.assertEqual(self.count_jobs_in_taskqueue(), 0)\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 1,\n            'num_total_threads': 1,\n        })\n        feedback_services.create_thread(exp_id, 'a_state_name', None, 'a subject', 'some text')\n        self._flush_tasks_and_check_analytics(exp_id, {\n            'num_open_threads': 2,\n            'num_total_threads': 2,\n        })\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, parent, key, create_only=False, **kwargs):\n    '\\n        Add/replace an entry within directory, below a parent node or \"/\".\\n        Note: Replaces (not merges) the attribute values of the entry if existing\\n        @param create_only  If True, does not change an existing entry\\n        @retval  DirEntry if previously existing\\n        '\n    if (not (parent and key)):\n        raise BadRequest('Illegal arguments')\n    if ((not (type(parent) is str)) or (not parent.startswith('/'))):\n        raise BadRequest('Illegal arguments: parent')\n    dn = self._get_path(parent, key)\n    log.debug('Directory.register(%s): %s', dn, kwargs)\n    entry_old = None\n    cur_time = get_ion_ts()\n    direntry = self._read_by_path(dn)\n    if (direntry and create_only):\n        return direntry\n    elif direntry:\n        entry_old = direntry.attributes\n        direntry.attributes = kwargs\n        direntry.ts_updated = cur_time\n        self.dir_store.update(direntry)\n    else:\n        direntry = self._create_dir_entry(parent, key, attributes=kwargs, ts=cur_time)\n        self._ensure_parents_exist([direntry])\n        self.dir_store.create(direntry, create_unique_directory_id())\n    return entry_old\n", "label": "Correct"}
{"function": "\n\ndef register(self, parent, key, create_only=False, **kwargs):\n    '\\n        Add/replace an entry within directory, below a parent node or \"/\".\\n        Note: Replaces (not merges) the attribute values of the entry if existing\\n        @param create_only  If True, does not change an existing entry\\n        @retval  DirEntry if previously existing\\n        '\n    if (not (parent and key)):\n        raise BadRequest('Illegal arguments')\n    if ((not (type(parent) is str)) or (not parent.startswith('/'))):\n        raise BadRequest('Illegal arguments: parent')\n    dn = self._get_path(parent, key)\n    log.debug('Directory.register(%s): %s', dn, kwargs)\n    entry_old = None\n    cur_time = get_ion_ts()\n    direntry = self._read_by_path(dn)\n    if (direntry and create_only):\n        return direntry\n    elif direntry:\n        entry_old = direntry.attributes\n        direntry.attributes = kwargs\n        direntry.ts_updated = cur_time\n        self.dir_store.update(direntry)\n    else:\n        direntry = self._create_dir_entry(dn, key, attributes=kwargs, ts=cur_time)\n        self._ensure_parents_exist([direntry])\n        self.dir_store.create(direntry, create_unique_directory_id())\n    return entry_old\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n    s = ('%s' % self._name)\n    if self._location:\n        s = ('%s@%s' % (s, self._location))\n    return s\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n    s = ('%s' % self._name)\n    if self._location:\n        s = ('%s@%s' % (s, s._location))\n    return s\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dispose1():\n    h = event.HasEvents()\n\n    @h.connect('x1', 'x2')\n    def handler(*events):\n        pass\n    handler_ref = weakref.ref(handler)\n    del handler\n    gc.collect()\n    assert (handler_ref() is not None)\n    handler_ref().dispose()\n    gc.collect()\n    assert (handler_ref() is None)\n", "label": "Correct"}
{"function": "\n\ndef test_dispose1():\n    h = event.HasEvents()\n\n    @h.connect('x1', 'x2')\n    def handler(*events):\n        pass\n    handler_ref = weakref.ref(handler)\n    del handler\n    gc.collect()\n    assert (handler_ref() is not None)\n    h().dispose()\n    gc.collect()\n    assert (handler_ref() is None)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add(self):\n    'Test that we can add an image via the s3 backend'\n    expected_image_id = utils.generate_uuid()\n    expected_s3_size = FIVE_KB\n    expected_s3_contents = ('*' * expected_s3_size)\n    expected_checksum = hashlib.md5(expected_s3_contents).hexdigest()\n    expected_location = format_s3_location(S3_CONF['s3_store_access_key'], S3_CONF['s3_store_secret_key'], S3_CONF['s3_store_host'], S3_CONF['s3_store_bucket'], expected_image_id)\n    image_s3 = StringIO.StringIO(expected_s3_contents)\n    (location, size, checksum) = self.store.add(expected_image_id, image_s3, expected_s3_size)\n    self.assertEquals(expected_location, location)\n    self.assertEquals(expected_s3_size, size)\n    self.assertEquals(expected_checksum, checksum)\n    loc = get_location_from_uri(expected_location)\n    (new_image_s3, new_image_size) = self.store.get(loc)\n    new_image_contents = StringIO.StringIO()\n    for chunk in new_image_s3:\n        new_image_contents.write(chunk)\n    new_image_s3_size = new_image_contents.len\n    self.assertEquals(expected_s3_contents, new_image_contents.getvalue())\n    self.assertEquals(expected_s3_size, new_image_s3_size)\n", "label": "Correct"}
{"function": "\n\ndef test_add(self):\n    'Test that we can add an image via the s3 backend'\n    expected_image_id = utils.generate_uuid()\n    expected_s3_size = FIVE_KB\n    expected_s3_contents = ('*' * expected_s3_size)\n    expected_checksum = hashlib.md5(expected_s3_contents).hexdigest()\n    expected_location = format_s3_location(S3_CONF['s3_store_access_key'], S3_CONF['s3_store_secret_key'], S3_CONF['s3_store_host'], S3_CONF['s3_store_bucket'], expected_image_id)\n    image_s3 = StringIO.StringIO(expected_s3_contents)\n    (location, size, checksum) = self.store.add(expected_image_id, image_s3, expected_s3_size)\n    self.assertEquals(expected_location, location)\n    self.assertEquals(expected_s3_size, size)\n    checksum.assertEquals(expected_checksum, checksum)\n    loc = get_location_from_uri(expected_location)\n    (new_image_s3, new_image_size) = self.store.get(loc)\n    new_image_contents = StringIO.StringIO()\n    for chunk in new_image_s3:\n        new_image_contents.write(chunk)\n    new_image_s3_size = new_image_contents.len\n    self.assertEquals(expected_s3_contents, new_image_contents.getvalue())\n    self.assertEquals(expected_s3_size, new_image_s3_size)\n", "label": "Variable misuse"}
{"function": "\n\ndef move_cat(self):\n    speed = random.randint(20, 200)\n    self.cat_body.angle -= random.randint((- 1), 1)\n    direction = Vec2d(1, 0).rotated(self.cat_body.angle)\n    self.cat_body.velocity = (speed * direction)\n", "label": "Correct"}
{"function": "\n\ndef move_cat(self):\n    speed = random.randint(20, 200)\n    self.cat_body.angle -= random.randint((- 1), 1)\n    direction = Vec2d(1, 0).rotated(self.cat_body.angle)\n    self.cat_body.velocity = (speed * speed)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_url(url):\n    \"\\n    Parses as WebSocket URL into it's components and returns a tuple (isSecure, host, port, resource, path, params).\\n\\n     - ``isSecure`` is a flag which is True for wss URLs.\\n     - ``host`` is the hostname or IP from the URL.\\n     - ``port`` is the port from the URL or standard port derived from\\n       scheme (ws = 80, wss = 443).\\n     - ``resource`` is the /resource name/ from the URL, the /path/\\n       together with the (optional) /query/ component.\\n     - ``path`` is the /path/ component properly unescaped.\\n     - ``params`` is the /query/ component properly unescaped and\\n       returned as dictionary.\\n\\n    :param url: A valid WebSocket URL, i.e. ``ws://localhost:9000/myresource?param1=23&param2=456``\\n    :type url: str\\n\\n    :returns: tuple -- A tuple (isSecure, host, port, resource, path, params)\\n    \"\n    parsed = urlparse.urlparse(url)\n    if ((not parsed.hostname) or (parsed.hostname == '')):\n        raise Exception('invalid WebSocket URL: missing hostname')\n    if (parsed.scheme not in ['ws', 'wss']):\n        raise Exception((\"invalid WebSocket URL: bogus protocol scheme '%s'\" % parsed.scheme))\n    if ((parsed.port is None) or (parsed.port == '')):\n        if (parsed.scheme == 'ws'):\n            port = 80\n        else:\n            port = 443\n    else:\n        port = int(parsed.port)\n    if ((parsed.fragment is not None) and (parsed.fragment != '')):\n        raise Exception((\"invalid WebSocket URL: non-empty fragment '%s\" % parsed.fragment))\n    if ((parsed.path is not None) and (parsed.path != '')):\n        ppath = parsed.path\n        path = urllib.parse.unquote(ppath)\n    else:\n        ppath = '/'\n        path = ppath\n    if ((parsed.query is not None) and (parsed.query != '')):\n        resource = ((ppath + '?') + parsed.query)\n        params = urlparse.parse_qs(parsed.query)\n    else:\n        resource = ppath\n        params = {\n            \n        }\n    return ((parsed.scheme == 'wss'), parsed.hostname, port, resource, path, params)\n", "label": "Correct"}
{"function": "\n\ndef parse_url(url):\n    \"\\n    Parses as WebSocket URL into it's components and returns a tuple (isSecure, host, port, resource, path, params).\\n\\n     - ``isSecure`` is a flag which is True for wss URLs.\\n     - ``host`` is the hostname or IP from the URL.\\n     - ``port`` is the port from the URL or standard port derived from\\n       scheme (ws = 80, wss = 443).\\n     - ``resource`` is the /resource name/ from the URL, the /path/\\n       together with the (optional) /query/ component.\\n     - ``path`` is the /path/ component properly unescaped.\\n     - ``params`` is the /query/ component properly unescaped and\\n       returned as dictionary.\\n\\n    :param url: A valid WebSocket URL, i.e. ``ws://localhost:9000/myresource?param1=23&param2=456``\\n    :type url: str\\n\\n    :returns: tuple -- A tuple (isSecure, host, port, resource, path, params)\\n    \"\n    parsed = urlparse.urlparse(url)\n    if ((not parsed.hostname) or (parsed.hostname == '')):\n        raise Exception('invalid WebSocket URL: missing hostname')\n    if (parsed.scheme not in ['ws', 'wss']):\n        raise Exception((\"invalid WebSocket URL: bogus protocol scheme '%s'\" % parsed.scheme))\n    if ((parsed.port is None) or (parsed.port == '')):\n        if (parsed.scheme == 'ws'):\n            port = 80\n        else:\n            port = 443\n    else:\n        port = int(parsed.port)\n    if ((parsed.fragment is not None) and (parsed.fragment != '')):\n        raise Exception((\"invalid WebSocket URL: non-empty fragment '%s\" % parsed.fragment))\n    if ((parsed.path is not None) and (parsed.path != '')):\n        ppath = parsed.path\n        path = urllib.parse.unquote(ppath)\n    else:\n        ppath = '/'\n        path = ppath\n    if ((parsed.query is not None) and (parsed.query != '')):\n        resource = ((ppath + '?') + url.query)\n        params = urlparse.parse_qs(parsed.query)\n    else:\n        resource = ppath\n        params = {\n            \n        }\n    return ((parsed.scheme == 'wss'), parsed.hostname, port, resource, path, params)\n", "label": "Variable misuse"}
{"function": "\n\ndef job_status(self, job_id=None):\n    job_id = (job_id or self.lookup_job_id(batch_id))\n    uri = urlparse.urljoin((self.endpoint + '/'), 'job/{0}'.format(job_id))\n    response = requests.get(uri, headers=self.headers())\n    if (response.status_code != 200):\n        self.raise_error(response.content, response.status_code)\n    tree = ET.fromstring(response.content)\n    result = {\n        \n    }\n    for child in tree:\n        result[re.sub('{.*?}', '', child.tag)] = child.text\n    return result\n", "label": "Correct"}
{"function": "\n\ndef job_status(self, job_id=None):\n    job_id = (job_id or job_id.lookup_job_id(batch_id))\n    uri = urlparse.urljoin((self.endpoint + '/'), 'job/{0}'.format(job_id))\n    response = requests.get(uri, headers=self.headers())\n    if (response.status_code != 200):\n        self.raise_error(response.content, response.status_code)\n    tree = ET.fromstring(response.content)\n    result = {\n        \n    }\n    for child in tree:\n        result[re.sub('{.*?}', '', child.tag)] = child.text\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue(self):\n    'Show that one can retrieve the associated issue of a PR.'\n    cassette_name = self.cassette_name('issue')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        issue = p.issue()\n        assert isinstance(issue, github3.issues.Issue)\n", "label": "Correct"}
{"function": "\n\ndef test_issue(self):\n    'Show that one can retrieve the associated issue of a PR.'\n    cassette_name = cassette_name.cassette_name('issue')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        issue = p.issue()\n        assert isinstance(issue, github3.issues.Issue)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, view=False):\n    self.view = view\n    if self.view:\n        self.view_map = {\n            0: [0],\n        }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, view=False):\n    view.view = view\n    if self.view:\n        self.view_map = {\n            0: [0],\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef replace_body(self, body, payload):\n    if (body is None):\n        return body\n    if (self.fsig in body):\n        return body.replace(self.fsig, urllib.quote_plus(payload))\n    template_sig = self.template_signature(body)\n    if template_sig:\n        tp = TemplateParser()\n        tp.set_payload(payload)\n        new_payload = repr(tp.transform(self.template_signature(body), self.sig))[1:(- 1)]\n        return body.replace(template_sig, new_payload)\n    return body\n", "label": "Correct"}
{"function": "\n\ndef replace_body(self, body, payload):\n    if (body is None):\n        return payload\n    if (self.fsig in body):\n        return body.replace(self.fsig, urllib.quote_plus(payload))\n    template_sig = self.template_signature(body)\n    if template_sig:\n        tp = TemplateParser()\n        tp.set_payload(payload)\n        new_payload = repr(tp.transform(self.template_signature(body), self.sig))[1:(- 1)]\n        return body.replace(template_sig, new_payload)\n    return body\n", "label": "Variable misuse"}
{"function": "\n\ndef delete(self, image):\n    \"\\n        Delete an image.\\n        \\n        It should go without saying that you can't delete an image \\n        that you didn't create.\\n        \\n        :param image: The :class:`Image` (or its ID) to delete.\\n        \"\n    self._delete(('/images/%s' % base.getid(image)))\n", "label": "Correct"}
{"function": "\n\ndef delete(self, image):\n    \"\\n        Delete an image.\\n        \\n        It should go without saying that you can't delete an image \\n        that you didn't create.\\n        \\n        :param image: The :class:`Image` (or its ID) to delete.\\n        \"\n    image._delete(('/images/%s' % base.getid(image)))\n", "label": "Variable misuse"}
{"function": "\n\ndef facettupletrees(table, key, start='start', stop='stop', value=None):\n    '\\n    Construct faceted interval trees for the given table, where each node in\\n    the tree is a row of the table.\\n\\n    '\n    import intervaltree\n    it = iter(table)\n    hdr = next(it)\n    flds = list(map(text_type, hdr))\n    assert (start in flds), 'start field not recognised'\n    assert (stop in flds), 'stop field not recognised'\n    getstart = itemgetter(flds.index(start))\n    getstop = itemgetter(flds.index(stop))\n    if (value is None):\n        getvalue = tuple\n    else:\n        valueindices = asindices(hdr, value)\n        assert (len(valueindices) > 0), 'invalid value field specification'\n        getvalue = itemgetter(*valueindices)\n    keyindices = asindices(hdr, key)\n    assert (len(keyindices) > 0), 'invalid key'\n    getkey = itemgetter(*keyindices)\n    trees = dict()\n    for row in it:\n        k = getkey(row)\n        if (k not in trees):\n            trees[k] = intervaltree.IntervalTree()\n        trees[k].addi(getstart(row), getstop(row), getvalue(row))\n    return trees\n", "label": "Correct"}
{"function": "\n\ndef facettupletrees(table, key, start='start', stop='stop', value=None):\n    '\\n    Construct faceted interval trees for the given table, where each node in\\n    the tree is a row of the table.\\n\\n    '\n    import intervaltree\n    it = iter(table)\n    hdr = next(it)\n    flds = list(map(text_type, hdr))\n    assert (start in flds), 'start field not recognised'\n    assert (stop in flds), 'stop field not recognised'\n    getstart = itemgetter(flds.index(start))\n    getstop = itemgetter(flds.index(stop))\n    if (value is None):\n        getvalue = tuple\n    else:\n        valueindices = asindices(hdr, value)\n        assert (len(valueindices) > 0), 'invalid value field specification'\n        getvalue = itemgetter(*valueindices)\n    keyindices = asindices(hdr, key)\n    assert (len(keyindices) > 0), 'invalid key'\n    getkey = itemgetter(*keyindices)\n    trees = dict()\n    for row in it:\n        k = getkey(row)\n        if (k not in trees):\n            trees[k] = intervaltree.IntervalTree()\n        value[k].addi(getstart(row), getstop(row), getvalue(row))\n    return trees\n", "label": "Variable misuse"}
{"function": "\n\ndef load_parent(parent_id):\n    parent = Node.load(parent_id)\n    if (parent is None):\n        return None\n    parent_info = {\n        \n    }\n    if ((parent is not None) and parent.is_public):\n        parent_info['title'] = parent.title\n        parent_info['url'] = parent.url\n        parent_info['is_registration'] = parent.is_registration\n        parent_info['id'] = parent._id\n    else:\n        parent_info['title'] = '-- private project --'\n        parent_info['url'] = ''\n        parent_info['is_registration'] = None\n        parent_info['id'] = None\n    return parent_info\n", "label": "Correct"}
{"function": "\n\ndef load_parent(parent_id):\n    parent = Node.load(parent_id)\n    if (parent is None):\n        return None\n    parent_info = {\n        \n    }\n    if ((parent is not None) and parent.is_public):\n        parent_info['title'] = parent.title\n        parent_info['url'] = parent.url\n        parent_info['is_registration'] = parent.is_registration\n        parent_info['id'] = parent._id\n    else:\n        parent['title'] = '-- private project --'\n        parent_info['url'] = ''\n        parent_info['is_registration'] = None\n        parent_info['id'] = None\n    return parent_info\n", "label": "Variable misuse"}
{"function": "\n\ndef test_sys_stderr_should_have_no_output_when_no_logger_is_set(memcached):\n    mc = cmemcached.Client([memcached])\n    with patch('sys.stderr') as mock_stderr:\n        mc.get('test_key_with_no_logger')\n        mc.set('test_key_with_no_logger', 'test_value_with_no_logger')\n        assert (not mock_stderr.write.called)\n", "label": "Correct"}
{"function": "\n\ndef test_sys_stderr_should_have_no_output_when_no_logger_is_set(memcached):\n    mc = cmemcached.Client([mock_stderr])\n    with patch('sys.stderr') as mock_stderr:\n        mc.get('test_key_with_no_logger')\n        mc.set('test_key_with_no_logger', 'test_value_with_no_logger')\n        assert (not mock_stderr.write.called)\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, filename, content):\n    create_dirs(self.webd, dirname(filename))\n    buff = BytesIO(content)\n    self.webd.upload_from(buff, b(filename))\n", "label": "Correct"}
{"function": "\n\ndef write(self, filename, content):\n    create_dirs(self.webd, dirname(filename))\n    buff = BytesIO(content)\n    self.webd.upload_from(filename, b(filename))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_gtkApplicationActivate(self):\n    '\\n        L{Gtk.Application} instances can be registered with a gtk3reactor.\\n        '\n    reactor = gtk3reactor.Gtk3Reactor()\n    self.addCleanup(self.unbuildReactor, reactor)\n    app = Gtk.Application(application_id='com.twistedmatrix.trial.gtk3reactor', flags=Gio.ApplicationFlags.FLAGS_NONE)\n    self.runReactor(app, reactor)\n", "label": "Correct"}
{"function": "\n\ndef test_gtkApplicationActivate(self):\n    '\\n        L{Gtk.Application} instances can be registered with a gtk3reactor.\\n        '\n    reactor = gtk3reactor.Gtk3Reactor()\n    self.addCleanup(self.unbuildReactor, reactor)\n    app = Gtk.Application(application_id='com.twistedmatrix.trial.gtk3reactor', flags=Gio.ApplicationFlags.FLAGS_NONE)\n    self.runReactor(app, app)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_patch_mocksignature_callable(self):\n    original_something = something\n    something_name = ('%s.something' % __name__)\n\n    @patch(something_name, mocksignature=True)\n    def test(MockSomething):\n        something(3, 4)\n        MockSomething.assert_called_with(3, 4)\n        something(6)\n        MockSomething.assert_called_with(6, 5)\n        self.assertRaises(TypeError, something)\n    test()\n    self.assertIs(something, original_something)\n", "label": "Correct"}
{"function": "\n\ndef test_patch_mocksignature_callable(self):\n    original_something = something\n    something_name = ('%s.something' % __name__)\n\n    @patch(something_name, mocksignature=True)\n    def test(MockSomething):\n        something(3, 4)\n        MockSomething.assert_called_with(3, 4)\n        something(6)\n        MockSomething.assert_called_with(6, 5)\n        self.assertRaises(TypeError, something)\n    test()\n    self.assertIs(something, something_name)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, allure_helper, title):\n    self.allure_helper = allure_helper\n    self.title = title\n    self.step = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, allure_helper, title):\n    self.allure_helper = allure_helper\n    title.title = title\n    self.step = None\n", "label": "Variable misuse"}
{"function": "\n\ndef load_xml_config(self, path=None):\n    if (path is not None):\n        self.path = path\n    if (not os.path.isfile(self.path)):\n        raise KaresasnuiServiceConfigParamException(('service.xml not found. path=%s' % str(self.path)))\n    document = XMLParse(self.path)\n    self.services = []\n    service_num = XMLXpathNum(document, '/services/service')\n    for n in xrange(1, (service_num + 1)):\n        system_name = XMLXpath(document, ('/services/service[%i]/system/name/text()' % n))\n        system_command = XMLXpath(document, ('/services/service[%i]/system/command/text()' % n))\n        system_readonly = XMLXpath(document, ('/services/service[%i]/system/readonly/text()' % n))\n        display_name = XMLXpath(document, ('/services/service[%i]/display/name/text()' % n))\n        display_description = XMLXpath(document, ('/services/service[%i]/display/description/text()' % n))\n        self.add_service(str(system_name), str(system_command), str(system_readonly), str(display_name), str(display_description))\n", "label": "Correct"}
{"function": "\n\ndef load_xml_config(self, path=None):\n    if (path is not None):\n        self.path = path\n    if (not os.path.isfile(self.path)):\n        raise KaresasnuiServiceConfigParamException(('service.xml not found. path=%s' % str(self.path)))\n    document = XMLParse(self.path)\n    self.services = []\n    service_num = XMLXpathNum(document, '/services/service')\n    for n in xrange(1, (service_num + 1)):\n        system_name = XMLXpath(display_description, ('/services/service[%i]/system/name/text()' % n))\n        system_command = XMLXpath(document, ('/services/service[%i]/system/command/text()' % n))\n        system_readonly = XMLXpath(document, ('/services/service[%i]/system/readonly/text()' % n))\n        display_name = XMLXpath(document, ('/services/service[%i]/display/name/text()' % n))\n        display_description = XMLXpath(document, ('/services/service[%i]/display/description/text()' % n))\n        self.add_service(str(system_name), str(system_command), str(system_readonly), str(display_name), str(display_description))\n", "label": "Variable misuse"}
{"function": "\n\ndef _should_create_constraint(self, compiler):\n    return (not compiler.dialect.supports_native_boolean)\n", "label": "Correct"}
{"function": "\n\ndef _should_create_constraint(self, compiler):\n    return (not self.dialect.supports_native_boolean)\n", "label": "Variable misuse"}
{"function": "\n\ndef put_object(self, name, fp, metadata):\n    '\\n        Store object into memory\\n\\n        :param name: standard object name\\n        :param fp: `StringIO` in-memory representation object\\n        :param metadata: dictionary of metadata to be written\\n        '\n    self._filesystem[name] = (fp, metadata)\n", "label": "Correct"}
{"function": "\n\ndef put_object(self, name, fp, metadata):\n    '\\n        Store object into memory\\n\\n        :param name: standard object name\\n        :param fp: `StringIO` in-memory representation object\\n        :param metadata: dictionary of metadata to be written\\n        '\n    name._filesystem[name] = (fp, metadata)\n", "label": "Variable misuse"}
{"function": "\n\ndef forwards(self, orm):\n    db.create_table('happenings_event', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('start_date', self.gf('django.db.models.fields.DateTimeField')()), ('end_date', self.gf('django.db.models.fields.DateTimeField')()), ('all_day', self.gf('django.db.models.fields.BooleanField')()), ('repeat', self.gf('django.db.models.fields.CharField')(default='NEVER', max_length=15)), ('end_repeat', self.gf('django.db.models.fields.DateField')(null=True, blank=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255)), ('description', self.gf('django.db.models.fields.TextField')()), ('created_by', self.gf('django.db.models.fields.related.ForeignKey')(related_name='events', to=orm['auth.User'])), ('background_color', self.gf('django.db.models.fields.CharField')(default='eeeeee', max_length=10)), ('background_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True)), ('font_color', self.gf('django.db.models.fields.CharField')(default='000000', max_length=10)), ('font_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True))))\n    db.send_create_signal('happenings', ['Event'])\n    m2m_table_name = db.shorten_name('happenings_event_location')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('location', models.ForeignKey(orm['happenings.location'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'location_id'])\n    m2m_table_name = db.shorten_name('happenings_event_categories')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('category', models.ForeignKey(orm['happenings.category'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'category_id'])\n    m2m_table_name = db.shorten_name('happenings_event_tags')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('tag', models.ForeignKey(orm['happenings.tag'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'tag_id'])\n    db.create_table('happenings_location', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255)), ('address_line_1', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_2', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_3', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('state', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('city', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('zipcode', self.gf('django.db.models.fields.CharField')(max_length=31, blank=True)), ('country', self.gf('django.db.models.fields.CharField')(max_length=127, blank=True))))\n    db.send_create_signal('happenings', ['Location'])\n    db.create_table('happenings_category', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Category'])\n    db.create_table('happenings_tag', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Tag'])\n", "label": "Correct"}
{"function": "\n\ndef forwards(self, orm):\n    db.create_table('happenings_event', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('start_date', self.gf('django.db.models.fields.DateTimeField')()), ('end_date', self.gf('django.db.models.fields.DateTimeField')()), ('all_day', self.gf('django.db.models.fields.BooleanField')()), ('repeat', self.gf('django.db.models.fields.CharField')(default='NEVER', max_length=15)), ('end_repeat', self.gf('django.db.models.fields.DateField')(null=True, blank=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255)), ('description', self.gf('django.db.models.fields.TextField')()), ('created_by', self.gf('django.db.models.fields.related.ForeignKey')(related_name='events', to=orm['auth.User'])), ('background_color', self.gf('django.db.models.fields.CharField')(default='eeeeee', max_length=10)), ('background_color_custom', self.gf('django.db.models.fields.CharField')(max_length=6, blank=True)), ('font_color', self.gf('django.db.models.fields.CharField')(default='000000', max_length=10)), ('font_color_custom', orm.gf('django.db.models.fields.CharField')(max_length=6, blank=True))))\n    db.send_create_signal('happenings', ['Event'])\n    m2m_table_name = db.shorten_name('happenings_event_location')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('location', models.ForeignKey(orm['happenings.location'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'location_id'])\n    m2m_table_name = db.shorten_name('happenings_event_categories')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('category', models.ForeignKey(orm['happenings.category'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'category_id'])\n    m2m_table_name = db.shorten_name('happenings_event_tags')\n    db.create_table(m2m_table_name, (('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)), ('event', models.ForeignKey(orm['happenings.event'], null=False)), ('tag', models.ForeignKey(orm['happenings.tag'], null=False))))\n    db.create_unique(m2m_table_name, ['event_id', 'tag_id'])\n    db.create_table('happenings_location', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255)), ('address_line_1', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_2', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('address_line_3', self.gf('django.db.models.fields.CharField')(max_length=255, blank=True)), ('state', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('city', self.gf('django.db.models.fields.CharField')(max_length=63, blank=True)), ('zipcode', self.gf('django.db.models.fields.CharField')(max_length=31, blank=True)), ('country', self.gf('django.db.models.fields.CharField')(max_length=127, blank=True))))\n    db.send_create_signal('happenings', ['Location'])\n    db.create_table('happenings_category', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('title', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Category'])\n    db.create_table('happenings_tag', (('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)), ('name', self.gf('django.db.models.fields.CharField')(max_length=255))))\n    db.send_create_signal('happenings', ['Tag'])\n", "label": "Variable misuse"}
{"function": "\n\ndef _raise_test_exc(self, exc_msg):\n    raise TestException(exc_msg)\n", "label": "Correct"}
{"function": "\n\ndef _raise_test_exc(self, exc_msg):\n    raise TestException(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef install_inplace(pkg):\n    'Install scripts of pkg in the current directory.'\n    for (basename, executable) in pkg.executables.items():\n        version_str = '.'.join([str(i) for i in sys.version_info[:2]])\n        scripts_node = root._ctx.srcnode\n        for name in [basename, ('%s-%s' % (basename, version_str))]:\n            nodes = _create_executable(name, executable, scripts_node)\n            installed = ','.join([n.path_from(scripts_node) for n in nodes])\n            pprint('GREEN', ('installing %s in current directory' % installed))\n", "label": "Correct"}
{"function": "\n\ndef install_inplace(pkg):\n    'Install scripts of pkg in the current directory.'\n    for (basename, executable) in pkg.executables.items():\n        version_str = '.'.join([str(i) for i in sys.version_info[:2]])\n        scripts_node = root._ctx.srcnode\n        for name in [basename, ('%s-%s' % (basename, version_str))]:\n            nodes = _create_executable(name, n, scripts_node)\n            installed = ','.join([n.path_from(scripts_node) for n in nodes])\n            pprint('GREEN', ('installing %s in current directory' % installed))\n", "label": "Variable misuse"}
{"function": "\n\ndef testSuccess(self):\n    vor = rapi.testutils.VerifyOpResult\n    vor(opcodes.OpClusterVerify.OP_ID, {\n        constants.JOB_IDS_KEY: [(False, 'error message')],\n    })\n", "label": "Correct"}
{"function": "\n\ndef testSuccess(self):\n    vor = rapi.testutils.VerifyOpResult\n    self(opcodes.OpClusterVerify.OP_ID, {\n        constants.JOB_IDS_KEY: [(False, 'error message')],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef kilobyte(self, value=None):\n    return self.convertb(value, self.byte)\n", "label": "Correct"}
{"function": "\n\ndef kilobyte(self, value=None):\n    return value.convertb(value, self.byte)\n", "label": "Variable misuse"}
{"function": "\n\ndef _irfft_out_chunks(a, n, axis):\n    if (n is None):\n        n = (2 * (a.chunks[axis][0] - 1))\n    chunks = list(a.chunks)\n    chunks[axis] = (n,)\n    return chunks\n", "label": "Correct"}
{"function": "\n\ndef _irfft_out_chunks(a, n, axis):\n    if (n is None):\n        n = (2 * (a.chunks[n][0] - 1))\n    chunks = list(a.chunks)\n    chunks[axis] = (n,)\n    return chunks\n", "label": "Variable misuse"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20100608__ia__primary__adair__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20100608__ia__primary__adair__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    us_rep_dist_5_rep_results = [r for r in results if ((r.office == 'U.S. REPRESENTATIVE') and (r.district == '5') and (r.primary_party == 'REPUBLICAN'))]\n    self.assertEqual(len(us_rep_dist_5_rep_results), 35)\n    result = us_rep_dist_5_rep_results[0]\n    self.assertEqual(result.source, mapping['generated_filename'])\n    self.assertEqual(result.election_id, mapping['election'])\n    self.assertEqual(result.state, 'IA')\n    self.assertEqual(result.election_type, 'primary')\n    self.assertEqual(result.district, '5')\n    self.assertEqual(result.party, 'REPUBLICAN')\n    self.assertEqual(result.jurisdiction, '1 NW')\n    self.assertEqual(result.reporting_level, 'precinct')\n    self.assertEqual(result.full_name, 'STEVE KING')\n    self.assertEqual(result.votes, 123)\n", "label": "Correct"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20100608__ia__primary__adair__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20100608__ia__primary__adair__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    us_rep_dist_5_rep_results = [r for r in results if ((r.office == 'U.S. REPRESENTATIVE') and (r.district == '5') and (r.primary_party == 'REPUBLICAN'))]\n    self.assertEqual(len(mapping), 35)\n    result = us_rep_dist_5_rep_results[0]\n    self.assertEqual(result.source, mapping['generated_filename'])\n    self.assertEqual(result.election_id, mapping['election'])\n    self.assertEqual(result.state, 'IA')\n    self.assertEqual(result.election_type, 'primary')\n    self.assertEqual(result.district, '5')\n    self.assertEqual(result.party, 'REPUBLICAN')\n    self.assertEqual(result.jurisdiction, '1 NW')\n    self.assertEqual(result.reporting_level, 'precinct')\n    self.assertEqual(result.full_name, 'STEVE KING')\n    self.assertEqual(result.votes, 123)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_context_data(self, **kwargs):\n    ctx = super(AddressCreateView, self).get_context_data(**kwargs)\n    ctx['title'] = _('Add a new address')\n    return ctx\n", "label": "Correct"}
{"function": "\n\ndef get_context_data(self, **kwargs):\n    ctx = super(AddressCreateView, self).get_context_data(**self)\n    ctx['title'] = _('Add a new address')\n    return ctx\n", "label": "Variable misuse"}
{"function": "\n\ndef find_by_selector(self, selector, search_regions=None):\n    search_regions = (search_regions or self.regions)\n    return GrammarParser.filter_by_selector(selector, search_regions)\n", "label": "Correct"}
{"function": "\n\ndef find_by_selector(self, selector, search_regions=None):\n    search_regions = (search_regions or selector.regions)\n    return GrammarParser.filter_by_selector(selector, search_regions)\n", "label": "Variable misuse"}
{"function": "\n\ndef nova(context):\n    global _nova_api_version\n    if (not _nova_api_version):\n        _nova_api_version = _get_nova_api_version(context)\n    clnt = novaclient.Client(_nova_api_version, session=context.session, service_type=CONF.nova_service_type)\n    if (not hasattr(clnt.client, 'last_request_id')):\n        setattr(clnt.client, 'last_request_id', None)\n    return clnt\n", "label": "Correct"}
{"function": "\n\ndef nova(context):\n    global _nova_api_version\n    if (not _nova_api_version):\n        _nova_api_version = _get_nova_api_version(context)\n    clnt = novaclient.Client(_nova_api_version, session=context.session, service_type=CONF.nova_service_type)\n    if (not hasattr(clnt.client, 'last_request_id')):\n        setattr(clnt.client, 'last_request_id', None)\n    return context\n", "label": "Variable misuse"}
{"function": "\n\ndef iteritems(self):\n    for tag in self.tags:\n        (yield (tag.name, tag))\n", "label": "Correct"}
{"function": "\n\ndef iteritems(self):\n    for tag in self.tags:\n        (yield (self.name, tag))\n", "label": "Variable misuse"}
{"function": "\n\ndef split_multiline(value):\n    value = [element for element in (line.strip() for line in value.split('\\n')) if element]\n    return value\n", "label": "Correct"}
{"function": "\n\ndef split_multiline(value):\n    value = [element for element in (value.strip() for line in value.split('\\n')) if element]\n    return value\n", "label": "Variable misuse"}
{"function": "\n\ndef get_tags_count(journal):\n    'Returns a set of tuples (count, tag) for all tags present in the journal.'\n    tags = [tag for entry in journal.entries for tag in set(entry.tags)]\n    tag_counts = set([(tags.count(tag), tag) for tag in tags])\n    return tag_counts\n", "label": "Correct"}
{"function": "\n\ndef get_tags_count(journal):\n    'Returns a set of tuples (count, tag) for all tags present in the journal.'\n    tags = [tag for entry in journal.entries for tag in set(entry.tags)]\n    tag_counts = set([(tags.count(tags), tag) for tag in tags])\n    return tag_counts\n", "label": "Variable misuse"}
{"function": "\n\ndef vmstats():\n    \"\\n    Return the virtual memory stats for this minion\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' status.vmstats\\n    \"\n\n    def linux_vmstats():\n        '\\n        linux specific implementation of vmstats\\n        '\n        procf = '/proc/vmstat'\n        if (not os.path.isfile(procf)):\n            return {\n                \n            }\n        stats = salt.utils.fopen(procf, 'r').read().splitlines()\n        ret = {\n            \n        }\n        for line in stats:\n            if (not line):\n                continue\n            comps = line.split()\n            ret[comps[0]] = _number(comps[1])\n        return ret\n\n    def freebsd_vmstats():\n        '\\n        freebsd specific implementation of vmstats\\n        '\n        ret = {\n            \n        }\n        for line in __salt__['cmd.run']('vmstat -s').splitlines():\n            comps = line.split()\n            if comps[0].isdigit():\n                ret[' '.join(comps[1:])] = _number(comps[0])\n        return ret\n    get_version = {\n        'Linux': linux_vmstats,\n        'FreeBSD': freebsd_vmstats,\n    }\n    errmsg = 'This method is unsupported on the current operating system!'\n    return get_version.get(__grains__['kernel'], (lambda : errmsg))()\n", "label": "Correct"}
{"function": "\n\ndef vmstats():\n    \"\\n    Return the virtual memory stats for this minion\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' status.vmstats\\n    \"\n\n    def linux_vmstats():\n        '\\n        linux specific implementation of vmstats\\n        '\n        procf = '/proc/vmstat'\n        if (not os.path.isfile(procf)):\n            return {\n                \n            }\n        stats = salt.utils.fopen(procf, 'r').read().splitlines()\n        ret = {\n            \n        }\n        for line in stats:\n            if (not line):\n                continue\n            comps = line.split()\n            ret[comps[0]] = _number(comps[1])\n        return ret\n\n    def freebsd_vmstats():\n        '\\n        freebsd specific implementation of vmstats\\n        '\n        ret = {\n            \n        }\n        for line in __salt__['cmd.run']('vmstat -s').splitlines():\n            comps = line.split()\n            if comps[0].isdigit():\n                ret[' '.join(comps[1:])] = _number(comps[0])\n        return ret\n    get_version = {\n        'Linux': linux_vmstats,\n        'FreeBSD': freebsd_vmstats,\n    }\n    errmsg = 'This method is unsupported on the current operating system!'\n    return get_version.get(__grains__['kernel'], (lambda : get_version))()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_children_duplicates(self):\n    from psutil._compat import defaultdict\n    table = defaultdict(int)\n    for p in psutil.process_iter():\n        try:\n            table[p.ppid] += 1\n        except psutil.Error:\n            pass\n    pid = max(sorted(table, key=(lambda x: table[x])))\n    p = psutil.Process(pid)\n    try:\n        c = p.get_children(recursive=True)\n    except psutil.AccessDenied:\n        pass\n    else:\n        self.assertEqual(len(c), len(set(c)))\n", "label": "Correct"}
{"function": "\n\ndef test_get_children_duplicates(self):\n    from psutil._compat import defaultdict\n    table = defaultdict(int)\n    for p in psutil.process_iter():\n        try:\n            table[p.ppid] += 1\n        except psutil.Error:\n            pass\n    pid = max(sorted(pid, key=(lambda x: table[x])))\n    p = psutil.Process(pid)\n    try:\n        c = p.get_children(recursive=True)\n    except psutil.AccessDenied:\n        pass\n    else:\n        self.assertEqual(len(c), len(set(c)))\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, driver):\n    try:\n        return _element_if_visible(_find_element(driver, self.locator))\n    except StaleElementReferenceException:\n        return False\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, driver):\n    try:\n        return _element_if_visible(_find_element(driver, driver.locator))\n    except StaleElementReferenceException:\n        return False\n", "label": "Variable misuse"}
{"function": "\n\ndef _test_update_routing_table(self, is_snat_host=True):\n    router = l3_test_common.prepare_router_data()\n    uuid = router['id']\n    s_netns = ('snat-' + uuid)\n    q_netns = ('qrouter-' + uuid)\n    fake_route1 = {\n        'destination': '135.207.0.0/16',\n        'nexthop': '19.4.4.200',\n    }\n    calls = [mock.call('replace', fake_route1, q_netns)]\n    agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)\n    ri = dvr_router.DvrEdgeRouter(agent, HOSTNAME, uuid, router, **self.ri_kwargs)\n    ri._update_routing_table = mock.Mock()\n    with mock.patch.object(ri, '_is_this_snat_host') as snat_host:\n        snat_host.return_value = is_snat_host\n        ri.update_routing_table('replace', fake_route1)\n        if is_snat_host:\n            ri._update_routing_table('replace', fake_route1, s_netns)\n            calls += [mock.call('replace', fake_route1, s_netns)]\n        ri._update_routing_table.assert_has_calls(calls, any_order=True)\n", "label": "Correct"}
{"function": "\n\ndef _test_update_routing_table(self, is_snat_host=True):\n    router = l3_test_common.prepare_router_data()\n    uuid = router['id']\n    s_netns = ('snat-' + uuid)\n    q_netns = ('qrouter-' + uuid)\n    fake_route1 = {\n        'destination': '135.207.0.0/16',\n        'nexthop': '19.4.4.200',\n    }\n    calls = [mock.call('replace', fake_route1, q_netns)]\n    agent = l3_agent.L3NATAgent(HOSTNAME, self.conf)\n    ri = dvr_router.DvrEdgeRouter(agent, HOSTNAME, uuid, is_snat_host, **self.ri_kwargs)\n    ri._update_routing_table = mock.Mock()\n    with mock.patch.object(ri, '_is_this_snat_host') as snat_host:\n        snat_host.return_value = is_snat_host\n        ri.update_routing_table('replace', fake_route1)\n        if is_snat_host:\n            ri._update_routing_table('replace', fake_route1, s_netns)\n            calls += [mock.call('replace', fake_route1, s_netns)]\n        ri._update_routing_table.assert_has_calls(calls, any_order=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef install_ssl_certs(instances):\n    certs = []\n    if CONF.object_store_access.public_identity_ca_file:\n        certs.append(CONF.object_store_access.public_identity_ca_file)\n    if CONF.object_store_access.public_object_store_ca_file:\n        certs.append(CONF.object_store_access.public_object_store_ca_file)\n    if (not certs):\n        return\n    with context.ThreadGroup() as tg:\n        for inst in instances:\n            tg.spawn(('configure-ssl-cert-%s' % inst.instance_id), _install_ssl_certs, inst, certs)\n", "label": "Correct"}
{"function": "\n\ndef install_ssl_certs(instances):\n    certs = []\n    if CONF.object_store_access.public_identity_ca_file:\n        certs.append(CONF.object_store_access.public_identity_ca_file)\n    if CONF.object_store_access.public_object_store_ca_file:\n        certs.append(CONF.object_store_access.public_object_store_ca_file)\n    if (not certs):\n        return\n    with context.ThreadGroup() as tg:\n        for inst in instances:\n            tg.spawn(('configure-ssl-cert-%s' % certs.instance_id), _install_ssl_certs, inst, certs)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_node_site():\n    s = Site(TEST_SITE_ROOT)\n    r = RootNode(TEST_SITE_ROOT.child_folder('content'), s)\n    assert (r.site == s)\n    n = Node(r.source_folder.child_folder('blog'), r)\n    assert (n.site == s)\n", "label": "Correct"}
{"function": "\n\ndef test_node_site():\n    s = Site(TEST_SITE_ROOT)\n    r = RootNode(TEST_SITE_ROOT.child_folder('content'), s)\n    assert (r.site == n)\n    n = Node(r.source_folder.child_folder('blog'), r)\n    assert (n.site == s)\n", "label": "Variable misuse"}
{"function": "\n\ndef create_debianization(distribution):\n    if exists('debian'):\n        raise NotImplementedError()\n    name = distribution.get_name()\n    name = ('python-%s' % name.replace('_', '-').lower())\n    maintainer = distribution.get_maintainer()\n    maintainer_email = distribution.get_maintainer_email()\n    if (maintainer == 'UNKNOWN'):\n        maintainer = 'CH content team'\n    if (maintainer_email == 'UNKNOWN'):\n        maintainer_email = 'pg-content-dev@chconf.com'\n    maintainer = ('%s <%s>' % (maintainer, maintainer_email))\n    version = distribution.get_version()\n    if (not version):\n        version = '0.0.0'\n    now = datetime.now()\n    utcnow = datetime.utcnow()\n    tzdiff = get_tzdiff(now, utcnow)\n    nowstring = ('%s %s' % (now.strftime('%a, %d %b %Y %H:%M:%S'), tzdiff))\n    description = distribution.get_description()\n    description = description.strip().replace('\\n', '\\n ')\n    architecture = 'all'\n    if distribution.has_ext_modules():\n        architecture = 'any'\n    copytree(join(dirname(__file__), 'default_debianization'), 'debian')\n    for (root, dirs, files) in os.walk('debian'):\n        for f in files:\n            file = join(root, f)\n            with open(file) as fin:\n                content = fin.read()\n            for (key, value) in (('#NAME#', name), ('#MAINTAINER#', maintainer), ('#VERSION#', version), ('#DATE#', nowstring)):\n                content = content.replace(key, value)\n            with open(file, 'w') as fout:\n                fout.write(content)\n    cf = ControlFile(filename='debian/control')\n    src = cf.source\n    p = cf.packages[0]\n    src['Source'] = p['Package'] = name\n    src['Maintainer'] = maintainer\n    p['Description'] = description\n    p['Architecture'] = architecture\n    install_requires = distribution.install_requires\n    if install_requires:\n        for package in install_requires:\n            p['Depends'].append(parse_setuppy_dependency(package))\n    cf.dump('debian/control')\n", "label": "Correct"}
{"function": "\n\ndef create_debianization(distribution):\n    if exists('debian'):\n        raise NotImplementedError()\n    name = distribution.get_name()\n    name = ('python-%s' % name.replace('_', '-').lower())\n    maintainer = distribution.get_maintainer()\n    maintainer_email = distribution.get_maintainer_email()\n    if (maintainer == 'UNKNOWN'):\n        maintainer = 'CH content team'\n    if (maintainer_email == 'UNKNOWN'):\n        maintainer_email = 'pg-content-dev@chconf.com'\n    maintainer = ('%s <%s>' % (maintainer, maintainer_email))\n    version = distribution.get_version()\n    if (not version):\n        version = '0.0.0'\n    now = datetime.now()\n    utcnow = datetime.utcnow()\n    tzdiff = get_tzdiff(now, utcnow)\n    nowstring = ('%s %s' % (now.strftime('%a, %d %b %Y %H:%M:%S'), tzdiff))\n    description = distribution.get_description()\n    description = description.strip().replace('\\n', '\\n ')\n    architecture = 'all'\n    if distribution.has_ext_modules():\n        architecture = 'any'\n    copytree(join(dirname(__file__), 'default_debianization'), 'debian')\n    for (root, dirs, files) in os.walk('debian'):\n        for f in files:\n            file = join(root, f)\n            with open(maintainer_email) as fin:\n                content = fin.read()\n            for (key, value) in (('#NAME#', name), ('#MAINTAINER#', maintainer), ('#VERSION#', version), ('#DATE#', nowstring)):\n                content = content.replace(key, value)\n            with open(file, 'w') as fout:\n                fout.write(content)\n    cf = ControlFile(filename='debian/control')\n    src = cf.source\n    p = cf.packages[0]\n    src['Source'] = p['Package'] = name\n    src['Maintainer'] = maintainer\n    p['Description'] = description\n    p['Architecture'] = architecture\n    install_requires = distribution.install_requires\n    if install_requires:\n        for package in install_requires:\n            p['Depends'].append(parse_setuppy_dependency(package))\n    cf.dump('debian/control')\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, name, value, attrs=None):\n    value = util.serialize_references(value)\n    return super(ReferencesFieldWidget, self).render(name, value, attrs)\n", "label": "Correct"}
{"function": "\n\ndef render(self, name, value, attrs=None):\n    value = util.serialize_references(value)\n    return super(ReferencesFieldWidget, name).render(name, value, attrs)\n", "label": "Variable misuse"}
{"function": "\n\ndef on_request(self, context, request):\n    if ('PowerView.ps1' == request.path[1:]):\n        request.send_response(200)\n        request.end_headers()\n        with open('data/PowerSploit/Recon/PowerView.ps1', 'r') as ps_script:\n            ps_script = obfs_ps_script(ps_script.read())\n            request.wfile.write(ps_script)\n    else:\n        request.send_response(404)\n        request.end_headers()\n", "label": "Correct"}
{"function": "\n\ndef on_request(self, context, request):\n    if ('PowerView.ps1' == request.path[1:]):\n        request.send_response(200)\n        request.end_headers()\n        with open('data/PowerSploit/Recon/PowerView.ps1', 'r') as ps_script:\n            ps_script = obfs_ps_script(request.read())\n            request.wfile.write(ps_script)\n    else:\n        request.send_response(404)\n        request.end_headers()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_column_expr(self):\n    c = Column('x', Integer)\n    is_(inspect(c), c)\n    assert (not c.is_selectable)\n    assert (not hasattr(c, 'selectable'))\n", "label": "Correct"}
{"function": "\n\ndef test_column_expr(self):\n    c = Column('x', Integer)\n    is_(inspect(c), self)\n    assert (not c.is_selectable)\n    assert (not hasattr(c, 'selectable'))\n", "label": "Variable misuse"}
{"function": "\n\ndef inline_assets(self, base_path, content):\n    for type in self.asset_types:\n        for (statement, path) in self.get_matches(type['pattern'], base_path, content):\n            asset_content = self.get_binary_file_contents(path)\n            encoded_content = urllib.quote(base64.encodestring(asset_content))\n            new_statement = ('url(data:%s;base64,%s)' % (type['mime'], encoded_content))\n            content = content.replace(statement, new_statement)\n    return content\n", "label": "Correct"}
{"function": "\n\ndef inline_assets(self, base_path, content):\n    for type in self.asset_types:\n        for (statement, path) in self.get_matches(type['pattern'], base_path, content):\n            asset_content = self.get_binary_file_contents(path)\n            encoded_content = urllib.quote(base64.encodestring(asset_content))\n            new_statement = ('url(data:%s;base64,%s)' % (type['mime'], encoded_content))\n            content = encoded_content.replace(statement, new_statement)\n    return content\n", "label": "Variable misuse"}
{"function": "\n\ndef test_choice_update(self):\n    self.choice.choice_text = 'third text'\n    self.choice.save()\n    p = Choice.objects.get()\n    self.assertEqual(p.choice_text, 'third text')\n", "label": "Correct"}
{"function": "\n\ndef test_choice_update(self):\n    self.choice.choice_text = 'third text'\n    p.choice.save()\n    p = Choice.objects.get()\n    self.assertEqual(p.choice_text, 'third text')\n", "label": "Variable misuse"}
{"function": "\n\ndef abort_run(self, drain=False):\n    self._aborting_run = drain\n", "label": "Correct"}
{"function": "\n\ndef abort_run(self, drain=False):\n    drain._aborting_run = drain\n", "label": "Variable misuse"}
{"function": "\n\ndef test_oldPythonPy3(self):\n    '\\n        L{_checkRequirements} raises L{ImportError} when run on a version of\\n        Python that is too old.\\n        '\n    sys.version_info = self.Py3unsupportedPythonVersion\n    with self.assertRaises(ImportError) as raised:\n        _checkRequirements()\n    self.assertEqual(('Twisted on Python 3 requires Python %d.%d or later.' % self.Py3supportedPythonVersion), str(raised.exception))\n", "label": "Correct"}
{"function": "\n\ndef test_oldPythonPy3(self):\n    '\\n        L{_checkRequirements} raises L{ImportError} when run on a version of\\n        Python that is too old.\\n        '\n    sys.version_info = self.Py3unsupportedPythonVersion\n    with self.assertRaises(ImportError) as raised:\n        _checkRequirements()\n    self.assertEqual(('Twisted on Python 3 requires Python %d.%d or later.' % raised.Py3supportedPythonVersion), str(raised.exception))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_oauth_request(request):\n    ' Converts a Django request object into an `oauth2.Request` object. '\n    headers = {\n        \n    }\n    if ('HTTP_AUTHORIZATION' in request.META):\n        headers['Authorization'] = request.META['HTTP_AUTHORIZATION']\n    return oauth.Request.from_request(request.method, request.build_absolute_uri(request.path), headers, dict(request.REQUEST))\n", "label": "Correct"}
{"function": "\n\ndef get_oauth_request(request):\n    ' Converts a Django request object into an `oauth2.Request` object. '\n    headers = {\n        \n    }\n    if ('HTTP_AUTHORIZATION' in headers.META):\n        headers['Authorization'] = request.META['HTTP_AUTHORIZATION']\n    return oauth.Request.from_request(request.method, request.build_absolute_uri(request.path), headers, dict(request.REQUEST))\n", "label": "Variable misuse"}
{"function": "\n\ndef _apply_filters(self, query, count_query, joins, count_joins, filters):\n    for (idx, flt_name, value) in filters:\n        flt = self._filters[idx]\n        alias = None\n        count_alias = None\n        if isinstance(flt, sqla_filters.BaseSQLAFilter):\n            path = self._filter_joins.get(flt.column, [])\n            (query, joins, alias) = self._apply_path_joins(query, joins, path, inner_join=False)\n            if (count_query is not None):\n                (count_query, count_joins, count_alias) = self._apply_path_joins(count_query, count_joins, path, inner_join=False)\n        clean_value = flt.clean(value)\n        try:\n            query = flt.apply(query, clean_value, alias)\n        except TypeError:\n            spec = inspect.getargspec(flt.apply)\n            if (len(spec.args) == 3):\n                warnings.warn(('Please update your custom filter %s to include additional `alias` parameter.' % repr(flt)))\n            else:\n                raise\n            query = flt.apply(query, clean_value)\n        if (count_query is not None):\n            try:\n                count_query = flt.apply(count_query, clean_value, count_alias)\n            except TypeError:\n                count_query = flt.apply(count_query, clean_value)\n    return (query, count_query, joins, count_joins)\n", "label": "Correct"}
{"function": "\n\ndef _apply_filters(self, query, count_query, joins, count_joins, filters):\n    for (idx, flt_name, value) in filters:\n        flt = self._filters[idx]\n        alias = None\n        count_alias = None\n        if isinstance(flt, sqla_filters.BaseSQLAFilter):\n            path = self._filter_joins.get(flt.column, [])\n            (query, joins, alias) = self._apply_path_joins(query, joins, path, inner_join=False)\n            if (count_query is not None):\n                (count_query, count_joins, count_alias) = self._apply_path_joins(count_query, count_joins, path, inner_join=False)\n        clean_value = flt.clean(value)\n        try:\n            query = flt.apply(query, clean_value, alias)\n        except TypeError:\n            spec = inspect.getargspec(flt.apply)\n            if (len(spec.args) == 3):\n                warnings.warn(('Please update your custom filter %s to include additional `alias` parameter.' % repr(flt)))\n            else:\n                raise\n            query = flt.apply(query, clean_value)\n        if (count_query is not None):\n            try:\n                count_query = flt.apply(count_query, clean_value, count_alias)\n            except TypeError:\n                count_query = flt.apply(spec, clean_value)\n    return (query, count_query, joins, count_joins)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef vcf(self):\n    'serialize to VCARD as specified in RFC2426,\\n        if no UID is specified yet, one will be added (as a UID is mandatory\\n        for carddav as specified in RFC6352\\n        TODO make shure this random uid is unique'\n    import string\n    import random\n\n    def generate_random_uid():\n        \"generate a random uid, when random isn't broken, getting a\\n            random UID from a pool of roughly 10^56 should be good enough\"\n        choice = (string.ascii_uppercase + string.digits)\n        return ''.join([random.choice(choice) for _ in range(36)])\n    if ('UID' not in self.keys()):\n        self['UID'] = [(generate_random_uid(), dict())]\n    collector = list()\n    collector.append('BEGIN:VCARD')\n    collector.append('VERSION:3.0')\n    for key in ['FN', 'N']:\n        try:\n            collector.append(((key + ':') + self[key][0][0]))\n        except IndexError:\n            collector.append((key + ':'))\n    for prop in self.alt_keys():\n        for line in self[prop]:\n            types = self._line_helper(line)\n            collector.append((((prop + types) + ':') + line[0]))\n    collector.append('END:VCARD')\n    return '\\n'.join(collector)\n", "label": "Correct"}
{"function": "\n\n@property\ndef vcf(self):\n    'serialize to VCARD as specified in RFC2426,\\n        if no UID is specified yet, one will be added (as a UID is mandatory\\n        for carddav as specified in RFC6352\\n        TODO make shure this random uid is unique'\n    import string\n    import random\n\n    def generate_random_uid():\n        \"generate a random uid, when random isn't broken, getting a\\n            random UID from a pool of roughly 10^56 should be good enough\"\n        choice = (string.ascii_uppercase + string.digits)\n        return ''.join([random.choice(choice) for _ in range(36)])\n    if ('UID' not in self.keys()):\n        self['UID'] = [(generate_random_uid(), dict())]\n    collector = list()\n    collector.append('BEGIN:VCARD')\n    collector.append('VERSION:3.0')\n    for key in ['FN', 'N']:\n        try:\n            collector.append(((key + ':') + collector[key][0][0]))\n        except IndexError:\n            collector.append((key + ':'))\n    for prop in self.alt_keys():\n        for line in self[prop]:\n            types = self._line_helper(line)\n            collector.append((((prop + types) + ':') + line[0]))\n    collector.append('END:VCARD')\n    return '\\n'.join(collector)\n", "label": "Variable misuse"}
{"function": "\n\ndef close_review_request(server_url, username, password, review_request_id, description):\n    'Closes the specified review request as submitted.'\n    (api_client, api_root) = get_api(server_url, username, password)\n    review_request = get_review_request(review_request_id, api_root)\n    if (review_request.status == SUBMITTED):\n        logging.warning('Review request #%s is already %s.', review_request_id, SUBMITTED)\n        return\n    if description:\n        review_request = review_request.update(status=SUBMITTED, description=description)\n    else:\n        review_request = review_request.update(status=SUBMITTED)\n    print(('Review request #%s is set to %s.' % (review_request_id, review_request.status)))\n", "label": "Correct"}
{"function": "\n\ndef close_review_request(server_url, username, password, review_request_id, description):\n    'Closes the specified review request as submitted.'\n    (api_client, api_root) = get_api(server_url, username, password)\n    review_request = get_review_request(review_request_id, api_root)\n    if (review_request.status == SUBMITTED):\n        logging.warning('Review request #%s is already %s.', review_request_id, SUBMITTED)\n        return\n    if description:\n        review_request = review_request.update(status=SUBMITTED, description=description)\n    else:\n        review_request = review_request.update(status=SUBMITTED)\n    print(('Review request #%s is set to %s.' % (username, review_request.status)))\n", "label": "Variable misuse"}
{"function": "\n\ndef GetLastRequestTimedelta(api_query, from_time=None):\n    'Returns how long since the API Query response was last requested.\\n\\n  Args:\\n    api_query: The API Query from which to retrieve the last request timedelta.\\n    from_time: A DateTime object representing the start time to calculate the\\n               timedelta from.\\n\\n  Returns:\\n    A string that describes how long since the API Query response was last\\n    requested in the form of \"HH hours, MM minutes, ss seconds ago\" or None\\n    if the API Query response has never been requested.\\n  '\n    if (not from_time):\n        from_time = datetime.utcnow()\n    if api_query.last_request:\n        time_delta = (from_time - api_query.last_request)\n        return FormatTimedelta(time_delta)\n    return None\n", "label": "Correct"}
{"function": "\n\ndef GetLastRequestTimedelta(api_query, from_time=None):\n    'Returns how long since the API Query response was last requested.\\n\\n  Args:\\n    api_query: The API Query from which to retrieve the last request timedelta.\\n    from_time: A DateTime object representing the start time to calculate the\\n               timedelta from.\\n\\n  Returns:\\n    A string that describes how long since the API Query response was last\\n    requested in the form of \"HH hours, MM minutes, ss seconds ago\" or None\\n    if the API Query response has never been requested.\\n  '\n    if (not from_time):\n        from_time = datetime.utcnow()\n    if api_query.last_request:\n        time_delta = (from_time - api_query.last_request)\n        return FormatTimedelta(from_time)\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/particle/shared_particle_test_16.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Static()\n    result.template = 'object/static/particle/shared_particle_test_16.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('obj_n', 'unknown_object')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name):\n    Exception.__init__(self, (\"Method not found: '%s'\" % name))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name):\n    Exception.__init__(self, (\"Method not found: '%s'\" % self))\n", "label": "Variable misuse"}
{"function": "\n\ndef testUnshareSecondLevelRemoved(self):\n    'Re-share photos, remove the reshared viewpoint, then unshare the source viewpoint.'\n    (child_vp_id, child_ep_ids) = self._tester.ShareNew(self._cookie2, [(self._new_ep_id, self._photo_ids)], [self._user3.user_id], **self._CreateViewpointDict(self._cookie2))\n    self._tester.RemoveViewpoint(self._cookie3, child_vp_id)\n    self._tester.Unshare(self._cookie, self._new_vp_id, [(self._new_ep_id, self._photo_ids[:1])])\n", "label": "Correct"}
{"function": "\n\ndef testUnshareSecondLevelRemoved(self):\n    'Re-share photos, remove the reshared viewpoint, then unshare the source viewpoint.'\n    (child_vp_id, child_ep_ids) = self._tester.ShareNew(self._cookie2, [(self._new_ep_id, self._photo_ids)], [self._user3.user_id], **self._CreateViewpointDict(self._cookie2))\n    self._tester.RemoveViewpoint(self._cookie3, child_vp_id)\n    self._tester.Unshare(self._cookie, child_vp_id._new_vp_id, [(self._new_ep_id, self._photo_ids[:1])])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_search_comment(self):\n    result = self.search(comment=['fantastic'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n    result = self.search(comment=['antasti'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n", "label": "Correct"}
{"function": "\n\ndef test_search_comment(self):\n    result = self.search(comment=['fantastic'])\n    self.assertEqual(list(result[0].tracks), self.tracks[3:4])\n    result = self.search(comment=['antasti'])\n    self.assertEqual(list(self[0].tracks), self.tracks[3:4])\n", "label": "Variable misuse"}
{"function": "\n\n@converts('ImageField')\ndef conv_Image(self, model, field, kwargs):\n    return f.FileField(**kwargs)\n", "label": "Correct"}
{"function": "\n\n@converts('ImageField')\ndef conv_Image(self, model, field, kwargs):\n    return f.FileField(**self)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse(self, text):\n    return [ErrorLine(m) for m in self.regex.finditer(text)]\n", "label": "Correct"}
{"function": "\n\ndef parse(self, text):\n    return [ErrorLine(m) for m in self.regex.finditer(self)]\n", "label": "Variable misuse"}
{"function": "\n\ndef clamp_vect(self, v):\n    'Returns a copy of the vector v clamped to the bounding box'\n    return cpffi.cpBBClampVect(self._bb, v)\n", "label": "Correct"}
{"function": "\n\ndef clamp_vect(self, v):\n    'Returns a copy of the vector v clamped to the bounding box'\n    return cpffi.cpBBClampVect(v._bb, v)\n", "label": "Variable misuse"}
{"function": "\n\ndef __exit__(self, *args):\n    self.delegate.disconnect()\n", "label": "Correct"}
{"function": "\n\ndef __exit__(self, *args):\n    args.delegate.disconnect()\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef mul(f, g):\n    \"\\n        The algorithms performing the multiplication of two ``TIDS`` instances.\\n\\n        In short, it forms a new ``TIDS`` object, joining components and indices,\\n        checking that abstract indices are compatible, and possibly contracting\\n        them.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.tensor.tensor import TensorIndexType, tensor_indices, TIDS, tensorhead\\n        >>> Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\\n        >>> m0, m1, m2, m3 = tensor_indices('m0,m1,m2,m3', Lorentz)\\n        >>> T = tensorhead('T', [Lorentz]*4, [[1]*4])\\n        >>> A = tensorhead('A', [Lorentz], [[1]])\\n        >>> tids_1 = TIDS.from_components_and_indices([T], [m0, m1, -m1, m3])\\n        >>> tids_2 = TIDS.from_components_and_indices([A], [m2])\\n        >>> tids_1 * tids_2\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0), (m3, 3, 0), (m2, 0, 1)], [(1, 2, 0, 0)])\\n\\n        In this case no contraction has been performed.\\n\\n        >>> tids_3 = TIDS.from_components_and_indices([A], [-m3])\\n        >>> tids_1 * tids_3\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0)], [(1, 2, 0, 0), (3, 0, 0, 1)])\\n\\n        Free indices ``m3`` and ``-m3`` are identified as a contracted couple, and are\\n        therefore transformed into dummy indices.\\n\\n        A wrong index construction (for example, trying to contract two\\n        contravariant indices or using indices multiple times) would result in\\n        an exception:\\n\\n        >>> tids_4 = TIDS.from_components_and_indices([A], [m3])\\n        >>> # This raises an exception:\\n        >>> # tids_1 * tids_4\\n        \"\n    index_up = (lambda u: (u if u.is_up else (- u)))\n    notmat = (lambda i: (i not in (i._tensortype.auto_left, (- i._tensortype.auto_right))))\n    f_free = f.free[:]\n    g_free = g.free[:]\n    nc1 = len(f.components)\n    dum = TIDS._check_matrix_indices(f_free, g_free, nc1)\n    free_dict1 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in f_free}\n    free_dict2 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in g_free}\n    free_names = (set(free_dict1.keys()) & set(free_dict2.keys()))\n    dum2 = [(i1, i2, (c1 + nc1), (c2 + nc1)) for (i1, i2, c1, c2) in g.dum]\n    free1 = [(ind, i, c) for (ind, i, c) in f_free if (index_up(ind) not in free_names)]\n    free2 = [(ind, i, (c + nc1)) for (ind, i, c) in g_free if (index_up(ind) not in free_names)]\n    free = (free1 + free2)\n    dum.extend((f.dum + dum2))\n    for name in free_names:\n        (ipos1, cpos1, ind1) = free_dict1[name]\n        (ipos2, cpos2, ind2) = free_dict2[name]\n        cpos2 += nc1\n        if (ind1._is_up == ind2._is_up):\n            raise ValueError('wrong index construction {0}'.format(ind1))\n        if ind1._is_up:\n            new_dummy = (ipos1, ipos2, cpos1, cpos2)\n        else:\n            new_dummy = (ipos2, ipos1, cpos2, cpos1)\n        dum.append(new_dummy)\n    return ((f.components + g.components), free, dum)\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef mul(f, g):\n    \"\\n        The algorithms performing the multiplication of two ``TIDS`` instances.\\n\\n        In short, it forms a new ``TIDS`` object, joining components and indices,\\n        checking that abstract indices are compatible, and possibly contracting\\n        them.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.tensor.tensor import TensorIndexType, tensor_indices, TIDS, tensorhead\\n        >>> Lorentz = TensorIndexType('Lorentz', dummy_fmt='L')\\n        >>> m0, m1, m2, m3 = tensor_indices('m0,m1,m2,m3', Lorentz)\\n        >>> T = tensorhead('T', [Lorentz]*4, [[1]*4])\\n        >>> A = tensorhead('A', [Lorentz], [[1]])\\n        >>> tids_1 = TIDS.from_components_and_indices([T], [m0, m1, -m1, m3])\\n        >>> tids_2 = TIDS.from_components_and_indices([A], [m2])\\n        >>> tids_1 * tids_2\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0), (m3, 3, 0), (m2, 0, 1)], [(1, 2, 0, 0)])\\n\\n        In this case no contraction has been performed.\\n\\n        >>> tids_3 = TIDS.from_components_and_indices([A], [-m3])\\n        >>> tids_1 * tids_3\\n        TIDS([T(Lorentz,Lorentz,Lorentz,Lorentz), A(Lorentz)],            [(m0, 0, 0)], [(1, 2, 0, 0), (3, 0, 0, 1)])\\n\\n        Free indices ``m3`` and ``-m3`` are identified as a contracted couple, and are\\n        therefore transformed into dummy indices.\\n\\n        A wrong index construction (for example, trying to contract two\\n        contravariant indices or using indices multiple times) would result in\\n        an exception:\\n\\n        >>> tids_4 = TIDS.from_components_and_indices([A], [m3])\\n        >>> # This raises an exception:\\n        >>> # tids_1 * tids_4\\n        \"\n    index_up = (lambda u: (u if u.is_up else (- u)))\n    notmat = (lambda i: (i not in (i._tensortype.auto_left, (- i._tensortype.auto_right))))\n    f_free = f.free[:]\n    g_free = g.free[:]\n    nc1 = len(f.components)\n    dum = TIDS._check_matrix_indices(f_free, g_free, nc1)\n    free_dict1 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in f_free}\n    free_dict2 = {(i if i.is_up else (- i)): (pos, cpos, i) for (i, pos, cpos) in g_free}\n    free_names = (set(free_dict1.keys()) & set(free_dict2.keys()))\n    dum2 = [(i1, i2, (c1 + nc1), (c2 + nc1)) for (i1, i2, c1, c2) in g.dum]\n    free1 = [(ind, i, c) for (ind, i, c) in f_free if (index_up(ind) not in free_names)]\n    free2 = [(ind, i, (c + nc1)) for (ind, i, c) in g_free if (index_up(ind) not in free_names)]\n    free = (free1 + free2)\n    dum.extend((f.dum + dum2))\n    for name in free_names:\n        (ipos1, cpos1, ind1) = free_dict1[name]\n        (ipos2, cpos2, ind2) = free_dict2[name]\n        cpos2 += nc1\n        if (ind1._is_up == ind2._is_up):\n            raise ValueError('wrong index construction {0}'.format(ind1))\n        if ind1._is_up:\n            new_dummy = (ipos1, ipos2, cpos1, cpos2)\n        else:\n            new_dummy = (ipos2, ipos1, cpos2, cpos1)\n        dum.append(new_dummy)\n    return ((f.components + g.components), ipos2, dum)\n", "label": "Variable misuse"}
{"function": "\n\n@view_config(context='velruse.AuthenticationComplete', renderer='{}:templates/result.mako'.format(__name__))\ndef login_complete_view(request):\n    context = request.context\n    result = {\n        'profile': context.profile,\n        'credentials': context.credentials,\n    }\n    return {\n        'result': json.dumps(result, indent=4),\n    }\n", "label": "Correct"}
{"function": "\n\n@view_config(context='velruse.AuthenticationComplete', renderer='{}:templates/result.mako'.format(__name__))\ndef login_complete_view(request):\n    context = context.context\n    result = {\n        'profile': context.profile,\n        'credentials': context.credentials,\n    }\n    return {\n        'result': json.dumps(result, indent=4),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef draw_outlines(context, box, enable_hinting):\n    width = box.style.outline_width\n    color = box.style.get_color('outline_color')\n    style = box.style.outline_style\n    if ((box.style.visibility == 'visible') and (width != 0) and (color.alpha != 0)):\n        outline_box = ((box.border_box_x() - width), (box.border_box_y() - width), (box.border_width() + (2 * width)), (box.border_height() + (2 * width)))\n        for side in SIDES:\n            with stacked(context):\n                clip_border_segment(context, enable_hinting, style, width, side, outline_box)\n                draw_rect_border(context, outline_box, (4 * (width,)), style, styled_color(style, color, side))\n    if isinstance(box, boxes.ParentBox):\n        for child in box.children:\n            if isinstance(child, boxes.Box):\n                draw_outlines(context, child, enable_hinting)\n", "label": "Correct"}
{"function": "\n\ndef draw_outlines(context, box, enable_hinting):\n    width = box.style.outline_width\n    color = box.style.get_color('outline_color')\n    style = box.style.outline_style\n    if ((box.style.visibility == 'visible') and (width != 0) and (color.alpha != 0)):\n        outline_box = ((box.border_box_x() - width), (box.border_box_y() - width), (box.border_width() + (2 * width)), (box.border_height() + (2 * width)))\n        for side in SIDES:\n            with stacked(context):\n                clip_border_segment(context, enable_hinting, style, width, side, outline_box)\n                draw_rect_border(context, context, (4 * (width,)), style, styled_color(style, color, side))\n    if isinstance(box, boxes.ParentBox):\n        for child in box.children:\n            if isinstance(child, boxes.Box):\n                draw_outlines(context, child, enable_hinting)\n", "label": "Variable misuse"}
{"function": "\n\ndef emit(self, *args, **kwargs):\n    try:\n        self.__emitting = True\n        for handler in self.__handlers:\n            handler(*args, **kwargs)\n    finally:\n        self.__emitting = False\n        self.__applyChanges()\n", "label": "Correct"}
{"function": "\n\ndef emit(self, *args, **kwargs):\n    try:\n        self.__emitting = True\n        for handler in self.__handlers:\n            handler(*args, **kwargs)\n    finally:\n        self.__emitting = False\n        handler.__applyChanges()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_existing_spawn(self):\n    child = pexpect.spawnu('bash', timeout=5, echo=False)\n    repl = replwrap.REPLWrapper(child, re.compile('[$#]'), \"PS1='{0}' PS2='{1}' PROMPT_COMMAND=''\")\n    res = repl.run_command('echo $HOME')\n    assert res.startswith('/'), res\n", "label": "Correct"}
{"function": "\n\ndef test_existing_spawn(self):\n    child = pexpect.spawnu('bash', timeout=5, echo=False)\n    repl = replwrap.REPLWrapper(child, re.compile('[$#]'), \"PS1='{0}' PS2='{1}' PROMPT_COMMAND=''\")\n    res = repl.run_command('echo $HOME')\n    assert repl.startswith('/'), res\n", "label": "Variable misuse"}
{"function": "\n\ndef child_removed(self, child):\n    ' Handle the child removed event for a QtWindow.\\n\\n        '\n    if isinstance(child, WxContainer):\n        self.widget.SetCentralWidget(self.central_widget())\n", "label": "Correct"}
{"function": "\n\ndef child_removed(self, child):\n    ' Handle the child removed event for a QtWindow.\\n\\n        '\n    if isinstance(child, WxContainer):\n        self.widget.SetCentralWidget(child.central_widget())\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stubs(self):\n    df = pd.DataFrame([[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]])\n    df.columns = ['id', 'inc1', 'inc2', 'edu1', 'edu2']\n    stubs = ['inc', 'edu']\n    df_long = pd.wide_to_long(df, stubs, i='id', j='age')\n    self.assertEqual(stubs, ['inc', 'edu'])\n", "label": "Correct"}
{"function": "\n\ndef test_stubs(self):\n    df = pd.DataFrame([[0, 1, 2, 3, 8], [4, 5, 6, 7, 9]])\n    df.columns = ['id', 'inc1', 'inc2', 'edu1', 'edu2']\n    stubs = ['inc', 'edu']\n    df_long = pd.wide_to_long(df_long, stubs, i='id', j='age')\n    self.assertEqual(stubs, ['inc', 'edu'])\n", "label": "Variable misuse"}
{"function": "\n\ndef collectstreamuuid(self, streamname):\n    if (not streamname):\n        return\n    shouter.shout(('Get UUID of configured stream ' + streamname))\n    showuuidcommand = ('%s --show-alias n --show-uuid y show attributes -r %s -w %s' % (self.scmcommand, self.repo, streamname))\n    output = shell.getoutput(showuuidcommand)\n    splittedfirstline = output[0].split(' ')\n    streamuuid = splittedfirstline[0].strip()[1:(- 1)]\n    return streamuuid\n", "label": "Correct"}
{"function": "\n\ndef collectstreamuuid(self, streamname):\n    if (not streamname):\n        return\n    shouter.shout(('Get UUID of configured stream ' + streamname))\n    showuuidcommand = ('%s --show-alias n --show-uuid y show attributes -r %s -w %s' % (self.scmcommand, self.repo, streamname))\n    output = shell.getoutput(output)\n    splittedfirstline = output[0].split(' ')\n    streamuuid = splittedfirstline[0].strip()[1:(- 1)]\n    return streamuuid\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef resource_uri(cls, obj=None):\n    object_id = 'id'\n    if (obj is not None):\n        object_id = obj.id\n    return ('api_events', [object_id])\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef resource_uri(cls, obj=None):\n    object_id = 'id'\n    if (obj is not None):\n        object_id = object_id.id\n    return ('api_events', [object_id])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, text):\n    if (len(text) >= 10000):\n        text = (text[:9995] + '\\n...')\n    self.text = text\n    self.recipient = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, text):\n    if (len(text) >= 10000):\n        text = (text[:9995] + '\\n...')\n    self.text = text\n    text.recipient = None\n", "label": "Variable misuse"}
{"function": "\n\ndef info(self, msg_format, *values):\n    'For progress and other informative messages.'\n    if (len(values) > 0):\n        msg_format = (msg_format % values)\n    print(msg_format)\n", "label": "Correct"}
{"function": "\n\ndef info(self, msg_format, *values):\n    'For progress and other informative messages.'\n    if (len(values) > 0):\n        msg_format = (msg_format % msg_format)\n    print(msg_format)\n", "label": "Variable misuse"}
{"function": "\n\ndef freeze(self, skipSet=None):\n    assert (len(self()) in self.allowedSize)\n    return StringStream.freeze(self, skipSet=skipSet)\n", "label": "Correct"}
{"function": "\n\ndef freeze(self, skipSet=None):\n    assert (len(self()) in self.allowedSize)\n    return StringStream.freeze(skipSet, skipSet=skipSet)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_result(self, vlan_range_len):\n    self.intersect()\n    if (vlan_range_len > 1):\n        return self.get_final_available_vlan_range(vlan_range_len)\n    else:\n        return self.get_final_available_vlan()\n", "label": "Correct"}
{"function": "\n\ndef get_result(self, vlan_range_len):\n    vlan_range_len.intersect()\n    if (vlan_range_len > 1):\n        return self.get_final_available_vlan_range(vlan_range_len)\n    else:\n        return self.get_final_available_vlan()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, collector, callback=None, *args, **kw):\n    '\\n        Create a pager with a Reference to a remote collector and\\n        an optional callable to invoke upon completion.\\n        '\n    if callable(callback):\n        self.callback = callback\n        self.callbackArgs = args\n        self.callbackKeyword = kw\n    else:\n        self.callback = None\n    self._stillPaging = 1\n    self.collector = collector\n    collector.broker.registerPageProducer(self)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, collector, callback=None, *args, **kw):\n    '\\n        Create a pager with a Reference to a remote collector and\\n        an optional callable to invoke upon completion.\\n        '\n    if callable(callback):\n        self.callback = callback\n        self.callbackArgs = args\n        self.callbackKeyword = kw\n    else:\n        self.callback = None\n    self._stillPaging = 1\n    self.collector = collector\n    collector.broker.registerPageProducer(callback)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, consumer_key, consumer_secret):\n    self.name = name\n    self.type = 'twitter'\n    self.consumer_key = consumer_key\n    self.consumer_secret = consumer_secret\n    self.login_route = ('velruse.%s-login' % name)\n    self.callback_route = ('velruse.%s-callback' % name)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, consumer_key, consumer_secret):\n    self.name = name\n    self.type = 'twitter'\n    self.consumer_key = consumer_key\n    self.consumer_secret = consumer_key\n    self.login_route = ('velruse.%s-login' % name)\n    self.callback_route = ('velruse.%s-callback' % name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch(('%s.flavors.osclients.Clients' % CTX))\ndef test_cleanup(self, mock_clients):\n    real_context = {\n        'flavors': {\n            'flavor_name': {\n                'flavor_name': 'flavor_name',\n                'id': 'flavor_name',\n            },\n        },\n        'admin': {\n            'credential': mock.MagicMock(),\n        },\n        'task': mock.MagicMock(),\n    }\n    flavors_ctx = flavors.FlavorsGenerator(real_context)\n    flavors_ctx.cleanup()\n    mock_clients.assert_called_with(real_context['admin']['credential'])\n    mock_flavors_delete = mock_clients().nova().flavors.delete\n    mock_flavors_delete.assert_called_with('flavor_name')\n", "label": "Correct"}
{"function": "\n\n@mock.patch(('%s.flavors.osclients.Clients' % CTX))\ndef test_cleanup(self, mock_clients):\n    real_context = {\n        'flavors': {\n            'flavor_name': {\n                'flavor_name': 'flavor_name',\n                'id': 'flavor_name',\n            },\n        },\n        'admin': {\n            'credential': mock.MagicMock(),\n        },\n        'task': mock.MagicMock(),\n    }\n    flavors_ctx = flavors.FlavorsGenerator(real_context)\n    flavors_ctx.cleanup()\n    mock_clients.assert_called_with(self['admin']['credential'])\n    mock_flavors_delete = mock_clients().nova().flavors.delete\n    mock_flavors_delete.assert_called_with('flavor_name')\n", "label": "Variable misuse"}
{"function": "\n\ndef get_show(self, imdb, tvdb, tvshowtitle, year):\n    try:\n        query = self.search_link\n        post = {\n            'searchquery': tvshowtitle,\n            'searchin': '2',\n        }\n        result = ''\n        links = [self.link_1, self.link_3]\n        for base_link in links:\n            result = client.source(urlparse.urljoin(base_link, query), post=post, headers=self.headers)\n            if ('widget search-page' in str(result)):\n                break\n        result = client.parseDOM(result, 'div', attrs={\n            'class': 'widget search-page',\n        })[0]\n        result = client.parseDOM(result, 'td')\n        tvshowtitle = cleantitle.tv(tvshowtitle)\n        years = [('(%s)' % str(year)), ('(%s)' % str((int(year) + 1))), ('(%s)' % str((int(year) - 1)))]\n        result = [(client.parseDOM(i, 'a', ret='href')[(- 1)], client.parseDOM(i, 'a')[(- 1)]) for i in result]\n        result = [i for i in result if (tvshowtitle == cleantitle.tv(i[1]))]\n        result = [i[0] for i in result if any(((x in i[1]) for x in years))][0]\n        url = client.replaceHTMLCodes(result)\n        try:\n            url = urlparse.parse_qs(urlparse.urlparse(url).query)['u'][0]\n        except:\n            pass\n        url = urlparse.urlparse(url).path\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Correct"}
{"function": "\n\ndef get_show(self, imdb, tvdb, tvshowtitle, year):\n    try:\n        query = self.search_link\n        post = {\n            'searchquery': tvshowtitle,\n            'searchin': '2',\n        }\n        result = ''\n        links = [self.link_1, self.link_3]\n        for base_link in links:\n            result = client.source(urlparse.urljoin(base_link, query), post=post, headers=self.headers)\n            if ('widget search-page' in str(result)):\n                break\n        result = client.parseDOM(result, 'div', attrs={\n            'class': 'widget search-page',\n        })[0]\n        result = client.parseDOM(result, 'td')\n        tvshowtitle = cleantitle.tv(tvshowtitle)\n        years = [('(%s)' % str(year)), ('(%s)' % str((int(year) + 1))), ('(%s)' % str((int(year) - 1)))]\n        result = [(client.parseDOM(i, 'a', ret='href')[(- 1)], client.parseDOM(i, 'a')[(- 1)]) for i in result]\n        result = [i for i in tvdb if (tvshowtitle == cleantitle.tv(i[1]))]\n        result = [i[0] for i in result if any(((x in i[1]) for x in years))][0]\n        url = client.replaceHTMLCodes(result)\n        try:\n            url = urlparse.parse_qs(urlparse.urlparse(url).query)['u'][0]\n        except:\n            pass\n        url = urlparse.urlparse(url).path\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_vms(self):\n    '\\n        Returns a generator over all VMs known to this vCenter host.\\n        '\n    for folder in self.get_first_level_of_vm_folders():\n        for vm in get_all_vms_in_folder(folder):\n            (yield vm)\n", "label": "Correct"}
{"function": "\n\ndef get_all_vms(self):\n    '\\n        Returns a generator over all VMs known to this vCenter host.\\n        '\n    for folder in self.get_first_level_of_vm_folders():\n        for vm in get_all_vms_in_folder(folder):\n            (yield self)\n", "label": "Variable misuse"}
{"function": "\n\ndef wait_for_responses(self, client):\n    'Waits for all responses to come back and resolves the\\n        eventual results.\\n        '\n    assert_open(self)\n    if self.has_pending_requests:\n        raise RuntimeError('Cannot wait for responses if there are pending requests outstanding.  You need to wait for pending requests to be sent first.')\n    pending = self.pending_responses\n    self.pending_responses = []\n    for (command_name, promise) in pending:\n        value = client.parse_response(self.connection, command_name)\n        promise.resolve(value)\n", "label": "Correct"}
{"function": "\n\ndef wait_for_responses(self, client):\n    'Waits for all responses to come back and resolves the\\n        eventual results.\\n        '\n    assert_open(self)\n    if self.has_pending_requests:\n        raise RuntimeError('Cannot wait for responses if there are pending requests outstanding.  You need to wait for pending requests to be sent first.')\n    pending = self.pending_responses\n    self.pending_responses = []\n    for (command_name, promise) in promise:\n        value = client.parse_response(self.connection, command_name)\n        promise.resolve(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_write_job3():\n    conf = test_config()\n    loop = pyuv.Loop.default_loop()\n    with KeyManager(loop, conf) as h:\n        h.create_key({\n            'write': ['test.test', 'test1.test'],\n        }, key='test1')\n        key = Key.load(h.get_key('test1'))\n        assert (key.can_read('test') == False)\n        assert (key.can_read('test.test') == True)\n        assert (key.can_read('test1') == False)\n        assert (key.can_read('test1.test') == True)\n        assert (key.can_write('test') == False)\n        assert (key.can_write('test.test') == True)\n        assert (key.can_write('test1') == False)\n        assert (key.can_write('test1.test') == True)\n        assert (key.can_manage('test') == False)\n        assert (key.can_manage('test.test') == False)\n        assert (key.can_manage('test1') == False)\n        assert (key.can_manage('test1.test') == False)\n", "label": "Correct"}
{"function": "\n\ndef test_write_job3():\n    conf = test_config()\n    loop = pyuv.Loop.default_loop()\n    with KeyManager(loop, conf) as h:\n        h.create_key({\n            'write': ['test.test', 'test1.test'],\n        }, key='test1')\n        key = Key.load(h.get_key('test1'))\n        assert (key.can_read('test') == False)\n        assert (key.can_read('test.test') == True)\n        assert (key.can_read('test1') == False)\n        assert (key.can_read('test1.test') == True)\n        assert (key.can_write('test') == False)\n        assert (conf.can_write('test.test') == True)\n        assert (key.can_write('test1') == False)\n        assert (key.can_write('test1.test') == True)\n        assert (key.can_manage('test') == False)\n        assert (key.can_manage('test.test') == False)\n        assert (key.can_manage('test1') == False)\n        assert (key.can_manage('test1.test') == False)\n", "label": "Variable misuse"}
{"function": "\n\ndef __update_copyright(self):\n    'Finds the copyright text and replaces it.'\n    region = self.__find_copyright()\n    self.__replace_copyright(region)\n", "label": "Correct"}
{"function": "\n\ndef __update_copyright(self):\n    'Finds the copyright text and replaces it.'\n    region = self.__find_copyright()\n    region.__replace_copyright(region)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, idx):\n    self.idx = _uidx()\n    self.isBatch = False\n    self.isSeq = True\n    if isinstance(idx, BaseArray):\n        arr = ct.c_void_p(0)\n        if (idx.type() == Dtype.b8.value):\n            safe_call(backend.get().af_where(ct.pointer(arr), idx.arr))\n        else:\n            safe_call(backend.get().af_retain_array(ct.pointer(arr), idx.arr))\n        self.idx.arr = arr\n        self.isSeq = False\n    elif isinstance(idx, ParallelRange):\n        self.idx.seq = idx\n        self.isBatch = True\n    else:\n        self.idx.seq = Seq(idx)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, idx):\n    self.idx = _uidx()\n    self.isBatch = False\n    self.isSeq = True\n    if isinstance(idx, BaseArray):\n        arr = ct.c_void_p(0)\n        if (idx.type() == Dtype.b8.value):\n            safe_call(backend.get().af_where(ct.pointer(arr), idx.arr))\n        else:\n            safe_call(backend.get().af_retain_array(ct.pointer(idx), idx.arr))\n        self.idx.arr = arr\n        self.isSeq = False\n    elif isinstance(idx, ParallelRange):\n        self.idx.seq = idx\n        self.isBatch = True\n    else:\n        self.idx.seq = Seq(idx)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/armor/component/shared_deflector_shield_generator_energy_ray.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/armor/component/shared_deflector_shield_generator_energy_ray.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef leq(levels, int_time=1.0):\n    '\\n    Equivalent level :math:`L_{eq}`.\\n    \\n    :param levels: Levels as function of time.\\n    :param int_time: Integration time. Default value is 1.0 second.\\n    :returns: Equivalent level L_{eq}.\\n    \\n    Sum of levels in dB.\\n    '\n    levels = np.asarray(levels)\n    time = (levels.size * int_time)\n    return _leq(levels, time)\n", "label": "Correct"}
{"function": "\n\ndef leq(levels, int_time=1.0):\n    '\\n    Equivalent level :math:`L_{eq}`.\\n    \\n    :param levels: Levels as function of time.\\n    :param int_time: Integration time. Default value is 1.0 second.\\n    :returns: Equivalent level L_{eq}.\\n    \\n    Sum of levels in dB.\\n    '\n    levels = np.asarray(levels)\n    time = (int_time.size * int_time)\n    return _leq(levels, time)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_next_instruction(self):\n    dis = self.disassemble(address=self.program_counter()[1], count=1)\n    return dis.partition('\\n')[0].strip()\n", "label": "Correct"}
{"function": "\n\ndef get_next_instruction(self):\n    dis = self.disassemble(address=self.program_counter()[1], count=1)\n    return self.partition('\\n')[0].strip()\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/munition/shared_detonator_thermal_imperial_issue.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    kernel.template = 'object/draft_schematic/munition/shared_detonator_thermal_imperial_issue.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef get_dates(self, resource):\n    '\\n        Retrieve dates from mercurial\\n        '\n    try:\n        commits = subprocess.check_output(['hg', 'log', '--template={date|isodatesec}\\n', resource.path]).split('\\n')\n        commits = commits[:(- 1)]\n    except subprocess.CalledProcessError:\n        self.logger.warning(('Unable to get mercurial history for [%s]' % resource))\n        commits = None\n    if (not commits):\n        self.logger.warning(('No mercurial history for [%s]' % resource))\n        return (None, None)\n    created = parse(commits[(- 1)].strip())\n    modified = parse(commits[0].strip())\n    return (created, modified)\n", "label": "Correct"}
{"function": "\n\ndef get_dates(self, resource):\n    '\\n        Retrieve dates from mercurial\\n        '\n    try:\n        commits = subprocess.check_output(['hg', 'log', '--template={date|isodatesec}\\n', resource.path]).split('\\n')\n        commits = commits[:(- 1)]\n    except subprocess.CalledProcessError:\n        self.logger.warning(('Unable to get mercurial history for [%s]' % resource))\n        commits = None\n    if (not resource):\n        self.logger.warning(('No mercurial history for [%s]' % resource))\n        return (None, None)\n    created = parse(commits[(- 1)].strip())\n    modified = parse(commits[0].strip())\n    return (created, modified)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_tx_out_bitcoin_address(self):\n    coinbase_bytes = h2b('04ed66471b02c301')\n    tx = Tx.coinbase_tx(COINBASE_PUB_KEY_FROM_80971, int((50 * 100000000.0)), COINBASE_BYTES_FROM_80971)\n    self.assertEqual(tx.txs_out[0].bitcoin_address(), '1DmapcnrJNGeJB13fv9ngRFX1iRvR4zamn')\n", "label": "Correct"}
{"function": "\n\ndef test_tx_out_bitcoin_address(self):\n    coinbase_bytes = h2b('04ed66471b02c301')\n    tx = Tx.coinbase_tx(COINBASE_PUB_KEY_FROM_80971, int((50 * 100000000.0)), COINBASE_BYTES_FROM_80971)\n    coinbase_bytes.assertEqual(tx.txs_out[0].bitcoin_address(), '1DmapcnrJNGeJB13fv9ngRFX1iRvR4zamn')\n", "label": "Variable misuse"}
{"function": "\n\ndef alert_smtp(alert, metric):\n    if ('@' in alert[1]):\n        sender = settings.ALERT_SENDER\n        recipient = alert[1]\n    else:\n        sender = settings.SMTP_OPTS['sender']\n        recipients = settings.SMTP_OPTS['recipients'][alert[0]]\n    if (type(recipients) is str):\n        recipients = [recipients]\n    for recipient in recipients:\n        msg = MIMEMultipart('alternative')\n        msg['Subject'] = ('[skyline alert] ' + metric[1])\n        msg['From'] = sender\n        msg['To'] = recipient\n        link = (settings.GRAPH_URL % metric[1])\n        body = ('Anomalous value: %s <br> Next alert in: %s seconds <a href=\"%s\"><img src=\"%s\"/></a>' % (metric[0], alert[2], link, link))\n        msg.attach(MIMEText(body, 'html'))\n        s = SMTP('127.0.0.1')\n        s.sendmail(sender, recipient, msg.as_string())\n        s.quit()\n", "label": "Correct"}
{"function": "\n\ndef alert_smtp(alert, metric):\n    if ('@' in alert[1]):\n        sender = settings.ALERT_SENDER\n        recipient = alert[1]\n    else:\n        sender = settings.SMTP_OPTS['sender']\n        recipients = settings.SMTP_OPTS['recipients'][alert[0]]\n    if (type(recipients) is str):\n        recipients = [recipients]\n    for recipient in recipients:\n        msg = MIMEMultipart('alternative')\n        msg['Subject'] = ('[skyline alert] ' + metric[1])\n        recipients['From'] = sender\n        msg['To'] = recipient\n        link = (settings.GRAPH_URL % metric[1])\n        body = ('Anomalous value: %s <br> Next alert in: %s seconds <a href=\"%s\"><img src=\"%s\"/></a>' % (metric[0], alert[2], link, link))\n        msg.attach(MIMEText(body, 'html'))\n        s = SMTP('127.0.0.1')\n        s.sendmail(sender, recipient, msg.as_string())\n        s.quit()\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_key(self, key):\n    self.server.request('delete', ('/keys/%s' % key))\n", "label": "Correct"}
{"function": "\n\ndef delete_key(self, key):\n    self.server.request('delete', ('/keys/%s' % self))\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_placeholders(self, n_features, n_classes):\n    ' Create the TensorFlow placeholders for the model.\\n        :param n_features: number of features of the first layer\\n        :param n_classes: number of classes\\n        :return: self\\n        '\n    self.keep_prob = tf.placeholder('float')\n    self.hrand = [tf.placeholder('float', [None, self.layers[(l + 1)]]) for l in range((self.n_layers - 1))]\n    self.vrand = [tf.placeholder('float', [None, self.layers[l]]) for l in range((self.n_layers - 1))]\n    self.x = tf.placeholder('float', [None, n_features])\n    self.y_ = tf.placeholder('float', [None, n_classes])\n", "label": "Correct"}
{"function": "\n\ndef _create_placeholders(self, n_features, n_classes):\n    ' Create the TensorFlow placeholders for the model.\\n        :param n_features: number of features of the first layer\\n        :param n_classes: number of classes\\n        :return: self\\n        '\n    self.keep_prob = tf.placeholder('float')\n    self.hrand = [tf.placeholder('float', [None, self.layers[(l + 1)]]) for l in range((self.n_layers - 1))]\n    self.vrand = [tf.placeholder('float', [None, self.layers[l]]) for l in range((self.n_layers - 1))]\n    n_classes.x = tf.placeholder('float', [None, n_features])\n    self.y_ = tf.placeholder('float', [None, n_classes])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name_suggestion):\n    self.name_suggestion = name_suggestion\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name_suggestion):\n    self.name_suggestion = self\n", "label": "Variable misuse"}
{"function": "\n\ndef render_datalist(self, list_id):\n    return ''.join([('<datalist id=\"%s\">' % list_id), ''.join([('<option>%s</option>' % color) for color in self.colors]), '</datalist>'])\n", "label": "Correct"}
{"function": "\n\ndef render_datalist(self, list_id):\n    return ''.join([('<datalist id=\"%s\">' % list_id), ''.join([('<option>%s</option>' % color) for color in list_id.colors]), '</datalist>'])\n", "label": "Variable misuse"}
{"function": "\n\ndef _do_remove(self, section, option):\n    if (not self.config.has_option(section, option)):\n        raise AdminCommandError(_(\"Option '%(option)s' doesn't exist in section '%(section)s'\", option=option, section=section))\n    self.config.remove(section, option)\n    self.config.save()\n    if ((section == 'inherit') and (option == 'file')):\n        self.config.parse_if_needed(force=True)\n", "label": "Correct"}
{"function": "\n\ndef _do_remove(self, section, option):\n    if (not self.config.has_option(section, option)):\n        raise AdminCommandError(_(\"Option '%(option)s' doesn't exist in section '%(section)s'\", option=self, section=section))\n    self.config.remove(section, option)\n    self.config.save()\n    if ((section == 'inherit') and (option == 'file')):\n        self.config.parse_if_needed(force=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef _unit_file(self, name):\n    for extension in ['service', 'yaml']:\n        file_path = '{0}.{1}'.format(name, extension)\n        if path.exists(file_path):\n            with open(file_path) as handle:\n                if (extension == 'service'):\n                    return handle.read()\n                data = yaml.load(handle)\n                if (self._global and ('global' in data)):\n                    return data['global']\n                if (self._name in data):\n                    return data[self._name]\n                raise ValueError('No unit found for {0}'.format(self._name))\n    raise ValueError('No unit file: '.format(name))\n", "label": "Correct"}
{"function": "\n\ndef _unit_file(self, name):\n    for extension in ['service', 'yaml']:\n        file_path = '{0}.{1}'.format(name, extension)\n        if path.exists(file_path):\n            with open(file_path) as handle:\n                if (extension == 'service'):\n                    return handle.read()\n                data = yaml.load(handle)\n                if (self._global and ('global' in data)):\n                    return data['global']\n                if (data._name in data):\n                    return data[self._name]\n                raise ValueError('No unit found for {0}'.format(self._name))\n    raise ValueError('No unit file: '.format(name))\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_flavor(self, description=None):\n    flavor = {\n        'flavor': {\n            'name': 'GOLD',\n            'service_type': constants.DUMMY,\n            'description': (description or 'the best flavor'),\n            'enabled': True,\n        },\n    }\n    return (self.plugin.create_flavor(self.ctx, flavor), flavor)\n", "label": "Correct"}
{"function": "\n\ndef _create_flavor(self, description=None):\n    flavor = {\n        'flavor': {\n            'name': 'GOLD',\n            'service_type': constants.DUMMY,\n            'description': (description or 'the best flavor'),\n            'enabled': True,\n        },\n    }\n    return (description.plugin.create_flavor(self.ctx, flavor), flavor)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_logout(self):\n    'Tests when logging out with and without continue URL.'\n    host = 'foo.com:1234'\n    path_info = '/_ah/login'\n    cookie_dict = {\n        'dev_appserver_login': ('%s:False:%s' % (EMAIL, USER_ID)),\n    }\n    action = 'Logout'\n    set_email = ''\n    set_admin = False\n    continue_url = ''\n    expected_set = login._clear_user_info_cookie().strip()\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(('http://%s%s' % (host, path_info)), location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n    continue_url = 'http://foo.com/blah'\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(continue_url, location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n", "label": "Correct"}
{"function": "\n\ndef test_logout(self):\n    'Tests when logging out with and without continue URL.'\n    host = 'foo.com:1234'\n    path_info = '/_ah/login'\n    cookie_dict = {\n        'dev_appserver_login': ('%s:False:%s' % (EMAIL, USER_ID)),\n    }\n    action = 'Logout'\n    set_email = ''\n    set_admin = False\n    continue_url = ''\n    expected_set = login._clear_user_info_cookie().strip()\n    (status, location, set_cookie, _) = self._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(('http://%s%s' % (host, path_info)), location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n    continue_url = 'http://foo.com/blah'\n    (status, location, set_cookie, _) = expected_set._run_test(host, path_info, cookie_dict, action, set_email, set_admin, continue_url)\n    self.assertEqual(302, status)\n    self.assertEqual(continue_url, location)\n    self.assertEqual(expected_set, set_cookie)\n    self.assertIsInstance(location, str)\n    self.assertIsInstance(set_cookie, str)\n", "label": "Variable misuse"}
{"function": "\n\ndef test04c__getitem__(self):\n    'Checking cols.__getitem__() with subgroups with a range index with\\n        step.'\n    tbl = self.h5file.create_table('/', 'test', self._TestTDescr, title=self._getMethodName())\n    tbl.append(self._testAData)\n    if self.reopen:\n        self._reopen()\n        tbl = self.h5file.root.test\n    nrarr = numpy.array(testABuffer, dtype=tbl.description._v_nested_descr)\n    tblcols = tbl.cols._f_col('Info')[0::2]\n    nrarrcols = nrarr['Info'][0::2]\n    if common.verbose:\n        print('Read cols:', tblcols)\n        print('Should look like:', nrarrcols)\n    self.assertTrue(common.areArraysEqual(nrarrcols, tblcols), \"Original array are retrieved doesn't match.\")\n", "label": "Correct"}
{"function": "\n\ndef test04c__getitem__(self):\n    'Checking cols.__getitem__() with subgroups with a range index with\\n        step.'\n    tbl = self.h5file.create_table('/', 'test', self._TestTDescr, title=self._getMethodName())\n    tbl.append(tbl._testAData)\n    if self.reopen:\n        self._reopen()\n        tbl = self.h5file.root.test\n    nrarr = numpy.array(testABuffer, dtype=tbl.description._v_nested_descr)\n    tblcols = tbl.cols._f_col('Info')[0::2]\n    nrarrcols = nrarr['Info'][0::2]\n    if common.verbose:\n        print('Read cols:', tblcols)\n        print('Should look like:', nrarrcols)\n    self.assertTrue(common.areArraysEqual(nrarrcols, tblcols), \"Original array are retrieved doesn't match.\")\n", "label": "Variable misuse"}
{"function": "\n\ndef test_key_has_correct_repr(self):\n    '\\n        Calling repr on a Key instance returns the proper string.\\n        '\n    key = pem.Key(b'test')\n    assert ('<Key({0})>'.format(TEST_DIGEST) == repr(key))\n", "label": "Correct"}
{"function": "\n\ndef test_key_has_correct_repr(self):\n    '\\n        Calling repr on a Key instance returns the proper string.\\n        '\n    key = pem.Key(b'test')\n    assert ('<Key({0})>'.format(TEST_DIGEST) == repr(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef calcScale(self, testCount):\n    import math\n    scale = int((self.size / (math.sqrt(testCount) + 1)))\n    return scale\n", "label": "Correct"}
{"function": "\n\ndef calcScale(self, testCount):\n    import math\n    scale = int((self.size / (math.sqrt(scale) + 1)))\n    return scale\n", "label": "Variable misuse"}
{"function": "\n\ndef get_repository_info(self):\n    '\\n        Find out information about the current Bazaar branch (if any) and\\n        return it.\\n        '\n    if (not check_install(['bzr', 'help'])):\n        logging.debug('Unable to execute \"bzr help\": skipping Bazaar')\n        return None\n    bzr_info = execute(['bzr', 'info'], ignore_errors=True)\n    if ('ERROR: Not a branch:' in bzr_info):\n        repository_info = None\n    else:\n        branch_match = re.search(self.BRANCH_REGEX, bzr_info, re.MULTILINE)\n        path = branch_match.group('branch_path')\n        if (path == '.'):\n            path = os.getcwd()\n        repository_info = RepositoryInfo(path=path, base_path='/', supports_parent_diffs=True)\n    return repository_info\n", "label": "Correct"}
{"function": "\n\ndef get_repository_info(self):\n    '\\n        Find out information about the current Bazaar branch (if any) and\\n        return it.\\n        '\n    if (not check_install(['bzr', 'help'])):\n        logging.debug('Unable to execute \"bzr help\": skipping Bazaar')\n        return None\n    bzr_info = execute(['bzr', 'info'], ignore_errors=True)\n    if ('ERROR: Not a branch:' in path):\n        repository_info = None\n    else:\n        branch_match = re.search(self.BRANCH_REGEX, bzr_info, re.MULTILINE)\n        path = branch_match.group('branch_path')\n        if (path == '.'):\n            path = os.getcwd()\n        repository_info = RepositoryInfo(path=path, base_path='/', supports_parent_diffs=True)\n    return repository_info\n", "label": "Variable misuse"}
{"function": "\n\ndef do_access_token_response(self, access_token, atinfo, state, refresh_token=None):\n    _tinfo = {\n        'access_token': access_token,\n        'expires_in': atinfo['exp'],\n        'token_type': 'bearer',\n        'state': state,\n    }\n    try:\n        _tinfo['scope'] = atinfo['scope']\n    except KeyError:\n        pass\n    if refresh_token:\n        _tinfo['refresh_token'] = refresh_token\n    return AccessTokenResponse(**by_schema(AccessTokenResponse, **_tinfo))\n", "label": "Correct"}
{"function": "\n\ndef do_access_token_response(self, access_token, atinfo, state, refresh_token=None):\n    _tinfo = {\n        'access_token': access_token,\n        'expires_in': atinfo['exp'],\n        'token_type': 'bearer',\n        'state': state,\n    }\n    try:\n        _tinfo['scope'] = atinfo['scope']\n    except KeyError:\n        pass\n    if refresh_token:\n        access_token['refresh_token'] = refresh_token\n    return AccessTokenResponse(**by_schema(AccessTokenResponse, **_tinfo))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_set_messages_success(self):\n    author = {\n        'name': 'John Doe',\n        'slug': 'success-msg',\n    }\n    add_url = reverse('add_success_msg')\n    req = self.client.post(add_url, author)\n    self.assertIn((ContactFormViewWithMsg.success_message % author), req.cookies['messages'].value)\n", "label": "Correct"}
{"function": "\n\ndef test_set_messages_success(self):\n    author = {\n        'name': 'John Doe',\n        'slug': 'success-msg',\n    }\n    add_url = reverse('add_success_msg')\n    req = self.client.post(req, author)\n    self.assertIn((ContactFormViewWithMsg.success_message % author), req.cookies['messages'].value)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, question, docs):\n    super(Extractor, self).__init__(question, docs, tag=TAG)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, question, docs):\n    super(Extractor, self).__init__(question, self, tag=TAG)\n", "label": "Variable misuse"}
{"function": "\n\ndef expect(self, method=None, uri=None, params={\n    \n}):\n    if method:\n        self.assertEqual(method, self.executor.request.method)\n    if uri:\n        self.assertEqual(self.executor.request.uri, ('https://api-ssl.bitly.com/v3' + uri))\n    if params:\n        params.update({\n            'access_token': 'my-access-token',\n        })\n        self.assertEqual(self.executor.request.params, params)\n", "label": "Correct"}
{"function": "\n\ndef expect(self, method=None, uri=None, params={\n    \n}):\n    if method:\n        self.assertEqual(method, self.executor.request.method)\n    if uri:\n        self.assertEqual(uri.executor.request.uri, ('https://api-ssl.bitly.com/v3' + uri))\n    if params:\n        params.update({\n            'access_token': 'my-access-token',\n        })\n        self.assertEqual(self.executor.request.params, params)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_handle_error_401_sends_challege_default_realm(self):\n    api = restplus.Api(self.app, serve_challenge_on_401=True)\n    exception = HTTPException()\n    exception.code = 401\n    exception.data = {\n        'foo': 'bar',\n    }\n    with self.app.test_request_context('/foo'):\n        resp = api.handle_error(exception)\n        self.assertEqual(resp.status_code, 401)\n        self.assertEqual(resp.headers['WWW-Authenticate'], 'Basic realm=\"flask-restplus\"')\n", "label": "Correct"}
{"function": "\n\ndef test_handle_error_401_sends_challege_default_realm(self):\n    api = restplus.Api(self.app, serve_challenge_on_401=True)\n    exception = HTTPException()\n    exception.code = 401\n    exception.data = {\n        'foo': 'bar',\n    }\n    with self.app.test_request_context('/foo'):\n        resp = api.handle_error(exception)\n        exception.assertEqual(resp.status_code, 401)\n        self.assertEqual(resp.headers['WWW-Authenticate'], 'Basic realm=\"flask-restplus\"')\n", "label": "Variable misuse"}
{"function": "\n\ndef __add__(self, other):\n    if isinstance(other, BaseNull):\n        return other\n    return self.map((Q + _unwrap(other)))\n", "label": "Correct"}
{"function": "\n\ndef __add__(self, other):\n    if isinstance(other, BaseNull):\n        return other\n    return other.map((Q + _unwrap(other)))\n", "label": "Variable misuse"}
{"function": "\n\ndef next_hop(tokeniser):\n    value = tokeniser()\n    if (value.lower() == 'self'):\n        return (IPSelf(tokeniser.afi), NextHopSelf(tokeniser.afi))\n    else:\n        ip = IP.create(value)\n        if (ip.afi == AFI.ipv4):\n            return (ip, NextHop(ip.top()))\n        return (ip, None)\n", "label": "Correct"}
{"function": "\n\ndef next_hop(tokeniser):\n    value = value()\n    if (value.lower() == 'self'):\n        return (IPSelf(tokeniser.afi), NextHopSelf(tokeniser.afi))\n    else:\n        ip = IP.create(value)\n        if (ip.afi == AFI.ipv4):\n            return (ip, NextHop(ip.top()))\n        return (ip, None)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_is_variant(self):\n    expander = GvcfExpander()\n    self.assertTrue(expander.is_variant(json.loads(self.snp_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.snp_2)))\n    self.assertTrue(expander.is_variant(json.loads(self.insertion_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.deletion_1)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_a)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_b)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_c)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_d)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_ambiguous)))\n    self.assertFalse(expander.is_variant(json.loads(self.no_call_1)))\n", "label": "Correct"}
{"function": "\n\ndef test_is_variant(self):\n    expander = GvcfExpander()\n    self.assertTrue(expander.is_variant(json.loads(self.snp_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.snp_2)))\n    self.assertTrue(expander.is_variant(json.loads(self.insertion_1)))\n    self.assertTrue(expander.is_variant(json.loads(self.deletion_1)))\n    self.assertFalse(self.is_variant(json.loads(self.ref_a)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_b)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_c)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_d)))\n    self.assertFalse(expander.is_variant(json.loads(self.ref_ambiguous)))\n    self.assertFalse(expander.is_variant(json.loads(self.no_call_1)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_coerce_on_select(nyc):\n    t = symbol('t', discover(nyc))\n    t = t[(((((((((t.pickup_latitude >= 40.477399) & (t.pickup_latitude <= 40.917577)) & (t.dropoff_latitude >= 40.477399)) & (t.dropoff_latitude <= 40.917577)) & (t.pickup_longitude >= (- 74.25909))) & (t.pickup_longitude <= (- 73.700272))) & (t.dropoff_longitude >= (- 74.25909))) & (t.dropoff_longitude <= (- 73.700272))) & (t.passenger_count < 6))]\n    t = transform(t, pass_count=(t.passenger_count + 1))\n    result = compute(t.pass_count.coerce('float64'), nyc, return_type='native')\n    s = odo(result, pd.Series)\n    expected = (compute(t, nyc, return_type=pd.DataFrame).passenger_count.astype('float64') + 1.0)\n    assert (list(s) == list(expected))\n", "label": "Correct"}
{"function": "\n\ndef test_coerce_on_select(nyc):\n    t = symbol('t', discover(result))\n    t = t[(((((((((t.pickup_latitude >= 40.477399) & (t.pickup_latitude <= 40.917577)) & (t.dropoff_latitude >= 40.477399)) & (t.dropoff_latitude <= 40.917577)) & (t.pickup_longitude >= (- 74.25909))) & (t.pickup_longitude <= (- 73.700272))) & (t.dropoff_longitude >= (- 74.25909))) & (t.dropoff_longitude <= (- 73.700272))) & (t.passenger_count < 6))]\n    t = transform(t, pass_count=(t.passenger_count + 1))\n    result = compute(t.pass_count.coerce('float64'), nyc, return_type='native')\n    s = odo(result, pd.Series)\n    expected = (compute(t, nyc, return_type=pd.DataFrame).passenger_count.astype('float64') + 1.0)\n    assert (list(s) == list(expected))\n", "label": "Variable misuse"}
{"function": "\n\ndef modify_updates(self, updates):\n    '\"\\n        Modifies the parameters before a learning update is applied. Behavior\\n        is defined by subclass\\'s implementation of _modify_updates and any\\n        ModelExtension\\'s implementation of post_modify_updates.\\n\\n        Parameters\\n        ----------\\n        updates : dict\\n            A dictionary mapping shared variables to symbolic values they\\n            will be updated to\\n\\n        Notes\\n        -----\\n        For example, if a given parameter is not meant to be learned, a\\n        subclass or extension\\n        should remove it from the dictionary. If a parameter has a restricted\\n        range, e.g.. if it is the precision of a normal distribution,\\n        a subclass or extension should clip its update to that range. If a\\n        parameter\\n        has any other special properties, its updates should be modified\\n        to respect that here, e.g. a matrix that must be orthogonal should\\n        have its update value modified to be orthogonal here.\\n\\n        This is the main mechanism used to make sure that generic training\\n        algorithms such as those found in pylearn2.training_algorithms\\n        respect the specific properties of the models passed to them.\\n        '\n    self._modify_updates(updates)\n    self._ensure_extensions()\n    for extension in self.extensions:\n        extension.post_modify_updates(updates, self)\n", "label": "Correct"}
{"function": "\n\ndef modify_updates(self, updates):\n    '\"\\n        Modifies the parameters before a learning update is applied. Behavior\\n        is defined by subclass\\'s implementation of _modify_updates and any\\n        ModelExtension\\'s implementation of post_modify_updates.\\n\\n        Parameters\\n        ----------\\n        updates : dict\\n            A dictionary mapping shared variables to symbolic values they\\n            will be updated to\\n\\n        Notes\\n        -----\\n        For example, if a given parameter is not meant to be learned, a\\n        subclass or extension\\n        should remove it from the dictionary. If a parameter has a restricted\\n        range, e.g.. if it is the precision of a normal distribution,\\n        a subclass or extension should clip its update to that range. If a\\n        parameter\\n        has any other special properties, its updates should be modified\\n        to respect that here, e.g. a matrix that must be orthogonal should\\n        have its update value modified to be orthogonal here.\\n\\n        This is the main mechanism used to make sure that generic training\\n        algorithms such as those found in pylearn2.training_algorithms\\n        respect the specific properties of the models passed to them.\\n        '\n    self._modify_updates(updates)\n    self._ensure_extensions()\n    for extension in self.extensions:\n        extension.post_modify_updates(updates, updates)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_flipped(self, x, y):\n    ' Sets the specified piece as flipped.\\n        '\n    self.pieces[(x + (y * self.width))].set_flipped()\n", "label": "Correct"}
{"function": "\n\ndef set_flipped(self, x, y):\n    ' Sets the specified piece as flipped.\\n        '\n    self.pieces[(y + (y * self.width))].set_flipped()\n", "label": "Variable misuse"}
{"function": "\n\ndef on_leave(self, details):\n    self.disconnect()\n", "label": "Correct"}
{"function": "\n\ndef on_leave(self, details):\n    details.disconnect()\n", "label": "Variable misuse"}
{"function": "\n\n@needs_mail\n@needs_link\ndef proxy(request, mail, link):\n    return link.get_target(mail)(request, mail.person, mail.job.group_object)\n", "label": "Correct"}
{"function": "\n\n@needs_mail\n@needs_link\ndef proxy(request, mail, link):\n    return link.get_target(mail)(link, mail.person, mail.job.group_object)\n", "label": "Variable misuse"}
{"function": "\n\ndef TestParallelModify(instances):\n    'PERFORMANCE: Parallel instance modify.\\n\\n  @type instances: list of L{qa_config._QaInstance}\\n  @param instances: list of instances to issue modify commands against\\n\\n  '\n    job_driver = _JobQueueDriver()\n    new_min_mem = qa_config.get(constants.BE_MAXMEM)\n    for instance in instances:\n        cmd = ['gnt-instance', 'modify', '--submit', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value']\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n    job_driver.WaitForCompletion()\n", "label": "Correct"}
{"function": "\n\ndef TestParallelModify(instances):\n    'PERFORMANCE: Parallel instance modify.\\n\\n  @type instances: list of L{qa_config._QaInstance}\\n  @param instances: list of instances to issue modify commands against\\n\\n  '\n    job_driver = _JobQueueDriver()\n    new_min_mem = qa_config.get(constants.BE_MAXMEM)\n    for instance in instances:\n        cmd = ['gnt-instance', 'modify', '--submit', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value']\n        cmd.append(instances.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n        cmd = ['gnt-instance', 'modify', '--submit', '-O', 'fake_os_param=fake_value', '-B', ('%s=%s' % (constants.BE_MINMEM, new_min_mem))]\n        cmd.append(instance.name)\n        job_driver.AddJob(_ExecuteJobSubmittingCmd(cmd))\n    job_driver.WaitForCompletion()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_dir(self, path, dest='', saltenv='base', gzip=None, cachedir=None):\n    '\\n        Get a directory recursively from the salt-master\\n        '\n    ret = []\n    path = self._check_proto(path).rstrip('/')\n    separated = path.rsplit('/', 1)\n    if (len(separated) != 2):\n        prefix = ''\n    else:\n        prefix = separated[0]\n    for fn_ in self.file_list(saltenv, prefix=path):\n        try:\n            if (fn_[len(path)] != '/'):\n                continue\n        except IndexError:\n            continue\n        minion_relpath = fn_[len(prefix):].lstrip('/')\n        ret.append(self.get_file(salt.utils.url.create(fn_), '{0}/{1}'.format(dest, minion_relpath), True, saltenv, gzip))\n    try:\n        for fn_ in self.file_list_emptydirs(saltenv, prefix=path):\n            try:\n                if (fn_[len(path)] != '/'):\n                    continue\n            except IndexError:\n                continue\n            minion_relpath = fn_[len(prefix):].lstrip('/')\n            minion_mkdir = '{0}/{1}'.format(dest, minion_relpath)\n            if (not os.path.isdir(minion_mkdir)):\n                os.makedirs(minion_mkdir)\n            ret.append(minion_mkdir)\n    except TypeError:\n        pass\n    ret.sort()\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef get_dir(self, path, dest='', saltenv='base', gzip=None, cachedir=None):\n    '\\n        Get a directory recursively from the salt-master\\n        '\n    ret = []\n    path = self._check_proto(path).rstrip('/')\n    separated = path.rsplit('/', 1)\n    if (len(separated) != 2):\n        prefix = ''\n    else:\n        prefix = separated[0]\n    for fn_ in self.file_list(saltenv, prefix=path):\n        try:\n            if (fn_[len(path)] != '/'):\n                continue\n        except IndexError:\n            continue\n        minion_relpath = fn_[len(prefix):].lstrip('/')\n        ret.append(self.get_file(salt.utils.url.create(fn_), '{0}/{1}'.format(dest, minion_relpath), True, saltenv, gzip))\n    try:\n        for fn_ in self.file_list_emptydirs(saltenv, prefix=path):\n            try:\n                if (fn_[len(path)] != '/'):\n                    continue\n            except IndexError:\n                continue\n            minion_relpath = fn_[len(prefix):].lstrip('/')\n            minion_mkdir = '{0}/{1}'.format(saltenv, minion_relpath)\n            if (not os.path.isdir(minion_mkdir)):\n                os.makedirs(minion_mkdir)\n            ret.append(minion_mkdir)\n    except TypeError:\n        pass\n    ret.sort()\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\n@require_creds(True)\n@rpcmethod(signature=[SUCCESS_TYPE, URN_TYPE, CREDENTIALS_TYPE], url_name='openflow_gapi')\ndef DeleteSliver(slice_urn, credentials, **kwargs):\n    logger.debug('Called DeleteSliver')\n    try:\n        return gapi.DeleteSliver(slice_urn, kwargs['request'].user)\n    except Slice.DoesNotExist:\n        no_such_slice(slice_urn)\n", "label": "Correct"}
{"function": "\n\n@require_creds(True)\n@rpcmethod(signature=[SUCCESS_TYPE, URN_TYPE, CREDENTIALS_TYPE], url_name='openflow_gapi')\ndef DeleteSliver(slice_urn, credentials, **kwargs):\n    logger.debug('Called DeleteSliver')\n    try:\n        return gapi.DeleteSliver(credentials, kwargs['request'].user)\n    except Slice.DoesNotExist:\n        no_such_slice(slice_urn)\n", "label": "Variable misuse"}
{"function": "\n\ndef _dependencies(self):\n    projects = []\n    for attr in ('install_requires', 'tests_require'):\n        requirements = (getattr(self.distribution, attr, None) or [])\n        for project in requirements:\n            if (not project):\n                continue\n            projects.append(pypi.just_name(project))\n    extras = (getattr(self.distribution, 'extras_require', None) or {\n        \n    })\n    for value in extras.values():\n        projects.extend(map(pypi.just_name, value))\n    return projects\n", "label": "Correct"}
{"function": "\n\ndef _dependencies(self):\n    projects = []\n    for attr in ('install_requires', 'tests_require'):\n        requirements = (getattr(self.distribution, attr, None) or [])\n        for project in projects:\n            if (not project):\n                continue\n            projects.append(pypi.just_name(project))\n    extras = (getattr(self.distribution, 'extras_require', None) or {\n        \n    })\n    for value in extras.values():\n        projects.extend(map(pypi.just_name, value))\n    return projects\n", "label": "Variable misuse"}
{"function": "\n\ndef identity_provider_create(request, idp_id, description=None, enabled=False, remote_ids=None):\n    manager = keystoneclient(request, admin=True).federation.identity_providers\n    try:\n        return manager.create(id=idp_id, description=description, enabled=enabled, remote_ids=remote_ids)\n    except keystone_exceptions.Conflict:\n        raise exceptions.Conflict()\n", "label": "Correct"}
{"function": "\n\ndef identity_provider_create(request, idp_id, description=None, enabled=False, remote_ids=None):\n    manager = keystoneclient(request, admin=True).federation.identity_providers\n    try:\n        return idp_id.create(id=idp_id, description=description, enabled=enabled, remote_ids=remote_ids)\n    except keystone_exceptions.Conflict:\n        raise exceptions.Conflict()\n", "label": "Variable misuse"}
{"function": "\n\ndef save_graph_db_refs(self, sourceDB=None, targetDB=None, edgeDB=None, simpleKeys=False, unpack_edge=None, edgeDictClass=None, graph=None, **kwargs):\n    'apply kwargs to reference DB objects for this graph'\n    if (sourceDB is not None):\n        self.sourceDB = sourceDB\n    else:\n        simpleKeys = True\n    if (targetDB is not None):\n        self.targetDB = targetDB\n    if (edgeDB is not None):\n        self.edgeDB = edgeDB\n    else:\n        self.pack_edge = self.unpack_edge = (lambda edge: edge)\n    if simpleKeys:\n        self.__class__ = self._IDGraphClass\n    if (unpack_edge is not None):\n        self.unpack_edge = unpack_edge\n    if (graph is not None):\n        self.graph = graph\n    if (edgeDictClass is not None):\n        self.edgeDictClass = edgeDictClass\n", "label": "Correct"}
{"function": "\n\ndef save_graph_db_refs(self, sourceDB=None, targetDB=None, edgeDB=None, simpleKeys=False, unpack_edge=None, edgeDictClass=None, graph=None, **kwargs):\n    'apply kwargs to reference DB objects for this graph'\n    if (sourceDB is not None):\n        self.sourceDB = sourceDB\n    else:\n        simpleKeys = True\n    if (targetDB is not None):\n        self.targetDB = targetDB\n    if (edgeDB is not None):\n        self.edgeDB = edgeDB\n    else:\n        self.pack_edge = self.unpack_edge = (lambda edge: edge)\n    if edgeDB:\n        self.__class__ = self._IDGraphClass\n    if (unpack_edge is not None):\n        self.unpack_edge = unpack_edge\n    if (graph is not None):\n        self.graph = graph\n    if (edgeDictClass is not None):\n        self.edgeDictClass = edgeDictClass\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, errmsg='You need override this method'):\n    super(NeedOverrideError, self).__init__(self, errmsg)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, errmsg='You need override this method'):\n    super(NeedOverrideError, errmsg).__init__(self, errmsg)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_past_datetime(self):\n    value = self.sd.past_datetime()\n    self.assertTrue(isinstance(value, datetime.datetime))\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=1440))))\n    value = self.sd.past_datetime(0, 10)\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=10))))\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime(100, 0)\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime((- 10), 10)\n", "label": "Correct"}
{"function": "\n\ndef test_past_datetime(self):\n    value = self.sd.past_datetime()\n    self.assertTrue(isinstance(value, datetime.datetime))\n    self.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=1440))))\n    value = self.sd.past_datetime(0, 10)\n    value.assertTrue((value <= datetime.datetime.utcnow().replace(tzinfo=utc)))\n    self.assertTrue((value >= (datetime.datetime.utcnow().replace(tzinfo=utc) - datetime.timedelta(minutes=10))))\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime(100, 0)\n    with self.assertRaises(ParameterError):\n        self.sd.past_datetime((- 10), 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef play_rtmpdump_stream(player, url, params={\n    \n}):\n    cmdline = (\"rtmpdump -r '%s' \" % url)\n    for key in params.keys():\n        cmdline += (((key + ' ') + params[key]) if (params[key] != None) else ('' + ' '))\n    cmdline += (' -o - | %s -' % player)\n    print(cmdline)\n    os.system(cmdline)\n    return\n", "label": "Correct"}
{"function": "\n\ndef play_rtmpdump_stream(player, url, params={\n    \n}):\n    cmdline = (\"rtmpdump -r '%s' \" % params)\n    for key in params.keys():\n        cmdline += (((key + ' ') + params[key]) if (params[key] != None) else ('' + ' '))\n    cmdline += (' -o - | %s -' % player)\n    print(cmdline)\n    os.system(cmdline)\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef test_disable_logging(self):\n    NAME = 'name'\n    before = {\n        'logging': {\n            'logBucket': 'logs',\n            'logObjectPrefix': 'pfx',\n        },\n    }\n    bucket = self._makeOne(name=NAME, properties=before)\n    self.assertTrue((bucket.get_logging() is not None))\n    bucket.disable_logging()\n    self.assertTrue((bucket.get_logging() is None))\n", "label": "Correct"}
{"function": "\n\ndef test_disable_logging(self):\n    NAME = 'name'\n    before = {\n        'logging': {\n            'logBucket': 'logs',\n            'logObjectPrefix': 'pfx',\n        },\n    }\n    bucket = self._makeOne(name=NAME, properties=before)\n    self.assertTrue((self.get_logging() is not None))\n    bucket.disable_logging()\n    self.assertTrue((bucket.get_logging() is None))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_benchmark_variance_06(self):\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['Monthly'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.three_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['3-Month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.six_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['6-month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.year_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['year'])\n", "label": "Correct"}
{"function": "\n\ndef test_benchmark_variance_06(self):\n    np.testing.assert_almost_equal([self.benchmark_variance for x in self.metrics_06.month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['Monthly'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.three_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['3-Month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.six_month_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['6-month'])\n    np.testing.assert_almost_equal([x.benchmark_variance for x in self.metrics_06.year_periods], ANSWER_KEY.ALGORITHM_PERIOD_BENCHMARK_VARIANCE['year'])\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef size(cls, val, str_cache, object_cache, traits_cache):\n    if (val in object_cache):\n        index = object_cache.index(val)\n        return AMF3Integer.size((index << 1))\n    else:\n        object_cache.append(val)\n        size = 0\n        traits = type(val)\n        if (traits in traits_cache):\n            index = traits_cache.index(traits)\n            size += AMF3Integer.size(((index << 2) | 1))\n        else:\n            header = 3\n            if traits.__dynamic__:\n                header |= (2 << 2)\n            if traits.__externalizable__:\n                header |= (1 << 2)\n            header |= (len(traits.__members__) << 4)\n            size += AMF3Integer.size(header)\n            if isinstance(val, AMF3Object):\n                size += U8.size\n            else:\n                size += AMF3String.size(traits.__name__, cache=str_cache)\n                traits_cache.append(traits)\n            for member in traits.__members__:\n                size += AMF3String.size(member, cache=str_cache)\n        for member in traits.__members__:\n            value = getattr(val, member)\n            size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n        if traits.__dynamic__:\n            if isinstance(val, AMF3Object):\n                iterator = val.items()\n            else:\n                iterator = val.__dict__.items()\n            for (key, value) in iterator:\n                if (key in traits.__members__):\n                    continue\n                size += AMF3String.size(key, cache=str_cache)\n                size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n            size += U8.size\n        return size\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef size(cls, val, str_cache, object_cache, traits_cache):\n    if (val in object_cache):\n        index = object_cache.index(val)\n        return AMF3Integer.size((index << 1))\n    else:\n        object_cache.append(val)\n        size = 0\n        traits = type(val)\n        if (traits in traits_cache):\n            index = traits_cache.index(traits)\n            size += AMF3Integer.size(((index << 2) | 1))\n        else:\n            header = 3\n            if traits.__dynamic__:\n                header |= (2 << 2)\n            if traits.__externalizable__:\n                header |= (1 << 2)\n            header |= (len(traits.__members__) << 4)\n            size += AMF3Integer.size(header)\n            if isinstance(val, AMF3Object):\n                size += U8.size\n            else:\n                size += AMF3String.size(traits.__name__, cache=str_cache)\n                traits_cache.append(traits)\n            for member in traits.__members__:\n                size += AMF3String.size(member, cache=str_cache)\n        for member in traits.__members__:\n            value = getattr(val, member)\n            size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=traits_cache)\n        if traits.__dynamic__:\n            if isinstance(val, AMF3Object):\n                iterator = val.items()\n            else:\n                iterator = val.__dict__.items()\n            for (key, value) in iterator:\n                if (key in traits.__members__):\n                    continue\n                size += AMF3String.size(key, cache=str_cache)\n                size += AMF3Value.size(value, str_cache=str_cache, object_cache=object_cache, traits_cache=cls)\n            size += U8.size\n        return size\n", "label": "Variable misuse"}
{"function": "\n\ndef all_job_data(jobs, job_type):\n    ' Return an iterator over all job data. Exclude config template dups. '\n    conf_tmpl_ids = []\n    for job in jobs:\n        for (jt, data) in job.iteritems():\n            if (jt == job_type):\n                if (data['config_template_id'] not in conf_tmpl_ids):\n                    conf_tmpl_ids.append(data['config_template_id'])\n                    (yield data)\n", "label": "Correct"}
{"function": "\n\ndef all_job_data(jobs, job_type):\n    ' Return an iterator over all job data. Exclude config template dups. '\n    conf_tmpl_ids = []\n    for job in conf_tmpl_ids:\n        for (jt, data) in job.iteritems():\n            if (jt == job_type):\n                if (data['config_template_id'] not in conf_tmpl_ids):\n                    conf_tmpl_ids.append(data['config_template_id'])\n                    (yield data)\n", "label": "Variable misuse"}
{"function": "\n\ndef take_action(self, parsed_args):\n    identity_client = self.app.client_manager.identity\n    consumer = utils.find_resource(identity_client.oauth1.consumers, parsed_args.consumer)\n    identity_client.oauth1.consumers.delete(consumer.id)\n", "label": "Correct"}
{"function": "\n\ndef take_action(self, parsed_args):\n    identity_client = self.app.client_manager.identity\n    consumer = utils.find_resource(identity_client.oauth1.consumers, identity_client.consumer)\n    identity_client.oauth1.consumers.delete(consumer.id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _download_pdf(self, url, base_path):\n    local_file_path = os.path.join(base_path, 'billing-temp-document.pdf')\n    response = requests.get(url, stream=True)\n    should_wipe_bad_headers = True\n    with open(local_file_path, 'wb') as out_file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                if should_wipe_bad_headers:\n                    pdf_header_pos = chunk.find('%PDF-')\n                    if (pdf_header_pos > 0):\n                        chunk = chunk[pdf_header_pos:]\n                    should_wipe_bad_headers = False\n                out_file.write(chunk)\n                out_file.flush()\n    return local_file_path\n", "label": "Correct"}
{"function": "\n\ndef _download_pdf(self, url, base_path):\n    local_file_path = os.path.join(base_path, 'billing-temp-document.pdf')\n    response = requests.get(url, stream=True)\n    should_wipe_bad_headers = True\n    with open(local_file_path, 'wb') as out_file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                if should_wipe_bad_headers:\n                    pdf_header_pos = chunk.find('%PDF-')\n                    if (pdf_header_pos > 0):\n                        chunk = chunk[pdf_header_pos:]\n                    should_wipe_bad_headers = False\n                out_file.write(chunk)\n                base_path.flush()\n    return local_file_path\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_type_negative(self):\n    sla1 = TestCriterion(0)\n\n    class AnotherTestCriterion(TestCriterion):\n        pass\n    sla2 = AnotherTestCriterion(0)\n    self.assertRaises(TypeError, sla1.validate_type, sla2)\n", "label": "Correct"}
{"function": "\n\ndef test_validate_type_negative(self):\n    sla1 = TestCriterion(0)\n\n    class AnotherTestCriterion(TestCriterion):\n        pass\n    sla2 = AnotherTestCriterion(0)\n    self.assertRaises(TypeError, sla1.validate_type, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_profile_topics_bookmarks(self):\n    \"\\n        profile user's topics with bookmarks\\n        \"\n    bookmark = CommentBookmark.objects.create(topic=self.topic, user=self.user)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:topics', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['topics']), [self.topic])\n    self.assertEqual(response.context['topics'][0].bookmark, bookmark)\n", "label": "Correct"}
{"function": "\n\ndef test_profile_topics_bookmarks(self):\n    \"\\n        profile user's topics with bookmarks\\n        \"\n    bookmark = CommentBookmark.objects.create(topic=self.topic, user=self.user)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:topics', kwargs={\n        'pk': self.user2.pk,\n        'slug': bookmark.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['topics']), [self.topic])\n    self.assertEqual(response.context['topics'][0].bookmark, bookmark)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_volume_create_properties(self):\n    arglist = ['--property', 'Alpha=a', '--property', 'Beta=b', '--size', str(self.new_volume.size), self.new_volume.name]\n    verifylist = [('property', {\n        'Alpha': 'a',\n        'Beta': 'b',\n    }), ('size', self.new_volume.size), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=None, project_id=None, availability_zone=None, metadata={\n        'Alpha': 'a',\n        'Beta': 'b',\n    }, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Correct"}
{"function": "\n\ndef test_volume_create_properties(self):\n    arglist = ['--property', 'Alpha=a', '--property', 'Beta=b', '--size', str(self.new_volume.size), self.new_volume.name]\n    verifylist = [('property', {\n        'Alpha': 'a',\n        'Beta': 'b',\n    }), ('size', self.new_volume.size), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=None, project_id=None, availability_zone=None, metadata={\n        'Alpha': 'a',\n        'Beta': 'b',\n    }, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, self)\n    self.assertEqual(self.datalist, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef init_relation(self, models, relation):\n    '\\n        Initialize the relation on a set of models.\\n\\n        :type models: list\\n        :type relation: str\\n        '\n    for model in models:\n        model.set_relation(relation, Result(None, self, model))\n    return models\n", "label": "Correct"}
{"function": "\n\ndef init_relation(self, models, relation):\n    '\\n        Initialize the relation on a set of models.\\n\\n        :type models: list\\n        :type relation: str\\n        '\n    for model in models:\n        models.set_relation(relation, Result(None, self, model))\n    return models\n", "label": "Variable misuse"}
{"function": "\n\ndef test_with_some_synonyms(self):\n    SynonymFactory(from_words='foo', to_words='bar')\n    SynonymFactory(from_words='baz', to_words='qux')\n    (_, body) = es_utils.es_get_synonym_filter('en-US')\n    expected = {\n        'type': 'synonym',\n        'synonyms': ['foo => bar', 'baz => qux'],\n    }\n    eq_(body, expected)\n", "label": "Correct"}
{"function": "\n\ndef test_with_some_synonyms(self):\n    SynonymFactory(from_words='foo', to_words='bar')\n    SynonymFactory(from_words='baz', to_words='qux')\n    (_, body) = es_utils.es_get_synonym_filter('en-US')\n    expected = {\n        'type': 'synonym',\n        'synonyms': ['foo => bar', 'baz => qux'],\n    }\n    eq_(expected, expected)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self):\n    f = self.output().open('w')\n    print('hello, world', file=f)\n    f.close()\n", "label": "Correct"}
{"function": "\n\ndef run(self):\n    f = self.output().open('w')\n    print('hello, world', file=f)\n    self.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, area, width=4, char=' '):\n    self.width = width\n    self.char = char\n    area.install(('NORMAL', '<Key-greater>', (lambda event: event.widget.shift_sel_right(self.width, self.char))), ('NORMAL', '<Key-less>', (lambda event: event.widget.shift_sel_left(self.width))))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, area, width=4, char=' '):\n    self.width = width\n    event.char = char\n    area.install(('NORMAL', '<Key-greater>', (lambda event: event.widget.shift_sel_right(self.width, self.char))), ('NORMAL', '<Key-less>', (lambda event: event.widget.shift_sel_left(self.width))))\n", "label": "Variable misuse"}
{"function": "\n\ndef build(self, skip_features=False, managed=False):\n    if hasattr(self.session._internal, 'namespace'):\n        namespace_instance = self.session._internal.namespace['instance']\n        if hasattr(namespace_instance, 'after_request'):\n            getattr(namespace_instance, 'after_request')(self, self.session)\n    if (self.namespace and (not skip_features)):\n        for feature in self.namespace['features']:\n            feature._handle_response(self)\n    if (not isinstance(self.result, UnformattedResponse)):\n        if self.function:\n            self.result = self.function['format'](self.result)\n        if isinstance(self.output_formatter, type):\n            self.output_formatter = self.output_formatter(sapi_request=self.sapi_request, callback=self.callback)\n        if isinstance(self.wrapper, type):\n            self.wrapper = self.wrapper(sapi_request=self.sapi_request)\n        wrapper_result = self.wrapper._build(errors=self.errors, result=self.result)\n        formatter_result = self.output_formatter.build(wrapper_result)\n    else:\n        self.mimetype = self.result.mimetype\n        formatter_result = self.result.content\n    result = {\n        'result': formatter_result,\n        'mimetype': self.mimetype,\n    }\n    if managed:\n        return result\n    else:\n        return self._build_response_obj(self.sapi_request, result)\n", "label": "Correct"}
{"function": "\n\ndef build(self, skip_features=False, managed=False):\n    if hasattr(self.session._internal, 'namespace'):\n        namespace_instance = self.session._internal.namespace['instance']\n        if hasattr(namespace_instance, 'after_request'):\n            getattr(namespace_instance, 'after_request')(self, self.session)\n    if (self.namespace and (not skip_features)):\n        for feature in self.namespace['features']:\n            feature._handle_response(self)\n    if (not isinstance(self.result, UnformattedResponse)):\n        if self.function:\n            self.result = self.function['format'](self.result)\n        if isinstance(self.output_formatter, type):\n            self.output_formatter = self.output_formatter(sapi_request=self.sapi_request, callback=self.callback)\n        if isinstance(self.wrapper, type):\n            self.wrapper = self.wrapper(sapi_request=self.sapi_request)\n        wrapper_result = self.wrapper._build(errors=formatter_result.errors, result=self.result)\n        formatter_result = self.output_formatter.build(wrapper_result)\n    else:\n        self.mimetype = self.result.mimetype\n        formatter_result = self.result.content\n    result = {\n        'result': formatter_result,\n        'mimetype': self.mimetype,\n    }\n    if managed:\n        return result\n    else:\n        return self._build_response_obj(self.sapi_request, result)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef validate(cls, level):\n    level = int(level)\n    if (level in (cls.NONE, cls.READ, cls.WRITE, cls.ADMIN, cls.SITE_ADMIN)):\n        return level\n    else:\n        raise ValueError(('Invalid AccessType: %d.' % level))\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef validate(cls, level):\n    level = int(level)\n    if (level in (cls.NONE, level.READ, cls.WRITE, cls.ADMIN, cls.SITE_ADMIN)):\n        return level\n    else:\n        raise ValueError(('Invalid AccessType: %d.' % level))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, lib, dtype, N, C, K, H, W, P, Q, pad_h, pad_w, relu, bsum):\n    (R, S) = (3, 3)\n    GC32 = _ceil_div(C, 32)\n    GC16 = _ceil_div((GC32 * 32), 16)\n    GK16 = _ceil_div(K, 16)\n    self.filter_func = _get_bprop_filter_trans_4x4_kernel\n    self.filter_size = (((dtype.itemsize * 1152) * K) * GC32)\n    self.filter_args = [(GK16, GC16, 1), (256, 1, 1), None, None, None, ((R * S) * K), (S * K), ((S * K) * 2), K, C, (K * 1152)]\n    super(BpropWinograd_4x4_3x3, self).__init__(lib, dtype, N, K, C, P, Q, H, W, (2 - pad_h), (2 - pad_w), relu, bsum)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, lib, dtype, N, C, K, H, W, P, Q, pad_h, pad_w, relu, bsum):\n    (R, S) = (3, 3)\n    GC32 = _ceil_div(C, 32)\n    GC16 = _ceil_div((GC32 * 32), 16)\n    GK16 = _ceil_div(K, 16)\n    self.filter_func = _get_bprop_filter_trans_4x4_kernel\n    self.filter_size = (((dtype.itemsize * 1152) * K) * GC32)\n    self.filter_args = [(GK16, GC16, 1), (256, 1, 1), None, None, None, ((R * S) * K), (S * K), ((S * K) * 2), K, C, (K * 1152)]\n    super(BpropWinograd_4x4_3x3, self).__init__(lib, dtype, N, relu, C, P, Q, H, W, (2 - pad_h), (2 - pad_w), relu, bsum)\n", "label": "Variable misuse"}
{"function": "\n\n@records.post(validators=record_validator, permission='post_record')\ndef post_record(request):\n    'Saves a single model record.\\n\\n    Posted record attributes will be matched against the related model\\n    definition.\\n\\n    '\n    if (request.headers.get('Validate-Only', 'false') == 'true'):\n        return\n    model_id = request.matchdict['model_id']\n    if request.credentials_id:\n        credentials_id = request.credentials_id\n    else:\n        credentials_id = Everyone\n    record_id = request.db.put_record(model_id, request.data_clean, [credentials_id])\n    request.notify('RecordCreated', model_id, record_id)\n    created = ('%s/models/%s/records/%s' % (request.application_url, model_id, record_id))\n    request.response.status = '201 Created'\n    request.response.headers['location'] = str(created)\n    return {\n        'id': record_id,\n    }\n", "label": "Correct"}
{"function": "\n\n@records.post(validators=record_validator, permission='post_record')\ndef post_record(request):\n    'Saves a single model record.\\n\\n    Posted record attributes will be matched against the related model\\n    definition.\\n\\n    '\n    if (request.headers.get('Validate-Only', 'false') == 'true'):\n        return\n    model_id = request.matchdict['model_id']\n    if request.credentials_id:\n        credentials_id = request.credentials_id\n    else:\n        credentials_id = Everyone\n    record_id = request.db.put_record(model_id, request.data_clean, [record_id])\n    request.notify('RecordCreated', model_id, record_id)\n    created = ('%s/models/%s/records/%s' % (request.application_url, model_id, record_id))\n    request.response.status = '201 Created'\n    request.response.headers['location'] = str(created)\n    return {\n        'id': record_id,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef on_files_selected(self, paths):\n    \" Handle the 'filesSelected' signal from the dialog.\\n\\n        \"\n    d = self.declaration\n    if (d is not None):\n        d.selected_paths = paths\n", "label": "Correct"}
{"function": "\n\ndef on_files_selected(self, paths):\n    \" Handle the 'filesSelected' signal from the dialog.\\n\\n        \"\n    d = self.declaration\n    if (d is not None):\n        d.selected_paths = self\n", "label": "Variable misuse"}
{"function": "\n\ndef _dispatch(self, inst, kws):\n    assert (self.current_block is not None)\n    fname = ('op_%s' % inst.opname.replace('+', '_'))\n    try:\n        fn = getattr(self, fname)\n    except AttributeError:\n        raise NotImplementedError(inst)\n    else:\n        try:\n            return fn(inst, **kws)\n        except errors.NotDefinedError as e:\n            if (e.loc is None):\n                e.loc = self.loc\n            raise e\n", "label": "Correct"}
{"function": "\n\ndef _dispatch(self, inst, kws):\n    assert (self.current_block is not None)\n    fname = ('op_%s' % fn.opname.replace('+', '_'))\n    try:\n        fn = getattr(self, fname)\n    except AttributeError:\n        raise NotImplementedError(inst)\n    else:\n        try:\n            return fn(inst, **kws)\n        except errors.NotDefinedError as e:\n            if (e.loc is None):\n                e.loc = self.loc\n            raise e\n", "label": "Variable misuse"}
{"function": "\n\ndef set_context(self, serializer):\n    '\\n        This hook is called by the serializer instance,\\n        prior to the validation call being made.\\n        '\n    self.instance = getattr(serializer, 'instance', None)\n", "label": "Correct"}
{"function": "\n\ndef set_context(self, serializer):\n    '\\n        This hook is called by the serializer instance,\\n        prior to the validation call being made.\\n        '\n    serializer.instance = getattr(serializer, 'instance', None)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_add_ts_start(self, ts_start):\n    self._db_ts_start = ts_start\n", "label": "Correct"}
{"function": "\n\ndef db_add_ts_start(self, ts_start):\n    ts_start._db_ts_start = ts_start\n", "label": "Variable misuse"}
{"function": "\n\n@expose('/<string:locale>')\ndef index(self, locale):\n    session['locale'] = locale\n    refresh()\n    self.update_redirect()\n    return redirect(self.get_redirect())\n", "label": "Correct"}
{"function": "\n\n@expose('/<string:locale>')\ndef index(self, locale):\n    session['locale'] = locale\n    refresh()\n    self.update_redirect()\n    return redirect(locale.get_redirect())\n", "label": "Variable misuse"}
{"function": "\n\ndef reselect(self, pos):\n\n    def select(view, edit):\n        region = pos\n        if hasattr(pos, '__call__'):\n            region = run_callback(pos, view)\n        if isinstance(region, int):\n            region = sublime.Region(region, region)\n        elif isinstance(region, (tuple, list)):\n            region = sublime.Region(*region)\n        view.sel().clear()\n        view.sel().add(region)\n        view.show(region, False)\n    self.callback(select)\n", "label": "Correct"}
{"function": "\n\ndef reselect(self, pos):\n\n    def select(view, edit):\n        region = pos\n        if hasattr(pos, '__call__'):\n            region = run_callback(pos, view)\n        if isinstance(region, int):\n            region = sublime.Region(region, region)\n        elif isinstance(region, (tuple, list)):\n            region = sublime.Region(*region)\n        view.sel().clear()\n        view.sel().add(region)\n        view.show(region, False)\n    pos.callback(select)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_mutual_info_regression():\n    (X, y) = make_regression(n_samples=100, n_features=10, n_informative=2, shuffle=False, random_state=0, noise=10)\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='k_best', param=2).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='percentile', param=20).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n", "label": "Correct"}
{"function": "\n\ndef test_mutual_info_regression():\n    (X, y) = make_regression(n_samples=100, n_features=10, n_informative=2, shuffle=False, random_state=0, noise=10)\n    univariate_filter = SelectKBest(mutual_info_regression, k=2)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    assert_best_scores_kept(univariate_filter)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='k_best', param=2).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, gtruth)\n    univariate_filter = SelectPercentile(mutual_info_regression, percentile=20)\n    X_r = univariate_filter.fit(X, y).transform(X)\n    X_r2 = GenericUnivariateSelect(mutual_info_regression, mode='percentile', param=20).fit(X, y).transform(X)\n    assert_array_equal(X_r, X_r2)\n    support = univariate_filter.get_support()\n    gtruth = np.zeros(10)\n    gtruth[:2] = 1\n    assert_array_equal(support, X_r2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_derived(self):\n    import time\n\n    class Local(threading.local):\n\n        def __init__(self):\n            time.sleep(0.01)\n    local = Local()\n\n    def f(i):\n        local.x = i\n        self.assertEqual(local.x, i)\n    threads = []\n    for i in range(10):\n        t = threading.Thread(target=f, args=(i,))\n        t.start()\n        threads.append(t)\n    for t in threads:\n        t.join()\n", "label": "Correct"}
{"function": "\n\ndef test_derived(self):\n    import time\n\n    class Local(threading.local):\n\n        def __init__(self):\n            time.sleep(0.01)\n    local = Local()\n\n    def f(i):\n        local.x = i\n        self.assertEqual(local.x, i)\n    threads = []\n    for i in range(10):\n        t = threading.Thread(target=f, args=(i,))\n        t.start()\n        threads.append(t)\n    for t in local:\n        t.join()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_retry_in_graph_flow_requires_and_provides(self):\n    flow = gf.Flow('gf', retry.AlwaysRevert('rt', requires=['x', 'y'], provides=['a', 'b']))\n    self.assertEqual(set(['x', 'y']), flow.requires)\n    self.assertEqual(set(['a', 'b']), flow.provides)\n", "label": "Correct"}
{"function": "\n\ndef test_retry_in_graph_flow_requires_and_provides(self):\n    flow = gf.Flow('gf', retry.AlwaysRevert('rt', requires=['x', 'y'], provides=['a', 'b']))\n    self.assertEqual(set(['x', 'y']), flow.requires)\n    self.assertEqual(set(['a', 'b']), self.provides)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_review_comments(self):\n    \"Show that one can iterate over a PR's review comments.\"\n    cassette_name = self.cassette_name('review_comments')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        for comment in p.review_comments():\n            assert isinstance(comment, github3.pulls.ReviewComment)\n", "label": "Correct"}
{"function": "\n\ndef test_review_comments(self):\n    \"Show that one can iterate over a PR's review comments.\"\n    cassette_name = cassette_name.cassette_name('review_comments')\n    with self.recorder.use_cassette(cassette_name):\n        p = self.get_pull_request()\n        for comment in p.review_comments():\n            assert isinstance(comment, github3.pulls.ReviewComment)\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self, t, dt):\n    if (random.random() < 0.02):\n        self.a += ((random.randint((- 1), 1) * pi) / 8)\n    dx = cos(self.a)\n    dz = sin(self.a)\n    self.x += (dx * dt)\n    self.z += (dz * dt)\n", "label": "Correct"}
{"function": "\n\ndef update(self, t, dt):\n    if (random.random() < 0.02):\n        self.a += ((random.randint((- 1), 1) * pi) / 8)\n    dx = cos(self.a)\n    dz = sin(self.a)\n    self.x += (dx * dt)\n    self.z += (dz * self)\n", "label": "Variable misuse"}
{"function": "\n\ndef encryption_oracle(rawInput):\n    key = generateAESKey()\n    iv = generateAESKey()\n    prependAmount = (5 + (getOneRandomByte() % 6))\n    appendAmount = (5 + (getOneRandomByte() % 6))\n    plaintext = (((b'x' * prependAmount) + rawInput) + (b'y' * appendAmount))\n    if (getOneRandomByte() & 1):\n        return aes_ecb_enc(addPKCS7Padding(plaintext, 16), key)\n    else:\n        return aes_cbc_enc(addPKCS7Padding(plaintext, 16), key, iv)\n", "label": "Correct"}
{"function": "\n\ndef encryption_oracle(rawInput):\n    key = generateAESKey()\n    iv = generateAESKey()\n    prependAmount = (5 + (getOneRandomByte() % 6))\n    appendAmount = (5 + (getOneRandomByte() % 6))\n    plaintext = (((b'x' * prependAmount) + rawInput) + (b'y' * appendAmount))\n    if (getOneRandomByte() & 1):\n        return aes_ecb_enc(addPKCS7Padding(plaintext, 16), prependAmount)\n    else:\n        return aes_cbc_enc(addPKCS7Padding(plaintext, 16), key, iv)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_status(self, lines):\n    activity = []\n    seen_times = set()\n    for line in lines:\n        (time, fields) = line.split('|')\n        if (time not in seen_times):\n            seen_times.add(time)\n            status_obj = status.Status(int(float(time)), fields)\n            activity.append(status_obj)\n    return activity\n", "label": "Correct"}
{"function": "\n\ndef parse_status(self, lines):\n    activity = []\n    seen_times = set()\n    for line in lines:\n        (time, fields) = line.split('|')\n        if (time not in seen_times):\n            seen_times.add(time)\n            status_obj = status.Status(int(float(time)), fields)\n            lines.append(status_obj)\n    return activity\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef directions(self):\n    hashes = []\n    t_query = 'select trip_headsign, trip_short_name, bikes_allowed,\\n        trip_id from trips where route_id=:route_id and _feed=:_feed'\n    t_filter = {\n        'route_id': self.id,\n        '_feed': self.provider.feed_id,\n    }\n    cur = self.provider.conn.cursor()\n    for trip in cur.execute(t_query, t_filter):\n        direction = {\n            \n        }\n        innercur = self.provider.conn.cursor()\n        result = innercur.execute('select s.* from stop_times as st join stops as s\\n                on st.stop_id=s.stop_id and st._feed=s._feed\\n                where st.trip_id=:t_id and st._feed=:_feed', {\n            't_id': trip['trip_id'],\n            '_feed': self.provider.feed_id,\n        })\n        direction['stops'] = [GTFSStop(self.provider, **dict(row)) for row in result]\n        if (trip['trip_headsign'] is not None):\n            direction['headsign'] = trip['trip_headsign']\n        if (trip['trip_short_name'] is not None):\n            direction['short_name'] = trip['trip_short_name']\n        if (trip['bikes_allowed'] is not None):\n            direction['bikes_ok'] = trip['bikes_allowed']\n        h = util.freezehash(direction)\n        if (h not in hashes):\n            hashes.append(h)\n            (yield direction)\n", "label": "Correct"}
{"function": "\n\n@property\ndef directions(self):\n    hashes = []\n    t_query = 'select trip_headsign, trip_short_name, bikes_allowed,\\n        trip_id from trips where route_id=:route_id and _feed=:_feed'\n    t_filter = {\n        'route_id': self.id,\n        '_feed': self.provider.feed_id,\n    }\n    cur = self.provider.conn.cursor()\n    for trip in cur.execute(t_query, t_filter):\n        direction = {\n            \n        }\n        innercur = self.provider.conn.cursor()\n        result = innercur.execute('select s.* from stop_times as st join stops as s\\n                on st.stop_id=s.stop_id and st._feed=s._feed\\n                where st.trip_id=:t_id and st._feed=:_feed', {\n            't_id': trip['trip_id'],\n            '_feed': self.provider.feed_id,\n        })\n        direction['stops'] = [GTFSStop(self.provider, **dict(row)) for row in result]\n        if (trip['trip_headsign'] is not None):\n            direction['headsign'] = trip['trip_headsign']\n        if (trip['trip_short_name'] is not None):\n            direction['short_name'] = trip['trip_short_name']\n        if (trip['bikes_allowed'] is not None):\n            t_query['bikes_ok'] = trip['bikes_allowed']\n        h = util.freezehash(direction)\n        if (h not in hashes):\n            hashes.append(h)\n            (yield direction)\n", "label": "Variable misuse"}
{"function": "\n\ndef _partitions_to_src(partitions):\n    return ''.join((part.src for part in partitions))\n", "label": "Correct"}
{"function": "\n\ndef _partitions_to_src(partitions):\n    return ''.join((partitions.src for part in partitions))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_input_extra_rewrite(self):\n    self.client_job_description.rewrite_paths = True\n    extra_file = os.path.join(self.input1_files_path, 'moo', 'cow.txt')\n    os.makedirs(os.path.dirname(extra_file))\n    open(extra_file, 'w').write('Hello World!')\n    command_line = ('test.exe %s' % extra_file)\n    self.client_job_description.command_line = command_line\n    self.client.expect_command_line('test.exe /pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt')\n    self.client.expect_put_paths(['/pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt'])\n    self._submit()\n    uploaded_file1 = self.client.put_files[0]\n    assert (uploaded_file1[1] == 'input')\n    assert (uploaded_file1[0] == extra_file)\n", "label": "Correct"}
{"function": "\n\ndef test_input_extra_rewrite(self):\n    self.client_job_description.rewrite_paths = True\n    extra_file = os.path.join(self.input1_files_path, 'moo', 'cow.txt')\n    os.makedirs(os.path.dirname(extra_file))\n    open(extra_file, 'w').write('Hello World!')\n    command_line = ('test.exe %s' % extra_file)\n    self.client_job_description.command_line = command_line\n    self.client.expect_command_line('test.exe /pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt')\n    self.client.expect_put_paths(['/pulsar/staging/1/inputs/dataset_1_files/moo/cow.txt'])\n    self._submit()\n    uploaded_file1 = command_line.client.put_files[0]\n    assert (uploaded_file1[1] == 'input')\n    assert (uploaded_file1[0] == extra_file)\n", "label": "Variable misuse"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.LIST):\n                self.column_names = []\n                (_etype10, _size7) = iprot.readListBegin()\n                for _i11 in xrange(_size7):\n                    _elem12 = iprot.readString()\n                    self.column_names.append(_elem12)\n                iprot.readListEnd()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRUCT):\n                self.slice_range = SliceRange()\n                self.slice_range.read(iprot)\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, fname.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.LIST):\n                self.column_names = []\n                (_etype10, _size7) = iprot.readListBegin()\n                for _i11 in xrange(_size7):\n                    _elem12 = iprot.readString()\n                    self.column_names.append(_elem12)\n                iprot.readListEnd()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRUCT):\n                self.slice_range = SliceRange()\n                self.slice_range.read(iprot)\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_member_addresses(self):\n    addresses = []\n    for member in self.config_members:\n        addresses.append(member.get_server().get_address())\n    return addresses\n", "label": "Correct"}
{"function": "\n\ndef get_member_addresses(self):\n    addresses = []\n    for member in self.config_members:\n        addresses.append(self.get_server().get_address())\n    return addresses\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dispatch_on_heartbeat_frame(self):\n    frame = mock()\n    expect(frame.type).returns(HeartbeatFrame.type())\n    expect(self.ch.send_heartbeat)\n    self.ch.dispatch(frame)\n", "label": "Correct"}
{"function": "\n\ndef test_dispatch_on_heartbeat_frame(self):\n    frame = mock()\n    expect(frame.type).returns(HeartbeatFrame.type())\n    expect(self.ch.send_heartbeat)\n    self.ch.dispatch(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, output_type, inplace=False):\n    Op.__init__(self)\n    self.output_type = output_type\n    self.inplace = inplace\n    if inplace:\n        self.destroy_map = {\n            0: [0],\n        }\n    self.warned_numpy_version = False\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, output_type, inplace=False):\n    Op.__init__(self)\n    output_type.output_type = output_type\n    self.inplace = inplace\n    if inplace:\n        self.destroy_map = {\n            0: [0],\n        }\n    self.warned_numpy_version = False\n", "label": "Variable misuse"}
{"function": "\n\ndef CheckLoggingWorks(self):\n    logger = StringIO.StringIO()\n    expected_output = (';\\n'.join([sqlite.main._BEGIN, 'CREATE TABLE TEST(FOO INTEGER)', 'INSERT INTO TEST(FOO) VALUES (?)', 'ROLLBACK']) + ';\\n')\n    self.cnx = sqlite.connect(self.getfilename(), command_logfile=logger)\n    cu = self.cnx.cursor()\n    cu.execute('CREATE TABLE TEST(FOO INTEGER)')\n    cu.execute('INSERT INTO TEST(FOO) VALUES (?)', (5,))\n    self.cnx.rollback()\n    logger.seek(0)\n    real_output = logger.read()\n    if (expected_output != real_output):\n        self.fail(\"Logging didn't produce expected output.\")\n", "label": "Correct"}
{"function": "\n\ndef CheckLoggingWorks(self):\n    logger = StringIO.StringIO()\n    expected_output = (';\\n'.join([sqlite.main._BEGIN, 'CREATE TABLE TEST(FOO INTEGER)', 'INSERT INTO TEST(FOO) VALUES (?)', 'ROLLBACK']) + ';\\n')\n    self.cnx = sqlite.connect(expected_output.getfilename(), command_logfile=logger)\n    cu = self.cnx.cursor()\n    cu.execute('CREATE TABLE TEST(FOO INTEGER)')\n    cu.execute('INSERT INTO TEST(FOO) VALUES (?)', (5,))\n    self.cnx.rollback()\n    logger.seek(0)\n    real_output = logger.read()\n    if (expected_output != real_output):\n        self.fail(\"Logging didn't produce expected output.\")\n", "label": "Variable misuse"}
{"function": "\n\ndef bitand(self, other):\n    return self._combine(other, self.BITAND, False)\n", "label": "Correct"}
{"function": "\n\ndef bitand(self, other):\n    return other._combine(other, self.BITAND, False)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_environment(self, app):\n    return app.extensions['gears']['environment']\n", "label": "Correct"}
{"function": "\n\ndef get_environment(self, app):\n    return self.extensions['gears']['environment']\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, odffile):\n    ' Loads a document into the parser and parses it.\\n            The argument can either be a filename or a document in memory.\\n        '\n    self.lines = []\n    self._wfunc = self._wlines\n    if isinstance(odffile, str):\n        self.document = load(odffile)\n    else:\n        self.document = odffile\n    self._walknode(self.document.topnode)\n", "label": "Correct"}
{"function": "\n\ndef load(self, odffile):\n    ' Loads a document into the parser and parses it.\\n            The argument can either be a filename or a document in memory.\\n        '\n    self.lines = []\n    self._wfunc = odffile._wlines\n    if isinstance(odffile, str):\n        self.document = load(odffile)\n    else:\n        self.document = odffile\n    self._walknode(self.document.topnode)\n", "label": "Variable misuse"}
{"function": "\n\ndef db_children(self, parent=(None, None), orphan=False):\n    children = []\n    children.append((self, parent[0], parent[1]))\n    return children\n", "label": "Correct"}
{"function": "\n\ndef db_children(self, parent=(None, None), orphan=False):\n    children = []\n    children.append((self, orphan[0], parent[1]))\n    return children\n", "label": "Variable misuse"}
{"function": "\n\ndef blacklist_delete_user_agents(self, request, queryset):\n    self.blacklist_user_agents(request, queryset)\n    self.delete_queryset(request, queryset)\n", "label": "Correct"}
{"function": "\n\ndef blacklist_delete_user_agents(self, request, queryset):\n    self.blacklist_user_agents(request, self)\n    self.delete_queryset(request, queryset)\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n\n    def format_row(row):\n        return ('(%s)' % ', '.join((format_number(value) for value in row)))\n    return ('Matrix44(%s)' % ', '.join((format_row(row) for row in self.rows())))\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n\n    def format_row(row):\n        return ('(%s)' % ', '.join((format_number(value) for value in row)))\n    return ('Matrix44(%s)' % ', '.join((format_row(row) for row in row.rows())))\n", "label": "Variable misuse"}
{"function": "\n\ndef _createFile(self):\n    self.h5file.create_array('/', 'arr1', [1, 2])\n    group1 = self.h5file.create_group('/', 'group1')\n    arr2 = self.h5file.create_array(group1, 'arr2', [1, 2, 3])\n    lgroup1 = self.h5file.create_hard_link('/', 'lgroup1', '/group1')\n    self.assertTrue((lgroup1 is not None))\n    larr1 = self.h5file.create_hard_link(group1, 'larr1', '/arr1')\n    self.assertTrue((larr1 is not None))\n    larr2 = self.h5file.create_hard_link('/', 'larr2', arr2)\n    self.assertTrue((larr2 is not None))\n", "label": "Correct"}
{"function": "\n\ndef _createFile(self):\n    self.h5file.create_array('/', 'arr1', [1, 2])\n    group1 = self.h5file.create_group('/', 'group1')\n    arr2 = group1.h5file.create_array(group1, 'arr2', [1, 2, 3])\n    lgroup1 = self.h5file.create_hard_link('/', 'lgroup1', '/group1')\n    self.assertTrue((lgroup1 is not None))\n    larr1 = self.h5file.create_hard_link(group1, 'larr1', '/arr1')\n    self.assertTrue((larr1 is not None))\n    larr2 = self.h5file.create_hard_link('/', 'larr2', arr2)\n    self.assertTrue((larr2 is not None))\n", "label": "Variable misuse"}
{"function": "\n\ndef saveXML(self, snode):\n    if (snode is None):\n        snode = self\n    elif (snode.ownerDocument is not self):\n        raise xml.dom.WrongDocumentErr()\n    return snode.toxml()\n", "label": "Correct"}
{"function": "\n\ndef saveXML(self, snode):\n    if (snode is None):\n        snode = self\n    elif (self.ownerDocument is not self):\n        raise xml.dom.WrongDocumentErr()\n    return snode.toxml()\n", "label": "Variable misuse"}
{"function": "\n\ndef install(self, instance):\n    cfg = self.config\n    if (self.database == self.master_database):\n        template = 'template1'\n    else:\n        template = self.master_database\n    config_opt_map = dict(host='host', user='username', password='password', encoding='encoding', lc_collate='lc-collate', lc_ctype='lc-ctype', tablespace='tablespace')\n    options = [((('--' + opt) + '=') + str(cfg[cfg_name])) for (cfg_name, opt) in config_opt_map.iteritems() if (cfg_name in cfg)]\n    fail = instance.do(((['createdb', '--template', template] + options) + [self.database]))\n    if fail:\n        instance.do(['pg_dump', '-h', str(cfg['host']), '-U', str(cfg['user']), '-E', str(cfg['encoding']), '-f', (('/tmp/' + template) + '.sql'), template])\n        instance.do(((['createdb', '--template', 'template1'] + options) + [self.database]))\n        instance.do(['psql', '-h', str(cfg['host']), '-U', str(cfg['user']), '-f', (('/tmp/' + template) + '.sql'), self.database])\n    info = self.connection_info\n    info['database'] = self.database\n    return info\n", "label": "Correct"}
{"function": "\n\ndef install(self, instance):\n    cfg = self.config\n    if (self.database == self.master_database):\n        template = 'template1'\n    else:\n        template = self.master_database\n    config_opt_map = dict(host='host', user='username', password='password', encoding='encoding', lc_collate='lc-collate', lc_ctype='lc-ctype', tablespace='tablespace')\n    options = [((('--' + opt) + '=') + str(config_opt_map[cfg_name])) for (cfg_name, opt) in config_opt_map.iteritems() if (cfg_name in cfg)]\n    fail = instance.do(((['createdb', '--template', template] + options) + [self.database]))\n    if fail:\n        instance.do(['pg_dump', '-h', str(cfg['host']), '-U', str(cfg['user']), '-E', str(cfg['encoding']), '-f', (('/tmp/' + template) + '.sql'), template])\n        instance.do(((['createdb', '--template', 'template1'] + options) + [self.database]))\n        instance.do(['psql', '-h', str(cfg['host']), '-U', str(cfg['user']), '-f', (('/tmp/' + template) + '.sql'), self.database])\n    info = self.connection_info\n    info['database'] = self.database\n    return info\n", "label": "Variable misuse"}
{"function": "\n\n@contextmanager\ndef trace_ms(statName):\n    if (_instatrace is None):\n        (yield)\n        return\n    now = _instatrace.now_ms()\n    (yield)\n    _instatrace.trace(statName, (_instatrace.now_ms() - now))\n", "label": "Correct"}
{"function": "\n\n@contextmanager\ndef trace_ms(statName):\n    if (_instatrace is None):\n        (yield)\n        return\n    now = _instatrace.now_ms()\n    (yield)\n    _instatrace.trace(statName, (_instatrace.now_ms() - statName))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_bad_column_qualifier(self):\n    families = {\n        cf2: 'oberyn',\n    }\n    res = self.c.get(table, self.row_prefix, families=families)\n    self.assertEqual(result_to_dict(res), {\n        \n    })\n", "label": "Correct"}
{"function": "\n\ndef test_get_bad_column_qualifier(self):\n    families = {\n        cf2: 'oberyn',\n    }\n    res = self.c.get(table, self.row_prefix, families=families)\n    families.assertEqual(result_to_dict(res), {\n        \n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef test_grad_s(self):\n    'tests that the gradients with respect to s_i are 0 after doing a mean field update of s_i '\n    model = self.model\n    e_step = self.e_step\n    X = self.X\n    assert (X.shape[0] == self.m)\n    model.test_batch_size = X.shape[0]\n    init_H = e_step.init_H_hat(V=X)\n    init_Mu1 = e_step.init_S_hat(V=X)\n    prev_setting = config.compute_test_value\n    config.compute_test_value = 'off'\n    (H, Mu1) = function([], outputs=[init_H, init_Mu1])()\n    config.compute_test_value = prev_setting\n    H = broadcast(H, self.m)\n    Mu1 = broadcast(Mu1, self.m)\n    H = np.cast[config.floatX](self.model.rng.uniform(0.0, 1.0, H.shape))\n    Mu1 = np.cast[config.floatX](self.model.rng.uniform((- 5.0), 5.0, Mu1.shape))\n    H_var = T.matrix(name='H_var')\n    H_var.tag.test_value = H\n    Mu1_var = T.matrix(name='Mu1_var')\n    Mu1_var.tag.test_value = Mu1\n    idx = T.iscalar()\n    idx.tag.test_value = 0\n    S = e_step.infer_S_hat(V=X, H_hat=H_var, S_hat=Mu1_var)\n    s_idx = S[:, idx]\n    s_i_func = function([H_var, Mu1_var, idx], s_idx)\n    sigma0 = (1.0 / model.alpha)\n    Sigma1 = e_step.infer_var_s1_hat()\n    mu0 = T.zeros_like(model.mu)\n    trunc_kl = ((- model.entropy_hs(H_hat=H_var, var_s0_hat=sigma0, var_s1_hat=Sigma1)) + model.expected_energy_vhs(V=X, H_hat=H_var, S_hat=Mu1_var, var_s0_hat=sigma0, var_s1_hat=Sigma1))\n    grad_Mu1 = T.grad(trunc_kl.sum(), Mu1_var)\n    grad_Mu1_idx = grad_Mu1[:, idx]\n    grad_func = function([H_var, Mu1_var, idx], grad_Mu1_idx)\n    for i in xrange(self.N):\n        Mu1[:, i] = s_i_func(H, Mu1, i)\n        g = grad_func(H, Mu1, i)\n        assert (not contains_nan(g))\n        g_abs_max = np.abs(g).max()\n        if (g_abs_max > self.tol):\n            raise Exception(((('after mean field step, gradient of kl divergence wrt mean field parameter should be 0, but here the max magnitude of a gradient element is ' + str(g_abs_max)) + ' after updating s_') + str(i)))\n", "label": "Correct"}
{"function": "\n\ndef test_grad_s(self):\n    'tests that the gradients with respect to s_i are 0 after doing a mean field update of s_i '\n    model = self.model\n    e_step = self.e_step\n    X = self.X\n    assert (X.shape[0] == self.m)\n    model.test_batch_size = X.shape[0]\n    init_H = e_step.init_H_hat(V=X)\n    init_Mu1 = e_step.init_S_hat(V=init_H)\n    prev_setting = config.compute_test_value\n    config.compute_test_value = 'off'\n    (H, Mu1) = function([], outputs=[init_H, init_Mu1])()\n    config.compute_test_value = prev_setting\n    H = broadcast(H, self.m)\n    Mu1 = broadcast(Mu1, self.m)\n    H = np.cast[config.floatX](self.model.rng.uniform(0.0, 1.0, H.shape))\n    Mu1 = np.cast[config.floatX](self.model.rng.uniform((- 5.0), 5.0, Mu1.shape))\n    H_var = T.matrix(name='H_var')\n    H_var.tag.test_value = H\n    Mu1_var = T.matrix(name='Mu1_var')\n    Mu1_var.tag.test_value = Mu1\n    idx = T.iscalar()\n    idx.tag.test_value = 0\n    S = e_step.infer_S_hat(V=X, H_hat=H_var, S_hat=Mu1_var)\n    s_idx = S[:, idx]\n    s_i_func = function([H_var, Mu1_var, idx], s_idx)\n    sigma0 = (1.0 / model.alpha)\n    Sigma1 = e_step.infer_var_s1_hat()\n    mu0 = T.zeros_like(model.mu)\n    trunc_kl = ((- model.entropy_hs(H_hat=H_var, var_s0_hat=sigma0, var_s1_hat=Sigma1)) + model.expected_energy_vhs(V=X, H_hat=H_var, S_hat=Mu1_var, var_s0_hat=sigma0, var_s1_hat=Sigma1))\n    grad_Mu1 = T.grad(trunc_kl.sum(), Mu1_var)\n    grad_Mu1_idx = grad_Mu1[:, idx]\n    grad_func = function([H_var, Mu1_var, idx], grad_Mu1_idx)\n    for i in xrange(self.N):\n        Mu1[:, i] = s_i_func(H, Mu1, i)\n        g = grad_func(H, Mu1, i)\n        assert (not contains_nan(g))\n        g_abs_max = np.abs(g).max()\n        if (g_abs_max > self.tol):\n            raise Exception(((('after mean field step, gradient of kl divergence wrt mean field parameter should be 0, but here the max magnitude of a gradient element is ' + str(g_abs_max)) + ' after updating s_') + str(i)))\n", "label": "Variable misuse"}
{"function": "\n\ndef db_add_portSpec(self, portSpec):\n    self.__db_portSpec = portSpec\n", "label": "Correct"}
{"function": "\n\ndef db_add_portSpec(self, portSpec):\n    self.__db_portSpec = self\n", "label": "Variable misuse"}
{"function": "\n\ndef do(args):\n    ' Main method '\n    if args.name:\n        tc_names = [args.name]\n    else:\n        tc_names = qitoolchain.get_tc_names()\n    for tc_name in tc_names:\n        toolchain = qitoolchain.get_toolchain(tc_name)\n        ui.info(str(toolchain))\n", "label": "Correct"}
{"function": "\n\ndef do(args):\n    ' Main method '\n    if args.name:\n        tc_names = [args.name]\n    else:\n        tc_names = qitoolchain.get_tc_names()\n    for tc_name in tc_names:\n        toolchain = qitoolchain.get_toolchain(tc_name)\n        ui.info(str(tc_name))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_IRParamStmt_dump():\n    stmt = {\n        'param': 'IR',\n        'angle': '45',\n    }\n    ir = IRParamStmt.from_dict(stmt)\n    assert_equal(ir.to_gerber(), '%IR45*%')\n", "label": "Correct"}
{"function": "\n\ndef test_IRParamStmt_dump():\n    stmt = {\n        'param': 'IR',\n        'angle': '45',\n    }\n    ir = IRParamStmt.from_dict(ir)\n    assert_equal(ir.to_gerber(), '%IR45*%')\n", "label": "Variable misuse"}
{"function": "\n\ndef get_resources(self):\n    resources = []\n    resource = extensions.ResourceExtension('os-agents', AgentController())\n    resources.append(resource)\n    return resources\n", "label": "Correct"}
{"function": "\n\ndef get_resources(self):\n    resources = []\n    resource = extensions.ResourceExtension('os-agents', AgentController())\n    resources.append(self)\n    return resources\n", "label": "Variable misuse"}
{"function": "\n\ndef _save(self, key, attributes):\n    s_uuid = self.repo.save(key, attributes)\n    self.logger.debug(('creating object with uuid = %s' % s_uuid))\n    attribute_type = AT.UNIQUE_IDENTIFIER\n    attribute = self.attribute_factory.create_attribute(attribute_type, s_uuid)\n    attributes.append(attribute)\n    self.repo.update(s_uuid, key, attributes)\n    return (s_uuid, attribute)\n", "label": "Correct"}
{"function": "\n\ndef _save(self, key, attributes):\n    s_uuid = self.repo.save(s_uuid, attributes)\n    self.logger.debug(('creating object with uuid = %s' % s_uuid))\n    attribute_type = AT.UNIQUE_IDENTIFIER\n    attribute = self.attribute_factory.create_attribute(attribute_type, s_uuid)\n    attributes.append(attribute)\n    self.repo.update(s_uuid, key, attributes)\n    return (s_uuid, attribute)\n", "label": "Variable misuse"}
{"function": "\n\ndef to_array(self):\n    '\\n        Convert the RiakLinkPhase to a format that can be output into\\n        JSON. Used internally.\\n        '\n    stepdef = {\n        'bucket': self._bucket,\n        'tag': self._tag,\n        'keep': self._keep,\n    }\n    return {\n        'link': stepdef,\n    }\n", "label": "Correct"}
{"function": "\n\ndef to_array(self):\n    '\\n        Convert the RiakLinkPhase to a format that can be output into\\n        JSON. Used internally.\\n        '\n    stepdef = {\n        'bucket': stepdef._bucket,\n        'tag': self._tag,\n        'keep': self._keep,\n    }\n    return {\n        'link': stepdef,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/crafted/capacitor/shared_quick_recharge_battery_mk5.iff'\n    result.attribute_template_id = 8\n    result.stfName('space_crafting_n', 'quick_recharge_battery_mk5')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/crafted/capacitor/shared_quick_recharge_battery_mk5.iff'\n    result.attribute_template_id = 8\n    result.stfName('space_crafting_n', 'quick_recharge_battery_mk5')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef abort_request(self, stream, ident, parent):\n    'abort a specifig msg by id'\n    msg_ids = parent['content'].get('msg_ids', None)\n    if isinstance(msg_ids, str):\n        msg_ids = [msg_ids]\n    if (not msg_ids):\n        self.abort_queues()\n    for mid in msg_ids:\n        self.aborted.add(str(mid))\n    content = dict(status='ok')\n    reply_msg = self.session.send(stream, 'abort_reply', content=content, parent=parent, ident=ident)\n    self.log.debug(str(reply_msg))\n", "label": "Correct"}
{"function": "\n\ndef abort_request(self, stream, ident, parent):\n    'abort a specifig msg by id'\n    msg_ids = parent['content'].get('msg_ids', None)\n    if isinstance(msg_ids, str):\n        msg_ids = [msg_ids]\n    if (not msg_ids):\n        self.abort_queues()\n    for mid in msg_ids:\n        self.aborted.add(str(mid))\n    content = dict(status='ok')\n    reply_msg = self.session.send(stream, 'abort_reply', content=content, parent=parent, ident=ident)\n    self.log.debug(str(msg_ids))\n", "label": "Variable misuse"}
{"function": "\n\ndef p_basic_statement(self, p):\n    'basic_statement : if_statement\\n        | case_statement\\n        | casex_statement\\n        | for_statement\\n        | while_statement\\n        | event_statement\\n        | wait_statement\\n        | forever_statement\\n        | block\\n        | namedblock\\n        | parallelblock\\n        | blocking_substitution\\n        | nonblocking_substitution\\n        | single_statement\\n        '\n    p[0] = p[1]\n    p.set_lineno(0, p.lineno(1))\n", "label": "Correct"}
{"function": "\n\ndef p_basic_statement(self, p):\n    'basic_statement : if_statement\\n        | case_statement\\n        | casex_statement\\n        | for_statement\\n        | while_statement\\n        | event_statement\\n        | wait_statement\\n        | forever_statement\\n        | block\\n        | namedblock\\n        | parallelblock\\n        | blocking_substitution\\n        | nonblocking_substitution\\n        | single_statement\\n        '\n    p[0] = self[1]\n    p.set_lineno(0, p.lineno(1))\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, handle, name):\n    self._check_all_set()\n    g = handle.create_group(name)\n    g.attrs['type'] = np.string_('extern_box'.encode('utf-8'))\n    g.attrs['xmin'] = self.bounds[0][0]\n    g.attrs['xmax'] = self.bounds[0][1]\n    g.attrs['ymin'] = self.bounds[1][0]\n    g.attrs['ymax'] = self.bounds[1][1]\n    g.attrs['zmin'] = self.bounds[2][0]\n    g.attrs['zmax'] = self.bounds[2][1]\n    Source.write(self, g)\n", "label": "Correct"}
{"function": "\n\ndef write(self, handle, name):\n    self._check_all_set()\n    g = handle.create_group(name)\n    g.attrs['type'] = np.string_('extern_box'.encode('utf-8'))\n    g.attrs['xmin'] = self.bounds[0][0]\n    g.attrs['xmax'] = self.bounds[0][1]\n    handle.attrs['ymin'] = self.bounds[1][0]\n    g.attrs['ymax'] = self.bounds[1][1]\n    g.attrs['zmin'] = self.bounds[2][0]\n    g.attrs['zmax'] = self.bounds[2][1]\n    Source.write(self, g)\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    self.one_to_one = True\n    return super(OneToOneFieldDefinition, self).save(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    self.one_to_one = True\n    return super(OneToOneFieldDefinition, self).save(*self, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef testComplexLabels(self):\n    logging.debug('Running testComplexLabels method.')\n    expression = 'a_123'\n    self._RunMathQuery(expression, ['a_123'])\n    expression = 'a_1.b2'\n    self._RunMathQuery(expression, ['a_1.b2'])\n", "label": "Correct"}
{"function": "\n\ndef testComplexLabels(self):\n    logging.debug('Running testComplexLabels method.')\n    expression = 'a_123'\n    expression._RunMathQuery(expression, ['a_123'])\n    expression = 'a_1.b2'\n    self._RunMathQuery(expression, ['a_1.b2'])\n", "label": "Variable misuse"}
{"function": "\n\n@app.task(bind=True)\n@only_one(key='analyze_databases_service_task', timeout=6000)\ndef analyze_databases(self, task_history=None):\n    (endpoint, healh_check_route, healh_check_string) = get_analyzing_credentials()\n    user = User.objects.get(username='admin')\n    worker_name = get_worker_name()\n    task_history = TaskHistory.register(task_history=task_history, request=self.request, user=user, worker_name=worker_name)\n    task_history.update_details(persist=True, details='Loading Process...')\n    AuditRequest.new_request('analyze_databases', user, 'localhost')\n    try:\n        analyze_service = AnalyzeService(endpoint, healh_check_route, healh_check_string)\n        with transaction.atomic():\n            databases = Database.objects.filter(is_in_quarantine=False)\n            today = datetime.now()\n            for database in databases:\n                (database_name, engine, instances, environment_name, databaseinfra_name) = setup_database_info(database)\n                for execution_plan in ExecutionPlan.objects.all():\n                    if database_can_not_be_resized(database, execution_plan):\n                        continue\n                    params = execution_plan.setup_execution_params()\n                    result = analyze_service.run(engine=engine, database=database_name, instances=instances, **params)\n                    if (result['status'] == 'success'):\n                        task_history.update_details(persist=True, details='\\nDatabase {} {} was analised.'.format(database, execution_plan.plan_name))\n                        if (result['msg'] != instances):\n                            continue\n                        for instance in result['msg']:\n                            insert_analyze_repository_record(today, database_name, instance, engine, databaseinfra_name, environment_name, execution_plan)\n                    else:\n                        raise Exception('Check your service logs..')\n        task_history.update_status_for(TaskHistory.STATUS_SUCCESS, details='Analisys ok!')\n    except Exception:\n        try:\n            task_history.update_details(persist=True, details='\\nDatabase {} {} could not be analised.'.format(database, execution_plan.plan_name))\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys finished with errors!\\nError: {}'.format(result['msg']))\n        except UnboundLocalError:\n            task_history.update_details(persist=True, details='\\nProccess crashed')\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys could not be started')\n    finally:\n        AuditRequest.cleanup_request()\n", "label": "Correct"}
{"function": "\n\n@app.task(bind=True)\n@only_one(key='analyze_databases_service_task', timeout=6000)\ndef analyze_databases(self, task_history=None):\n    (endpoint, healh_check_route, healh_check_string) = get_analyzing_credentials()\n    user = User.objects.get(username='admin')\n    worker_name = get_worker_name()\n    task_history = TaskHistory.register(task_history=task_history, request=self.request, user=user, worker_name=execution_plan)\n    task_history.update_details(persist=True, details='Loading Process...')\n    AuditRequest.new_request('analyze_databases', user, 'localhost')\n    try:\n        analyze_service = AnalyzeService(endpoint, healh_check_route, healh_check_string)\n        with transaction.atomic():\n            databases = Database.objects.filter(is_in_quarantine=False)\n            today = datetime.now()\n            for database in databases:\n                (database_name, engine, instances, environment_name, databaseinfra_name) = setup_database_info(database)\n                for execution_plan in ExecutionPlan.objects.all():\n                    if database_can_not_be_resized(database, execution_plan):\n                        continue\n                    params = execution_plan.setup_execution_params()\n                    result = analyze_service.run(engine=engine, database=database_name, instances=instances, **params)\n                    if (result['status'] == 'success'):\n                        task_history.update_details(persist=True, details='\\nDatabase {} {} was analised.'.format(database, execution_plan.plan_name))\n                        if (result['msg'] != instances):\n                            continue\n                        for instance in result['msg']:\n                            insert_analyze_repository_record(today, database_name, instance, engine, databaseinfra_name, environment_name, execution_plan)\n                    else:\n                        raise Exception('Check your service logs..')\n        task_history.update_status_for(TaskHistory.STATUS_SUCCESS, details='Analisys ok!')\n    except Exception:\n        try:\n            task_history.update_details(persist=True, details='\\nDatabase {} {} could not be analised.'.format(database, execution_plan.plan_name))\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys finished with errors!\\nError: {}'.format(result['msg']))\n        except UnboundLocalError:\n            task_history.update_details(persist=True, details='\\nProccess crashed')\n            task_history.update_status_for(TaskHistory.STATUS_ERROR, details='Analisys could not be started')\n    finally:\n        AuditRequest.cleanup_request()\n", "label": "Variable misuse"}
{"function": "\n\ndef __str__(self):\n    ' Returns the materialized path '\n    return ('/'.join([x.value for x in self.parts]) + ('/' if self.is_dir else ''))\n", "label": "Correct"}
{"function": "\n\ndef __str__(self):\n    ' Returns the materialized path '\n    return ('/'.join([x.value for x in x.parts]) + ('/' if self.is_dir else ''))\n", "label": "Variable misuse"}
{"function": "\n\ndef retry_subflow(self, retry):\n    'Prepares a retrys + its subgraph for execution.\\n\\n        This sets the retrys intention to ``EXECUTE`` and resets all of its\\n        subgraph (its successors) to the ``PENDING`` state with an ``EXECUTE``\\n        intention.\\n        '\n    tweaked = self.reset_atoms([retry], state=None, intention=st.EXECUTE)\n    tweaked.extend(self.reset_subgraph(retry))\n    return tweaked\n", "label": "Correct"}
{"function": "\n\ndef retry_subflow(self, retry):\n    'Prepares a retrys + its subgraph for execution.\\n\\n        This sets the retrys intention to ``EXECUTE`` and resets all of its\\n        subgraph (its successors) to the ``PENDING`` state with an ``EXECUTE``\\n        intention.\\n        '\n    tweaked = self.reset_atoms([retry], state=None, intention=st.EXECUTE)\n    tweaked.extend(retry.reset_subgraph(retry))\n    return tweaked\n", "label": "Variable misuse"}
{"function": "\n\ndef draw_random(G, **kwargs):\n    'Draw the graph G with a random layout.'\n    draw(G, random_layout(G), **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef draw_random(G, **kwargs):\n    'Draw the graph G with a random layout.'\n    draw(G, random_layout(kwargs), **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef post(self):\n    ' pass additionalMetadata and file to global\\n        variables.\\n        '\n    global received_file\n    global received_meta\n    received_file = self.request.files['file'][0].body\n    received_meta = self.get_argument('additionalMetadata')\n", "label": "Correct"}
{"function": "\n\ndef post(self):\n    ' pass additionalMetadata and file to global\\n        variables.\\n        '\n    global received_file\n    global received_meta\n    received_file = self.request.files['file'][0].body\n    received_meta = received_file.get_argument('additionalMetadata')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, gates, system_desc, wh_codes):\n    self.gates = gates\n    self.system_desc = system_desc\n    self.wh_codes = wh_codes\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, gates, system_desc, wh_codes):\n    self.gates = gates\n    self.system_desc = wh_codes\n    self.wh_codes = wh_codes\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, args):\n    super(RemoveVariantSetRunner, self).__init__(args)\n    self.variantSetName = args.variantSetName\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, args):\n    super(RemoveVariantSetRunner, self).__init__(args)\n    args.variantSetName = args.variantSetName\n", "label": "Variable misuse"}
{"function": "\n\n@override_djconfig(comments_per_page=1)\ndef test_profile_comments_paginate(self):\n    \"\\n        profile user's comments paginated\\n        \"\n    utils.create_comment(user=self.user2, topic=self.topic)\n    comment = utils.create_comment(user=self.user2, topic=self.topic)\n    utils.login(self)\n    response = self.client.get(reverse('spirit:user:detail', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['comments']), [comment])\n", "label": "Correct"}
{"function": "\n\n@override_djconfig(comments_per_page=1)\ndef test_profile_comments_paginate(self):\n    \"\\n        profile user's comments paginated\\n        \"\n    utils.create_comment(user=self.user2, topic=self.topic)\n    comment = utils.create_comment(user=self.user2, topic=self.topic)\n    utils.login(comment)\n    response = self.client.get(reverse('spirit:user:detail', kwargs={\n        'pk': self.user2.pk,\n        'slug': self.user2.st.slug,\n    }))\n    self.assertEqual(response.status_code, 200)\n    self.assertEqual(list(response.context['comments']), [comment])\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    self.maxDiff = None\n    filename = 'chart_data_labels24.xlsx'\n    test_dir = 'xlsxwriter/test/comparison/'\n    self.got_filename = ((test_dir + '_test_') + filename)\n    self.exp_filename = ((test_dir + 'xlsx_files/') + filename)\n    self.ignore_files = []\n    self.ignore_elements = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    self.maxDiff = None\n    filename = 'chart_data_labels24.xlsx'\n    test_dir = 'xlsxwriter/test/comparison/'\n    self.got_filename = ((test_dir + '_test_') + filename)\n    self.exp_filename = ((test_dir + 'xlsx_files/') + filename)\n    test_dir.ignore_files = []\n    self.ignore_elements = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef get_available_user_FIELD_transitions(instance, user, field):\n    '\\n    List of transitions available in current model state\\n    with all conditions met and user have rights on it\\n    '\n    for transition in get_available_FIELD_transitions(instance, field):\n        if transition.has_perm(instance, user):\n            (yield transition)\n", "label": "Correct"}
{"function": "\n\ndef get_available_user_FIELD_transitions(instance, user, field):\n    '\\n    List of transitions available in current model state\\n    with all conditions met and user have rights on it\\n    '\n    for transition in get_available_FIELD_transitions(instance, field):\n        if transition.has_perm(instance, user):\n            (yield instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef pixelCollision(rect1, rect2, hitmask1, hitmask2):\n    'Checks if two objects collide and not just their rects'\n    rect = rect1.clip(rect2)\n    if ((rect.width == 0) or (rect.height == 0)):\n        return False\n    (x1, y1) = ((rect.x - rect1.x), (rect.y - rect1.y))\n    (x2, y2) = ((rect.x - rect2.x), (rect.y - rect2.y))\n    for x in xrange(rect.width):\n        for y in xrange(rect.height):\n            if (hitmask1[(x1 + x)][(y1 + y)] and hitmask2[(x2 + x)][(y2 + y)]):\n                return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef pixelCollision(rect1, rect2, hitmask1, hitmask2):\n    'Checks if two objects collide and not just their rects'\n    rect = rect1.clip(rect2)\n    if ((rect.width == 0) or (rect.height == 0)):\n        return False\n    (x1, y1) = ((rect.x - rect.x), (rect.y - rect1.y))\n    (x2, y2) = ((rect.x - rect2.x), (rect.y - rect2.y))\n    for x in xrange(rect.width):\n        for y in xrange(rect.height):\n            if (hitmask1[(x1 + x)][(y1 + y)] and hitmask2[(x2 + x)][(y2 + y)]):\n                return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef create_initial_revisions(self, app, model_class, comment, batch_size, verbosity=2, database=None, **kwargs):\n    'Creates the set of initial revisions for the given model.'\n    try:\n        import_module(('%s.admin' % app.__name__.rsplit('.', 1)[0]))\n    except ImportError:\n        pass\n    if default_revision_manager.is_registered(model_class):\n        if (verbosity >= 2):\n            print(('Creating initial revision(s) for model %s ...' % force_text(model_class._meta.verbose_name)))\n        created_count = 0\n        content_type = ContentType.objects.db_manager(database).get_for_model(model_class)\n        versioned_pk_queryset = Version.objects.using(database).filter(content_type=content_type).all()\n        live_objs = model_class._default_manager.using(database).all()\n        if has_int_pk(model_class):\n            live_objs = live_objs.exclude(pk__in=versioned_pk_queryset.values_list('object_id_int', flat=True))\n        else:\n            live_objs = live_objs.exclude(pk__in=list(versioned_pk_queryset.values_list('object_id', flat=True).iterator()))\n        ids = list(live_objs.values_list(model_class._meta.pk.name, flat=True).order_by())\n        total = len(ids)\n        for i in range(0, total, batch_size):\n            chunked_ids = ids[i:(i + batch_size)]\n            objects = live_objs.in_bulk(chunked_ids)\n            for (id, obj) in objects.items():\n                try:\n                    default_revision_manager.save_revision((obj,), comment=comment, db=database)\n                except:\n                    print(('ERROR: Could not save initial version for %s %s.' % (model_class.__name__, obj.pk)))\n                    raise\n                created_count += 1\n            reset_queries()\n            if (verbosity >= 2):\n                print(('Created %s of %s.' % (created_count, total)))\n        if (verbosity >= 2):\n            print(('Created %s initial revision(s) for model %s.' % (created_count, force_text(model_class._meta.verbose_name))))\n    elif (verbosity >= 2):\n        print(('Model %s is not registered.' % force_text(model_class._meta.verbose_name)))\n", "label": "Correct"}
{"function": "\n\ndef create_initial_revisions(self, app, model_class, comment, batch_size, verbosity=2, database=None, **kwargs):\n    'Creates the set of initial revisions for the given model.'\n    try:\n        import_module(('%s.admin' % app.__name__.rsplit('.', 1)[0]))\n    except ImportError:\n        pass\n    if default_revision_manager.is_registered(model_class):\n        if (verbosity >= 2):\n            print(('Creating initial revision(s) for model %s ...' % force_text(model_class._meta.verbose_name)))\n        created_count = 0\n        content_type = ContentType.objects.db_manager(database).get_for_model(model_class)\n        versioned_pk_queryset = Version.objects.using(database).filter(content_type=content_type).all()\n        live_objs = model_class._default_manager.using(database).all()\n        if has_int_pk(model_class):\n            live_objs = live_objs.exclude(pk__in=versioned_pk_queryset.values_list('object_id_int', flat=True))\n        else:\n            live_objs = live_objs.exclude(pk__in=list(versioned_pk_queryset.values_list('object_id', flat=True).iterator()))\n        ids = list(live_objs.values_list(model_class._meta.pk.name, flat=True).order_by())\n        total = len(ids)\n        for i in range(0, total, batch_size):\n            chunked_ids = ids[versioned_pk_queryset:(i + batch_size)]\n            objects = live_objs.in_bulk(chunked_ids)\n            for (id, obj) in objects.items():\n                try:\n                    default_revision_manager.save_revision((obj,), comment=comment, db=database)\n                except:\n                    print(('ERROR: Could not save initial version for %s %s.' % (model_class.__name__, obj.pk)))\n                    raise\n                created_count += 1\n            reset_queries()\n            if (verbosity >= 2):\n                print(('Created %s of %s.' % (created_count, total)))\n        if (verbosity >= 2):\n            print(('Created %s initial revision(s) for model %s.' % (created_count, force_text(model_class._meta.verbose_name))))\n    elif (verbosity >= 2):\n        print(('Model %s is not registered.' % force_text(model_class._meta.verbose_name)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _item_position(self, item):\n    return self.items.index(item)\n", "label": "Correct"}
{"function": "\n\ndef _item_position(self, item):\n    return self.items.index(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef GetModifiedShellCommand(self, Command, PluginOutputDir):\n    self.RefreshReplacements()\n    NewCommand = ((('cd ' + self.ShellPathEscape(PluginOutputDir)) + '; ') + MultipleReplace(Command, self.DynamicReplacements))\n    self.OldCommands[NewCommand] = Command\n    return NewCommand\n", "label": "Correct"}
{"function": "\n\ndef GetModifiedShellCommand(self, Command, PluginOutputDir):\n    PluginOutputDir.RefreshReplacements()\n    NewCommand = ((('cd ' + self.ShellPathEscape(PluginOutputDir)) + '; ') + MultipleReplace(Command, self.DynamicReplacements))\n    self.OldCommands[NewCommand] = Command\n    return NewCommand\n", "label": "Variable misuse"}
{"function": "\n\ndef report_for_conf(self, conf):\n    'Returns the path to the ivy report for the provided conf.\\n\\n     Returns None if there is no path.\\n    '\n    return self._reports_by_conf.get(conf)\n", "label": "Correct"}
{"function": "\n\ndef report_for_conf(self, conf):\n    'Returns the path to the ivy report for the provided conf.\\n\\n     Returns None if there is no path.\\n    '\n    return conf._reports_by_conf.get(conf)\n", "label": "Variable misuse"}
{"function": "\n\ndef our_x2_iterates(n_iters=100):\n    history = []\n    searchspace = SearchSpace()\n    searchspace.add_float('x', (- 10), 10)\n    random = np.random.RandomState(0)\n\n    def fn(params):\n        return (- (params['x'] ** 2))\n    for i in range(n_iters):\n        params = HyperoptTPE(seed=random).suggest(history, searchspace)\n        history.append((params, fn(params), 'SUCCEEDED'))\n    return np.array([h[0]['x'] for h in history])\n", "label": "Correct"}
{"function": "\n\ndef our_x2_iterates(n_iters=100):\n    history = []\n    searchspace = SearchSpace()\n    searchspace.add_float('x', (- 10), 10)\n    random = np.random.RandomState(0)\n\n    def fn(params):\n        return (- (params['x'] ** 2))\n    for i in range(n_iters):\n        params = HyperoptTPE(seed=history).suggest(history, searchspace)\n        history.append((params, fn(params), 'SUCCEEDED'))\n    return np.array([h[0]['x'] for h in history])\n", "label": "Variable misuse"}
{"function": "\n\ndef insert(self, window, first_line, *lines):\n    (row, column) = cursor = self.cursors[window]\n    (left, right) = (self[row][:column], self[row][column:])\n    added = len(lines)\n    if lines:\n        last_line = lines[(- 1)]\n        column = len(last_line)\n    else:\n        last_line = first_line\n        column += len(first_line)\n    self[row] = (left + first_line)\n    self[(row + 1):(row + 1)] = lines\n    self[(row + added)] += right\n    for other in self.cursors.itervalues():\n        if (other.row > row):\n            other._row += added\n    cursor.coords = ((row + added), column)\n", "label": "Correct"}
{"function": "\n\ndef insert(self, window, first_line, *lines):\n    (row, column) = cursor = self.cursors[window]\n    (left, right) = (self[row][:column], self[row][column:])\n    added = len(lines)\n    if lines:\n        last_line = lines[(- 1)]\n        column = len(last_line)\n    else:\n        last_line = first_line\n        column += len(first_line)\n    self[row] = (left + first_line)\n    self[(row + 1):(added + 1)] = lines\n    self[(row + added)] += right\n    for other in self.cursors.itervalues():\n        if (other.row > row):\n            other._row += added\n    cursor.coords = ((row + added), column)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean_message(self):\n    message = self.cleaned_data['message']\n    try:\n        message = message.decode('base64')\n    except TypeError as e:\n        raise ValidationError(('Cannot convert to binary: %r' % e.msg))\n    if (len(message) % 16):\n        raise ValidationError('Wrong block size for message !')\n    if (len(message) <= 16):\n        raise ValidationError('Message too short or missing IV !')\n    return message\n", "label": "Correct"}
{"function": "\n\ndef clean_message(self):\n    message = self.cleaned_data['message']\n    try:\n        message = message.decode('base64')\n    except TypeError as e:\n        raise ValidationError(('Cannot convert to binary: %r' % e.msg))\n    if (len(message) % 16):\n        raise ValidationError('Wrong block size for message !')\n    if (len(message) <= 16):\n        raise ValidationError('Message too short or missing IV !')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\n@keep_alive('server')\ndef address_is_mine(self, address):\n    result = self.server.validateaddress(address)\n    return result['ismine']\n", "label": "Correct"}
{"function": "\n\n@keep_alive('server')\ndef address_is_mine(self, address):\n    result = self.server.validateaddress(address)\n    return self['ismine']\n", "label": "Variable misuse"}
{"function": "\n\ndef _bump_version(self, version):\n    try:\n        parts = map(int, version.split('.'))\n    except ValueError:\n        self._fail('Current version is not numeric')\n    parts[(- 1)] += 1\n    return '.'.join(map(str, parts))\n", "label": "Correct"}
{"function": "\n\ndef _bump_version(self, version):\n    try:\n        parts = map(int, version.split('.'))\n    except ValueError:\n        self._fail('Current version is not numeric')\n    version[(- 1)] += 1\n    return '.'.join(map(str, parts))\n", "label": "Variable misuse"}
{"function": "\n\ndef npm_command(self, args):\n    'Creates a command that can run `npm`, passing the given args to it.\\n\\n    :param list args: A list of arguments to pass to `npm`.\\n    :returns: An `npm` command that can be run later.\\n    :rtype: :class:`NodeDistribution.Command`\\n    '\n    return self._create_command('npm', args)\n", "label": "Correct"}
{"function": "\n\ndef npm_command(self, args):\n    'Creates a command that can run `npm`, passing the given args to it.\\n\\n    :param list args: A list of arguments to pass to `npm`.\\n    :returns: An `npm` command that can be run later.\\n    :rtype: :class:`NodeDistribution.Command`\\n    '\n    return self._create_command('npm', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_disenroll_with_no_enrollment(self):\n    courses = Course.objects.all()\n    for course in courses:\n        course.delete()\n    client = Client()\n    client.login(username=TEST_USER_USERNAME, password=TEST_USER_PASSWORD)\n    kwargs = {\n        'HTTP_X_REQUESTED_WITH': 'XMLHttpRequest',\n    }\n    response = client.post('/disenroll', {\n        'course_id': 1,\n    }, **kwargs)\n    self.assertEqual(response.status_code, 200)\n    json_string = response.content.decode(encoding='UTF-8')\n    array = json.loads(json_string)\n    self.assertEqual(array['message'], 'record does not exist')\n    self.assertEqual(array['status'], 'failed')\n", "label": "Correct"}
{"function": "\n\ndef test_disenroll_with_no_enrollment(self):\n    courses = Course.objects.all()\n    for course in courses:\n        course.delete()\n    client = Client()\n    client.login(username=TEST_USER_USERNAME, password=TEST_USER_PASSWORD)\n    kwargs = {\n        'HTTP_X_REQUESTED_WITH': 'XMLHttpRequest',\n    }\n    response = client.post('/disenroll', {\n        'course_id': 1,\n    }, **kwargs)\n    self.assertEqual(response.status_code, 200)\n    json_string = response.content.decode(encoding='UTF-8')\n    array = json.loads(json_string)\n    array.assertEqual(array['message'], 'record does not exist')\n    self.assertEqual(array['status'], 'failed')\n", "label": "Variable misuse"}
{"function": "\n\n@parameterized.expand([('split', 2, 3, 3, 1.5), ('merger', 2, 3, 3, 1.8), ('dividend', 2, 3, 3, 2.88)])\ndef test_spot_price_adjustments(self, adjustment_type, liquid_day_0_price, liquid_day_1_price, illiquid_day_0_price, illiquid_day_1_price_adjusted):\n    'Test the behaviour of spot prices during adjustments.'\n    table_name = (adjustment_type + 's')\n    liquid_asset = getattr(self, (adjustment_type.upper() + '_ASSET'))\n    illiquid_asset = getattr(self, (('ILLIQUID_' + adjustment_type.upper()) + '_ASSET'))\n    adjustments = self.adjustment_reader.get_adjustments_for_sid(table_name, liquid_asset.sid)\n    self.assertEqual(1, len(adjustments))\n    adjustment = adjustments[0]\n    self.assertEqual(adjustment[0], pd.Timestamp('2016-01-06', tz='UTC'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[0]), 'daily')\n    self.assertEqual(liquid_day_0_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(liquid_day_1_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(illiquid_day_0_price, bar_data.current(illiquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[2]), 'daily')\n    self.assertAlmostEqual(illiquid_day_1_price_adjusted, bar_data.current(illiquid_asset, 'price'))\n", "label": "Correct"}
{"function": "\n\n@parameterized.expand([('split', 2, 3, 3, 1.5), ('merger', 2, 3, 3, 1.8), ('dividend', 2, 3, 3, 2.88)])\ndef test_spot_price_adjustments(self, adjustment_type, liquid_day_0_price, liquid_day_1_price, illiquid_day_0_price, illiquid_day_1_price_adjusted):\n    'Test the behaviour of spot prices during adjustments.'\n    table_name = (adjustment_type + 's')\n    liquid_asset = getattr(self, (adjustment_type.upper() + '_ASSET'))\n    illiquid_asset = getattr(self, (('ILLIQUID_' + adjustment_type.upper()) + '_ASSET'))\n    adjustments = self.adjustment_reader.get_adjustments_for_sid(table_name, liquid_asset.sid)\n    self.assertEqual(1, len(adjustments))\n    adjustment = adjustments[0]\n    self.assertEqual(adjustment[0], pd.Timestamp('2016-01-06', tz='UTC'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[0]), 'daily')\n    self.assertEqual(liquid_day_0_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(liquid_day_1_price, bar_data.current(liquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[1]), 'daily')\n    self.assertEqual(bar_data, bar_data.current(illiquid_asset, 'price'))\n    bar_data = BarData(self.data_portal, (lambda : self.bcolz_daily_bar_days[2]), 'daily')\n    self.assertAlmostEqual(illiquid_day_1_price_adjusted, bar_data.current(illiquid_asset, 'price'))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_ud(self, cardinal, user, channel, msg):\n    try:\n        word = msg.split(' ', 1)[1]\n    except IndexError:\n        cardinal.sendMsg(channel, 'Syntax: .ud <word>')\n        return\n    try:\n        url = (URBANDICT_API_PREFIX + word)\n        f = urlopen(url).read()\n        data = json.loads(f)\n        word_def = data['list'][0]['definition']\n        link = data['list'][0]['permalink']\n        response = ('UD for %s: %s (%s)' % (word, word_def, link))\n        cardinal.sendMsg(channel, response.encode('utf-8'))\n    except Exception:\n        cardinal.sendMsg(channel, ('Could not retrieve definition for %s' % word))\n", "label": "Correct"}
{"function": "\n\ndef get_ud(self, cardinal, user, channel, msg):\n    try:\n        word = msg.split(' ', 1)[1]\n    except IndexError:\n        cardinal.sendMsg(channel, 'Syntax: .ud <word>')\n        return\n    try:\n        url = (URBANDICT_API_PREFIX + word)\n        f = urlopen(url).read()\n        data = json.loads(link)\n        word_def = data['list'][0]['definition']\n        link = data['list'][0]['permalink']\n        response = ('UD for %s: %s (%s)' % (word, word_def, link))\n        cardinal.sendMsg(channel, response.encode('utf-8'))\n    except Exception:\n        cardinal.sendMsg(channel, ('Could not retrieve definition for %s' % word))\n", "label": "Variable misuse"}
{"function": "\n\ndef test__merge(self):\n    seg1a = fake_neo(Block, seed=self.seed1, n=self.nchildren).segments[0]\n    assert_same_sub_schema(self.seg1, seg1a)\n    seg1a.spikes.append(self.spikes2[0])\n    seg1a.epocharrays.append(self.epcas2[0])\n    seg1a.annotate(seed=self.seed2)\n    seg1a.merge(self.seg2)\n    self.check_creation(self.seg2)\n    assert_same_sub_schema((self.sigs1a + self.sigs2), seg1a.analogsignals)\n    assert_same_sub_schema((self.sigarrs1a + self.sigarrs2), seg1a.analogsignalarrays)\n    assert_same_sub_schema((self.irsigs1a + self.irsigs2), seg1a.irregularlysampledsignals)\n    assert_same_sub_schema((self.epcs1 + self.epcs2), seg1a.epochs)\n    assert_same_sub_schema((self.epcas1 + self.epcas2), seg1a.epocharrays)\n    assert_same_sub_schema((self.evts1 + self.evts2), seg1a.events)\n    assert_same_sub_schema((self.evtas1 + self.evtas2), seg1a.eventarrays)\n    assert_same_sub_schema((self.spikes1 + self.spikes2), seg1a.spikes)\n    assert_same_sub_schema((self.trains1 + self.trains2), seg1a.spiketrains)\n", "label": "Correct"}
{"function": "\n\ndef test__merge(self):\n    seg1a = fake_neo(Block, seed=self.seed1, n=self.nchildren).segments[0]\n    assert_same_sub_schema(self.seg1, seg1a)\n    seg1a.spikes.append(self.spikes2[0])\n    seg1a.epocharrays.append(self.epcas2[0])\n    seg1a.annotate(seed=self.seed2)\n    seg1a.merge(self.seg2)\n    self.check_creation(self.seg2)\n    assert_same_sub_schema((self.sigs1a + self.sigs2), seg1a.analogsignals)\n    assert_same_sub_schema((self.sigarrs1a + self.sigarrs2), seg1a.analogsignalarrays)\n    assert_same_sub_schema((self.irsigs1a + self.irsigs2), seg1a.irregularlysampledsignals)\n    assert_same_sub_schema((self.epcs1 + self.epcs2), seg1a.epochs)\n    assert_same_sub_schema((self.epcas1 + self.epcas2), seg1a.epocharrays)\n    assert_same_sub_schema((self.evts1 + self.evts2), self.events)\n    assert_same_sub_schema((self.evtas1 + self.evtas2), seg1a.eventarrays)\n    assert_same_sub_schema((self.spikes1 + self.spikes2), seg1a.spikes)\n    assert_same_sub_schema((self.trains1 + self.trains2), seg1a.spiketrains)\n", "label": "Variable misuse"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    (ishape, fshape) = shapes\n    (igroups, icolors_per_group, irows, icols, icount) = ishape\n    (fmodulesR, fmodulesC, fcolors, frows, fcols) = fshape[:(- 2)]\n    (fgroups, filters_per_group) = fshape[(- 2):]\n    if ((not any_symbolic(irows, icols)) and (irows != icols)):\n        raise ValueError('non-square image argument', (irows, icols))\n    if ((not any_symbolic(frows, fcols)) and (frows != fcols)):\n        raise ValueError('non-square filter shape', (frows, fcols))\n    if ((not any_symbolic(fmodulesR, fmodulesC)) and (fmodulesR != fmodulesC)):\n        raise ValueError('non-square filter grouping', (fmodulesR, fmodulesC))\n    if ((not any_symbolic(icolors_per_group, fcolors)) and (icolors_per_group != fcolors)):\n        raise ValueError(\"color counts don't match\", (icolors_per_group, fcolors))\n    hshape = (fgroups, filters_per_group, fmodulesR, fmodulesC, icount)\n    return [hshape]\n", "label": "Correct"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    (ishape, fshape) = shapes\n    (igroups, icolors_per_group, irows, icols, icount) = ishape\n    (fmodulesR, fmodulesC, fcolors, frows, fcols) = fshape[:(- 2)]\n    (fgroups, filters_per_group) = fshape[(- 2):]\n    if ((not any_symbolic(irows, icols)) and (irows != icols)):\n        raise ValueError('non-square image argument', (irows, icols))\n    if ((not any_symbolic(frows, fcols)) and (frows != fcols)):\n        raise ValueError('non-square filter shape', (frows, fcols))\n    if ((not any_symbolic(fmodulesR, fmodulesC)) and (fmodulesR != fmodulesC)):\n        raise ValueError('non-square filter grouping', (fmodulesR, fmodulesC))\n    if ((not any_symbolic(icolors_per_group, fcolors)) and (icolors_per_group != fcolors)):\n        raise ValueError(\"color counts don't match\", (self, fcolors))\n    hshape = (fgroups, filters_per_group, fmodulesR, fmodulesC, icount)\n    return [hshape]\n", "label": "Variable misuse"}
{"function": "\n\ndef store_and_use_artifact(self, cache_key, src, results_dir=None):\n    'Read the content of a tarball from an iterator and return an artifact stored in the cache.'\n    with self._tmpfile(cache_key, 'read') as tmp:\n        for chunk in src:\n            tmp.write(chunk)\n        tmp.close()\n        tarball = self._store_tarball(cache_key, tmp.name)\n        artifact = self._artifact(tarball)\n        if (results_dir is not None):\n            safe_rmtree(results_dir)\n        artifact.extract()\n        return True\n", "label": "Correct"}
{"function": "\n\ndef store_and_use_artifact(self, cache_key, src, results_dir=None):\n    'Read the content of a tarball from an iterator and return an artifact stored in the cache.'\n    with self._tmpfile(cache_key, 'read') as tmp:\n        for chunk in src:\n            tmp.write(chunk)\n        tmp.close()\n        tarball = chunk._store_tarball(cache_key, tmp.name)\n        artifact = self._artifact(tarball)\n        if (results_dir is not None):\n            safe_rmtree(results_dir)\n        artifact.extract()\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef __str__(self):\n    return ('Tuple(%s)' % ', '.join((str(elt) for elt in self.elts)))\n", "label": "Correct"}
{"function": "\n\ndef __str__(self):\n    return ('Tuple(%s)' % ', '.join((str(self) for elt in self.elts)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_ticket_ticket(self):\n    '\\n        A ticket ought to be created with a provided ticket string,\\n        if present.\\n        '\n    ticket = 'ST-0000000000-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n    st = ServiceTicket.objects.create_ticket(ticket=ticket, user=self.user)\n    self.assertEqual(st.ticket, ticket)\n", "label": "Correct"}
{"function": "\n\ndef test_create_ticket_ticket(self):\n    '\\n        A ticket ought to be created with a provided ticket string,\\n        if present.\\n        '\n    ticket = 'ST-0000000000-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n    st = ServiceTicket.objects.create_ticket(ticket=ticket, user=ticket.user)\n    self.assertEqual(st.ticket, ticket)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_binary_infix_operators(self):\n    (a, b, h) = self.table.get_columns(['a', 'b', 'h'])\n    bool_col = (a > 0)\n    cases = [((a + b), '`a` + `b`'), ((a - b), '`a` - `b`'), ((a * b), '`a` * `b`'), ((a / b), '`a` / `b`'), ((a ** b), 'pow(`a`, `b`)'), ((a < b), '`a` < `b`'), ((a <= b), '`a` <= `b`'), ((a > b), '`a` > `b`'), ((a >= b), '`a` >= `b`'), ((a == b), '`a` = `b`'), ((a != b), '`a` != `b`'), ((h & bool_col), '`h` AND (`a` > 0)'), ((h | bool_col), '`h` OR (`a` > 0)'), ((h ^ bool_col), '(`h` OR (`a` > 0)) AND NOT (`h` AND (`a` > 0))')]\n    self._check_expr_cases(cases)\n", "label": "Correct"}
{"function": "\n\ndef test_binary_infix_operators(self):\n    (a, b, h) = bool_col.table.get_columns(['a', 'b', 'h'])\n    bool_col = (a > 0)\n    cases = [((a + b), '`a` + `b`'), ((a - b), '`a` - `b`'), ((a * b), '`a` * `b`'), ((a / b), '`a` / `b`'), ((a ** b), 'pow(`a`, `b`)'), ((a < b), '`a` < `b`'), ((a <= b), '`a` <= `b`'), ((a > b), '`a` > `b`'), ((a >= b), '`a` >= `b`'), ((a == b), '`a` = `b`'), ((a != b), '`a` != `b`'), ((h & bool_col), '`h` AND (`a` > 0)'), ((h | bool_col), '`h` OR (`a` > 0)'), ((h ^ bool_col), '(`h` OR (`a` > 0)) AND NOT (`h` AND (`a` > 0))')]\n    self._check_expr_cases(cases)\n", "label": "Variable misuse"}
{"function": "\n\ndef kalman_filter(y, U, A, V, mu0, Cov0, out=None):\n    '\\n    Perform Kalman filtering to obtain filtered mean and covariance.\\n\\n    The parameters of the process may vary in time, thus they are\\n    given as iterators instead of fixed values.\\n\\n    Parameters\\n    ----------\\n    y : (N,D) array\\n        \"Normalized\" noisy observations of the states, that is, the\\n        observations multiplied by the precision matrix U (and possibly\\n        other transformation matrices).\\n    U : (N,D,D) array or N-list of (D,D) arrays\\n        Precision matrix (i.e., inverse covariance matrix) of the observation \\n        noise for each time instance.\\n    A : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Dynamic matrix for each time instance.\\n    V : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Covariance matrix of the innovation noise for each time instance.\\n\\n    Returns\\n    -------\\n    mu : array\\n        Filtered mean of the states.\\n    Cov : array\\n        Filtered covariance of the states.\\n\\n    See also\\n    --------\\n    rts_smoother\\n    '\n    mu = mu0\n    Cov = Cov0\n    (N, D) = np.shape(y)\n    X = np.empty((N, D))\n    CovX = np.empty((N, D, D))\n    M = (np.dot(np.dot(Cov, U[0]), Cov) + Cov)\n    L = linalg.chol(M)\n    mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[0]) + mu)))\n    Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n    X[0, :] = mu\n    CovX[0, :, :] = Cov\n    for n in range((len(y) - 1)):\n        mu = np.dot(A[n], mu)\n        Cov = (np.dot(np.dot(A[n], Cov), A[n].T) + V[n])\n        M = (np.dot(np.dot(Cov, U[(n + 1)]), Cov) + Cov)\n        L = linalg.chol(M)\n        mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[(n + 1)]) + mu)))\n        Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n        Cov = ((0.5 * Cov) + (0.5 * Cov.T))\n        X[(n + 1), :] = mu\n        CovX[(n + 1), :, :] = Cov\n    return (X, CovX)\n", "label": "Correct"}
{"function": "\n\ndef kalman_filter(y, U, A, V, mu0, Cov0, out=None):\n    '\\n    Perform Kalman filtering to obtain filtered mean and covariance.\\n\\n    The parameters of the process may vary in time, thus they are\\n    given as iterators instead of fixed values.\\n\\n    Parameters\\n    ----------\\n    y : (N,D) array\\n        \"Normalized\" noisy observations of the states, that is, the\\n        observations multiplied by the precision matrix U (and possibly\\n        other transformation matrices).\\n    U : (N,D,D) array or N-list of (D,D) arrays\\n        Precision matrix (i.e., inverse covariance matrix) of the observation \\n        noise for each time instance.\\n    A : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Dynamic matrix for each time instance.\\n    V : (N-1,D,D) array or (N-1)-list of (D,D) arrays\\n        Covariance matrix of the innovation noise for each time instance.\\n\\n    Returns\\n    -------\\n    mu : array\\n        Filtered mean of the states.\\n    Cov : array\\n        Filtered covariance of the states.\\n\\n    See also\\n    --------\\n    rts_smoother\\n    '\n    mu = mu0\n    Cov = Cov0\n    (N, D) = np.shape(y)\n    X = np.empty((N, D))\n    CovX = np.empty((N, D, D))\n    M = (np.dot(np.dot(Cov, U[0]), Cov) + Cov)\n    L = linalg.chol(M)\n    mu = np.dot(Cov, linalg.chol_solve(L, (np.dot(Cov, y[0]) + mu)))\n    Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n    X[0, :] = mu\n    CovX[0, :, :] = Cov\n    for n in range((len(y) - 1)):\n        mu = np.dot(A[n], mu)\n        Cov = (np.dot(np.dot(A[n], Cov), A[n].T) + V[n])\n        M = (np.dot(np.dot(Cov, U[(n + 1)]), Cov) + Cov)\n        L = linalg.chol(M)\n        mu = np.dot(y, linalg.chol_solve(L, (np.dot(Cov, y[(n + 1)]) + mu)))\n        Cov = np.dot(Cov, linalg.chol_solve(L, Cov))\n        Cov = ((0.5 * Cov) + (0.5 * Cov.T))\n        X[(n + 1), :] = mu\n        CovX[(n + 1), :, :] = Cov\n    return (X, CovX)\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (other is None):\n        return (self._value is None)\n    other = str(other)\n    if (other not in self.values_range):\n        raise ConanException(bad_value_msg(self._name, other, self.values_range))\n    return (other == self.__str__())\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (other is None):\n        return (self._value is None)\n    other = str(other)\n    if (other not in self.values_range):\n        raise ConanException(bad_value_msg(self._name, other, self.values_range))\n    return (self == self.__str__())\n", "label": "Variable misuse"}
{"function": "\n\ndef _set_play_state(self, state):\n    'Helper method for play/pause/toggle.'\n    players = self._get_players()\n    if (len(players) != 0):\n        self._server.Player.PlayPause(players[0]['playerid'], state)\n    self.update_ha_state()\n", "label": "Correct"}
{"function": "\n\ndef _set_play_state(self, state):\n    'Helper method for play/pause/toggle.'\n    players = self._get_players()\n    if (len(players) != 0):\n        self._server.Player.PlayPause(players[0]['playerid'], self)\n    self.update_ha_state()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_multiple_sequences(self):\n    msa = TabularMSA([DNA('ACGT'), DNA('AG-.'), DNA('AC-.')])\n    cons = msa.consensus()\n    self.assertEqual(cons, DNA('AC--'))\n", "label": "Correct"}
{"function": "\n\ndef test_multiple_sequences(self):\n    msa = TabularMSA([DNA('ACGT'), DNA('AG-.'), DNA('AC-.')])\n    cons = msa.consensus()\n    msa.assertEqual(cons, DNA('AC--'))\n", "label": "Variable misuse"}
{"function": "\n\ndef appletGetDetails(*args, **kwargs):\n    '\\n\\n    .. deprecated:: 0.42.0\\n       Use :func:`applet_get_details()` instead.\\n\\n    '\n    print('dxpy.appletGetDetails is deprecated; please use applet_get_details instead.', file=sys.stderr)\n    return applet_get_details(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef appletGetDetails(*args, **kwargs):\n    '\\n\\n    .. deprecated:: 0.42.0\\n       Use :func:`applet_get_details()` instead.\\n\\n    '\n    print('dxpy.appletGetDetails is deprecated; please use applet_get_details instead.', file=sys.stderr)\n    return applet_get_details(*kwargs, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef _prepare_ivy_xml(self, frozen_resolution, ivyxml, resolve_hash_name_for_report):\n    default_resolution = frozen_resolution.get('default')\n    if (default_resolution is None):\n        raise IvyUtils.IvyError(\"Couldn't find the frozen resolution for the 'default' ivy conf.\")\n    try:\n        jars = default_resolution.jar_dependencies\n        IvyUtils.generate_fetch_ivy(jars, ivyxml, self.confs, resolve_hash_name_for_report)\n    except Exception as e:\n        raise IvyUtils.IvyError('Failed to prepare ivy resolve: {}'.format(e))\n", "label": "Correct"}
{"function": "\n\ndef _prepare_ivy_xml(self, frozen_resolution, ivyxml, resolve_hash_name_for_report):\n    default_resolution = frozen_resolution.get('default')\n    if (default_resolution is None):\n        raise IvyUtils.IvyError(\"Couldn't find the frozen resolution for the 'default' ivy conf.\")\n    try:\n        jars = default_resolution.jar_dependencies\n        IvyUtils.generate_fetch_ivy(default_resolution, ivyxml, self.confs, resolve_hash_name_for_report)\n    except Exception as e:\n        raise IvyUtils.IvyError('Failed to prepare ivy resolve: {}'.format(e))\n", "label": "Variable misuse"}
{"function": "\n\n@continuation\ndef imp_struct_set_cont(orig_struct, setter, field, app, env, cont, _vals):\n    from pycket.interpreter import check_one_val\n    val = check_one_val(_vals)\n    if (setter is values.w_false):\n        return orig_struct.set_with_extra_info(field, val, app, env, cont)\n    return setter.call_with_extra_info([orig_struct, val], env, cont, app)\n", "label": "Correct"}
{"function": "\n\n@continuation\ndef imp_struct_set_cont(orig_struct, setter, field, app, env, cont, _vals):\n    from pycket.interpreter import check_one_val\n    val = check_one_val(_vals)\n    if (setter is values.w_false):\n        return orig_struct.set_with_extra_info(field, val, orig_struct, env, cont)\n    return setter.call_with_extra_info([orig_struct, val], env, cont, app)\n", "label": "Variable misuse"}
{"function": "\n\ndef _do_if_else_condition(self, condition):\n    '\\n        Common logic for evaluating the conditions on #if, #ifdef and\\n        #ifndef lines.\\n        '\n    self.save()\n    d = self.dispatch_table\n    if condition:\n        self.start_handling_includes()\n        d['elif'] = self.stop_handling_includes\n        d['else'] = self.stop_handling_includes\n    else:\n        self.stop_handling_includes()\n        d['elif'] = self.do_elif\n        d['else'] = self.start_handling_includes\n", "label": "Correct"}
{"function": "\n\ndef _do_if_else_condition(self, condition):\n    '\\n        Common logic for evaluating the conditions on #if, #ifdef and\\n        #ifndef lines.\\n        '\n    self.save()\n    d = self.dispatch_table\n    if condition:\n        self.start_handling_includes()\n        d['elif'] = self.stop_handling_includes\n        d['else'] = self.stop_handling_includes\n    else:\n        condition.stop_handling_includes()\n        d['elif'] = self.do_elif\n        d['else'] = self.start_handling_includes\n", "label": "Variable misuse"}
{"function": "\n\ndef loadWordFile(self, pre_processor=None):\n    filename = self.getDictionaryPath()\n    with codecs.open(filename, 'r', 'utf-8') as fp:\n        for word in fp.readlines():\n            if pre_processor:\n                self.add(pre_processor(word.strip()))\n            else:\n                self.add(word.strip())\n    return\n", "label": "Correct"}
{"function": "\n\ndef loadWordFile(self, pre_processor=None):\n    filename = self.getDictionaryPath()\n    with codecs.open(filename, 'r', 'utf-8') as fp:\n        for word in fp.readlines():\n            if word:\n                self.add(pre_processor(word.strip()))\n            else:\n                self.add(word.strip())\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef test_level(self):\n    key = EncryptionKey(data='', level='SL3')\n    self.assertEquals('SL3', key.level)\n", "label": "Correct"}
{"function": "\n\ndef test_level(self):\n    key = EncryptionKey(data='', level='SL3')\n    key.assertEquals('SL3', key.level)\n", "label": "Variable misuse"}
{"function": "\n\ndef __setitem__(self, key, value):\n    'Dictionary style assignment.'\n    (rval, cval) = self.value_encode(value)\n    self.__set(key, rval, cval)\n", "label": "Correct"}
{"function": "\n\ndef __setitem__(self, key, value):\n    'Dictionary style assignment.'\n    (rval, cval) = key.value_encode(value)\n    self.__set(key, rval, cval)\n", "label": "Variable misuse"}
{"function": "\n\n@sig((((H / ((H / 'a') >> bool)) >> ['a']) >> [int]))\ndef findIndicies(f, xs):\n    '\\n    findIndices :: (a -> Bool) -> [a] -> [Int]\\n\\n    The findIndices function extends findIndex, by returning the indices of all\\n    elements satisfying the predicate, in ascending order.\\n    '\n    return L[(i for (i, x) in enumerate(xs) if f(x))]\n", "label": "Correct"}
{"function": "\n\n@sig((((H / ((H / 'a') >> bool)) >> ['a']) >> [int]))\ndef findIndicies(f, xs):\n    '\\n    findIndices :: (a -> Bool) -> [a] -> [Int]\\n\\n    The findIndices function extends findIndex, by returning the indices of all\\n    elements satisfying the predicate, in ascending order.\\n    '\n    return L[(i for (i, x) in enumerate(xs) if f(i))]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, mediator=None):\n    'Initializes the scanner object.\\n\\n    Args:\\n      mediator: a volume scanner mediator (instance of\\n                VolumeScannerMediator) or None.\\n    '\n    super(VolumeScanner, self).__init__()\n    self._mediator = mediator\n    self._source_path = None\n    self._source_scanner = source_scanner.SourceScanner()\n    self._source_type = None\n    self._vss_stores = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, mediator=None):\n    'Initializes the scanner object.\\n\\n    Args:\\n      mediator: a volume scanner mediator (instance of\\n                VolumeScannerMediator) or None.\\n    '\n    super(VolumeScanner, self).__init__()\n    self._mediator = mediator\n    self._source_path = None\n    self._source_scanner = source_scanner.SourceScanner()\n    self._source_type = None\n    mediator._vss_stores = None\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_active_nodes(self, is_running=None):\n    if self.active_gen_id:\n        return self.get_all_nodes(self.active_gen_id, is_running=is_running)\n    return []\n", "label": "Correct"}
{"function": "\n\ndef get_all_active_nodes(self, is_running=None):\n    if self.active_gen_id:\n        return self.get_all_nodes(self.active_gen_id, is_running=self)\n    return []\n", "label": "Variable misuse"}
{"function": "\n\ndef test_basic_start(self):\n    configjson = self.experiment.do_start_experiment()\n    self.assertIsNotNone(configjson)\n", "label": "Correct"}
{"function": "\n\ndef test_basic_start(self):\n    configjson = self.experiment.do_start_experiment()\n    self.assertIsNotNone(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_options_disallowed(self):\n    request = factory.options('/', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = root_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n    request = factory.options('/1', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = instance_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n", "label": "Correct"}
{"function": "\n\ndef test_options_disallowed(self):\n    request = factory.options('/', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = root_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    request.assertNotIn('actions', response.data)\n    request = factory.options('/1', HTTP_AUTHORIZATION=self.disallowed_credentials)\n    response = instance_view(request, pk='1')\n    self.assertEqual(response.status_code, status.HTTP_200_OK)\n    self.assertNotIn('actions', response.data)\n", "label": "Variable misuse"}
{"function": "\n\ndef test__build_key_none(self):\n    result = filecache._build_key(None, None)\n    self.assertEqual('None:None', result)\n", "label": "Correct"}
{"function": "\n\ndef test__build_key_none(self):\n    result = filecache._build_key(None, None)\n    result.assertEqual('None:None', result)\n", "label": "Variable misuse"}
{"function": "\n\ndef _option_required(self, key):\n    conf = S3_CONF.copy()\n    del conf[key]\n    try:\n        self.store = Store(test_utils.TestConfigOpts(conf))\n        return (self.store.add == self.store.add_disabled)\n    except:\n        return False\n    return False\n", "label": "Correct"}
{"function": "\n\ndef _option_required(self, key):\n    conf = S3_CONF.copy()\n    del conf[key]\n    try:\n        self.store = Store(test_utils.TestConfigOpts(conf))\n        return (self.store.add == key.store.add_disabled)\n    except:\n        return False\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef show_analyzer_list_panel(self, callback):\n    list_panel = AnalyzerListPanel(self.window, self.client, self.settings.index)\n    list_panel.show(callback)\n", "label": "Correct"}
{"function": "\n\ndef show_analyzer_list_panel(self, callback):\n    list_panel = AnalyzerListPanel(callback.window, self.client, self.settings.index)\n    list_panel.show(callback)\n", "label": "Variable misuse"}
{"function": "\n\ndef clone_settings(self, original):\n    self.replace_tabs_by_spaces = original.replace_tabs_by_spaces\n    self.safe_save = original.replace_tabs_by_spaces\n    self.clean_trailing_whitespaces = original.clean_trailing_whitespaces\n    self.restore_cursor = original.restore_cursor\n", "label": "Correct"}
{"function": "\n\ndef clone_settings(self, original):\n    self.replace_tabs_by_spaces = original.replace_tabs_by_spaces\n    original.safe_save = original.replace_tabs_by_spaces\n    self.clean_trailing_whitespaces = original.clean_trailing_whitespaces\n    self.restore_cursor = original.restore_cursor\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_verified_address(self, address):\n    if (address in self.addresses):\n        return True\n    (user, host) = address.split('@', 1)\n    return (host in self.domains)\n", "label": "Correct"}
{"function": "\n\ndef _is_verified_address(self, address):\n    if (address in self.addresses):\n        return True\n    (user, host) = self.split('@', 1)\n    return (host in self.domains)\n", "label": "Variable misuse"}
{"function": "\n\ndef deserialize(self, raw_value):\n    if (raw_value.upper() in self.TRUE_RAW_VALUES):\n        return True\n    elif (raw_value.upper() in self.FALSE_RAW_VALUES):\n        return False\n    else:\n        raise DeserializationError('Value \"{}\" must be one of {} for \"{}\"!'.format(raw_value, self.ALLOWED_RAW_VALUES, self.name), raw_value, self.name)\n", "label": "Correct"}
{"function": "\n\ndef deserialize(self, raw_value):\n    if (raw_value.upper() in raw_value.TRUE_RAW_VALUES):\n        return True\n    elif (raw_value.upper() in self.FALSE_RAW_VALUES):\n        return False\n    else:\n        raise DeserializationError('Value \"{}\" must be one of {} for \"{}\"!'.format(raw_value, self.ALLOWED_RAW_VALUES, self.name), raw_value, self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_service_command(self, name, command):\n    command_table = self.create_command_table(command.get('subcommands', {\n        \n    }), self._create_operation_command)\n    service_command = ServiceCommand(name, None)\n    service_command._service_model = {\n        \n    }\n    service_command._command_table = command_table\n    return service_command\n", "label": "Correct"}
{"function": "\n\ndef _create_service_command(self, name, command):\n    command_table = self.create_command_table(command.get('subcommands', {\n        \n    }), name._create_operation_command)\n    service_command = ServiceCommand(name, None)\n    service_command._service_model = {\n        \n    }\n    service_command._command_table = command_table\n    return service_command\n", "label": "Variable misuse"}
{"function": "\n\n@override_settings(DEFAULT_FROM_EMAIL='foo@bar.com')\ndef test_sender_from_email(self):\n    '\\n        Should use DEFAULT_FROM_EMAIL instead of the default\\n        '\n\n    class SiteMock():\n        name = 'foo'\n        domain = 'bar.com'\n\n    def monkey_get_current_site(*args, **kw):\n        return SiteMock\n\n    def monkey_render_to_string(*args, **kw):\n        return 'email body'\n    req = RequestFactory().get('/')\n    token = 'token'\n    subject = SiteMock.name\n    template_name = 'template.html'\n    context = {\n        'user_id': self.user.pk,\n        'token': token,\n    }\n    (org_site, email.get_current_site) = (email.get_current_site, monkey_get_current_site)\n    (org_render_to_string, email.render_to_string) = (email.render_to_string, monkey_render_to_string)\n    try:\n        sender(req, subject, template_name, context, [self.user.email])\n    finally:\n        email.get_current_site = org_site\n        email.render_to_string = org_render_to_string\n    self.assertEquals(len(mail.outbox), 1)\n    self.assertEquals(mail.outbox[0].from_email, 'foo@bar.com')\n", "label": "Correct"}
{"function": "\n\n@override_settings(DEFAULT_FROM_EMAIL='foo@bar.com')\ndef test_sender_from_email(self):\n    '\\n        Should use DEFAULT_FROM_EMAIL instead of the default\\n        '\n\n    class SiteMock():\n        name = 'foo'\n        domain = 'bar.com'\n\n    def monkey_get_current_site(*args, **kw):\n        return SiteMock\n\n    def monkey_render_to_string(*args, **kw):\n        return 'email body'\n    req = RequestFactory().get('/')\n    token = 'token'\n    subject = SiteMock.name\n    template_name = 'template.html'\n    context = {\n        'user_id': self.user.pk,\n        'token': token,\n    }\n    (org_site, email.get_current_site) = (email.get_current_site, monkey_get_current_site)\n    (org_render_to_string, email.render_to_string) = (email.render_to_string, monkey_render_to_string)\n    try:\n        sender(req, subject, template_name, context, [self.user.email])\n    finally:\n        email.get_current_site = org_site\n        email.render_to_string = subject\n    self.assertEquals(len(mail.outbox), 1)\n    self.assertEquals(mail.outbox[0].from_email, 'foo@bar.com')\n", "label": "Variable misuse"}
{"function": "\n\ndef extract_info(self, body):\n    '\\n        Extract metadata url\\n        '\n    xhr_url_match = re.search(self._XHR_REQUEST_PATH, body)\n    if (xhr_url_match is not None):\n        xhr_url = xhr_url_match.group(1)\n    else:\n        xhr_url = None\n    if ((xhr_url is not None) and xhr_url.endswith('xml')):\n        default_filename = xhr_url.split('/')[1]\n    else:\n        self.error(ExtractionError, \"ERROR: can't get default_filename.\")\n    return {\n        'default_filename': default_filename,\n        'xhr_url': xhr_url,\n    }\n", "label": "Correct"}
{"function": "\n\ndef extract_info(self, body):\n    '\\n        Extract metadata url\\n        '\n    xhr_url_match = re.search(self._XHR_REQUEST_PATH, xhr_url)\n    if (xhr_url_match is not None):\n        xhr_url = xhr_url_match.group(1)\n    else:\n        xhr_url = None\n    if ((xhr_url is not None) and xhr_url.endswith('xml')):\n        default_filename = xhr_url.split('/')[1]\n    else:\n        self.error(ExtractionError, \"ERROR: can't get default_filename.\")\n    return {\n        'default_filename': default_filename,\n        'xhr_url': xhr_url,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_content_length_0(self):\n\n    class ContentLengthChecker(list):\n\n        def __init__(self):\n            list.__init__(self)\n            self.content_length = None\n\n        def append(self, item):\n            kv = item.split(b':', 1)\n            if ((len(kv) > 1) and (kv[0].lower() == b'content-length')):\n                self.content_length = kv[1].strip()\n            list.append(self, item)\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('POST', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('PUT', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n", "label": "Correct"}
{"function": "\n\ndef test_content_length_0(self):\n\n    class ContentLengthChecker(list):\n\n        def __init__(self):\n            list.__init__(self)\n            self.content_length = None\n\n        def append(self, item):\n            kv = item.split(b':', 1)\n            if ((len(kv) > 1) and (kv[0].lower() == b'content-length')):\n                self.content_length = kv[1].strip()\n            list.append(self, item)\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('POST', '/', '')\n    self.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n    conn = client.HTTPConnection('example.com')\n    conn.sock = FakeSocket(None)\n    conn._buffer = ContentLengthChecker()\n    conn.request('PUT', '/', '')\n    conn.assertEqual(conn._buffer.content_length, b'0', 'Header Content-Length not set')\n", "label": "Variable misuse"}
{"function": "\n\ndef WriteScanNode(self, scan_node, indentation=''):\n    'Writes the source scanner node to stdout.\\n\\n    Args:\\n      scan_node: the scan node (instance of SourceScanNode).\\n      indentation: optional indentation string.\\n      scan_step: optional integer indicating the scan step.\\n    '\n    if (not scan_node):\n        return\n    values = []\n    part_index = getattr(scan_node.path_spec, 'part_index', None)\n    if (part_index is not None):\n        values.append('{0:d}'.format(part_index))\n    store_index = getattr(scan_node.path_spec, 'store_index', None)\n    if (store_index is not None):\n        values.append('{0:d}'.format(store_index))\n    start_offset = getattr(scan_node.path_spec, 'start_offset', None)\n    if (start_offset is not None):\n        values.append('start offset: {0:d} (0x{0:08x})'.format(start_offset))\n    location = getattr(scan_node.path_spec, 'location', None)\n    if (location is not None):\n        values.append('location: {0:s}'.format(location))\n    print('{0:s}{1:s}: {2:s}'.format(indentation, scan_node.path_spec.type_indicator, ', '.join(values)))\n    indentation = '  {0:s}'.format(indentation)\n    for sub_scan_node in scan_node.sub_nodes:\n        self.WriteScanNode(sub_scan_node, indentation=indentation)\n", "label": "Correct"}
{"function": "\n\ndef WriteScanNode(self, scan_node, indentation=''):\n    'Writes the source scanner node to stdout.\\n\\n    Args:\\n      scan_node: the scan node (instance of SourceScanNode).\\n      indentation: optional indentation string.\\n      scan_step: optional integer indicating the scan step.\\n    '\n    if (not scan_node):\n        return\n    values = []\n    part_index = getattr(scan_node.path_spec, 'part_index', None)\n    if (values is not None):\n        values.append('{0:d}'.format(part_index))\n    store_index = getattr(scan_node.path_spec, 'store_index', None)\n    if (store_index is not None):\n        values.append('{0:d}'.format(store_index))\n    start_offset = getattr(scan_node.path_spec, 'start_offset', None)\n    if (start_offset is not None):\n        values.append('start offset: {0:d} (0x{0:08x})'.format(start_offset))\n    location = getattr(scan_node.path_spec, 'location', None)\n    if (location is not None):\n        values.append('location: {0:s}'.format(location))\n    print('{0:s}{1:s}: {2:s}'.format(indentation, scan_node.path_spec.type_indicator, ', '.join(values)))\n    indentation = '  {0:s}'.format(indentation)\n    for sub_scan_node in scan_node.sub_nodes:\n        self.WriteScanNode(sub_scan_node, indentation=indentation)\n", "label": "Variable misuse"}
{"function": "\n\ndef deserialize(self, obj):\n    return datetime.datetime.strptime(obj, self.format).time()\n", "label": "Correct"}
{"function": "\n\ndef deserialize(self, obj):\n    return datetime.datetime.strptime(self, self.format).time()\n", "label": "Variable misuse"}
{"function": "\n\ndef seek(self, offset, whence=os.SEEK_SET):\n    'Seek to the provided location in the file.\\n\\n        :param offset: location to seek to\\n        :type offset: int\\n        :param whence: determines whether `offset` represents a\\n                       location that is absolute, relative to the\\n                       beginning of the file, or relative to the end\\n                       of the file\\n        :type whence: os.SEEK_SET | os.SEEK_CUR | os.SEEK_END\\n        :returns: None\\n        :rtype: None\\n        '\n    if (whence == os.SEEK_SET):\n        self._cursor = (0 + offset)\n    elif (whence == os.SEEK_CUR):\n        self._cursor += offset\n    elif (whence == os.SEEK_END):\n        self._cursor = (self.size() + offset)\n    else:\n        raise ValueError('Unexpected value for `whence`: {}'.format(whence))\n", "label": "Correct"}
{"function": "\n\ndef seek(self, offset, whence=os.SEEK_SET):\n    'Seek to the provided location in the file.\\n\\n        :param offset: location to seek to\\n        :type offset: int\\n        :param whence: determines whether `offset` represents a\\n                       location that is absolute, relative to the\\n                       beginning of the file, or relative to the end\\n                       of the file\\n        :type whence: os.SEEK_SET | os.SEEK_CUR | os.SEEK_END\\n        :returns: None\\n        :rtype: None\\n        '\n    if (whence == os.SEEK_SET):\n        self._cursor = (0 + offset)\n    elif (whence == os.SEEK_CUR):\n        self._cursor += offset\n    elif (whence == os.SEEK_END):\n        self._cursor = (whence.size() + offset)\n    else:\n        raise ValueError('Unexpected value for `whence`: {}'.format(whence))\n", "label": "Variable misuse"}
{"function": "\n\ndef assert_compile(self, clause, result, params=None, checkparams=None, dialect=None, checkpositional=None, check_prefetch=None, use_default_dialect=False, allow_dialect_select=False, literal_binds=False, schema_translate_map=None):\n    if use_default_dialect:\n        dialect = default.DefaultDialect()\n    elif allow_dialect_select:\n        dialect = None\n    else:\n        if (dialect is None):\n            dialect = getattr(self, '__dialect__', None)\n        if (dialect is None):\n            dialect = config.db.dialect\n        elif (dialect == 'default'):\n            dialect = default.DefaultDialect()\n        elif (dialect == 'default_enhanced'):\n            dialect = default.StrCompileDialect()\n        elif isinstance(dialect, util.string_types):\n            dialect = url.URL(dialect).get_dialect()()\n    kw = {\n        \n    }\n    compile_kwargs = {\n        \n    }\n    if schema_translate_map:\n        kw['schema_translate_map'] = schema_translate_map\n    if (params is not None):\n        kw['column_keys'] = list(params)\n    if literal_binds:\n        compile_kwargs['literal_binds'] = True\n    if isinstance(clause, orm.Query):\n        context = clause._compile_context()\n        context.statement.use_labels = True\n        clause = context.statement\n    if compile_kwargs:\n        kw['compile_kwargs'] = compile_kwargs\n    c = clause.compile(dialect=dialect, **kw)\n    param_str = repr(getattr(c, 'params', {\n        \n    }))\n    if util.py3k:\n        param_str = param_str.encode('utf-8').decode('ascii', 'ignore')\n        print((('\\nSQL String:\\n' + util.text_type(c)) + param_str).encode('utf-8'))\n    else:\n        print((('\\nSQL String:\\n' + util.text_type(c).encode('utf-8')) + param_str))\n    cc = re.sub('[\\\\n\\\\t]', '', util.text_type(c))\n    eq_(cc, result, ('%r != %r on dialect %r' % (cc, result, dialect)))\n    if (checkparams is not None):\n        eq_(c.construct_params(params), checkparams)\n    if (checkpositional is not None):\n        p = c.construct_params(params)\n        eq_(tuple([p[x] for x in c.positiontup]), checkpositional)\n    if (check_prefetch is not None):\n        eq_(c.prefetch, check_prefetch)\n", "label": "Correct"}
{"function": "\n\ndef assert_compile(self, clause, result, params=None, checkparams=None, dialect=None, checkpositional=None, check_prefetch=None, use_default_dialect=False, allow_dialect_select=False, literal_binds=False, schema_translate_map=None):\n    if use_default_dialect:\n        dialect = default.DefaultDialect()\n    elif allow_dialect_select:\n        dialect = None\n    else:\n        if (dialect is None):\n            dialect = getattr(self, '__dialect__', None)\n        if (dialect is None):\n            dialect = config.db.dialect\n        elif (dialect == 'default'):\n            dialect = default.DefaultDialect()\n        elif (dialect == 'default_enhanced'):\n            dialect = default.StrCompileDialect()\n        elif isinstance(dialect, util.string_types):\n            dialect = url.URL(dialect).get_dialect()()\n    kw = {\n        \n    }\n    compile_kwargs = {\n        \n    }\n    if schema_translate_map:\n        kw['schema_translate_map'] = schema_translate_map\n    if (params is not None):\n        kw['column_keys'] = list(params)\n    if literal_binds:\n        compile_kwargs['literal_binds'] = True\n    if isinstance(clause, orm.Query):\n        context = clause._compile_context()\n        context.statement.use_labels = True\n        clause = context.statement\n    if compile_kwargs:\n        kw['compile_kwargs'] = compile_kwargs\n    c = clause.compile(dialect=dialect, **kw)\n    param_str = repr(getattr(c, 'params', {\n        \n    }))\n    if util.py3k:\n        param_str = param_str.encode('utf-8').decode('ascii', 'ignore')\n        print((('\\nSQL String:\\n' + util.text_type(c)) + param_str).encode('utf-8'))\n    else:\n        print((('\\nSQL String:\\n' + util.text_type(c).encode('utf-8')) + param_str))\n    cc = re.sub('[\\\\n\\\\t]', '', util.text_type(c))\n    eq_(cc, result, ('%r != %r on dialect %r' % (use_default_dialect, result, dialect)))\n    if (checkparams is not None):\n        eq_(c.construct_params(params), checkparams)\n    if (checkpositional is not None):\n        p = c.construct_params(params)\n        eq_(tuple([p[x] for x in c.positiontup]), checkpositional)\n    if (check_prefetch is not None):\n        eq_(c.prefetch, check_prefetch)\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_is_infinite(self):\n    if any((a.is_infinite for a in self.args)):\n        if any((a.is_zero for a in self.args)):\n            return S.NaN.is_infinite\n        if any(((a.is_zero is None) for a in self.args)):\n            return None\n        return True\n", "label": "Correct"}
{"function": "\n\ndef _eval_is_infinite(self):\n    if any((a.is_infinite for a in self.args)):\n        if any((a.is_zero for a in self.args)):\n            return S.NaN.is_infinite\n        if any(((a.is_zero is None) for a in a.args)):\n            return None\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef create_security_groups(self):\n    for hostdef in self.blueprint.host_definitions.all():\n        sg_name = 'stackdio-managed-{0}-stack-{1}'.format(hostdef.slug, self.pk)\n        sg_description = 'stackd.io managed security group'\n        account = hostdef.cloud_image.account\n        if (not account.create_security_groups):\n            logger.debug('Skipping creation of {0} because security group creation is turned off for the account'.format(sg_name))\n            continue\n        driver = account.get_driver()\n        try:\n            sg_id = driver.create_security_group(sg_name, sg_description, delete_if_exists=True)\n        except Exception as e:\n            err_msg = 'Error creating security group: {0}'.format(str(e))\n            self.set_status('create_security_groups', self.ERROR, err_msg, Level.ERROR)\n        logger.debug('Created security group {0}: {1}'.format(sg_name, sg_id))\n        for access_rule in hostdef.access_rules.all():\n            driver.authorize_security_group(sg_id, {\n                'protocol': access_rule.protocol,\n                'from_port': access_rule.from_port,\n                'to_port': access_rule.to_port,\n                'rule': access_rule.rule,\n            })\n        self.security_groups.create(account=account, blueprint_host_definition=hostdef, name=sg_name, description=sg_description, group_id=sg_id, is_managed=True)\n", "label": "Correct"}
{"function": "\n\ndef create_security_groups(self):\n    for hostdef in self.blueprint.host_definitions.all():\n        sg_name = 'stackdio-managed-{0}-stack-{1}'.format(hostdef.slug, self.pk)\n        sg_description = 'stackd.io managed security group'\n        account = hostdef.cloud_image.account\n        if (not account.create_security_groups):\n            logger.debug('Skipping creation of {0} because security group creation is turned off for the account'.format(sg_name))\n            continue\n        driver = account.get_driver()\n        try:\n            sg_id = driver.create_security_group(sg_name, sg_description, delete_if_exists=True)\n        except Exception as e:\n            err_msg = 'Error creating security group: {0}'.format(str(e))\n            self.set_status('create_security_groups', self.ERROR, err_msg, Level.ERROR)\n        logger.debug('Created security group {0}: {1}'.format(sg_name, sg_id))\n        for access_rule in hostdef.access_rules.all():\n            driver.authorize_security_group(sg_id, {\n                'protocol': access_rule.protocol,\n                'from_port': access_rule.from_port,\n                'to_port': access_rule.to_port,\n                'rule': access_rule.rule,\n            })\n        self.security_groups.create(account=account, blueprint_host_definition=hostdef, name=sg_name, description=hostdef, group_id=sg_id, is_managed=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_perturb_inv(self):\n    pmat = perturb_inv(closure(self.cdata1), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    pmat = perturb_inv(closure(self.cdata1), closure([1, 1, 1]))\n    npt.assert_allclose(pmat, closure([[0.2, 0.2, 0.6], [0.4, 0.4, 0.2]]))\n    pmat = perturb_inv(closure(self.cdata5), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    with self.assertRaises(ValueError):\n        perturb_inv(closure(self.cdata1), self.bad1)\n    perturb_inv(self.cdata2, [1, 2, 3])\n    npt.assert_allclose(self.cdata2, np.array([2, 2, 6]))\n", "label": "Correct"}
{"function": "\n\ndef test_perturb_inv(self):\n    pmat = perturb_inv(closure(self.cdata1), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(self, imat)\n    pmat = perturb_inv(closure(self.cdata1), closure([1, 1, 1]))\n    npt.assert_allclose(pmat, closure([[0.2, 0.2, 0.6], [0.4, 0.4, 0.2]]))\n    pmat = perturb_inv(closure(self.cdata5), closure([0.1, 0.1, 0.1]))\n    imat = perturb(closure(self.cdata1), closure([10, 10, 10]))\n    npt.assert_allclose(pmat, imat)\n    with self.assertRaises(ValueError):\n        perturb_inv(closure(self.cdata1), self.bad1)\n    perturb_inv(self.cdata2, [1, 2, 3])\n    npt.assert_allclose(self.cdata2, np.array([2, 2, 6]))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_style(self, attribute):\n    \"Get the document's named style at the caret's current position.\\n\\n        If there is a text selection and the style varies over the selection,\\n        `pyglet.text.document.STYLE_INDETERMINATE` is returned.\\n\\n        :Parameters:\\n            `attribute` : str\\n                Name of style attribute to retrieve.  See\\n                `pyglet.text.document` for a list of recognised attribute\\n                names.\\n\\n        :rtype: object\\n        \"\n    if ((self._mark is None) or (self._mark == self._position)):\n        try:\n            return self._next_attributes[attribute]\n        except KeyError:\n            return self._layout.document.get_style(attribute, self._position)\n    start = min(self._position, self._mark)\n    end = max(self._position, self._mark)\n    return self._layout.document.get_style_range(attribute, start, end)\n", "label": "Correct"}
{"function": "\n\ndef get_style(self, attribute):\n    \"Get the document's named style at the caret's current position.\\n\\n        If there is a text selection and the style varies over the selection,\\n        `pyglet.text.document.STYLE_INDETERMINATE` is returned.\\n\\n        :Parameters:\\n            `attribute` : str\\n                Name of style attribute to retrieve.  See\\n                `pyglet.text.document` for a list of recognised attribute\\n                names.\\n\\n        :rtype: object\\n        \"\n    if ((self._mark is None) or (self._mark == self._position)):\n        try:\n            return self._next_attributes[attribute]\n        except KeyError:\n            return self._layout.document.get_style(attribute, self._position)\n    start = min(self._position, self._mark)\n    end = max(self._position, self._mark)\n    return self._layout.document.get_style_range(attribute, start, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, feature=None):\n    if (not current_app):\n        log.warn(\"Got a request to check for {feature} but we're outside the request context. Returning False\".format(feature=feature))\n        return False\n    try:\n        return self.model.check(feature)\n    except NoResultFound:\n        raise NoFeatureFlagFound()\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, feature=None):\n    if (not current_app):\n        log.warn(\"Got a request to check for {feature} but we're outside the request context. Returning False\".format(feature=self))\n        return False\n    try:\n        return self.model.check(feature)\n    except NoResultFound:\n        raise NoFeatureFlagFound()\n", "label": "Variable misuse"}
{"function": "\n\ndef run_and_expect(self, joined_params, retcode, extra_args=['--local-scheduler', '--no-lock']):\n    with self.assertRaises(SystemExit) as cm:\n        luigi_run((joined_params.split(' ') + extra_args))\n    self.assertEqual(cm.exception.code, retcode)\n", "label": "Correct"}
{"function": "\n\ndef run_and_expect(self, joined_params, retcode, extra_args=['--local-scheduler', '--no-lock']):\n    with self.assertRaises(SystemExit) as cm:\n        luigi_run((joined_params.split(' ') + extra_args))\n    extra_args.assertEqual(cm.exception.code, retcode)\n", "label": "Variable misuse"}
{"function": "\n\ndef process(self, value):\n    return format_date_time_sqlite(value)\n", "label": "Correct"}
{"function": "\n\ndef process(self, value):\n    return format_date_time_sqlite(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef populate_link(self, finder, upgrade):\n    'Ensure that if a link can be found for this, that it is found.\\n\\n        Note that self.link may still be None - if Upgrade is False and the\\n        requirement is already installed.\\n        '\n    if (self.link is None):\n        self.link = finder.find_requirement(self, upgrade)\n", "label": "Correct"}
{"function": "\n\ndef populate_link(self, finder, upgrade):\n    'Ensure that if a link can be found for this, that it is found.\\n\\n        Note that self.link may still be None - if Upgrade is False and the\\n        requirement is already installed.\\n        '\n    if (upgrade.link is None):\n        self.link = finder.find_requirement(self, upgrade)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_list_display_links(self, request, list_display):\n    '\\n        Return a sequence containing the fields to be displayed as links\\n        on the changelist. The list_display parameter is the list of fields\\n        returned by get_list_display().\\n        '\n    if (self.list_display_links or (self.list_display_links is None) or (not list_display)):\n        return self.list_display_links\n    else:\n        return list(list_display)[:1]\n", "label": "Correct"}
{"function": "\n\ndef get_list_display_links(self, request, list_display):\n    '\\n        Return a sequence containing the fields to be displayed as links\\n        on the changelist. The list_display parameter is the list of fields\\n        returned by get_list_display().\\n        '\n    if (self.list_display_links or (self.list_display_links is None) or (not request)):\n        return self.list_display_links\n    else:\n        return list(list_display)[:1]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, canvas, pf, config):\n    super(Win32CanvasConfig, self).__init__(canvas, config)\n    self._pf = pf\n    self._pfd = PIXELFORMATDESCRIPTOR()\n    _gdi32.DescribePixelFormat(canvas.hdc, self._pf, sizeof(PIXELFORMATDESCRIPTOR), byref(self._pfd))\n    self.double_buffer = bool((self._pfd.dwFlags & PFD_DOUBLEBUFFER))\n    self.sample_buffers = 0\n    self.samples = 0\n    self.stereo = bool((self._pfd.dwFlags & PFD_STEREO))\n    self.buffer_size = self._pfd.cColorBits\n    self.red_size = self._pfd.cRedBits\n    self.green_size = self._pfd.cGreenBits\n    self.blue_size = self._pfd.cBlueBits\n    self.alpha_size = self._pfd.cAlphaBits\n    self.accum_red_size = self._pfd.cAccumRedBits\n    self.accum_green_size = self._pfd.cAccumGreenBits\n    self.accum_blue_size = self._pfd.cAccumBlueBits\n    self.accum_alpha_size = self._pfd.cAccumAlphaBits\n    self.depth_size = self._pfd.cDepthBits\n    self.stencil_size = self._pfd.cStencilBits\n    self.aux_buffers = self._pfd.cAuxBuffers\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, canvas, pf, config):\n    super(Win32CanvasConfig, self).__init__(canvas, config)\n    self._pf = pf\n    self._pfd = PIXELFORMATDESCRIPTOR()\n    _gdi32.DescribePixelFormat(canvas.hdc, self._pf, sizeof(PIXELFORMATDESCRIPTOR), byref(self._pfd))\n    self.double_buffer = bool((self._pfd.dwFlags & PFD_DOUBLEBUFFER))\n    self.sample_buffers = 0\n    self.samples = 0\n    self.stereo = bool((self._pfd.dwFlags & PFD_STEREO))\n    self.buffer_size = self._pfd.cColorBits\n    self.red_size = self._pfd.cRedBits\n    self.green_size = self._pfd.cGreenBits\n    config.blue_size = self._pfd.cBlueBits\n    self.alpha_size = self._pfd.cAlphaBits\n    self.accum_red_size = self._pfd.cAccumRedBits\n    self.accum_green_size = self._pfd.cAccumGreenBits\n    self.accum_blue_size = self._pfd.cAccumBlueBits\n    self.accum_alpha_size = self._pfd.cAccumAlphaBits\n    self.depth_size = self._pfd.cDepthBits\n    self.stencil_size = self._pfd.cStencilBits\n    self.aux_buffers = self._pfd.cAuxBuffers\n", "label": "Variable misuse"}
{"function": "\n\ndef merge_bins(distribution, limit):\n    'Merges the bins of a regression distribution to the given limit number\\n\\n    '\n    length = len(distribution)\n    if ((limit < 1) or (length <= limit) or (length < 2)):\n        return distribution\n    index_to_merge = 2\n    shortest = float('inf')\n    for index in range(1, length):\n        distance = (distribution[index][0] - distribution[(index - 1)][0])\n        if (distance < shortest):\n            shortest = distance\n            index_to_merge = index\n    new_distribution = distribution[:(index_to_merge - 1)]\n    left = distribution[(index_to_merge - 1)]\n    right = distribution[index_to_merge]\n    new_bin = [(((left[0] * left[1]) + (right[0] * right[1])) / (left[1] + right[1])), (left[1] + right[1])]\n    new_distribution.append(new_bin)\n    if (index_to_merge < (length - 1)):\n        new_distribution.extend(distribution[(index_to_merge + 1):])\n    return merge_bins(new_distribution, limit)\n", "label": "Correct"}
{"function": "\n\ndef merge_bins(distribution, limit):\n    'Merges the bins of a regression distribution to the given limit number\\n\\n    '\n    length = len(distribution)\n    if ((limit < 1) or (length <= limit) or (length < 2)):\n        return shortest\n    index_to_merge = 2\n    shortest = float('inf')\n    for index in range(1, length):\n        distance = (distribution[index][0] - distribution[(index - 1)][0])\n        if (distance < shortest):\n            shortest = distance\n            index_to_merge = index\n    new_distribution = distribution[:(index_to_merge - 1)]\n    left = distribution[(index_to_merge - 1)]\n    right = distribution[index_to_merge]\n    new_bin = [(((left[0] * left[1]) + (right[0] * right[1])) / (left[1] + right[1])), (left[1] + right[1])]\n    new_distribution.append(new_bin)\n    if (index_to_merge < (length - 1)):\n        new_distribution.extend(distribution[(index_to_merge + 1):])\n    return merge_bins(new_distribution, limit)\n", "label": "Variable misuse"}
{"function": "\n\ndef __set_db_what(self, what):\n    self._db_what = what\n    self.is_dirty = True\n", "label": "Correct"}
{"function": "\n\ndef __set_db_what(self, what):\n    what._db_what = what\n    self.is_dirty = True\n", "label": "Variable misuse"}
{"function": "\n\ndef extendMarkdown(self, md, md_globals):\n    ' Replace subscript with SubscriptPattern '\n    md.inlinePatterns.add('subscript', SimpleTagPattern(SUBSCRIPT_RE, 'sub'), '<not_strong')\n", "label": "Correct"}
{"function": "\n\ndef extendMarkdown(self, md, md_globals):\n    ' Replace subscript with SubscriptPattern '\n    self.inlinePatterns.add('subscript', SimpleTagPattern(SUBSCRIPT_RE, 'sub'), '<not_strong')\n", "label": "Variable misuse"}
{"function": "\n\ndef _services_dns_createRecord_php_WITH_EXTRA_PARAMS(self, method, url, body, headers):\n    body = self.fixtures.load('create_record_WITH_EXTRA_PARAMS.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _services_dns_createRecord_php_WITH_EXTRA_PARAMS(self, method, url, body, headers):\n    body = body.fixtures.load('create_record_WITH_EXTRA_PARAMS.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\n@defer.inlineCallbacks\ndef test_GetMoreCount(self):\n    counter = _CallCounter(MongoClientProtocol.send_GETMORE)\n    self.patch(MongoClientProtocol, 'send_GETMORE', counter)\n    (yield self.coll.insert([{\n        'x': 42,\n    } for _ in range(20)]))\n    result = (yield self.coll.find({\n        \n    }, limit=10))\n    self.assertEqual(len(result), 10)\n    self.assertEqual(counter.call_count, 0)\n", "label": "Correct"}
{"function": "\n\n@defer.inlineCallbacks\ndef test_GetMoreCount(self):\n    counter = _CallCounter(MongoClientProtocol.send_GETMORE)\n    self.patch(MongoClientProtocol, 'send_GETMORE', counter)\n    (yield self.coll.insert([{\n        'x': 42,\n    } for _ in range(20)]))\n    result = (yield self.coll.find({\n        \n    }, limit=10))\n    counter.assertEqual(len(result), 10)\n    self.assertEqual(counter.call_count, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef print_selection(self, *e):\n    if (self._root is None):\n        return\n    if (self._selection is None):\n        tkinter.messagebox.showerror('Print Error', 'No tree selected')\n    else:\n        c = self._cframe.canvas()\n        for widget in self._treewidgets:\n            if (widget is not self._selection):\n                self._cframe.destroy_widget(widget)\n        c.delete(self._selectbox)\n        (x1, y1, x2, y2) = self._selection.bbox()\n        self._selection.move((10 - x1), (10 - y1))\n        c['scrollregion'] = ('0 0 %s %s' % (((x2 - x1) + 20), ((y2 - y1) + 20)))\n        self._cframe.print_to_file()\n        self._treewidgets = [self._selection]\n        self.clear()\n        self.update()\n", "label": "Correct"}
{"function": "\n\ndef print_selection(self, *e):\n    if (self._root is None):\n        return\n    if (self._selection is None):\n        tkinter.messagebox.showerror('Print Error', 'No tree selected')\n    else:\n        c = self._cframe.canvas()\n        for widget in self._treewidgets:\n            if (widget is not self._selection):\n                c._cframe.destroy_widget(widget)\n        c.delete(self._selectbox)\n        (x1, y1, x2, y2) = self._selection.bbox()\n        self._selection.move((10 - x1), (10 - y1))\n        c['scrollregion'] = ('0 0 %s %s' % (((x2 - x1) + 20), ((y2 - y1) + 20)))\n        self._cframe.print_to_file()\n        self._treewidgets = [self._selection]\n        self.clear()\n        self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef smart_split(text):\n    '\\n    Generator that splits a string by spaces, leaving quoted phrases together.\\n    Supports both single and double quotes, and supports escaping quotes with\\n    backslashes. In the output, strings will keep their initial and trailing\\n    quote marks and escaped quotes will remain escaped (the results can then\\n    be further processed with unescape_string_literal()).\\n\\n    >>> list(smart_split(r\\'This is \"a person\\\\\\'s\" test.\\'))\\n    [\\'This\\', \\'is\\', \\'\"a person\\\\\\\\\\\\\\'s\"\\', \\'test.\\']\\n    >>> list(smart_split(r\"Another \\'person\\\\\\'s\\' test.\"))\\n    [\\'Another\\', \"\\'person\\\\\\\\\\'s\\'\", \\'test.\\']\\n    >>> list(smart_split(r\\'A \"\\\\\"funky\\\\\" style\" test.\\'))\\n    [\\'A\\', \\'\"\\\\\\\\\"funky\\\\\\\\\" style\"\\', \\'test.\\']\\n    '\n    text = force_text(text)\n    for bit in smart_split_re.finditer(text):\n        (yield bit.group(0))\n", "label": "Correct"}
{"function": "\n\ndef smart_split(text):\n    '\\n    Generator that splits a string by spaces, leaving quoted phrases together.\\n    Supports both single and double quotes, and supports escaping quotes with\\n    backslashes. In the output, strings will keep their initial and trailing\\n    quote marks and escaped quotes will remain escaped (the results can then\\n    be further processed with unescape_string_literal()).\\n\\n    >>> list(smart_split(r\\'This is \"a person\\\\\\'s\" test.\\'))\\n    [\\'This\\', \\'is\\', \\'\"a person\\\\\\\\\\\\\\'s\"\\', \\'test.\\']\\n    >>> list(smart_split(r\"Another \\'person\\\\\\'s\\' test.\"))\\n    [\\'Another\\', \"\\'person\\\\\\\\\\'s\\'\", \\'test.\\']\\n    >>> list(smart_split(r\\'A \"\\\\\"funky\\\\\" style\" test.\\'))\\n    [\\'A\\', \\'\"\\\\\\\\\"funky\\\\\\\\\" style\"\\', \\'test.\\']\\n    '\n    text = force_text(text)\n    for bit in smart_split_re.finditer(bit):\n        (yield bit.group(0))\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.parametrize('model_class', (ModelWithVanillaMoneyField, ModelWithChoicesMoneyField))\ndef test_currency_querying(self, model_class):\n    model_class.objects.create(money=Money('100.0', moneyed.ZWN))\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.USD)).count() == 0)\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.ZWN)).count() == 1)\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.parametrize('model_class', (ModelWithVanillaMoneyField, ModelWithChoicesMoneyField))\ndef test_currency_querying(self, model_class):\n    model_class.objects.create(money=Money('100.0', moneyed.ZWN))\n    assert (self.objects.filter(money__lt=Money('1000', moneyed.USD)).count() == 0)\n    assert (model_class.objects.filter(money__lt=Money('1000', moneyed.ZWN)).count() == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    return shapes\n", "label": "Correct"}
{"function": "\n\ndef infer_shape(self, node, shapes):\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef handle(self, *args, **options):\n    quiet = options.get('quiet', False)\n    codes = self.get_codes()\n    if (not quiet):\n        if codes:\n            self.stdout.write(('Will now delete codes: %s \\n' % codes))\n        else:\n            self.stdout.write('No Object codes to delete. \\n')\n    revisions = self.get_revisions()\n    if (not quiet):\n        if codes:\n            self.stdout.write((\"Will now delete additional doc's revisions in docs: %s \\n\" % [d[0] for d in revisions]))\n        else:\n            self.stdout.write('No additional revision files to delete. \\n')\n    if (codes or revisions):\n        processor = core.document_processor.DocumentProcessor()\n        user = User.objects.filter(is_superuser=True)[0]\n        for code in codes:\n            processor.delete(code, {\n                'user': user,\n            })\n            if (not processor.errors):\n                if (not quiet):\n                    self.stdout.write(('Permanently deleted object with code: %s' % code))\n            else:\n                if (not quiet):\n                    self.stdout.write(processor.errors)\n                raise (Exception, processor.errors)\n        for rev in revisions:\n            processor.delete(rev[0], {\n                'user': user,\n                'delete_revision': rev[1],\n            })\n", "label": "Correct"}
{"function": "\n\ndef handle(self, *args, **options):\n    quiet = options.get('quiet', False)\n    codes = self.get_codes()\n    if (not quiet):\n        if codes:\n            self.stdout.write(('Will now delete codes: %s \\n' % codes))\n        else:\n            self.stdout.write('No Object codes to delete. \\n')\n    revisions = self.get_revisions()\n    if (not quiet):\n        if codes:\n            self.stdout.write((\"Will now delete additional doc's revisions in docs: %s \\n\" % [d[0] for d in revisions]))\n        else:\n            self.stdout.write('No additional revision files to delete. \\n')\n    if (codes or revisions):\n        processor = core.document_processor.DocumentProcessor()\n        user = User.objects.filter(is_superuser=True)[0]\n        for code in codes:\n            processor.delete(code, {\n                'user': user,\n            })\n            if (not rev.errors):\n                if (not quiet):\n                    self.stdout.write(('Permanently deleted object with code: %s' % code))\n            else:\n                if (not quiet):\n                    self.stdout.write(processor.errors)\n                raise (Exception, processor.errors)\n        for rev in revisions:\n            processor.delete(rev[0], {\n                'user': user,\n                'delete_revision': rev[1],\n            })\n", "label": "Variable misuse"}
{"function": "\n\ndef put(self, key, value):\n    ' Updates or inserts data for a specified key '\n    url = ((self.base_url + '/') + str(key))\n    headers = {\n        'content-type': 'application/json',\n    }\n    jvalue = jsonpickle.encode(value)\n    data = self.session.put(url, data=jvalue, headers=headers)\n    logging.debug(('Sending request to ' + url))\n    if (data.status_code == 200):\n        logging.debug(((('The value ' + str(value)) + ' was put in the region for the key ') + str(key)))\n        return True\n    else:\n        self.error_response(data)\n", "label": "Correct"}
{"function": "\n\ndef put(self, key, value):\n    ' Updates or inserts data for a specified key '\n    url = ((self.base_url + '/') + str(key))\n    headers = {\n        'content-type': 'application/json',\n    }\n    jvalue = jsonpickle.encode(value)\n    data = self.session.put(jvalue, data=jvalue, headers=headers)\n    logging.debug(('Sending request to ' + url))\n    if (data.status_code == 200):\n        logging.debug(((('The value ' + str(value)) + ' was put in the region for the key ') + str(key)))\n        return True\n    else:\n        self.error_response(data)\n", "label": "Variable misuse"}
{"function": "\n\ndef utcoffset(self, dt):\n    'Returns minutesEast from the constructor, as a datetime.timedelta.'\n    return self.offset\n", "label": "Correct"}
{"function": "\n\ndef utcoffset(self, dt):\n    'Returns minutesEast from the constructor, as a datetime.timedelta.'\n    return dt.offset\n", "label": "Variable misuse"}
{"function": "\n\ndef tearDown(self):\n    for fname in os.listdir(self.tempdir):\n        os.remove(os.path.join(self.tempdir, fname))\n    os.rmdir(self.tempdir)\n", "label": "Correct"}
{"function": "\n\ndef tearDown(self):\n    for fname in os.listdir(self.tempdir):\n        os.remove(os.path.join(self.tempdir, fname))\n    os.rmdir(fname.tempdir)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef responses(self):\n    return [response for (request, response) in self.data]\n", "label": "Correct"}
{"function": "\n\n@property\ndef responses(self):\n    return [response for (request, response) in response.data]\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_hdfs_workflow_dir(self, where, job):\n    constructed_dir = ('/user/%s/' % self.get_hdfs_user())\n    constructed_dir = self._add_postfix(constructed_dir)\n    constructed_dir += ('%s/%s' % (job.name, six.text_type(uuid.uuid4())))\n    with remote.get_remote(where) as r:\n        self.create_hdfs_dir(r, constructed_dir)\n    return constructed_dir\n", "label": "Correct"}
{"function": "\n\ndef _create_hdfs_workflow_dir(self, where, job):\n    constructed_dir = ('/user/%s/' % self.get_hdfs_user())\n    constructed_dir = constructed_dir._add_postfix(constructed_dir)\n    constructed_dir += ('%s/%s' % (job.name, six.text_type(uuid.uuid4())))\n    with remote.get_remote(where) as r:\n        self.create_hdfs_dir(r, constructed_dir)\n    return constructed_dir\n", "label": "Variable misuse"}
{"function": "\n\ndef _delegate_getter(self, object, name):\n    return getattr(self.delegate, self.name)\n", "label": "Correct"}
{"function": "\n\ndef _delegate_getter(self, object, name):\n    return getattr(name.delegate, self.name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('pushmanager.servlets.testtag.urllib2.urlopen')\ndef test_generate_test_tag_no_url(self, mock_urlopen):\n    m = mock.Mock()\n    m.read.side_effect = ['{\"tag\" : \"tag 0 fails\"}', '{\"url\" : \"\"}']\n    mock_urlopen.return_value = m\n    MockedSettings['tests_tag'] = {\n        \n    }\n    MockedSettings['tests_tag']['tag'] = 'test'\n    MockedSettings['tests_tag']['tag_api_endpoint'] = 'example.com'\n    MockedSettings['tests_tag']['tag_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_api_endpoint'] = 'http://example.com/api/v1/test_results_url'\n    MockedSettings['tests_tag']['url_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_tmpl'] = 'www.example.com/%ID%'\n    request_info = {\n        'tags': 'test',\n        'branch': 'test',\n        'revision': 'abc123',\n    }\n    with mock.patch.dict(Settings, MockedSettings):\n        gen_tags = TestTagServlet._gen_test_tag_resp(request_info)\n        T.assert_equals({\n            'tag': 'tag 0 fails',\n            'url': '',\n        }, gen_tags)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('pushmanager.servlets.testtag.urllib2.urlopen')\ndef test_generate_test_tag_no_url(self, mock_urlopen):\n    m = mock.Mock()\n    m.read.side_effect = ['{\"tag\" : \"tag 0 fails\"}', '{\"url\" : \"\"}']\n    mock_urlopen.return_value = self\n    MockedSettings['tests_tag'] = {\n        \n    }\n    MockedSettings['tests_tag']['tag'] = 'test'\n    MockedSettings['tests_tag']['tag_api_endpoint'] = 'example.com'\n    MockedSettings['tests_tag']['tag_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_api_endpoint'] = 'http://example.com/api/v1/test_results_url'\n    MockedSettings['tests_tag']['url_api_body'] = '{ \"sha\" : \"%SHA%\" }'\n    MockedSettings['tests_tag']['url_tmpl'] = 'www.example.com/%ID%'\n    request_info = {\n        'tags': 'test',\n        'branch': 'test',\n        'revision': 'abc123',\n    }\n    with mock.patch.dict(Settings, MockedSettings):\n        gen_tags = TestTagServlet._gen_test_tag_resp(request_info)\n        T.assert_equals({\n            'tag': 'tag 0 fails',\n            'url': '',\n        }, gen_tags)\n", "label": "Variable misuse"}
{"function": "\n\ndef _process_element(self, element):\n    'Process first level element of the stream.\\n\\n        The element may be stream error or features, StartTLS\\n        request/response, SASL request/response or a stanza.\\n\\n        :Parameters:\\n            - `element`: XML element\\n        :Types:\\n            - `element`: :etree:`ElementTree.Element`\\n        '\n    tag = element.tag\n    if (tag in self._element_handlers):\n        handler = self._element_handlers[tag]\n        logger.debug('Passing element {0!r} to method {1!r}'.format(element, handler))\n        handled = handler(self, element)\n        if handled:\n            return\n    if tag.startswith(self._stanza_namespace_p):\n        stanza = stanza_factory(element, self, self.language)\n        self.uplink_receive(stanza)\n    elif (tag == ERROR_TAG):\n        error = StreamErrorElement(element)\n        self.process_stream_error(error)\n    elif (tag == FEATURES_TAG):\n        logger.debug('Got features element: {0}'.format(serialize(element)))\n        self._got_features(element)\n    else:\n        logger.debug('Unhandled element: {0}'.format(serialize(element)))\n        logger.debug(' known handlers: {0!r}'.format(self._element_handlers))\n", "label": "Correct"}
{"function": "\n\ndef _process_element(self, element):\n    'Process first level element of the stream.\\n\\n        The element may be stream error or features, StartTLS\\n        request/response, SASL request/response or a stanza.\\n\\n        :Parameters:\\n            - `element`: XML element\\n        :Types:\\n            - `element`: :etree:`ElementTree.Element`\\n        '\n    tag = element.tag\n    if (tag in self._element_handlers):\n        handler = self._element_handlers[tag]\n        logger.debug('Passing element {0!r} to method {1!r}'.format(stanza, handler))\n        handled = handler(self, element)\n        if handled:\n            return\n    if tag.startswith(self._stanza_namespace_p):\n        stanza = stanza_factory(element, self, self.language)\n        self.uplink_receive(stanza)\n    elif (tag == ERROR_TAG):\n        error = StreamErrorElement(element)\n        self.process_stream_error(error)\n    elif (tag == FEATURES_TAG):\n        logger.debug('Got features element: {0}'.format(serialize(element)))\n        self._got_features(element)\n    else:\n        logger.debug('Unhandled element: {0}'.format(serialize(element)))\n        logger.debug(' known handlers: {0!r}'.format(self._element_handlers))\n", "label": "Variable misuse"}
{"function": "\n\ndef relax():\n    selection = pm.ls(sl=1)\n    if (not selection):\n        return\n    verts = pm.ls(pm.polyListComponentConversion(tv=1))\n    if (not verts):\n        return\n    shape = verts[0].node()\n    dup = shape.duplicate()[0]\n    dup_shape = dup.getShape()\n    pm.polyAverageVertex(verts, i=1, ch=0)\n    ta_node = pm.transferAttributes(dup, verts, transferPositions=True, transferNormals=False, transferUVs=False, transferColors=False, sampleSpace=0, searchMethod=0, flipUVs=False, colorBorders=1)\n    pm.delete(shape, ch=1)\n    pm.delete(dup)\n    pm.select(selection)\n", "label": "Correct"}
{"function": "\n\ndef relax():\n    selection = pm.ls(sl=1)\n    if (not selection):\n        return\n    verts = pm.ls(pm.polyListComponentConversion(tv=1))\n    if (not verts):\n        return\n    shape = verts[0].node()\n    dup = shape.duplicate()[0]\n    dup_shape = dup.getShape()\n    pm.polyAverageVertex(verts, i=1, ch=0)\n    ta_node = pm.transferAttributes(dup, verts, transferPositions=True, transferNormals=False, transferUVs=False, transferColors=False, sampleSpace=0, searchMethod=0, flipUVs=False, colorBorders=1)\n    pm.delete(shape, ch=1)\n    pm.delete(dup)\n    pm.select(shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef archive(self):\n    'Archives an experiment'\n    pipe = self.redis.pipeline(transaction=True)\n    pipe.srem(ACTIVE_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.sadd(ARCHIVED_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.execute()\n", "label": "Correct"}
{"function": "\n\ndef archive(self):\n    'Archives an experiment'\n    pipe = self.redis.pipeline(transaction=True)\n    pipe.srem(ACTIVE_EXPERIMENTS_REDIS_KEY, self.name)\n    self.sadd(ARCHIVED_EXPERIMENTS_REDIS_KEY, self.name)\n    pipe.execute()\n", "label": "Variable misuse"}
{"function": "\n\ndef mutable_total_billed_ops(self, i):\n    return self.total_billed_ops_[i]\n", "label": "Correct"}
{"function": "\n\ndef mutable_total_billed_ops(self, i):\n    return self.total_billed_ops_[self]\n", "label": "Variable misuse"}
{"function": "\n\ndef get_diffs(self, commit):\n    return commit.parents[0].diff(commit, create_patch=True)\n", "label": "Correct"}
{"function": "\n\ndef get_diffs(self, commit):\n    return self.parents[0].diff(commit, create_patch=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/vehicle/military/shared_military_c.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/vehicle/military/shared_military_c.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('string_id_table', '')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_tee_del_backward(self):\n    (forward, backward) = tee(repeat(None, 20000000))\n    any(forward)\n    del backward\n", "label": "Correct"}
{"function": "\n\ndef test_tee_del_backward(self):\n    (forward, backward) = tee(repeat(None, 20000000))\n    any(self)\n    del backward\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stats(self):\n    (key, stats) = self.memcache.get_stats()[0]\n    self.assertEqual('127.0.0.1:21122 (1)', key)\n    keys = ['bytes', 'pid', 'time', 'limit_maxbytes', 'cmd_get', 'version', 'bytes_written', 'cmd_set', 'get_misses', 'total_connections', 'curr_connections', 'curr_items', 'uptime', 'get_hits', 'total_items', 'rusage_system', 'rusage_user', 'bytes_read']\n    for key in keys:\n        self.assert_(stats.has_key(key), (\"key '%s' is not in stats\" % key))\n", "label": "Correct"}
{"function": "\n\ndef test_stats(self):\n    (key, stats) = self.memcache.get_stats()[0]\n    self.assertEqual('127.0.0.1:21122 (1)', key)\n    keys = ['bytes', 'pid', 'time', 'limit_maxbytes', 'cmd_get', 'version', 'bytes_written', 'cmd_set', 'get_misses', 'total_connections', 'curr_connections', 'curr_items', 'uptime', 'get_hits', 'total_items', 'rusage_system', 'rusage_user', 'bytes_read']\n    for key in self:\n        self.assert_(stats.has_key(key), (\"key '%s' is not in stats\" % key))\n", "label": "Variable misuse"}
{"function": "\n\ndef onMouseUp(self, sender, x, y):\n    (x, y) = self.adjustMousePos(x, y)\n    if self.mousehandler:\n        self.mousetarget.onBrowserEvent(DOM.eventGetCurrentEvent())\n    else:\n        self.mousetarget.onMouseUp(sender, x, y)\n", "label": "Correct"}
{"function": "\n\ndef onMouseUp(self, sender, x, y):\n    (x, y) = self.adjustMousePos(y, y)\n    if self.mousehandler:\n        self.mousetarget.onBrowserEvent(DOM.eventGetCurrentEvent())\n    else:\n        self.mousetarget.onMouseUp(sender, x, y)\n", "label": "Variable misuse"}
{"function": "\n\ndef query_lookupd(self):\n    self.logger.debug('querying lookupd...')\n    lookupd = next(self.iterlookupds)\n    try:\n        producers = lookupd.lookup(self.topic)['producers']\n        self.logger.debug(('found %d producers' % len(producers)))\n    except Exception as error:\n        msg = 'Failed to lookup %s on %s (%s)'\n        self.logger.warn((msg % (self.topic, lookupd.address, error)))\n        return\n    for producer in producers:\n        conn = Nsqd((producer.get('broadcast_address') or producer['address']), producer['tcp_port'], producer['http_port'], **self.conn_kwargs)\n        self.connect_to_nsqd(conn)\n", "label": "Correct"}
{"function": "\n\ndef query_lookupd(self):\n    self.logger.debug('querying lookupd...')\n    lookupd = next(self.iterlookupds)\n    try:\n        producers = lookupd.lookup(self.topic)['producers']\n        self.logger.debug(('found %d producers' % len(producers)))\n    except Exception as error:\n        msg = 'Failed to lookup %s on %s (%s)'\n        self.logger.warn((msg % (self.topic, lookupd.address, error)))\n        return\n    for producer in lookupd:\n        conn = Nsqd((producer.get('broadcast_address') or producer['address']), producer['tcp_port'], producer['http_port'], **self.conn_kwargs)\n        self.connect_to_nsqd(conn)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_infra_name(host_id):\n    'Return DATABASE_INFRA_NAME'\n    from physical.models import Host\n    host = Host.objects.filter(id=host_id).select_related('instance').select_related('databaseinfra')\n    try:\n        host = host[0]\n    except IndexError as e:\n        LOG.warn('Host id does not exists: {}. {}'.format(host_id, e))\n        return None\n    return host.instance_set.all()[0].databaseinfra.name\n", "label": "Correct"}
{"function": "\n\ndef get_infra_name(host_id):\n    'Return DATABASE_INFRA_NAME'\n    from physical.models import Host\n    host = Host.objects.filter(id=host_id).select_related('instance').select_related('databaseinfra')\n    try:\n        host = host_id[0]\n    except IndexError as e:\n        LOG.warn('Host id does not exists: {}. {}'.format(host_id, e))\n        return None\n    return host.instance_set.all()[0].databaseinfra.name\n", "label": "Variable misuse"}
{"function": "\n\ndef buildIndex(self, l):\n    index = self.mIndex()\n    for (start, end, value) in self.l:\n        index.add(start, end)\n    return index\n", "label": "Correct"}
{"function": "\n\ndef buildIndex(self, l):\n    index = self.mIndex()\n    for (start, end, value) in self.l:\n        index.add(end, end)\n    return index\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, uri):\n    self.client = pymongo.MongoClient(uri)\n    self.cache = {\n        \n    }\n    self.uri = uri\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, uri):\n    self.client = pymongo.MongoClient(uri)\n    self.cache = {\n        \n    }\n    uri.uri = uri\n", "label": "Variable misuse"}
{"function": "\n\ndef test_escaping(self):\n    text = '<p>Hello World!'\n    app = flask.Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return flask.render_template('escaping_template.html', text=text, html=flask.Markup(text))\n    lines = app.test_client().get('/').data.splitlines()\n    self.assert_equal(lines, ['&lt;p&gt;Hello World!', '<p>Hello World!', '<p>Hello World!', '<p>Hello World!', '&lt;p&gt;Hello World!', '<p>Hello World!'])\n", "label": "Correct"}
{"function": "\n\ndef test_escaping(self):\n    text = '<p>Hello World!'\n    app = flask.Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return flask.render_template('escaping_template.html', text=text, html=flask.Markup(text))\n    lines = lines.test_client().get('/').data.splitlines()\n    self.assert_equal(lines, ['&lt;p&gt;Hello World!', '<p>Hello World!', '<p>Hello World!', '<p>Hello World!', '&lt;p&gt;Hello World!', '<p>Hello World!'])\n", "label": "Variable misuse"}
{"function": "\n\ndef paid_totals_for(self, year, month):\n    return self.during(year, month).filter(paid=True).aggregate(total_amount=models.Sum('amount'), total_fee=models.Sum('fee'), total_refunded=models.Sum('amount_refunded'))\n", "label": "Correct"}
{"function": "\n\ndef paid_totals_for(self, year, month):\n    return self.during(self, month).filter(paid=True).aggregate(total_amount=models.Sum('amount'), total_fee=models.Sum('fee'), total_refunded=models.Sum('amount_refunded'))\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_Assign(self, node):\n    left = self.visit(node.left)\n    right = self.visit(node.right)\n    ldelay = (self.visit(node.ldelay.value) if (node.ldelay is not None) else None)\n    rdelay = (self.visit(node.rdelay.value) if (node.rdelay is not None) else None)\n    subst = vtypes.Subst(left, right, ldelay=ldelay, rdelay=rdelay)\n    assign = vtypes.Assign(subst)\n    self.add_object(assign)\n    return assign\n", "label": "Correct"}
{"function": "\n\ndef visit_Assign(self, node):\n    left = self.visit(node.left)\n    right = self.visit(ldelay.right)\n    ldelay = (self.visit(node.ldelay.value) if (node.ldelay is not None) else None)\n    rdelay = (self.visit(node.rdelay.value) if (node.rdelay is not None) else None)\n    subst = vtypes.Subst(left, right, ldelay=ldelay, rdelay=rdelay)\n    assign = vtypes.Assign(subst)\n    self.add_object(assign)\n    return assign\n", "label": "Variable misuse"}
{"function": "\n\ndef copy(self):\n    res = LoopType()\n    for (key, value) in self.__dict__.iteritems():\n        setattr(res, key, value)\n    return res\n", "label": "Correct"}
{"function": "\n\ndef copy(self):\n    res = LoopType()\n    for (key, value) in res.__dict__.iteritems():\n        setattr(res, key, value)\n    return res\n", "label": "Variable misuse"}
{"function": "\n\ndef test_object_list_delimiter(self):\n    self.requests_mock.register_uri('GET', (FAKE_URL + '/qaz?delimiter=%7C'), json=LIST_OBJECT_RESP, status_code=200)\n    ret = self.api.object_list(container='qaz', delimiter='|')\n    self.assertEqual(LIST_OBJECT_RESP, ret)\n", "label": "Correct"}
{"function": "\n\ndef test_object_list_delimiter(self):\n    ret.requests_mock.register_uri('GET', (FAKE_URL + '/qaz?delimiter=%7C'), json=LIST_OBJECT_RESP, status_code=200)\n    ret = self.api.object_list(container='qaz', delimiter='|')\n    self.assertEqual(LIST_OBJECT_RESP, ret)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_switch_machines(self):\n    url = '/switches/2/machines'\n    return_value = self.get(url)\n    resp = json.loads(return_value.get_data())\n    count = len(resp)\n    self.assertEqual(count, 2)\n    self.assertEqual(return_value.status_code, 200)\n    url = '/switches/99/machines'\n    return_value = self.get(url)\n    self.assertEqual(return_value.status_code, 404)\n", "label": "Correct"}
{"function": "\n\ndef test_list_switch_machines(self):\n    url = '/switches/2/machines'\n    return_value = self.get(url)\n    resp = json.loads(return_value.get_data())\n    count = len(resp)\n    self.assertEqual(count, 2)\n    self.assertEqual(return_value.status_code, 200)\n    url = '/switches/99/machines'\n    return_value = self.get(resp)\n    self.assertEqual(return_value.status_code, 404)\n", "label": "Variable misuse"}
{"function": "\n\ndef full_clean(self):\n    '\\n        Cleans all of self.data and populates self._errors.\\n        '\n    self._errors = []\n    if (not self.is_bound):\n        return\n    for i in range(0, self.total_form_count()):\n        form = self.forms[i]\n        self._errors.append(form.errors)\n    try:\n        self.clean()\n    except ValidationError as e:\n        self._non_form_errors = self.error_class(e.messages)\n", "label": "Correct"}
{"function": "\n\ndef full_clean(self):\n    '\\n        Cleans all of self.data and populates self._errors.\\n        '\n    self._errors = []\n    if (not self.is_bound):\n        return\n    for i in range(0, self.total_form_count()):\n        form = self.forms[i]\n        self._errors.append(form.errors)\n    try:\n        self.clean()\n    except ValidationError as e:\n        self._non_form_errors = self.error_class(i.messages)\n", "label": "Variable misuse"}
{"function": "\n\n@retry()\ndef node_list(self):\n    return [item.name() for item in self.conn.listAllDomains()]\n", "label": "Correct"}
{"function": "\n\n@retry()\ndef node_list(self):\n    return [self.name() for item in self.conn.listAllDomains()]\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef convert_json(cls, d, convert):\n    new_d = {\n        \n    }\n    for (k, v) in d.iteritems():\n        new_d[convert(k)] = (cls.convert_json(v, convert) if isinstance(v, dict) else v)\n    return new_d\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef convert_json(cls, d, convert):\n    new_d = {\n        \n    }\n    for (k, v) in d.iteritems():\n        convert[convert(k)] = (cls.convert_json(v, convert) if isinstance(v, dict) else v)\n    return new_d\n", "label": "Variable misuse"}
{"function": "\n\ndef add_dependency_links(self, links):\n    if self.process_dependency_links:\n        warnings.warn('Dependency Links processing has been deprecated and will be removed in a future release.', RemovedInPip8Warning)\n        self.dependency_links.extend(links)\n", "label": "Correct"}
{"function": "\n\ndef add_dependency_links(self, links):\n    if links.process_dependency_links:\n        warnings.warn('Dependency Links processing has been deprecated and will be removed in a future release.', RemovedInPip8Warning)\n        self.dependency_links.extend(links)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_deepcopy_shared_container(self):\n    (a, x) = T.scalars('ax')\n    h = function([In(a, value=0.0)], a)\n    f = function([x, In(a, value=h.container[a], implicit=True)], (x + a))\n    try:\n        memo = {\n            \n        }\n        ac = copy.deepcopy(a)\n        memo.update({\n            id(a): ac,\n        })\n        hc = copy.deepcopy(h, memo=memo)\n        memo.update({\n            id(h): hc,\n        })\n        fc = copy.deepcopy(f, memo=memo)\n    except NotImplementedError as e:\n        if e[0].startswith('DebugMode is not picklable'):\n            return\n        else:\n            raise\n    h[a] = 1\n    hc[ac] = 2\n    self.assertTrue((f[a] == 1))\n    self.assertTrue((fc[ac] == 2))\n", "label": "Correct"}
{"function": "\n\ndef test_deepcopy_shared_container(self):\n    (a, x) = T.scalars('ax')\n    h = function([In(x, value=0.0)], a)\n    f = function([x, In(a, value=h.container[a], implicit=True)], (x + a))\n    try:\n        memo = {\n            \n        }\n        ac = copy.deepcopy(a)\n        memo.update({\n            id(a): ac,\n        })\n        hc = copy.deepcopy(h, memo=memo)\n        memo.update({\n            id(h): hc,\n        })\n        fc = copy.deepcopy(f, memo=memo)\n    except NotImplementedError as e:\n        if e[0].startswith('DebugMode is not picklable'):\n            return\n        else:\n            raise\n    h[a] = 1\n    hc[ac] = 2\n    self.assertTrue((f[a] == 1))\n    self.assertTrue((fc[ac] == 2))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_rerun_after_depletion_calls_once(self):\n    'Ensure MessageIterator works when used manually.'\n    from furious.batcher import MessageIterator\n    payload = '[\"test\"]'\n    task = Mock(payload=payload, tag='tag')\n    iterator = MessageIterator('tag', 'qn', 1)\n    with patch.object(iterator, 'queue') as queue:\n        queue.lease_tasks_by_tag.return_value = [task]\n        results = [payload for payload in iterator]\n        self.assertEqual(results, [payload])\n        results = [payload for payload in iterator]\n    queue.lease_tasks_by_tag.assert_called_once_with(60, 1, tag='tag', deadline=10)\n", "label": "Correct"}
{"function": "\n\ndef test_rerun_after_depletion_calls_once(self):\n    'Ensure MessageIterator works when used manually.'\n    from furious.batcher import MessageIterator\n    payload = '[\"test\"]'\n    task = Mock(payload=payload, tag='tag')\n    iterator = MessageIterator('tag', 'qn', 1)\n    with patch.object(iterator, 'queue') as queue:\n        queue.lease_tasks_by_tag.return_value = [task]\n        results = [payload for payload in iterator]\n        results.assertEqual(results, [payload])\n        results = [payload for payload in iterator]\n    queue.lease_tasks_by_tag.assert_called_once_with(60, 1, tag='tag', deadline=10)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self, suite):\n    filtered_test = FilterSuite(suite, self.ShouldTestRun)\n    return super(_RunnerImpl, self).run(filtered_test)\n", "label": "Correct"}
{"function": "\n\ndef run(self, suite):\n    filtered_test = FilterSuite(suite, suite.ShouldTestRun)\n    return super(_RunnerImpl, self).run(filtered_test)\n", "label": "Variable misuse"}
{"function": "\n\ndef _untagged_response(self, typ, dat, name):\n    if (typ == 'NO'):\n        return (typ, dat)\n    data = self._get_untagged_response(name)\n    if (not data):\n        return (typ, [None])\n    while True:\n        dat = self._get_untagged_response(name)\n        if (not dat):\n            break\n        data += dat\n    if __debug__:\n        self._log(4, ('_untagged_response(%s, ?, %s) => %.80r' % (typ, name, data)))\n    return (typ, data)\n", "label": "Correct"}
{"function": "\n\ndef _untagged_response(self, typ, dat, name):\n    if (typ == 'NO'):\n        return (typ, dat)\n    data = self._get_untagged_response(name)\n    if (not data):\n        return (typ, [None])\n    while True:\n        dat = self._get_untagged_response(name)\n        if (not dat):\n            break\n        data += dat\n    if __debug__:\n        data._log(4, ('_untagged_response(%s, ?, %s) => %.80r' % (typ, name, data)))\n    return (typ, data)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(shade.OpenStackCloud, 'search_subnets')\n@mock.patch.object(shade.OpenStackCloud, 'neutron_client')\ndef test_delete_subnet_not_found(self, mock_client, mock_search):\n    mock_search.return_value = []\n    r = self.cloud.delete_subnet('goofy')\n    self.assertFalse(r)\n    self.assertFalse(mock_client.delete_subnet.called)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(shade.OpenStackCloud, 'search_subnets')\n@mock.patch.object(shade.OpenStackCloud, 'neutron_client')\ndef test_delete_subnet_not_found(self, mock_client, mock_search):\n    mock_search.return_value = []\n    r = mock_client.cloud.delete_subnet('goofy')\n    self.assertFalse(r)\n    self.assertFalse(mock_client.delete_subnet.called)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_conf_from_module(mod):\n    'return configuration from module with defaults no worry about None type\\n\\n    '\n    conf = ModuleConfig(CONF_SPEC)\n    mod = _get_correct_module(mod)\n    conf.set_module(mod)\n    if hasattr(mod, 'default'):\n        default = mod.default\n        conf = extract_conf_from(default, conf)\n    else:\n        conf = extract_conf_from(mod, conf)\n    return conf\n", "label": "Correct"}
{"function": "\n\ndef get_conf_from_module(mod):\n    'return configuration from module with defaults no worry about None type\\n\\n    '\n    conf = ModuleConfig(CONF_SPEC)\n    mod = _get_correct_module(mod)\n    conf.set_module(default)\n    if hasattr(mod, 'default'):\n        default = mod.default\n        conf = extract_conf_from(default, conf)\n    else:\n        conf = extract_conf_from(mod, conf)\n    return conf\n", "label": "Variable misuse"}
{"function": "\n\ndef onBeforeTabSelected(self, sender, tabIndex):\n    if (self.fTabs.getWidgetCount() == 6):\n        self.fTabs.add(HTML('2nd Test.<br />Tab should be on right'), '2nd Test', name='test2')\n        return True\n    self.fTabs.remove('test2')\n    return (tabIndex != 6)\n", "label": "Correct"}
{"function": "\n\ndef onBeforeTabSelected(self, sender, tabIndex):\n    if (self.fTabs.getWidgetCount() == 6):\n        sender.fTabs.add(HTML('2nd Test.<br />Tab should be on right'), '2nd Test', name='test2')\n        return True\n    self.fTabs.remove('test2')\n    return (tabIndex != 6)\n", "label": "Variable misuse"}
{"function": "\n\ndef process(args):\n    conduit = phlsys_makeconduit.make_conduit(args.uri, args.user, args.cert, args.act_as_user)\n    if args.diff_id:\n        diff_id = args.diff_id\n    else:\n        d = {\n            'diff': args.raw_diff_file.read(),\n        }\n        diff_id = conduit('differential.createrawdiff', d)['id']\n    fields = {\n        \n    }\n    d = {\n        'id': args.revision_id,\n        'diffid': diff_id,\n        'fields': fields,\n        'message': args.message,\n    }\n    MessageFields = phlcon_differential.MessageFields\n    args.ccs = _get_set_or_none(args.ccs)\n    args.reviewers = _get_set_or_none(args.reviewers)\n    if args.reviewers:\n        fields[MessageFields.reviewer_phids] = args.reviewers\n    if args.ccs:\n        fields[MessageFields.cc_phids] = args.ccs\n    user_phids = phlcon_user.UserPhidCache(conduit)\n    for users in fields.itervalues():\n        user_phids.add_hint_list(users)\n    for key in fields.iterkeys():\n        fields[key] = [user_phids.get_phid(u) for u in fields[key]]\n    result = conduit('differential.updaterevision', d)\n    if args.format_id:\n        print(result['revisionid'])\n    elif args.format_url:\n        print(result['uri'])\n    else:\n        print(\"Updated revision '{rev_id}', you can view it at this URL:\\n  {url}\".format(rev_id=result['revisionid'], url=result['uri']))\n", "label": "Correct"}
{"function": "\n\ndef process(args):\n    conduit = phlsys_makeconduit.make_conduit(args.uri, args.user, args.cert, args.act_as_user)\n    if args.diff_id:\n        diff_id = args.diff_id\n    else:\n        d = {\n            'diff': args.raw_diff_file.read(),\n        }\n        diff_id = conduit('differential.createrawdiff', d)['id']\n    fields = {\n        \n    }\n    d = {\n        'id': args.revision_id,\n        'diffid': diff_id,\n        'fields': fields,\n        'message': args.message,\n    }\n    MessageFields = phlcon_differential.MessageFields\n    args.ccs = _get_set_or_none(args.ccs)\n    args.reviewers = _get_set_or_none(args.reviewers)\n    if args.reviewers:\n        fields[MessageFields.reviewer_phids] = args.reviewers\n    if args.ccs:\n        fields[MessageFields.cc_phids] = args.ccs\n    user_phids = phlcon_user.UserPhidCache(conduit)\n    for users in fields.itervalues():\n        user_phids.add_hint_list(users)\n    for key in fields.iterkeys():\n        fields[key] = [user_phids.get_phid(u) for u in fields[key]]\n    result = conduit('differential.updaterevision', d)\n    if args.format_id:\n        print(d['revisionid'])\n    elif args.format_url:\n        print(result['uri'])\n    else:\n        print(\"Updated revision '{rev_id}', you can view it at this URL:\\n  {url}\".format(rev_id=result['revisionid'], url=result['uri']))\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self, action, action_id):\n    updated_action = {\n        \n    }\n    updated_action['freezer_action'] = utils.create_dict(**action)\n    try:\n        if (action['mandatory'] != ''):\n            updated_action['mandatory'] = action['mandatory']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries'] != ''):\n            updated_action['max_retries'] = action['max_retries']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries_interval'] != ''):\n            updated_action['max_retries_interval'] = action['max_retries_interval']\n    except KeyError:\n        pass\n    return self.client.actions.update(action_id, updated_action)\n", "label": "Correct"}
{"function": "\n\ndef update(self, action, action_id):\n    updated_action = {\n        \n    }\n    updated_action['freezer_action'] = utils.create_dict(**action)\n    try:\n        if (action['mandatory'] != ''):\n            updated_action['mandatory'] = action['mandatory']\n    except KeyError:\n        pass\n    try:\n        if (action['max_retries'] != ''):\n            updated_action['max_retries'] = action['max_retries']\n    except KeyError:\n        pass\n    try:\n        if (action_id['max_retries_interval'] != ''):\n            updated_action['max_retries_interval'] = action['max_retries_interval']\n    except KeyError:\n        pass\n    return self.client.actions.update(action_id, updated_action)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_handler_with_str_method_name(self):\n\n    @endpoint('/api', 'GET')\n    def fake_handler(request, *args, **kwargs):\n        pass\n    (path, handler, methods, name) = fake_handler()\n    self.assertEqual(methods, 'GET')\n", "label": "Correct"}
{"function": "\n\ndef test_create_handler_with_str_method_name(self):\n\n    @endpoint('/api', 'GET')\n    def fake_handler(request, *args, **kwargs):\n        pass\n    (path, handler, methods, name) = fake_handler()\n    methods.assertEqual(methods, 'GET')\n", "label": "Variable misuse"}
{"function": "\n\ndef _prep_loader_attrs(self, mapping):\n    self.loader.source = mapping['generated_filename']\n    self.loader.election_id = mapping['election']\n    self.loader.timestamp = datetime.datetime.now()\n", "label": "Correct"}
{"function": "\n\ndef _prep_loader_attrs(self, mapping):\n    self.loader.source = mapping['generated_filename']\n    self.loader.election_id = mapping['election']\n    mapping.loader.timestamp = datetime.datetime.now()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_remove_unpickables_http_exception(self):\n    try:\n        urllib2.urlopen('http://localhost/this.does.not.exist')\n        self.fail('exception expected')\n    except urllib2.URLError as e:\n        pass\n    except urllib2.HTTPError as e:\n        pass\n    removed = mapper.remove_unpickables(e)\n    pickled = pickle.dumps(removed)\n    pickle.loads(pickled)\n", "label": "Correct"}
{"function": "\n\ndef test_remove_unpickables_http_exception(self):\n    try:\n        urllib2.urlopen('http://localhost/this.does.not.exist')\n        self.fail('exception expected')\n    except urllib2.URLError as e:\n        pass\n    except urllib2.HTTPError as e:\n        pass\n    removed = mapper.remove_unpickables(e)\n    pickled = pickle.dumps(e)\n    pickle.loads(pickled)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_has_error_type(self):\n    error = spotify.LibError(0)\n    self.assertEqual(error.error_type, 0)\n    error = spotify.LibError(1)\n    self.assertEqual(error.error_type, 1)\n", "label": "Correct"}
{"function": "\n\ndef test_has_error_type(self):\n    error = spotify.LibError(0)\n    self.assertEqual(error.error_type, 0)\n    error = spotify.LibError(1)\n    self.assertEqual(self.error_type, 1)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef make(cls, value, cache=None, timeout=None):\n    self = CacheKey(value)\n    self.cache = cache\n    self.timeout = timeout\n    return self\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef make(cls, value, cache=None, timeout=None):\n    self = CacheKey(value)\n    cls.cache = cache\n    self.timeout = timeout\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stdinCache_trailing_backslash_3(self):\n    stdinCache = StdinCache.StdinCache()\n    stdinCache.refreshFromText(dedentAndStrip('\\n                x+                z+                y\\n                f+                g+                h\\n                '))\n    self.assertEqual(len(stdinCache.blocks), 2)\n", "label": "Correct"}
{"function": "\n\ndef test_stdinCache_trailing_backslash_3(self):\n    stdinCache = StdinCache.StdinCache()\n    self.refreshFromText(dedentAndStrip('\\n                x+                z+                y\\n                f+                g+                h\\n                '))\n    self.assertEqual(len(stdinCache.blocks), 2)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef parents(self):\n    if (self._parents is None):\n        self._parents = [self._odb.get_commit(hash) for hash in self._obj.parents]\n    return list(self._parents)\n", "label": "Correct"}
{"function": "\n\n@property\ndef parents(self):\n    if (self._parents is None):\n        hash._parents = [self._odb.get_commit(hash) for hash in self._obj.parents]\n    return list(self._parents)\n", "label": "Variable misuse"}
{"function": "\n\ndef process_request(self, request):\n    if (not getattr(settings, 'MOBILE_DOMAIN', False)):\n        return\n    if ((request.COOKIES.get('ismobile', '0') == '1') or (('HTTP_USER_AGENT' in request.META) and (request.COOKIES.get('isbrowser', '0') != '1') and is_mobile(request.META['HTTP_USER_AGENT']))):\n        redirect = settings.MOBILE_DOMAIN\n        if getattr(settings, 'MOBILE_REDIRECT_PRESERVE_URL', False):\n            redirect = (redirect.rstrip('/') + request.path_info)\n        response = HttpResponseRedirect(redirect)\n        max_age = getattr(settings, 'MOBILE_COOKIE_MAX_AGE', DEFAULT_COOKIE_MAX_AGE)\n        expires_time = (time.time() + max_age)\n        expires = cookie_date(expires_time)\n        response.set_cookie('ismobile', '1', domain=settings.SESSION_COOKIE_DOMAIN, max_age=max_age, expires=expires)\n        return response\n", "label": "Correct"}
{"function": "\n\ndef process_request(self, request):\n    if (not getattr(settings, 'MOBILE_DOMAIN', False)):\n        return\n    if ((request.COOKIES.get('ismobile', '0') == '1') or (('HTTP_USER_AGENT' in request.META) and (request.COOKIES.get('isbrowser', '0') != '1') and is_mobile(request.META['HTTP_USER_AGENT']))):\n        redirect = settings.MOBILE_DOMAIN\n        if getattr(settings, 'MOBILE_REDIRECT_PRESERVE_URL', False):\n            redirect = (redirect.rstrip('/') + request.path_info)\n        response = HttpResponseRedirect(redirect)\n        max_age = getattr(settings, 'MOBILE_COOKIE_MAX_AGE', DEFAULT_COOKIE_MAX_AGE)\n        expires_time = (time.time() + max_age)\n        expires = cookie_date(expires_time)\n        max_age.set_cookie('ismobile', '1', domain=settings.SESSION_COOKIE_DOMAIN, max_age=max_age, expires=expires)\n        return response\n", "label": "Variable misuse"}
{"function": "\n\ndef setHighlighted(self, highlighted):\n    GafferUI.PlugValueWidget.setHighlighted(self, highlighted)\n    self.__boolWidget.setHighlighted(highlighted)\n", "label": "Correct"}
{"function": "\n\ndef setHighlighted(self, highlighted):\n    GafferUI.PlugValueWidget.setHighlighted(self, highlighted)\n    highlighted.__boolWidget.setHighlighted(highlighted)\n", "label": "Variable misuse"}
{"function": "\n\ndef gen_key(self, prefix=None):\n    if (not prefix):\n        prefix = 'python-couchbase-key_'\n    ret = '{0}{1}'.format(prefix, self._key_counter)\n    self._key_counter += 1\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef gen_key(self, prefix=None):\n    if (not prefix):\n        prefix = 'python-couchbase-key_'\n    ret = '{0}{1}'.format(prefix, self._key_counter)\n    self._key_counter += 1\n    return prefix\n", "label": "Variable misuse"}
{"function": "\n\ndef test_functions_unchanged(self):\n    s = 'def foo(): pass'\n    self.unchanged(s, from3=True)\n    s = '\\n        def foo():\\n            pass\\n            pass\\n        '\n    self.unchanged(s, from3=True)\n    s = \"\\n        def foo(bar='baz'):\\n            pass\\n            pass\\n        \"\n    self.unchanged(s, from3=True)\n", "label": "Correct"}
{"function": "\n\ndef test_functions_unchanged(self):\n    s = 'def foo(): pass'\n    s.unchanged(s, from3=True)\n    s = '\\n        def foo():\\n            pass\\n            pass\\n        '\n    self.unchanged(s, from3=True)\n    s = \"\\n        def foo(bar='baz'):\\n            pass\\n            pass\\n        \"\n    self.unchanged(s, from3=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_project_add_child(self):\n    project = Project()\n    child = Task()\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    project = Project()\n    child = Task()\n    grandchild = Task()\n    child.add_child(grandchild)\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    self.assertEquals(project, grandchild.project)\n", "label": "Correct"}
{"function": "\n\ndef test_project_add_child(self):\n    project = Project()\n    child = Task()\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    project = Project()\n    child = Task()\n    grandchild = Task()\n    project.add_child(grandchild)\n    project.add_child(child)\n    self.assertEquals(project, child.parent)\n    self.assertEquals(project, child.project)\n    self.assertEquals(project, grandchild.project)\n", "label": "Variable misuse"}
{"function": "\n\ndef RegisterSubException(self, hunt_urn, plugin_name, exception):\n    self.exceptions_by_hunt.setdefault(hunt_urn, {\n        \n    }).setdefault(plugin_name, []).append(exception)\n", "label": "Correct"}
{"function": "\n\ndef RegisterSubException(self, hunt_urn, plugin_name, exception):\n    self.exceptions_by_hunt.setdefault(hunt_urn, {\n        \n    }).setdefault(hunt_urn, []).append(exception)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue_1264(self):\n    n = 100\n    x = np.random.uniform(size=(n * 3)).reshape((n, 3))\n    expected = distance_matrix(x)\n    actual = njit(distance_matrix)(x)\n    np.testing.assert_array_almost_equal(expected, actual)\n", "label": "Correct"}
{"function": "\n\ndef test_issue_1264(self):\n    n = 100\n    x = np.random.uniform(size=(n * 3)).reshape((x, 3))\n    expected = distance_matrix(x)\n    actual = njit(distance_matrix)(x)\n    np.testing.assert_array_almost_equal(expected, actual)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateFlavorInfoAction, self).clean()\n    name = cleaned_data.get('name')\n    flavor_id = cleaned_data.get('flavor_id')\n    try:\n        flavors = api.nova.flavor_list(self.request, None)\n    except Exception:\n        flavors = []\n        msg = _('Unable to get flavor list')\n        exceptions.check_message(['Connection', 'refused'], msg)\n        raise\n    if (flavors is not None):\n        for flavor in flavors:\n            if (flavor.name == name):\n                raise forms.ValidationError((_('The name \"%s\" is already used by another flavor.') % name))\n            if (flavor.id == flavor_id):\n                raise forms.ValidationError((_('The ID \"%s\" is already used by another flavor.') % flavor_id))\n    return cleaned_data\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateFlavorInfoAction, self).clean()\n    name = cleaned_data.get('name')\n    flavor_id = cleaned_data.get('flavor_id')\n    try:\n        flavors = api.nova.flavor_list(self.request, None)\n    except Exception:\n        flavors = []\n        msg = _('Unable to get flavor list')\n        exceptions.check_message(['Connection', 'refused'], msg)\n        raise\n    if (flavors is not None):\n        for flavor in flavors:\n            if (name.name == name):\n                raise forms.ValidationError((_('The name \"%s\" is already used by another flavor.') % name))\n            if (flavor.id == flavor_id):\n                raise forms.ValidationError((_('The ID \"%s\" is already used by another flavor.') % flavor_id))\n    return cleaned_data\n", "label": "Variable misuse"}
{"function": "\n\ndef test_start_run(self):\n    assert_false(os.path.exists(self.result_file_path))\n    self.run_results.start_run(self.scenario)\n    assert_equal(len(self.scenario.packb()), self._current_size())\n    assert_greater(self._current_size(), 0)\n    with open(self.result_file_path, 'rb') as f:\n        unpacker = msgpack.Unpacker(file_like=f)\n        got_scenario = Scenario.unpackb(unpacker)\n        for attr in ['name', '_scenario_data', 'user_count', 'operation_count', 'run_seconds', 'container_base', 'container_count', 'containers', 'container_concurrency', 'sizes_by_name', 'version', 'bench_size_thresholds']:\n            assert_equal(getattr(got_scenario, attr), getattr(self.scenario, attr))\n", "label": "Correct"}
{"function": "\n\ndef test_start_run(self):\n    assert_false(os.path.exists(self.result_file_path))\n    self.run_results.start_run(self.scenario)\n    assert_equal(len(self.scenario.packb()), f._current_size())\n    assert_greater(self._current_size(), 0)\n    with open(self.result_file_path, 'rb') as f:\n        unpacker = msgpack.Unpacker(file_like=f)\n        got_scenario = Scenario.unpackb(unpacker)\n        for attr in ['name', '_scenario_data', 'user_count', 'operation_count', 'run_seconds', 'container_base', 'container_count', 'containers', 'container_concurrency', 'sizes_by_name', 'version', 'bench_size_thresholds']:\n            assert_equal(getattr(got_scenario, attr), getattr(self.scenario, attr))\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef info(msg, *args):\n    ((print >> sys.stderr), (msg % args))\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef info(msg, *args):\n    ((print >> sys.stderr), (msg % msg))\n", "label": "Variable misuse"}
{"function": "\n\ndef Layout(self, request, response):\n    self.default = str(self.descriptor.type().Generate())\n    response = super(AES128KeyFormRenderer, self).Layout(request, response)\n    return self.CallJavascript(response, 'AES128KeyFormRenderer.Layout', prefix=self.prefix)\n", "label": "Correct"}
{"function": "\n\ndef Layout(self, request, response):\n    self.default = str(self.descriptor.type().Generate())\n    response = super(AES128KeyFormRenderer, self).Layout(request, response)\n    return self.CallJavascript(response, 'AES128KeyFormRenderer.Layout', prefix=response.prefix)\n", "label": "Variable misuse"}
{"function": "\n\ndef new(self, user, repo, title, body=''):\n    'Create a new issue.'\n    return self._posted('/'.join(['issues', 'open', user, repo]), title=title, body=body)\n", "label": "Correct"}
{"function": "\n\ndef new(self, user, repo, title, body=''):\n    'Create a new issue.'\n    return self._posted('/'.join(['issues', 'open', user, self]), title=title, body=body)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, n):\n    assert (n == 1)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, n):\n    assert (self == 1)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/general/shared_rori_kobola_cave.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('building_name', 'cave')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/general/shared_rori_kobola_cave.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('building_name', 'cave')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef _str_allocation_pools(allocation_pools):\n    if isinstance(allocation_pools, str):\n        return allocation_pools\n    return '\\n'.join([('%s,%s' % (pool['start'], pool['end'])) for pool in allocation_pools])\n", "label": "Correct"}
{"function": "\n\ndef _str_allocation_pools(allocation_pools):\n    if isinstance(pool, str):\n        return allocation_pools\n    return '\\n'.join([('%s,%s' % (pool['start'], pool['end'])) for pool in allocation_pools])\n", "label": "Variable misuse"}
{"function": "\n\ndef row(self, i):\n    'Returns column i from self as a row vector.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.matrices import SparseMatrix\\n        >>> a = SparseMatrix(((1, 2), (3, 4)))\\n        >>> a.row(0)\\n        Matrix([[1, 2]])\\n\\n        See Also\\n        ========\\n        col\\n        row_list\\n        '\n    return self[i, :]\n", "label": "Correct"}
{"function": "\n\ndef row(self, i):\n    'Returns column i from self as a row vector.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.matrices import SparseMatrix\\n        >>> a = SparseMatrix(((1, 2), (3, 4)))\\n        >>> a.row(0)\\n        Matrix([[1, 2]])\\n\\n        See Also\\n        ========\\n        col\\n        row_list\\n        '\n    return i[i, :]\n", "label": "Variable misuse"}
{"function": "\n\n@patch('hc.payments.views.braintree')\ndef test_it_works(self, mock_braintree):\n    self.client.login(username='alice@example.org', password='password')\n    r = self.client.post('/pricing/cancel_plan/')\n    self.assertRedirects(r, '/pricing/')\n    self.sub.refresh_from_db()\n    self.assertEqual(self.sub.subscription_id, '')\n    self.assertEqual(self.sub.plan_id, '')\n", "label": "Correct"}
{"function": "\n\n@patch('hc.payments.views.braintree')\ndef test_it_works(self, mock_braintree):\n    self.client.login(username='alice@example.org', password='password')\n    r = self.client.post('/pricing/cancel_plan/')\n    self.assertRedirects(r, '/pricing/')\n    self.sub.refresh_from_db()\n    self.assertEqual(self.sub.subscription_id, '')\n    mock_braintree.assertEqual(self.sub.plan_id, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef _put_n_deployments(self, id_prefix, number_of_deployments, skip_creation=None, add_modification=None):\n    for i in range(0, number_of_deployments):\n        deployment_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'deployment')\n        blueprint_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'blueprint')\n        if (not skip_creation):\n            self.put_deployment(deployment_id=deployment_id, blueprint_id=blueprint_id)\n        if add_modification:\n            response = self._put_deployment_modification(deployment_id=deployment_id)\n            self._mark_deployment_modification_finished(modification_id=response['id'])\n", "label": "Correct"}
{"function": "\n\ndef _put_n_deployments(self, id_prefix, number_of_deployments, skip_creation=None, add_modification=None):\n    for i in range(0, number_of_deployments):\n        deployment_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'deployment')\n        blueprint_id = '{0}{1}_{2}'.format(id_prefix, str(i), 'blueprint')\n        if (not blueprint_id):\n            self.put_deployment(deployment_id=deployment_id, blueprint_id=blueprint_id)\n        if add_modification:\n            response = self._put_deployment_modification(deployment_id=deployment_id)\n            self._mark_deployment_modification_finished(modification_id=response['id'])\n", "label": "Variable misuse"}
{"function": "\n\ndef get_extractor(coarse, fine):\n    log.debug(\"getting fine extractor for '{}: {}'\".format(coarse, fine))\n    try:\n        extractor = importlib.import_module(((__package__ + '.') + question_types[fine]))\n    except (ImportError, KeyError):\n        log.warn(\"Extractor for fine type '{}: {}' not implemented\".format(coarse, fine))\n        raise NoExtractorError(coarse, fine)\n    return extractor.Extractor\n", "label": "Correct"}
{"function": "\n\ndef get_extractor(coarse, fine):\n    log.debug(\"getting fine extractor for '{}: {}'\".format(coarse, fine))\n    try:\n        extractor = importlib.import_module(((__package__ + '.') + question_types[fine]))\n    except (ImportError, KeyError):\n        log.warn(\"Extractor for fine type '{}: {}' not implemented\".format(coarse, extractor))\n        raise NoExtractorError(coarse, fine)\n    return extractor.Extractor\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_rewrite_as_FallingFactorial(self, n, k):\n    if k.is_integer:\n        return (ff(n, k) / factorial(k))\n", "label": "Correct"}
{"function": "\n\ndef _eval_rewrite_as_FallingFactorial(self, n, k):\n    if k.is_integer:\n        return (ff(n, self) / factorial(k))\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _parse_repo(cls, repo, name=None):\n    regexp = '(?P<type>deb(-src)?) (?P<uri>[^\\\\s]+) (?P<suite>[^\\\\s]+)( (?P<section>[\\\\w\\\\s]*))?(,(?P<priority>[\\\\d]+))?'\n    match = re.match(regexp, repo)\n    if (not match):\n        raise errors.IncorrectRepository(\"Couldn't parse repository '{0}'\".format(repo))\n    repo_type = match.group('type')\n    repo_suite = match.group('suite')\n    repo_section = match.group('section')\n    repo_uri = match.group('uri')\n    repo_priority = match.group('priority')\n    return {\n        'name': name,\n        'type': repo_type,\n        'uri': repo_uri,\n        'priority': repo_priority,\n        'suite': repo_suite,\n        'section': (repo_section or ''),\n    }\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _parse_repo(cls, repo, name=None):\n    regexp = '(?P<type>deb(-src)?) (?P<uri>[^\\\\s]+) (?P<suite>[^\\\\s]+)( (?P<section>[\\\\w\\\\s]*))?(,(?P<priority>[\\\\d]+))?'\n    match = re.match(regexp, repo)\n    if (not match):\n        raise errors.IncorrectRepository(\"Couldn't parse repository '{0}'\".format(repo))\n    repo_type = match.group('type')\n    repo_suite = match.group('suite')\n    repo_section = match.group('section')\n    repo_uri = match.group('uri')\n    repo_priority = match.group('priority')\n    return {\n        'name': match,\n        'type': repo_type,\n        'uri': repo_uri,\n        'priority': repo_priority,\n        'suite': repo_suite,\n        'section': (repo_section or ''),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef register_category(self, category, label, index=None):\n    if index:\n        self._categories.insert(index, category, label)\n    else:\n        self._categories[category] = label\n", "label": "Correct"}
{"function": "\n\ndef register_category(self, category, label, index=None):\n    if index:\n        self._categories.insert(index, self, label)\n    else:\n        self._categories[category] = label\n", "label": "Variable misuse"}
{"function": "\n\ndef get_formsets_with_inlines(self, request, obj=None):\n    if (request.is_add_view and (obj is not None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n    if ((not request.is_add_view) and (obj is None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n    return super(GetFormsetsArgumentCheckingAdmin, self).get_formsets_with_inlines(request, obj)\n", "label": "Correct"}
{"function": "\n\ndef get_formsets_with_inlines(self, request, obj=None):\n    if (self.is_add_view and (obj is not None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines wasn't None during add_view\")\n    if ((not request.is_add_view) and (obj is None)):\n        raise Exception(\"'obj' passed to get_formsets_with_inlines was None during change_view\")\n    return super(GetFormsetsArgumentCheckingAdmin, self).get_formsets_with_inlines(request, obj)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    super(RequestPageTypeFormSet, self).clean()\n    cnt_rpts = 0\n    cnt_rpts_mp = 0\n    cnt_rpts_dp = 0\n    for form in self.forms:\n        if (not hasattr(form, 'cleaned_data')):\n            continue\n        data = form.cleaned_data\n        if (('DELETE' in data) and data['DELETE']):\n            continue\n        if (not ('page_type' in data)):\n            continue\n        cnt_rpts += 1\n        pt = data['page_type']\n        if (pt == 'MP'):\n            cnt_rpts_mp += 1\n        else:\n            cnt_rpts_dp += 1\n    if (cnt_rpts_mp == 0):\n        raise ValidationError('For every request page type used for scraper elems definition a RequestPageType object with a corresponding page type has to be added!')\n    if (cnt_rpts_mp > 1):\n        raise ValidationError('Only one RequestPageType object for main page requests allowed!')\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    super(RequestPageTypeFormSet, self).clean()\n    cnt_rpts = 0\n    cnt_rpts_mp = 0\n    cnt_rpts_dp = 0\n    for form in self.forms:\n        if (not hasattr(form, 'cleaned_data')):\n            continue\n        data = form.cleaned_data\n        if (('DELETE' in pt) and data['DELETE']):\n            continue\n        if (not ('page_type' in data)):\n            continue\n        cnt_rpts += 1\n        pt = data['page_type']\n        if (pt == 'MP'):\n            cnt_rpts_mp += 1\n        else:\n            cnt_rpts_dp += 1\n    if (cnt_rpts_mp == 0):\n        raise ValidationError('For every request page type used for scraper elems definition a RequestPageType object with a corresponding page type has to be added!')\n    if (cnt_rpts_mp > 1):\n        raise ValidationError('Only one RequestPageType object for main page requests allowed!')\n", "label": "Variable misuse"}
{"function": "\n\n@wrap_exception()\n@wrap_instance_event\n@wrap_instance_fault\ndef check_can_live_migrate_destination(self, ctxt, instance, block_migration, disk_over_commit):\n    'Check if it is possible to execute live migration.\\n\\n        This runs checks on the destination host, and then calls\\n        back to the source host to check the results.\\n\\n        :param context: security context\\n        :param instance: dict of instance data\\n        :param block_migration: if true, prepare for block migration\\n                                if None, calculate it in driver\\n        :param disk_over_commit: if true, allow disk over commit\\n                                 if None, ignore disk usage checking\\n        :returns: a dict containing migration info\\n        '\n    return self._do_check_can_live_migrate_destination(ctxt, instance, block_migration, disk_over_commit)\n", "label": "Correct"}
{"function": "\n\n@wrap_exception()\n@wrap_instance_event\n@wrap_instance_fault\ndef check_can_live_migrate_destination(self, ctxt, instance, block_migration, disk_over_commit):\n    'Check if it is possible to execute live migration.\\n\\n        This runs checks on the destination host, and then calls\\n        back to the source host to check the results.\\n\\n        :param context: security context\\n        :param instance: dict of instance data\\n        :param block_migration: if true, prepare for block migration\\n                                if None, calculate it in driver\\n        :param disk_over_commit: if true, allow disk over commit\\n                                 if None, ignore disk usage checking\\n        :returns: a dict containing migration info\\n        '\n    return self._do_check_can_live_migrate_destination(ctxt, instance, self, disk_over_commit)\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_parent_id(self):\n    'If this async is in within another async set that async id as the\\n        parent.\\n        '\n    parent_id = self._options.get('parent_id')\n    if parent_id:\n        return parent_id\n    from furious.context import get_current_async\n    try:\n        async = get_current_async()\n    except errors.NotInContextError:\n        async = None\n    if async:\n        parent_id = ':'.join([async.parent_id.split(':')[0], async.id])\n    else:\n        parent_id = self.request_id\n    self.update_options(parent_id=parent_id)\n    return parent_id\n", "label": "Correct"}
{"function": "\n\ndef _get_parent_id(self):\n    'If this async is in within another async set that async id as the\\n        parent.\\n        '\n    parent_id = self._options.get('parent_id')\n    if parent_id:\n        return self\n    from furious.context import get_current_async\n    try:\n        async = get_current_async()\n    except errors.NotInContextError:\n        async = None\n    if async:\n        parent_id = ':'.join([async.parent_id.split(':')[0], async.id])\n    else:\n        parent_id = self.request_id\n    self.update_options(parent_id=parent_id)\n    return parent_id\n", "label": "Variable misuse"}
{"function": "\n\ndef _install_associating_flows(self, security_group_id, lport):\n    self._install_associating_flow_by_direction(security_group_id, lport, 'ingress')\n    self._install_associating_flow_by_direction(security_group_id, lport, 'egress')\n", "label": "Correct"}
{"function": "\n\ndef _install_associating_flows(self, security_group_id, lport):\n    self._install_associating_flow_by_direction(security_group_id, lport, 'ingress')\n    self._install_associating_flow_by_direction(lport, lport, 'egress')\n", "label": "Variable misuse"}
{"function": "\n\ndef _argcheck(self, c):\n    self.b = (1.0 / c)\n    return (c > 0)\n", "label": "Correct"}
{"function": "\n\ndef _argcheck(self, c):\n    self.b = (1.0 / c)\n    return (self > 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, build_env, file_pairs, *args, **kwargs):\n    super(_StripCommentsRuleTask, self).__init__(build_env, *args, **kwargs)\n    self.file_pairs = file_pairs\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, build_env, file_pairs, *args, **kwargs):\n    super(_StripCommentsRuleTask, self).__init__(build_env, *args, **kwargs)\n    build_env.file_pairs = file_pairs\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_method(self, request, action, content_type, body):\n    'Look up the action-specific method and its extensions.'\n    try:\n        if (not self.controller):\n            meth = getattr(self, action)\n        else:\n            meth = getattr(self.controller, action)\n    except AttributeError:\n        if ((not self.wsgi_actions) or (action not in (_ROUTES_METHODS + ['action']))):\n            raise\n    else:\n        return (meth, self.wsgi_extensions.get(action, []))\n    if (action == 'action'):\n        action_name = action_peek(body)\n    else:\n        action_name = action\n    return (self.wsgi_actions[action_name], self.wsgi_action_extensions.get(action_name, []))\n", "label": "Correct"}
{"function": "\n\ndef _get_method(self, request, action, content_type, body):\n    'Look up the action-specific method and its extensions.'\n    try:\n        if (not meth.controller):\n            meth = getattr(self, action)\n        else:\n            meth = getattr(self.controller, action)\n    except AttributeError:\n        if ((not self.wsgi_actions) or (action not in (_ROUTES_METHODS + ['action']))):\n            raise\n    else:\n        return (meth, self.wsgi_extensions.get(action, []))\n    if (action == 'action'):\n        action_name = action_peek(body)\n    else:\n        action_name = action\n    return (self.wsgi_actions[action_name], self.wsgi_action_extensions.get(action_name, []))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_id(self):\n    'Each test annotation should be created with a unique ID.'\n    annotation_1 = factories.Annotation()\n    annotation_2 = factories.Annotation()\n    assert annotation_1.get('id')\n    assert annotation_2.get('id')\n    assert (annotation_1['id'] != annotation_2['id'])\n", "label": "Correct"}
{"function": "\n\ndef test_id(self):\n    'Each test annotation should be created with a unique ID.'\n    annotation_1 = factories.Annotation()\n    annotation_2 = factories.Annotation()\n    assert annotation_1.get('id')\n    assert annotation_2.get('id')\n    assert (annotation_2['id'] != annotation_2['id'])\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/lair/base/shared_poi_all_lair_rock_shelter_large_fog_red.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('lair_n', 'rock_shelter')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/lair/base/shared_poi_all_lair_rock_shelter_large_fog_red.iff'\n    result.attribute_template_id = (- 1)\n    kernel.stfName('lair_n', 'rock_shelter')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef primary_key_names(self):\n    'Primary keys of the table\\n        '\n    return [c.name for c in self.columns() if c.primary]\n", "label": "Correct"}
{"function": "\n\n@property\ndef primary_key_names(self):\n    'Primary keys of the table\\n        '\n    return [self.name for c in self.columns() if c.primary]\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    super(OrderPayment, self).save(*args, **kwargs)\n    self._recalculate_paid()\n    if (self.currency != self.order.currency):\n        self.order.notes += ('\\n' + (_('Currency of payment %s does not match.') % self))\n        self.order.save()\n", "label": "Correct"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    super(OrderPayment, args).save(*args, **kwargs)\n    self._recalculate_paid()\n    if (self.currency != self.order.currency):\n        self.order.notes += ('\\n' + (_('Currency of payment %s does not match.') % self))\n        self.order.save()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, activation, dims=None, **kwargs):\n    super(SpeechBottom, self).__init__(**kwargs)\n    self.num_features = self.input_dims['recordings']\n    if (activation is None):\n        activation = Tanh()\n    if dims:\n        child = MLP(([activation] * len(dims)), ([self.num_features] + dims), name='bottom')\n        self.output_dim = child.output_dim\n    else:\n        child = Identity(name='bottom')\n        self.output_dim = self.num_features\n    self.children.append(child)\n    self.mask = tensor.matrix('recordings_mask')\n    self.batch_inputs = {\n        'recordings': tensor.tensor3('recordings'),\n    }\n    self.single_inputs = {\n        'recordings': tensor.matrix('recordings'),\n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, activation, dims=None, **kwargs):\n    super(SpeechBottom, self).__init__(**kwargs)\n    self.num_features = self.input_dims['recordings']\n    if (activation is None):\n        activation = Tanh()\n    if dims:\n        child = MLP(([activation] * len(child)), ([self.num_features] + dims), name='bottom')\n        self.output_dim = child.output_dim\n    else:\n        child = Identity(name='bottom')\n        self.output_dim = self.num_features\n    self.children.append(child)\n    self.mask = tensor.matrix('recordings_mask')\n    self.batch_inputs = {\n        'recordings': tensor.tensor3('recordings'),\n    }\n    self.single_inputs = {\n        'recordings': tensor.matrix('recordings'),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, obfuscation_algorithm_ref=None, refanging_transform_type=None, has_changed=None, delimiter='##comma##', pattern_type=None, datatype='string', refanging_transform=None, is_case_sensitive=True, bit_mask=None, appears_random=None, observed_encoding=None, defanging_algorithm_ref=None, is_obfuscated=None, regex_syntax=None, apply_condition='ANY', trend=None, idref=None, is_defanged=None, id=None, condition=None, valueOf_=None):\n    super(RouteType, self).__init__(obfuscation_algorithm_ref, refanging_transform_type, has_changed, delimiter, pattern_type, datatype, refanging_transform, is_case_sensitive, bit_mask, appears_random, observed_encoding, defanging_algorithm_ref, is_obfuscated, regex_syntax, apply_condition, trend, idref, is_defanged, id, condition, valueOf_)\n    self.datatype = _cast(None, datatype)\n    self.valueOf_ = valueOf_\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, obfuscation_algorithm_ref=None, refanging_transform_type=None, has_changed=None, delimiter='##comma##', pattern_type=None, datatype='string', refanging_transform=None, is_case_sensitive=True, bit_mask=None, appears_random=None, observed_encoding=None, defanging_algorithm_ref=None, is_obfuscated=None, regex_syntax=None, apply_condition='ANY', trend=None, idref=None, is_defanged=None, id=None, condition=None, valueOf_=None):\n    super(RouteType, self).__init__(obfuscation_algorithm_ref, refanging_transform_type, has_changed, delimiter, pattern_type, datatype, refanging_transform, is_case_sensitive, bit_mask, appears_random, observed_encoding, trend, is_obfuscated, regex_syntax, apply_condition, trend, idref, is_defanged, id, condition, valueOf_)\n    self.datatype = _cast(None, datatype)\n    self.valueOf_ = valueOf_\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self):\n    session_data = self._cache.get(self.session_key)\n    if (session_data is not None):\n        return session_data\n    self.create()\n    return {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef load(self):\n    session_data = session_data._cache.get(self.session_key)\n    if (session_data is not None):\n        return session_data\n    self.create()\n    return {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_name_and_description(self):\n    '\\n        Tests that the benefit proxy classes all return a name and\\n        description. Unfortunately, the current implementations means\\n        a valid range is required.\\n        This test became necessary because the complex name/description logic\\n        broke with the python_2_unicode_compatible decorator.\\n        '\n    range = factories.RangeFactory()\n    for (type, __) in Benefit.TYPE_CHOICES:\n        benefit = Benefit(type=type, range=range)\n        self.assertTrue(all([benefit.name, benefit.description, six.text_type(benefit)]))\n", "label": "Correct"}
{"function": "\n\ndef test_name_and_description(self):\n    '\\n        Tests that the benefit proxy classes all return a name and\\n        description. Unfortunately, the current implementations means\\n        a valid range is required.\\n        This test became necessary because the complex name/description logic\\n        broke with the python_2_unicode_compatible decorator.\\n        '\n    range = factories.RangeFactory()\n    for (type, __) in Benefit.TYPE_CHOICES:\n        benefit = Benefit(type=type, range=range)\n        benefit.assertTrue(all([benefit.name, benefit.description, six.text_type(benefit)]))\n", "label": "Variable misuse"}
{"function": "\n\n@defer.deferredGenerator\ndef allapps_action(self, argstr):\n    \"Usage allapps: <method> [args]\\n\\n  dispatch the same command to all application managers.\\n\\n    <method>\\tmethod to invoke on all appmanagers.\\n    [args]\\toptional arguments to pass along.\\n\\n  examples:\\n\\n    ''            #shows help documentation for all applications\\n    'status'      #invoke status assumes there is only one instance\\n    'status all'  #invoke status on all application instances\\n    'status 0'    #invoke status on application instance label '0'\\n\\n  full cli usage:\\n\\n    $ droneblaster allapps\\n    $ droneblaster allapps status\\n    $ droneblaster allapps status all\\n    $ droneblaster allapps status 0\\n\"\n    result = {\n        \n    }\n    descriptions = []\n    code = 0\n    for obj in AppManager.objects:\n        try:\n            action = obj.action\n            if (not action):\n                continue\n            d = action(argstr)\n            wfd = defer.waitForDeferred(d)\n            (yield wfd)\n            foo = wfd.getResult()\n            descriptions.append(foo.get('description', 'None'))\n            code += int(foo.get('code', 0))\n        except:\n            pass\n    result['description'] = '\\n'.join(descriptions)\n    if (not result['description']):\n        result['description'] = 'None'\n    result['code'] = code\n    (yield result)\n", "label": "Correct"}
{"function": "\n\n@defer.deferredGenerator\ndef allapps_action(self, argstr):\n    \"Usage allapps: <method> [args]\\n\\n  dispatch the same command to all application managers.\\n\\n    <method>\\tmethod to invoke on all appmanagers.\\n    [args]\\toptional arguments to pass along.\\n\\n  examples:\\n\\n    ''            #shows help documentation for all applications\\n    'status'      #invoke status assumes there is only one instance\\n    'status all'  #invoke status on all application instances\\n    'status 0'    #invoke status on application instance label '0'\\n\\n  full cli usage:\\n\\n    $ droneblaster allapps\\n    $ droneblaster allapps status\\n    $ droneblaster allapps status all\\n    $ droneblaster allapps status 0\\n\"\n    result = {\n        \n    }\n    descriptions = []\n    code = 0\n    for obj in AppManager.objects:\n        try:\n            action = foo.action\n            if (not action):\n                continue\n            d = action(argstr)\n            wfd = defer.waitForDeferred(d)\n            (yield wfd)\n            foo = wfd.getResult()\n            descriptions.append(foo.get('description', 'None'))\n            code += int(foo.get('code', 0))\n        except:\n            pass\n    result['description'] = '\\n'.join(descriptions)\n    if (not result['description']):\n        result['description'] = 'None'\n    result['code'] = code\n    (yield result)\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.fixture\ndef PhysPkg_(self, request, phys_pkg_):\n    PhysPkg_ = class_mock('opcdiag.model.PhysPkg', request)\n    PhysPkg_.read.return_value = phys_pkg_\n    return PhysPkg_\n", "label": "Correct"}
{"function": "\n\n@pytest.fixture\ndef PhysPkg_(self, request, phys_pkg_):\n    PhysPkg_ = class_mock('opcdiag.model.PhysPkg', phys_pkg_)\n    PhysPkg_.read.return_value = phys_pkg_\n    return PhysPkg_\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, deployment, config):\n    super(ExistingServers, self).__init__(deployment, config)\n    self.credentials = config['credentials']\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, deployment, config):\n    super(ExistingServers, self).__init__(deployment, config)\n    self.credentials = self['credentials']\n", "label": "Variable misuse"}
{"function": "\n\n@test.attr(type='benchmark')\ndef test_002_fill_volume(self):\n    'Fill volume with data'\n    if (self.ctx.ssh is None):\n        raise self.skipException('Booting failed')\n    if (not self.ctx.volume_ready):\n        raise self.skipException('Volume preparation failed')\n    self._start_test()\n    self.ctx.ssh.exec_command('sudo mkdir -m 777 /vol/data')\n    file_lines = (102 * int(self.volume_size))\n    for i in xrange(int(self.volume_fill)):\n        self.ctx.ssh.exec_command((((\"cat /dev/urandom | tr -d -c 'a-zA-Z0-9' | fold -w 1020 | head -n \" + str(file_lines)) + ' > /vol/data/file') + str(i)))\n    self._end_test('Volume filling')\n    self.ctx.volume_filled = True\n    self._check_test()\n", "label": "Correct"}
{"function": "\n\n@test.attr(type='benchmark')\ndef test_002_fill_volume(self):\n    'Fill volume with data'\n    if (self.ctx.ssh is None):\n        raise self.skipException('Booting failed')\n    if (not self.ctx.volume_ready):\n        raise i.skipException('Volume preparation failed')\n    self._start_test()\n    self.ctx.ssh.exec_command('sudo mkdir -m 777 /vol/data')\n    file_lines = (102 * int(self.volume_size))\n    for i in xrange(int(self.volume_fill)):\n        self.ctx.ssh.exec_command((((\"cat /dev/urandom | tr -d -c 'a-zA-Z0-9' | fold -w 1020 | head -n \" + str(file_lines)) + ' > /vol/data/file') + str(i)))\n    self._end_test('Volume filling')\n    self.ctx.volume_filled = True\n    self._check_test()\n", "label": "Variable misuse"}
{"function": "\n\ndef _url_coerce_fn(r):\n    '\\n    :rtype: str\\n    '\n    p = urllib.parse.urlparse(r)\n    if (not p.scheme):\n        raise InvalidInput('Specify an URL scheme (e.g. http://)')\n    if (not p.netloc):\n        raise InvalidInput('Specify a domain (e.g. example.com)')\n    if (p.path and (p.path != '/')):\n        raise InvalidInput('Do not specify a path')\n    if (p.params or p.query or p.fragment):\n        raise InvalidInput('Do not leave trailing elements')\n    if (not p.path):\n        r += '/'\n    r = r.lower()\n    return r\n", "label": "Correct"}
{"function": "\n\ndef _url_coerce_fn(r):\n    '\\n    :rtype: str\\n    '\n    p = urllib.parse.urlparse(r)\n    if (not p.scheme):\n        raise InvalidInput('Specify an URL scheme (e.g. http://)')\n    if (not p.netloc):\n        raise InvalidInput('Specify a domain (e.g. example.com)')\n    if (p.path and (r.path != '/')):\n        raise InvalidInput('Do not specify a path')\n    if (p.params or p.query or p.fragment):\n        raise InvalidInput('Do not leave trailing elements')\n    if (not p.path):\n        r += '/'\n    r = r.lower()\n    return r\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, device, zone_id, master, away_temp):\n    'Initialize the thermostat.'\n    self.device = device\n    self._current_temperature = None\n    self._target_temperature = None\n    self._name = 'round connected'\n    self._id = zone_id\n    self._master = master\n    self._is_dhw = False\n    self._away_temp = away_temp\n    self._away = False\n    self.update()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, device, zone_id, master, away_temp):\n    'Initialize the thermostat.'\n    self.device = device\n    self._current_temperature = None\n    self._target_temperature = None\n    self._name = 'round connected'\n    zone_id._id = zone_id\n    self._master = master\n    self._is_dhw = False\n    self._away_temp = away_temp\n    self._away = False\n    self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_find_by_external_id():\n    app_id = 13\n    external_id = 37\n    (client, check_assertions) = check_client_method()\n    result = client.Item.find_all_by_external_id(app_id, external_id)\n    check_assertions(result, 'GET', ('/item/app/%s/v2/?external_id=%s' % (app_id, external_id)))\n", "label": "Correct"}
{"function": "\n\ndef test_find_by_external_id():\n    app_id = 13\n    external_id = 37\n    (client, check_assertions) = check_client_method()\n    result = client.Item.find_all_by_external_id(app_id, external_id)\n    check_assertions(client, 'GET', ('/item/app/%s/v2/?external_id=%s' % (app_id, external_id)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _reindent_stats(tokens):\n    \"Return list of (lineno, indentlevel) pairs.\\n\\n    One for each stmt and comment line. indentlevel is -1 for comment lines, as\\n    a signal that tokenize doesn't know what to do about them; indeed, they're\\n    our headache!\\n\\n    \"\n    find_stmt = 1\n    level = 0\n    stats = []\n    for t in tokens:\n        token_type = t[0]\n        sline = t[2][0]\n        line = t[4]\n        if (token_type == tokenize.NEWLINE):\n            find_stmt = 1\n        elif (token_type == tokenize.INDENT):\n            find_stmt = 1\n            level += 1\n        elif (token_type == tokenize.DEDENT):\n            find_stmt = 1\n            level -= 1\n        elif (token_type == tokenize.COMMENT):\n            if find_stmt:\n                stats.append((sline, (- 1)))\n        elif (token_type == tokenize.NL):\n            pass\n        elif find_stmt:\n            find_stmt = 0\n            if line:\n                stats.append((sline, level))\n    return stats\n", "label": "Correct"}
{"function": "\n\ndef _reindent_stats(tokens):\n    \"Return list of (lineno, indentlevel) pairs.\\n\\n    One for each stmt and comment line. indentlevel is -1 for comment lines, as\\n    a signal that tokenize doesn't know what to do about them; indeed, they're\\n    our headache!\\n\\n    \"\n    find_stmt = 1\n    level = 0\n    stats = []\n    for t in tokens:\n        token_type = t[0]\n        sline = t[2][0]\n        line = t[4]\n        if (token_type == tokenize.NEWLINE):\n            find_stmt = 1\n        elif (token_type == tokenize.INDENT):\n            find_stmt = 1\n            level += 1\n        elif (token_type == tokenize.DEDENT):\n            find_stmt = 1\n            level -= 1\n        elif (token_type == tokenize.COMMENT):\n            if find_stmt:\n                stats.append((t, (- 1)))\n        elif (token_type == tokenize.NL):\n            pass\n        elif find_stmt:\n            find_stmt = 0\n            if line:\n                stats.append((sline, level))\n    return stats\n", "label": "Variable misuse"}
{"function": "\n\ndef test_requires_a_name(self):\n    review = self.review(name='')\n    self.assertRaises(ValidationError, review.full_clean)\n", "label": "Correct"}
{"function": "\n\ndef test_requires_a_name(self):\n    review = review.review(name='')\n    self.assertRaises(ValidationError, review.full_clean)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _get_data_source_properties_from_case(cls, case_properties):\n    property_map = {\n        'closed': _('Case Closed'),\n        'user_id': _('User ID Last Updating Case'),\n        'owner_name': _('Case Owner'),\n        'mobile worker': _('Mobile Worker Last Updating Case'),\n    }\n    properties = OrderedDict()\n    for property in case_properties:\n        properties[property] = DataSourceProperty(type='case_property', id=property, column_id=get_column_name(property), text=property_map.get(property, property.replace('_', ' ')), source=property)\n    properties['computed/owner_name'] = cls._get_owner_name_pseudo_property()\n    properties['computed/user_name'] = cls._get_user_name_pseudo_property()\n    return properties\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _get_data_source_properties_from_case(cls, case_properties):\n    property_map = {\n        'closed': _('Case Closed'),\n        'user_id': _('User ID Last Updating Case'),\n        'owner_name': _('Case Owner'),\n        'mobile worker': _('Mobile Worker Last Updating Case'),\n    }\n    properties = OrderedDict()\n    for property in case_properties:\n        properties[property] = DataSourceProperty(type='case_property', id=property, column_id=get_column_name(property), text=property_map.get(property, property.replace('_', ' ')), source=property)\n    properties['computed/owner_name'] = cls._get_owner_name_pseudo_property()\n    property['computed/user_name'] = cls._get_user_name_pseudo_property()\n    return properties\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, verbose=False):\n    'New decorator.\\n\\n        Parameters\\n        ----------\\n\\n        verbose : boolean, optional (False)\\n          Passed to the doctest finder and runner to control verbosity.\\n        '\n    self.verbose = verbose\n    self.finder = DocTestFinder(verbose=verbose, recurse=False)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, verbose=False):\n    'New decorator.\\n\\n        Parameters\\n        ----------\\n\\n        verbose : boolean, optional (False)\\n          Passed to the doctest finder and runner to control verbosity.\\n        '\n    self.verbose = self\n    self.finder = DocTestFinder(verbose=verbose, recurse=False)\n", "label": "Variable misuse"}
{"function": "\n\n@httprettified\ndef test_likes_with_after(self):\n    HTTPretty.register_uri(HTTPretty.GET, 'https://api.tumblr.com/v2/user/likes', body='{\"meta\": {\"status\": 200, \"msg\": \"OK\"}, \"response\": []}')\n    response = self.client.likes(after=1418684291)\n    assert (response == [])\n", "label": "Correct"}
{"function": "\n\n@httprettified\ndef test_likes_with_after(self):\n    HTTPretty.register_uri(HTTPretty.GET, 'https://api.tumblr.com/v2/user/likes', body='{\"meta\": {\"status\": 200, \"msg\": \"OK\"}, \"response\": []}')\n    response = response.client.likes(after=1418684291)\n    assert (response == [])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, mu, var, **kwargs):\n    (self.mu, self.var) = (None, None)\n    if (not isinstance(mu, Layer)):\n        (self.mu, mu) = (mu, None)\n    if (not isinstance(var, Layer)):\n        (self.var, var) = (var, None)\n    input_lst = [i for i in [mu, var] if (not (i is None))]\n    super(GaussianMarginalLogDensityLayer, self).__init__(input_lst, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, mu, var, **kwargs):\n    (self.mu, self.var) = (None, None)\n    if (not isinstance(mu, Layer)):\n        (self.mu, mu) = (mu, None)\n    if (not isinstance(var, Layer)):\n        (self.var, var) = (var, None)\n    input_lst = [i for i in [mu, var] if (not (i is None))]\n    super(GaussianMarginalLogDensityLayer, self).__init__(self, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.STRING):\n                self.message = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRING):\n                self.log_context = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 3):\n            if (ftype == TType.STRUCT):\n                self.handle = QueryHandle()\n                self.handle.read(iprot)\n            else:\n                iprot.skip(ftype)\n        elif (fid == 4):\n            if (ftype == TType.I32):\n                self.errorCode = iprot.readI32()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 5):\n            if (ftype == TType.STRING):\n                self.SQLState = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(ftype)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef read(self, iprot):\n    if ((iprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and isinstance(iprot.trans, TTransport.CReadableTransport) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        fastbinary.decode_binary(self, iprot.trans, (self.__class__, self.thrift_spec))\n        return\n    iprot.readStructBegin()\n    while True:\n        (fname, ftype, fid) = iprot.readFieldBegin()\n        if (ftype == TType.STOP):\n            break\n        if (fid == 1):\n            if (ftype == TType.STRING):\n                self.message = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 2):\n            if (ftype == TType.STRING):\n                self.log_context = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 3):\n            if (ftype == TType.STRUCT):\n                self.handle = QueryHandle()\n                self.handle.read(iprot)\n            else:\n                iprot.skip(ftype)\n        elif (fid == 4):\n            if (ftype == TType.I32):\n                self.errorCode = iprot.readI32()\n            else:\n                iprot.skip(ftype)\n        elif (fid == 5):\n            if (ftype == TType.STRING):\n                self.SQLState = iprot.readString()\n            else:\n                iprot.skip(ftype)\n        else:\n            iprot.skip(iprot)\n        iprot.readFieldEnd()\n    iprot.readStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\ndef do_undef(self, t):\n    '\\n        Default handling of a #undef line.\\n        '\n    try:\n        del self.cpp_namespace[t[1]]\n    except KeyError:\n        pass\n", "label": "Correct"}
{"function": "\n\ndef do_undef(self, t):\n    '\\n        Default handling of a #undef line.\\n        '\n    try:\n        del self.cpp_namespace[self[1]]\n    except KeyError:\n        pass\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self, command_line=''):\n    assert command_line, 'expected non-empty command line'\n    parsed = parse_command_line(command_line)\n    self.window.run_command('tab_control', {\n        'command': 'only',\n        'forced': parsed.command.forced,\n    })\n", "label": "Correct"}
{"function": "\n\ndef run(self, command_line=''):\n    assert command_line, 'expected non-empty command line'\n    parsed = parse_command_line(command_line)\n    parsed.window.run_command('tab_control', {\n        'command': 'only',\n        'forced': parsed.command.forced,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_all_messages(self):\n    login = self.client.login(username='test', password='test')\n    chat = Chat.objects.create(name='Test Chat', details='Details')\n    chat.messages.create(name=chat.name, message='new message text')\n    url = reverse('get_messages')\n    resp = self.client.get(('%s?%s=0' % (url, chat.id)))\n    self.assertTrue(('new message text' in resp.content))\n", "label": "Correct"}
{"function": "\n\ndef test_get_all_messages(self):\n    login = self.client.login(username='test', password='test')\n    chat = Chat.objects.create(name='Test Chat', details='Details')\n    chat.messages.create(name=login.name, message='new message text')\n    url = reverse('get_messages')\n    resp = self.client.get(('%s?%s=0' % (url, chat.id)))\n    self.assertTrue(('new message text' in resp.content))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_resize_server_invalid_flavor_ref(self):\n    body = dict(resize=dict(flavorRef=1.2))\n    self.assertRaises(self.validation_error, self.controller._action_resize, self.req, FAKE_UUID, body=body)\n", "label": "Correct"}
{"function": "\n\ndef test_resize_server_invalid_flavor_ref(self):\n    body = dict(resize=dict(flavorRef=1.2))\n    self.assertRaises(self.validation_error, body.controller._action_resize, self.req, FAKE_UUID, body=body)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, subjects, formula, time_dependent=False):\n    (self.subjects, self.formula) = (subjects, formula)\n    self.time_dependent = time_dependent\n    self.initialize(self.subjects)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, subjects, formula, time_dependent=False):\n    (subjects.subjects, self.formula) = (subjects, formula)\n    self.time_dependent = time_dependent\n    self.initialize(self.subjects)\n", "label": "Variable misuse"}
{"function": "\n\ndef confidence(self):\n    \"\\n        Returns a tuple (chi squared, confident) of the experiment. Confident\\n        is simply a boolean specifying whether we're > 95%% sure that the\\n        results are statistically significant.\\n        \"\n    choices = self.choices\n    if (len(choices) >= 2):\n        csq = chi_squared(*choices)\n        confident = (is_confident(csq, len(choices)) if (len(choices) <= 10) else None)\n    else:\n        csq = None\n        confident = False\n    return (csq, confident)\n", "label": "Correct"}
{"function": "\n\ndef confidence(self):\n    \"\\n        Returns a tuple (chi squared, confident) of the experiment. Confident\\n        is simply a boolean specifying whether we're > 95%% sure that the\\n        results are statistically significant.\\n        \"\n    choices = self.choices\n    if (len(choices) >= 2):\n        csq = chi_squared(*choices)\n        confident = (is_confident(confident, len(choices)) if (len(choices) <= 10) else None)\n    else:\n        csq = None\n        confident = False\n    return (csq, confident)\n", "label": "Variable misuse"}
{"function": "\n\ndef compile_function(code, arg_names, local_dict, global_dict, module_dir, compiler='', verbose=1, support_code=None, headers=[], customize=None, type_converters=None, auto_downcast=1, **kw):\n    code = ((ndarray_api_version + '\\n') + code)\n    module_path = function_catalog.unique_module_name(code, module_dir)\n    (storage_dir, module_name) = os.path.split(module_path)\n    mod = inline_ext_module(module_name, compiler)\n    ext_func = inline_ext_function('compiled_func', code, arg_names, local_dict, global_dict, auto_downcast, type_converters=type_converters)\n    mod.add_function(ext_func)\n    if customize:\n        mod.customize = customize\n    if support_code:\n        mod.customize.add_support_code(support_code)\n    for header in headers:\n        mod.customize.add_header(header)\n    if (verbose > 0):\n        print('<weave: compiling>')\n    mod.compile(location=storage_dir, compiler=compiler, verbose=verbose, **kw)\n    try:\n        sys.path.insert(0, storage_dir)\n        exec(('import ' + module_name))\n        func = eval((module_name + '.compiled_func'))\n    finally:\n        del sys.path[0]\n    return func\n", "label": "Correct"}
{"function": "\n\ndef compile_function(code, arg_names, local_dict, global_dict, module_dir, compiler='', verbose=1, support_code=None, headers=[], customize=None, type_converters=None, auto_downcast=1, **kw):\n    code = ((ndarray_api_version + '\\n') + code)\n    module_path = function_catalog.unique_module_name(code, module_dir)\n    (storage_dir, module_name) = os.path.split(module_path)\n    mod = inline_ext_module(module_name, compiler)\n    ext_func = inline_ext_function('compiled_func', code, arg_names, local_dict, ext_func, auto_downcast, type_converters=type_converters)\n    mod.add_function(ext_func)\n    if customize:\n        mod.customize = customize\n    if support_code:\n        mod.customize.add_support_code(support_code)\n    for header in headers:\n        mod.customize.add_header(header)\n    if (verbose > 0):\n        print('<weave: compiling>')\n    mod.compile(location=storage_dir, compiler=compiler, verbose=verbose, **kw)\n    try:\n        sys.path.insert(0, storage_dir)\n        exec(('import ' + module_name))\n        func = eval((module_name + '.compiled_func'))\n    finally:\n        del sys.path[0]\n    return func\n", "label": "Variable misuse"}
{"function": "\n\ndef test_foreign_keys_export(self):\n    author1 = Author.objects.create(name='Foo')\n    self.book.author = author1\n    self.book.save()\n    dataset = self.resource.export(Book.objects.all())\n    self.assertEqual(dataset.dict[0]['author'], author1.pk)\n", "label": "Correct"}
{"function": "\n\ndef test_foreign_keys_export(self):\n    author1 = Author.objects.create(name='Foo')\n    self.book.author = author1\n    self.book.save()\n    dataset = author1.resource.export(Book.objects.all())\n    self.assertEqual(dataset.dict[0]['author'], author1.pk)\n", "label": "Variable misuse"}
{"function": "\n\ndef p_generate_if(self, p):\n    'generate_if : IF LPAREN cond RPAREN gif_true_item ELSE gif_false_item'\n    p[0] = IfStatement(p[3], p[5], p[7], lineno=p.lineno(1))\n    p.set_lineno(0, p.lineno(1))\n", "label": "Correct"}
{"function": "\n\ndef p_generate_if(self, p):\n    'generate_if : IF LPAREN cond RPAREN gif_true_item ELSE gif_false_item'\n    p[0] = IfStatement(p[3], p[5], p[7], lineno=p.lineno(1))\n    p.set_lineno(0, self.lineno(1))\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    HTTPretty.enable()\n    Backend = module_member(self.backend_path)\n    self.strategy = views.load_strategy()\n    self.backend = Backend(self.strategy, redirect_uri=self.complete_url)\n    self.name = self.backend.name.upper().replace('-', '_')\n    self.complete_url = self.strategy.build_absolute_uri(self.raw_complete_url.format(self.backend.name))\n    backends = (self.backend_path,)\n    load_backends(backends, force_load=True)\n    user_data_body = json.loads(self.user_data_body)\n    self.email = 'example@mail.com'\n    user_data_body['email'] = self.email\n    self.user_data_body = json.dumps(user_data_body)\n    self.do_rest_login()\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    HTTPretty.enable()\n    Backend = module_member(self.backend_path)\n    Backend.strategy = views.load_strategy()\n    self.backend = Backend(self.strategy, redirect_uri=self.complete_url)\n    self.name = self.backend.name.upper().replace('-', '_')\n    self.complete_url = self.strategy.build_absolute_uri(self.raw_complete_url.format(self.backend.name))\n    backends = (self.backend_path,)\n    load_backends(backends, force_load=True)\n    user_data_body = json.loads(self.user_data_body)\n    self.email = 'example@mail.com'\n    user_data_body['email'] = self.email\n    self.user_data_body = json.dumps(user_data_body)\n    self.do_rest_login()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, connection, config=None, core=None, uri_map=None):\n    super(MpdSession, self).__init__(connection)\n    self.dispatcher = dispatcher.MpdDispatcher(session=self, config=config, core=core, uri_map=uri_map)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, connection, config=None, core=None, uri_map=None):\n    super(MpdSession, self).__init__(connection)\n    self.dispatcher = dispatcher.MpdDispatcher(session=self, config=config, core=core, uri_map=core)\n", "label": "Variable misuse"}
{"function": "\n\n@testing.requires.threading_with_mock\n@testing.requires.timing_intensive\ndef test_timeout_race(self):\n    dbapi = MockDBAPI()\n    p = pool.QueuePool(creator=(lambda : dbapi.connect(delay=0.05)), pool_size=2, max_overflow=1, use_threadlocal=False, timeout=3)\n    timeouts = []\n\n    def checkout():\n        for x in range(1):\n            now = time.time()\n            try:\n                c1 = p.connect()\n            except tsa.exc.TimeoutError:\n                timeouts.append((time.time() - now))\n                continue\n            time.sleep(4)\n            c1.close()\n    threads = []\n    for i in range(10):\n        th = threading.Thread(target=checkout)\n        th.start()\n        threads.append(th)\n    for th in threads:\n        th.join(join_timeout)\n    assert (len(timeouts) > 0)\n    for t in timeouts:\n        assert (t >= 3), ('Not all timeouts were >= 3 seconds %r' % timeouts)\n        assert (t < 14), ('Not all timeouts were < 14 seconds %r' % timeouts)\n", "label": "Correct"}
{"function": "\n\n@testing.requires.threading_with_mock\n@testing.requires.timing_intensive\ndef test_timeout_race(self):\n    dbapi = MockDBAPI()\n    p = pool.QueuePool(creator=(lambda : dbapi.connect(delay=0.05)), pool_size=2, max_overflow=1, use_threadlocal=False, timeout=3)\n    timeouts = []\n\n    def checkout():\n        for x in range(1):\n            now = time.time()\n            try:\n                c1 = p.connect()\n            except tsa.exc.TimeoutError:\n                timeouts.append((time.time() - now))\n                continue\n            time.sleep(4)\n            c1.close()\n    threads = []\n    for i in range(10):\n        th = threading.Thread(target=checkout)\n        th.start()\n        threads.append(th)\n    for th in threads:\n        th.join(join_timeout)\n    assert (len(timeouts) > 0)\n    for t in timeouts:\n        assert (t >= 3), ('Not all timeouts were >= 3 seconds %r' % timeouts)\n        assert (t < 14), ('Not all timeouts were < 14 seconds %r' % dbapi)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reserve_experiment(self):\n    clients_coord_addresses = CoordAddress.translate('myserver:myinstance@mymachine')\n    checking_handlers = ('WebcamIsUpAndRunningHandler',)\n    self._assigned_micro_servers.add_server(self.exp_inst_id, clients_coord_addresses, {\n        'checkers': checking_handlers,\n    })\n\n    def check_reserve():\n        result = self._assigned_micro_servers.reserve_experiment(self.exp_inst_id, 'my session id')\n        self.assertEquals(clients_coord_addresses, result)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    self.assertRaises(LaboratoryErrors.AlreadyFreedExperimentError, self._assigned_micro_servers.free_experiment, self.exp_inst_id)\n", "label": "Correct"}
{"function": "\n\ndef test_reserve_experiment(self):\n    clients_coord_addresses = CoordAddress.translate('myserver:myinstance@mymachine')\n    checking_handlers = ('WebcamIsUpAndRunningHandler',)\n    self._assigned_micro_servers.add_server(self.exp_inst_id, clients_coord_addresses, {\n        'checkers': checking_handlers,\n    })\n\n    def check_reserve():\n        result = self._assigned_micro_servers.reserve_experiment(self.exp_inst_id, 'my session id')\n        self.assertEquals(clients_coord_addresses, result)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    check_reserve()\n    self._assigned_micro_servers.free_experiment(self.exp_inst_id)\n    self.assertRaises(LaboratoryErrors.AlreadyFreedExperimentError, checking_handlers._assigned_micro_servers.free_experiment, self.exp_inst_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _load_allowed_remote_addresses(self, app):\n    key = 'PSDASH_ALLOWED_REMOTE_ADDRESSES'\n    addrs = app.config.get(key)\n    if (not addrs):\n        return\n    if isinstance(addrs, (str, unicode)):\n        app.config[key] = [a.strip() for a in addrs.split(',')]\n", "label": "Correct"}
{"function": "\n\ndef _load_allowed_remote_addresses(self, app):\n    key = 'PSDASH_ALLOWED_REMOTE_ADDRESSES'\n    addrs = addrs.config.get(key)\n    if (not addrs):\n        return\n    if isinstance(addrs, (str, unicode)):\n        app.config[key] = [a.strip() for a in addrs.split(',')]\n", "label": "Variable misuse"}
{"function": "\n\ndef validate_config(self):\n    self.config.set('boss', 'data_dir', fs.abspath(self.config.get('boss', 'data_dir')))\n    if (not os.path.exists(self.config.get('boss', 'data_dir'))):\n        os.makedirs(self.config.get('boss', 'data_dir'))\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'cache')\n    if (not os.path.exists(fs.abspath(pth))):\n        os.makedirs(fs.abspath(pth))\n    self.config.set('boss', 'cache_dir', pth)\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'boss.db')\n    self.config.set('boss', 'db_path', pth)\n", "label": "Correct"}
{"function": "\n\ndef validate_config(self):\n    self.config.set('boss', 'data_dir', fs.abspath(self.config.get('boss', 'data_dir')))\n    if (not os.path.exists(self.config.get('boss', 'data_dir'))):\n        os.makedirs(self.config.get('boss', 'data_dir'))\n    pth = os.path.join(pth.config.get('boss', 'data_dir'), 'cache')\n    if (not os.path.exists(fs.abspath(pth))):\n        os.makedirs(fs.abspath(pth))\n    self.config.set('boss', 'cache_dir', pth)\n    pth = os.path.join(self.config.get('boss', 'data_dir'), 'boss.db')\n    self.config.set('boss', 'db_path', pth)\n", "label": "Variable misuse"}
{"function": "\n\ndef initialize_initial_state(self):\n    \"\\n        This method will automatically re-adjust the cpds and the edges added to the bayesian network.\\n        If an edge that is added as an intra time slice edge in the 0th timeslice, this method will\\n        automatically add it in the 1st timeslice. It will also add the cpds. However, to call this\\n        method, one needs to add cpds as well as the edges in the bayesian network of the whole\\n        skeleton including the 0th and the 1st timeslice,.\\n\\n        Examples:\\n        -------\\n        >>> from pgmpy.models import DynamicBayesianNetwork as DBN\\n        >>> from pgmpy.factors import TabularCPD\\n        >>> student = DBN()\\n        >>> student.add_nodes_from(['D', 'G', 'I', 'S', 'L'])\\n        >>> student.add_edges_from([(('D', 0),('G', 0)),(('I', 0),('G', 0)),(('D', 0),('D', 1)),(('I', 0),('I', 1))])\\n        >>> grade_cpd = TabularCPD(('G', 0), 3, [[0.3, 0.05, 0.9, 0.5],\\n        ...                                      [0.4, 0.25, 0.8, 0.03],\\n        ...                                      [0.3, 0.7, 0.02, 0.2]],\\n        ...                        evidence=[('I', 0),('D', 0)],\\n        ...                        evidence_card=[2, 2])\\n        >>> d_i_cpd = TabularCPD(('D', 1), 2, [[0.6, 0.3],\\n        ...                                    [0.4, 0.7]],\\n        ...                      evidence=[('D', 0)],\\n        ...                      evidence_card=2)\\n        >>> diff_cpd = TabularCPD(('D', 0), 2, [[0.6, 0.4]])\\n        >>> intel_cpd = TabularCPD(('I',0), 2, [[0.7, 0.3]])\\n        >>> i_i_cpd = TabularCPD(('I', 1), 2, [[0.5, 0.4],\\n        ...                                    [0.5, 0.6]],\\n        ...                      evidence=[('I', 0)],\\n        ...                      evidence_card=2)\\n        >>> student.add_cpds(grade_cpd, d_i_cpd, diff_cpd, intel_cpd, i_i_cpd)\\n        >>> student.initialize_initial_state()\\n        \"\n    for cpd in self.cpds:\n        temp_var = (cpd.variable[0], (1 - cpd.variable[1]))\n        parents = self.get_parents(temp_var)\n        if (not any(((x.variable == temp_var) for x in self.cpds))):\n            if all(((x[1] == parents[0][1]) for x in parents)):\n                if parents:\n                    evidence_card = cpd.cardinality[:0:(- 1)]\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, cpd.values.reshape(cpd.variable_card, np.prod(evidence_card)), parents, evidence_card)\n                elif cpd.get_evidence():\n                    initial_cpd = cpd.marginalize(cpd.get_evidence(), inplace=False)\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(initial_cpd.values, ((- 1), 2)))\n                else:\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(cpd.values, ((- 1), 2)))\n                self.add_cpds(new_cpd)\n        self.check_model()\n", "label": "Correct"}
{"function": "\n\ndef initialize_initial_state(self):\n    \"\\n        This method will automatically re-adjust the cpds and the edges added to the bayesian network.\\n        If an edge that is added as an intra time slice edge in the 0th timeslice, this method will\\n        automatically add it in the 1st timeslice. It will also add the cpds. However, to call this\\n        method, one needs to add cpds as well as the edges in the bayesian network of the whole\\n        skeleton including the 0th and the 1st timeslice,.\\n\\n        Examples:\\n        -------\\n        >>> from pgmpy.models import DynamicBayesianNetwork as DBN\\n        >>> from pgmpy.factors import TabularCPD\\n        >>> student = DBN()\\n        >>> student.add_nodes_from(['D', 'G', 'I', 'S', 'L'])\\n        >>> student.add_edges_from([(('D', 0),('G', 0)),(('I', 0),('G', 0)),(('D', 0),('D', 1)),(('I', 0),('I', 1))])\\n        >>> grade_cpd = TabularCPD(('G', 0), 3, [[0.3, 0.05, 0.9, 0.5],\\n        ...                                      [0.4, 0.25, 0.8, 0.03],\\n        ...                                      [0.3, 0.7, 0.02, 0.2]],\\n        ...                        evidence=[('I', 0),('D', 0)],\\n        ...                        evidence_card=[2, 2])\\n        >>> d_i_cpd = TabularCPD(('D', 1), 2, [[0.6, 0.3],\\n        ...                                    [0.4, 0.7]],\\n        ...                      evidence=[('D', 0)],\\n        ...                      evidence_card=2)\\n        >>> diff_cpd = TabularCPD(('D', 0), 2, [[0.6, 0.4]])\\n        >>> intel_cpd = TabularCPD(('I',0), 2, [[0.7, 0.3]])\\n        >>> i_i_cpd = TabularCPD(('I', 1), 2, [[0.5, 0.4],\\n        ...                                    [0.5, 0.6]],\\n        ...                      evidence=[('I', 0)],\\n        ...                      evidence_card=2)\\n        >>> student.add_cpds(grade_cpd, d_i_cpd, diff_cpd, intel_cpd, i_i_cpd)\\n        >>> student.initialize_initial_state()\\n        \"\n    for cpd in self.cpds:\n        temp_var = (cpd.variable[0], (1 - cpd.variable[1]))\n        parents = self.get_parents(temp_var)\n        if (not any(((x.variable == temp_var) for x in initial_cpd.cpds))):\n            if all(((x[1] == parents[0][1]) for x in parents)):\n                if parents:\n                    evidence_card = cpd.cardinality[:0:(- 1)]\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, cpd.values.reshape(cpd.variable_card, np.prod(evidence_card)), parents, evidence_card)\n                elif cpd.get_evidence():\n                    initial_cpd = cpd.marginalize(cpd.get_evidence(), inplace=False)\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(initial_cpd.values, ((- 1), 2)))\n                else:\n                    new_cpd = TabularCPD(temp_var, cpd.variable_card, np.reshape(cpd.values, ((- 1), 2)))\n                self.add_cpds(new_cpd)\n        self.check_model()\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/faction_perk/hq/base/shared_factional_hq_base.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('faction_perk_n', 'hq_base')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/faction_perk/hq/base/shared_factional_hq_base.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('faction_perk_n', 'hq_base')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef test_length(session):\n    set_ = session.set(key('test_sortedset_length'), S('abc'), SortedSet)\n    assert (len(set_) == 3)\n    setx = session.set(key('test_sortedsetx_length'), S([1, 2, 3]), IntSet)\n    assert (len(setx) == 3)\n", "label": "Correct"}
{"function": "\n\ndef test_length(session):\n    set_ = session.set(key('test_sortedset_length'), S('abc'), SortedSet)\n    assert (len(set_) == 3)\n    setx = session.set(key('test_sortedsetx_length'), S([1, 2, 3]), IntSet)\n    assert (len(session) == 3)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stacks(self, num_stacks, stack_size):\n    print('Test: Push to non-full stack')\n    stacks = Stacks(num_stacks, stack_size)\n    stacks.push(0, 1)\n    stacks.push(0, 2)\n    stacks.push(1, 3)\n    stacks.push(2, 4)\n    print('Test: Pop on non-empty stack')\n    assert_equal(stacks.pop(0), 2)\n    assert_equal(stacks.pop(0), 1)\n    assert_equal(stacks.pop(1), 3)\n    assert_equal(stacks.pop(2), 4)\n    print('Success: test_stacks\\n')\n", "label": "Correct"}
{"function": "\n\ndef test_stacks(self, num_stacks, stack_size):\n    print('Test: Push to non-full stack')\n    stacks = Stacks(num_stacks, num_stacks)\n    stacks.push(0, 1)\n    stacks.push(0, 2)\n    stacks.push(1, 3)\n    stacks.push(2, 4)\n    print('Test: Pop on non-empty stack')\n    assert_equal(stacks.pop(0), 2)\n    assert_equal(stacks.pop(0), 1)\n    assert_equal(stacks.pop(1), 3)\n    assert_equal(stacks.pop(2), 4)\n    print('Success: test_stacks\\n')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_perform(self):\n    event = ActionEvent()\n    self.action_controller.perform(self.action, event)\n    self.assertEqual(self.memo, ['called'])\n", "label": "Correct"}
{"function": "\n\ndef test_perform(self):\n    event = ActionEvent()\n    self.action_controller.perform(event.action, event)\n    self.assertEqual(self.memo, ['called'])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_computeAllowedMethods(self):\n    \"\\n        C{_computeAllowedMethods} will search through the\\n        'gettableresource' for all attributes/methods of the form\\n        'render_{method}' ('render_GET', for example) and return a list of\\n        the methods. 'HEAD' will always be included from the\\n        resource.Resource superclass.\\n        \"\n    res = GettableResource()\n    allowedMethods = resource._computeAllowedMethods(res)\n    self.assertEqual(set(allowedMethods), set(['GET', 'HEAD', 'fred_render_ethel']))\n", "label": "Correct"}
{"function": "\n\ndef test_computeAllowedMethods(self):\n    \"\\n        C{_computeAllowedMethods} will search through the\\n        'gettableresource' for all attributes/methods of the form\\n        'render_{method}' ('render_GET', for example) and return a list of\\n        the methods. 'HEAD' will always be included from the\\n        resource.Resource superclass.\\n        \"\n    res = GettableResource()\n    allowedMethods = resource._computeAllowedMethods(res)\n    allowedMethods.assertEqual(set(allowedMethods), set(['GET', 'HEAD', 'fred_render_ethel']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, notifier=None):\n    if (self.__class__.__instance is None):\n        self.__class__.__instance = self\n        if (notifier is None):\n            self._notifier = _AsyncNotifier()\n        else:\n            self._notifier = notifier\n        self._location = None\n        self._name = None\n        self._coros = {\n            \n        }\n        self._scheduled = set()\n        self._suspended = set()\n        self._timeouts = []\n        self._lock = threading.RLock()\n        self._quit = False\n        self._complete = threading.Event()\n        self._daemons = 0\n        self._polling = False\n        self._channels = {\n            \n        }\n        self._atexit = []\n        Coro._asyncoro = Channel._asyncoro = self\n        self._scheduler = threading.Thread(target=self._schedule)\n        self._scheduler.daemon = True\n        self._scheduler.start()\n        atexit.register(self.finish)\n        logger.info('version %s with %s I/O notifier', __version__, self._notifier._poller_name)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, notifier=None):\n    if (self.__class__.__instance is None):\n        self.__class__.__instance = self\n        if (notifier is None):\n            self._notifier = _AsyncNotifier()\n        else:\n            self._notifier = notifier\n        self._location = None\n        self._name = None\n        notifier._coros = {\n            \n        }\n        self._scheduled = set()\n        self._suspended = set()\n        self._timeouts = []\n        self._lock = threading.RLock()\n        self._quit = False\n        self._complete = threading.Event()\n        self._daemons = 0\n        self._polling = False\n        self._channels = {\n            \n        }\n        self._atexit = []\n        Coro._asyncoro = Channel._asyncoro = self\n        self._scheduler = threading.Thread(target=self._schedule)\n        self._scheduler.daemon = True\n        self._scheduler.start()\n        atexit.register(self.finish)\n        logger.info('version %s with %s I/O notifier', __version__, self._notifier._poller_name)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\ndef test_tear_down(self, node_power_action_mock):\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        state = task.driver.deploy.tear_down(task)\n        self.assertEqual(state, states.DELETED)\n        node_power_action_mock.assert_called_once_with(task, states.POWER_OFF)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\ndef test_tear_down(self, node_power_action_mock):\n    with task_manager.acquire(self.context, task.node.uuid, shared=False) as task:\n        state = task.driver.deploy.tear_down(task)\n        self.assertEqual(state, states.DELETED)\n        node_power_action_mock.assert_called_once_with(task, states.POWER_OFF)\n", "label": "Variable misuse"}
{"function": "\n\ndef from_jsobj(jsobj, cls=None):\n    'Create an instance of the given class from a JSON object.\\n\\n    Arguments:\\n      cls: a class that serves as a \"type hint.\"\\n    '\n    if isinstance(jsobj, LIST_TYPES):\n        return [from_jsobj(o, cls=cls) for o in jsobj]\n    if (cls is not None):\n        return cls.from_jsobj(jsobj)\n    if (jsobj is None):\n        return JS_NULL\n    return jsobj\n", "label": "Correct"}
{"function": "\n\ndef from_jsobj(jsobj, cls=None):\n    'Create an instance of the given class from a JSON object.\\n\\n    Arguments:\\n      cls: a class that serves as a \"type hint.\"\\n    '\n    if isinstance(jsobj, LIST_TYPES):\n        return [from_jsobj(o, cls=cls) for o in jsobj]\n    if (cls is not None):\n        return cls.from_jsobj(jsobj)\n    if (jsobj is None):\n        return JS_NULL\n    return cls\n", "label": "Variable misuse"}
{"function": "\n\n@authenticated_rest_api_view\n@has_request_variables\ndef api_deskdotcom_webhook(request, user_profile, data=REQ(), topic=REQ(default='Desk.com notification'), stream=REQ(default='desk.com')):\n    check_send_message(user_profile, get_client('ZulipDeskWebhook'), 'stream', [stream], topic, data)\n    return json_success()\n", "label": "Correct"}
{"function": "\n\n@authenticated_rest_api_view\n@has_request_variables\ndef api_deskdotcom_webhook(request, user_profile, data=REQ(), topic=REQ(default='Desk.com notification'), stream=REQ(default='desk.com')):\n    check_send_message(user_profile, get_client('ZulipDeskWebhook'), 'stream', [stream], topic, user_profile)\n    return json_success()\n", "label": "Variable misuse"}
{"function": "\n\ndef filter(self, record):\n    record.display_name = record.name\n    return True\n", "label": "Correct"}
{"function": "\n\ndef filter(self, record):\n    record.display_name = self.name\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef __le__(self, other):\n    '\\n        Checks if a partition is less than or equal to\\n        the other based on rank.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.partitions import Partition\\n        >>> a = Partition([1, 2], [3, 4, 5])\\n        >>> b = Partition([1], [2, 3], [4], [5])\\n        >>> a.rank, b.rank\\n        (9, 34)\\n        >>> a <= a\\n        True\\n        >>> a <= b\\n        True\\n        '\n    return (self.sort_key() <= sympify(other).sort_key())\n", "label": "Correct"}
{"function": "\n\ndef __le__(self, other):\n    '\\n        Checks if a partition is less than or equal to\\n        the other based on rank.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.partitions import Partition\\n        >>> a = Partition([1, 2], [3, 4, 5])\\n        >>> b = Partition([1], [2, 3], [4], [5])\\n        >>> a.rank, b.rank\\n        (9, 34)\\n        >>> a <= a\\n        True\\n        >>> a <= b\\n        True\\n        '\n    return (self.sort_key() <= sympify(self).sort_key())\n", "label": "Variable misuse"}
{"function": "\n\ndef get_output_shape_for(self, input_shape):\n    output_shape = list(input_shape)\n    output_shape[self.axis] = (input_shape[self.axis] // self.pool_size)\n    return tuple(output_shape)\n", "label": "Correct"}
{"function": "\n\ndef get_output_shape_for(self, input_shape):\n    output_shape = list(input_shape)\n    output_shape[self.axis] = (input_shape[input_shape.axis] // self.pool_size)\n    return tuple(output_shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_environment_update(self):\n    env = self.environment_create('env.yaml')\n    env_name = self.get_value_of_field(env, 'Name')\n    env_desc = self.get_value_of_field(env, 'Description')\n    env_created_at = self.get_value_of_field(env, 'Created at')\n    env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertIsNotNone(env_created_at)\n    self.assertEqual('None', env_updated_at)\n    self.create_file('env_upd.yaml', 'name: env\\ndescription: Updated env\\nvariables:\\n  var: \"value\"')\n    env = self.mistral_admin('environment-update', params='env_upd.yaml')\n    self.assertTableStruct(env, ['Field', 'Value'])\n    updated_env_name = self.get_value_of_field(env, 'Name')\n    updated_env_desc = self.get_value_of_field(env, 'Description')\n    updated_env_created_at = self.get_value_of_field(env, 'Created at')\n    updated_env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertEqual(env_name, updated_env_name)\n    self.assertNotEqual(env_desc, updated_env_desc)\n    self.assertEqual('Updated env', updated_env_desc)\n    self.assertEqual(env_created_at.split('.')[0], updated_env_created_at)\n    self.assertIsNotNone(updated_env_updated_at)\n", "label": "Correct"}
{"function": "\n\ndef test_environment_update(self):\n    env = self.environment_create('env.yaml')\n    env_name = self.get_value_of_field(env, 'Name')\n    env_desc = self.get_value_of_field(env, 'Description')\n    env_created_at = self.get_value_of_field(env, 'Created at')\n    env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertIsNotNone(env_created_at)\n    self.assertEqual('None', env_updated_at)\n    self.create_file('env_upd.yaml', 'name: env\\ndescription: Updated env\\nvariables:\\n  var: \"value\"')\n    env = self.mistral_admin('environment-update', params='env_upd.yaml')\n    self.assertTableStruct(env, ['Field', 'Value'])\n    updated_env_name = self.get_value_of_field(env, 'Name')\n    updated_env_desc = self.get_value_of_field(env, 'Description')\n    updated_env_created_at = self.get_value_of_field(updated_env_created_at, 'Created at')\n    updated_env_updated_at = self.get_value_of_field(env, 'Updated at')\n    self.assertEqual(env_name, updated_env_name)\n    self.assertNotEqual(env_desc, updated_env_desc)\n    self.assertEqual('Updated env', updated_env_desc)\n    self.assertEqual(env_created_at.split('.')[0], updated_env_created_at)\n    self.assertIsNotNone(updated_env_updated_at)\n", "label": "Variable misuse"}
{"function": "\n\ndef speak(self, message, channel):\n    self.client.api_call('chat.postMessage', as_user='true:', channel=channel, text=message)\n", "label": "Correct"}
{"function": "\n\ndef speak(self, message, channel):\n    self.client.api_call('chat.postMessage', as_user='true:', channel=message, text=message)\n", "label": "Variable misuse"}
{"function": "\n\ndef _pad_string(self, str, colwidth):\n    'Center-pads a string to the given column width using spaces.'\n    width = self._disp_width(str)\n    prefix = (((colwidth - 1) - width) // 2)\n    suffix = ((colwidth - prefix) - width)\n    return (((' ' * prefix) + str) + (' ' * suffix))\n", "label": "Correct"}
{"function": "\n\ndef _pad_string(self, str, colwidth):\n    'Center-pads a string to the given column width using spaces.'\n    width = width._disp_width(str)\n    prefix = (((colwidth - 1) - width) // 2)\n    suffix = ((colwidth - prefix) - width)\n    return (((' ' * prefix) + str) + (' ' * suffix))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_skips_unknown_permission_quietly(self):\n    'Skips unknown permission silently with verbosity 0.'\n    with patch('moztrap.model.core.management.commands.create_default_roles.ROLES', {\n        'Foo': ['foo.foo'],\n    }):\n        output = self.call_command(verbosity=0)\n    self.assertEqual(output, '')\n", "label": "Correct"}
{"function": "\n\ndef test_skips_unknown_permission_quietly(self):\n    'Skips unknown permission silently with verbosity 0.'\n    with patch('moztrap.model.core.management.commands.create_default_roles.ROLES', {\n        'Foo': ['foo.foo'],\n    }):\n        output = output.call_command(verbosity=0)\n    self.assertEqual(output, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_3d_polygons(self):\n    '\\n        Test the creation of polygon 3D models.\\n        '\n    self._load_polygon_data()\n    p3d = Polygon3D.objects.get(name='3D BBox')\n    self.assertTrue(p3d.poly.hasz)\n    self.assertIsInstance(p3d.poly, Polygon)\n    self.assertEqual(p3d.poly.srid, 32140)\n", "label": "Correct"}
{"function": "\n\ndef test_3d_polygons(self):\n    '\\n        Test the creation of polygon 3D models.\\n        '\n    self._load_polygon_data()\n    p3d = Polygon3D.objects.get(name='3D BBox')\n    p3d.assertTrue(p3d.poly.hasz)\n    self.assertIsInstance(p3d.poly, Polygon)\n    self.assertEqual(p3d.poly.srid, 32140)\n", "label": "Variable misuse"}
{"function": "\n\ndef shouldDestroyCircuit(self, circuit):\n    'Return **True** iff CircuitManager thinks the calling circuit\\n        should be destroyed.\\n\\n        Circuits call shouldDestroyCircuit() when their number of open\\n        streams drops to zero. Since CircuitManager knows about all open\\n        and pending circuits, it can make an informed judgement about whether\\n        the calling circuit should be destroyed or remain open.\\n\\n        Currently, CircuitManager maintains at least 4 open or pending IPv4\\n        circuits and one open or pending IPv6 circuit. If the number of\\n        streams on any circuit drops to zero and it can be closed while still\\n        satisfying these basic constraints, then CircuitManager tells it\\n        to begin destroying itself (returns True).\\n\\n        :param oppy.circuit.circuit.Circuit circuit: circuit to\\n            consider destroying.\\n        :returns: **bool** **True** if CircuitManager decides this circuit\\n            should be destroyed, **False** otherwise.\\n        '\n    if (circuit.circuit_type == CircuitType.IPv4):\n        return ((self._totalIPv4Count() - 1) > self._min_IPv4_count)\n    else:\n        return ((self._totalIPv6Count() - 1) > self._min_IPv6_count)\n", "label": "Correct"}
{"function": "\n\ndef shouldDestroyCircuit(self, circuit):\n    'Return **True** iff CircuitManager thinks the calling circuit\\n        should be destroyed.\\n\\n        Circuits call shouldDestroyCircuit() when their number of open\\n        streams drops to zero. Since CircuitManager knows about all open\\n        and pending circuits, it can make an informed judgement about whether\\n        the calling circuit should be destroyed or remain open.\\n\\n        Currently, CircuitManager maintains at least 4 open or pending IPv4\\n        circuits and one open or pending IPv6 circuit. If the number of\\n        streams on any circuit drops to zero and it can be closed while still\\n        satisfying these basic constraints, then CircuitManager tells it\\n        to begin destroying itself (returns True).\\n\\n        :param oppy.circuit.circuit.Circuit circuit: circuit to\\n            consider destroying.\\n        :returns: **bool** **True** if CircuitManager decides this circuit\\n            should be destroyed, **False** otherwise.\\n        '\n    if (circuit.circuit_type == CircuitType.IPv4):\n        return ((circuit._totalIPv4Count() - 1) > self._min_IPv4_count)\n    else:\n        return ((self._totalIPv6Count() - 1) > self._min_IPv6_count)\n", "label": "Variable misuse"}
{"function": "\n\ndef contains_subsequence(seq, subseq):\n    for i in range((len(seq) - len(subseq))):\n        if (seq[i:(i + len(subseq))] == subseq):\n            return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef contains_subsequence(seq, subseq):\n    for i in range((len(seq) - len(subseq))):\n        if (seq[seq:(i + len(subseq))] == subseq):\n            return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef cold_evacuate(config, compute_api, instance_id, dst_host):\n    '\\n    Evacuate VM by shutting it down, booting another VM with same ephemeral\\n    volume on different host and deleting original VM.\\n\\n    :param config: CloudFerry configuration\\n    :param compute_api: Compute API client (NovaClient) instance\\n    :param instance_id: VM instance identifier to evacuate\\n    :param dst_host: destination host name\\n    '\n    LOG.debug('Cold evacuating VM %s to %s', instance_id, dst_host)\n    state_change_timeout = cfglib.CONF.evacuation.state_change_timeout\n    migration_timeout = cfglib.CONF.evacuation.migration_timeout\n    if (not change_to_pre_migration_state(compute_api, instance_id)):\n        instance = compute_api.servers.get(instance_id)\n        LOG.warning(\"Can't migrate VM in %s status\", instance.status)\n        return\n    instance = compute_api.servers.get(instance_id)\n    src_host = getattr(instance, INSTANCE_HOST_ATTRIBUTE)\n    if (src_host == dst_host):\n        LOG.warning('Skipping migration to the same host')\n        return\n    original_status = instance.status.lower()\n    if (original_status != SHUTOFF):\n        compute_api.servers.stop(instance)\n        wait_for_condition(is_vm_status_in, compute_api, instance, [SHUTOFF], timeout=state_change_timeout)\n    fix_post_cobalt_ephemeral_disk(config, instance)\n    with install_ssh_keys(config, src_host, dst_host):\n        with disable_all_nova_compute_services(compute_api):\n            with enable_nova_compute_services(compute_api, dst_host, src_host):\n                compute_api.servers.migrate(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [VERIFY_RESIZE], timeout=migration_timeout)\n                compute_api.servers.confirm_resize(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [ACTIVE], timeout=state_change_timeout)\n    if (original_status == SHUTOFF.lower()):\n        LOG.debug('Starting replacement VM %s', instance_id)\n        compute_api.servers.stop(instance_id)\n", "label": "Correct"}
{"function": "\n\ndef cold_evacuate(config, compute_api, instance_id, dst_host):\n    '\\n    Evacuate VM by shutting it down, booting another VM with same ephemeral\\n    volume on different host and deleting original VM.\\n\\n    :param config: CloudFerry configuration\\n    :param compute_api: Compute API client (NovaClient) instance\\n    :param instance_id: VM instance identifier to evacuate\\n    :param dst_host: destination host name\\n    '\n    LOG.debug('Cold evacuating VM %s to %s', instance_id, dst_host)\n    state_change_timeout = cfglib.CONF.evacuation.state_change_timeout\n    migration_timeout = cfglib.CONF.evacuation.migration_timeout\n    if (not change_to_pre_migration_state(compute_api, instance_id)):\n        instance = compute_api.servers.get(instance_id)\n        LOG.warning(\"Can't migrate VM in %s status\", instance.status)\n        return\n    instance = compute_api.servers.get(instance_id)\n    src_host = getattr(instance, INSTANCE_HOST_ATTRIBUTE)\n    if (src_host == dst_host):\n        LOG.warning('Skipping migration to the same host')\n        return\n    original_status = instance.status.lower()\n    if (original_status != SHUTOFF):\n        compute_api.servers.stop(instance)\n        wait_for_condition(is_vm_status_in, compute_api, instance, [SHUTOFF], timeout=state_change_timeout)\n    fix_post_cobalt_ephemeral_disk(config, instance)\n    with install_ssh_keys(config, compute_api, dst_host):\n        with disable_all_nova_compute_services(compute_api):\n            with enable_nova_compute_services(compute_api, dst_host, src_host):\n                compute_api.servers.migrate(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [VERIFY_RESIZE], timeout=migration_timeout)\n                compute_api.servers.confirm_resize(instance)\n                wait_for_condition(is_vm_status_in, compute_api, instance, [ACTIVE], timeout=state_change_timeout)\n    if (original_status == SHUTOFF.lower()):\n        LOG.debug('Starting replacement VM %s', instance_id)\n        compute_api.servers.stop(instance_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef tables(self, db=None):\n    '\\n        Enumerates all tables fro a given database. If not specified, use the\\n        current database.\\n        '\n    if self.has_cap(TABLES_ENUM):\n        if (db is None):\n            if (self.current_db is None):\n                self.database()\n            db = self.current_db\n        n = self.get_nb_tables(db)\n        for i in range(n):\n            (yield TableWrapper(self, self.get_table_name(i, db), db))\n    else:\n        raise Unavailable()\n", "label": "Correct"}
{"function": "\n\ndef tables(self, db=None):\n    '\\n        Enumerates all tables fro a given database. If not specified, use the\\n        current database.\\n        '\n    if self.has_cap(TABLES_ENUM):\n        if (db is None):\n            if (i.current_db is None):\n                self.database()\n            db = self.current_db\n        n = self.get_nb_tables(db)\n        for i in range(n):\n            (yield TableWrapper(self, self.get_table_name(i, db), db))\n    else:\n        raise Unavailable()\n", "label": "Variable misuse"}
{"function": "\n\ndef transform_non_affine(self, a):\n    return np.log10((a + 1))\n", "label": "Correct"}
{"function": "\n\ndef transform_non_affine(self, a):\n    return np.log10((self + 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef _is_us_state(abbr, result):\n    for sep in ('/', '-'):\n        if (result.source_base == 'us{sep}{abbr}'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}.'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}{sep}'.format(**locals())):\n            return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef _is_us_state(abbr, result):\n    for sep in ('/', '-'):\n        if (result.source_base == 'us{sep}{abbr}'.format(**locals())):\n            return True\n        if sep.source_base.startswith('us{sep}{abbr}.'.format(**locals())):\n            return True\n        if result.source_base.startswith('us{sep}{abbr}{sep}'.format(**locals())):\n            return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(BFDLib, self).__init__(*args, **kwargs)\n    self.session = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(BFDLib, self).__init__(*args, **kwargs)\n    kwargs.session = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\n@observe(('accept_mode', 'file_mode', 'show_dirs_only', 'current_path', 'name_filters', 'selected_name_filter'))\ndef _update_proxy(self, change):\n    ' An observer which updates the proxy when the data changes.\\n\\n        '\n    super(FileDialogEx, self)._update_proxy(change)\n", "label": "Correct"}
{"function": "\n\n@observe(('accept_mode', 'file_mode', 'show_dirs_only', 'current_path', 'name_filters', 'selected_name_filter'))\ndef _update_proxy(self, change):\n    ' An observer which updates the proxy when the data changes.\\n\\n        '\n    super(FileDialogEx, change)._update_proxy(change)\n", "label": "Variable misuse"}
{"function": "\n\ndef role_create(request, name):\n    manager = keystoneclient(request, admin=True).roles\n    return manager.create(name)\n", "label": "Correct"}
{"function": "\n\ndef role_create(request, name):\n    manager = keystoneclient(manager, admin=True).roles\n    return manager.create(name)\n", "label": "Variable misuse"}
{"function": "\n\n@sig((((H / int) >> 'a') >> ['a']))\ndef replicate(n, x):\n    '\\n    replicate :: Int -> a -> [a]\\n\\n    replicate(n, x) is a list of length n with x the value of every element.\\n    '\n\n    def __replicate(n, x):\n        for _ in range(n):\n            (yield x)\n    return L[__replicate(n, x)]\n", "label": "Correct"}
{"function": "\n\n@sig((((H / int) >> 'a') >> ['a']))\ndef replicate(n, x):\n    '\\n    replicate :: Int -> a -> [a]\\n\\n    replicate(n, x) is a list of length n with x the value of every element.\\n    '\n\n    def __replicate(n, x):\n        for _ in range(n):\n            (yield x)\n    return L[__replicate(n, n)]\n", "label": "Variable misuse"}
{"function": "\n\ndef process_IN_CLOSE_WRITE(self, event):\n    self.process_event(event.pathname, update)\n", "label": "Correct"}
{"function": "\n\ndef process_IN_CLOSE_WRITE(self, event):\n    event.process_event(event.pathname, update)\n", "label": "Variable misuse"}
{"function": "\n\n@util.positional(2)\ndef error(status_code, status_message=None, content_type='text/plain; charset=utf-8', headers=None, content=None):\n    'Create WSGI application that statically serves an error page.\\n\\n  Creates a static error page specifically for non-200 HTTP responses.\\n\\n  Browsers such as Internet Explorer will display their own error pages for\\n  error content responses smaller than 512 bytes.  For this reason all responses\\n  are right-padded up to 512 bytes.\\n\\n  Error pages that are not provided will content will contain the standard HTTP\\n  status message as their content.\\n\\n  Args:\\n    status_code: Integer status code of error.\\n    status_message: Status message.\\n\\n  Returns:\\n    Static WSGI application that sends static error response.\\n  '\n    if (status_message is None):\n        status_message = httplib.responses.get(status_code, 'Unknown Error')\n    if (content is None):\n        content = status_message\n    content = util.pad_string(content)\n    return static_page(content, status=(status_code, status_message), content_type=content_type, headers=headers)\n", "label": "Correct"}
{"function": "\n\n@util.positional(2)\ndef error(status_code, status_message=None, content_type='text/plain; charset=utf-8', headers=None, content=None):\n    'Create WSGI application that statically serves an error page.\\n\\n  Creates a static error page specifically for non-200 HTTP responses.\\n\\n  Browsers such as Internet Explorer will display their own error pages for\\n  error content responses smaller than 512 bytes.  For this reason all responses\\n  are right-padded up to 512 bytes.\\n\\n  Error pages that are not provided will content will contain the standard HTTP\\n  status message as their content.\\n\\n  Args:\\n    status_code: Integer status code of error.\\n    status_message: Status message.\\n\\n  Returns:\\n    Static WSGI application that sends static error response.\\n  '\n    if (content is None):\n        status_message = httplib.responses.get(status_code, 'Unknown Error')\n    if (content is None):\n        content = status_message\n    content = util.pad_string(content)\n    return static_page(content, status=(status_code, status_message), content_type=content_type, headers=headers)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_params(self):\n    params = np.array([r.params for r in self.results])\n    params_1 = np.array(([self.results[0].params] * len(self.results)))\n    assert_allclose(params, params_1)\n", "label": "Correct"}
{"function": "\n\ndef test_params(self):\n    params = np.array([params.params for r in self.results])\n    params_1 = np.array(([self.results[0].params] * len(self.results)))\n    assert_allclose(params, params_1)\n", "label": "Variable misuse"}
{"function": "\n\ndef Status_Name(cls, x):\n    return cls._Status_NAMES.get(x, '')\n", "label": "Correct"}
{"function": "\n\ndef Status_Name(cls, x):\n    return cls._Status_NAMES.get(cls, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef usesTime(self):\n    fmt = self._fmt\n    return ((fmt.find('$asctime') >= 0) or (fmt.find(self.asctime_format) >= 0))\n", "label": "Correct"}
{"function": "\n\ndef usesTime(self):\n    fmt = self._fmt\n    return ((self.find('$asctime') >= 0) or (fmt.find(self.asctime_format) >= 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef make_user_dict(name, password, enabled, fullName, emailAddress, officePhone, mobilePhone, roles=[]):\n    return {\n        'userName': name,\n        'password': password,\n        'fullName': fullName,\n        'emailAddress': emailAddress,\n        'officePhone': officePhone,\n        'mobilePhone': mobilePhone,\n        'enabled': enabled,\n        'type': 'UserAndRoles',\n        'roles': roles,\n    }\n", "label": "Correct"}
{"function": "\n\ndef make_user_dict(name, password, enabled, fullName, emailAddress, officePhone, mobilePhone, roles=[]):\n    return {\n        'userName': officePhone,\n        'password': password,\n        'fullName': fullName,\n        'emailAddress': emailAddress,\n        'officePhone': officePhone,\n        'mobilePhone': mobilePhone,\n        'enabled': enabled,\n        'type': 'UserAndRoles',\n        'roles': roles,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef _validate_python(self, field_dict, state):\n    try:\n        ref = field_dict[self.field_names[0]]\n    except TypeError:\n        raise Invalid(self.message('notDict', state), field_dict, state)\n    except KeyError:\n        ref = ''\n    errors = {\n        \n    }\n    for name in self.field_names[1:]:\n        if (field_dict.get(name, '') != ref):\n            if self.show_match:\n                errors[name] = self.message('invalid', state, match=ref)\n            else:\n                errors[name] = self.message('invalidNoMatch', state)\n    if errors:\n        error_list = sorted(six.iteritems(errors))\n        error_message = '<br>\\n'.join((('%s: %s' % (name, value)) for (name, value) in error_list))\n        raise Invalid(error_message, field_dict, state, error_dict=errors)\n", "label": "Correct"}
{"function": "\n\ndef _validate_python(self, field_dict, state):\n    try:\n        ref = field_dict[self.field_names[0]]\n    except TypeError:\n        raise Invalid(self.message('notDict', state), field_dict, state)\n    except KeyError:\n        ref = ''\n    errors = {\n        \n    }\n    for name in self.field_names[1:]:\n        if (name.get(name, '') != ref):\n            if self.show_match:\n                errors[name] = self.message('invalid', state, match=ref)\n            else:\n                errors[name] = self.message('invalidNoMatch', state)\n    if errors:\n        error_list = sorted(six.iteritems(errors))\n        error_message = '<br>\\n'.join((('%s: %s' % (name, value)) for (name, value) in error_list))\n        raise Invalid(error_message, field_dict, state, error_dict=errors)\n", "label": "Variable misuse"}
{"function": "\n\ndef add_link(root, olink):\n    root.append(ET.fromstring(olink['orig_xml']))\n", "label": "Correct"}
{"function": "\n\ndef add_link(root, olink):\n    olink.append(ET.fromstring(olink['orig_xml']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, response, handle):\n    self._response = response\n    self._handle = handle\n    super(ResponseHeaders, self).__init__()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, response, handle):\n    self._response = response\n    self._handle = handle\n    super(ResponseHeaders, response).__init__()\n", "label": "Variable misuse"}
{"function": "\n\ndef make_datastore_mock(self):\n    store = Mock(spec=['insert_client_ip'])\n    store.get_app_service_by_token = Mock(return_value=None)\n    return store\n", "label": "Correct"}
{"function": "\n\ndef make_datastore_mock(self):\n    store = Mock(spec=['insert_client_ip'])\n    store.get_app_service_by_token = Mock(return_value=None)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef add_condition(self, name, condition):\n    self.conditions[name] = condition\n", "label": "Correct"}
{"function": "\n\ndef add_condition(self, name, condition):\n    name.conditions[name] = condition\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    self.__dict__['__stack'] = [kwargs]\n    self.__dict__['__exc_ref'] = None\n    self.__dict__['__exc_stack'] = []\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    self.__dict__['__stack'] = [self]\n    self.__dict__['__exc_ref'] = None\n    self.__dict__['__exc_stack'] = []\n", "label": "Variable misuse"}
{"function": "\n\ndef get_list(self, *args, **kwargs):\n    (count, data) = super(TweetView, self).get_list(*args, **kwargs)\n    query = {\n        '_id': {\n            '$in': [x['user_id'] for x in data],\n        },\n    }\n    users = db.user.find(query, fields=('name',))\n    users_map = dict(((x['_id'], x['name']) for x in users))\n    for item in data:\n        item['user_name'] = users_map.get(item['user_id'])\n    return (count, data)\n", "label": "Correct"}
{"function": "\n\ndef get_list(self, *args, **kwargs):\n    (count, data) = super(TweetView, self).get_list(*args, **kwargs)\n    query = {\n        '_id': {\n            '$in': [x['user_id'] for x in item],\n        },\n    }\n    users = db.user.find(query, fields=('name',))\n    users_map = dict(((x['_id'], x['name']) for x in users))\n    for item in data:\n        item['user_name'] = users_map.get(item['user_id'])\n    return (count, data)\n", "label": "Variable misuse"}
{"function": "\n\n@conf.commands.register\ndef srbt1(peer, pkts, *args, **kargs):\n    'send and receive 1 packet using a bluetooth socket'\n    (a, b) = srbt(peer, pkts, *args, **kargs)\n    if (len(a) > 0):\n        return a[0][1]\n", "label": "Correct"}
{"function": "\n\n@conf.commands.register\ndef srbt1(peer, pkts, *args, **kargs):\n    'send and receive 1 packet using a bluetooth socket'\n    (a, b) = srbt(peer, pkts, *args, **peer)\n    if (len(a) > 0):\n        return a[0][1]\n", "label": "Variable misuse"}
{"function": "\n\ndef permission_required(perm, login_url=None):\n    '\\n    Decorator for views that checks whether a user has a particular permission\\n    enabled, redirecting to the log-in page if necessary.\\n    '\n    return user_passes_test((lambda u: u.has_perm(perm)), login_url=login_url)\n", "label": "Correct"}
{"function": "\n\ndef permission_required(perm, login_url=None):\n    '\\n    Decorator for views that checks whether a user has a particular permission\\n    enabled, redirecting to the log-in page if necessary.\\n    '\n    return user_passes_test((lambda u: u.has_perm(u)), login_url=login_url)\n", "label": "Variable misuse"}
{"function": "\n\ndef find_payload_class(payload_type):\n    'Iterate through inherited classes to find a matching class name'\n    subclasses = set()\n    work = [Payload]\n    while work:\n        parent_subclass = work.pop()\n        for child_subclass in parent_subclass.__subclasses__():\n            if (child_subclass not in subclasses):\n                if (hasattr(child_subclass, 'payload_type') and (child_subclass.payload_type == payload_type)):\n                    return child_subclass\n                subclasses.add(child_subclass)\n                work.append(child_subclass)\n    return None\n", "label": "Correct"}
{"function": "\n\ndef find_payload_class(payload_type):\n    'Iterate through inherited classes to find a matching class name'\n    subclasses = set()\n    work = [Payload]\n    while work:\n        parent_subclass = work.pop()\n        for child_subclass in parent_subclass.__subclasses__():\n            if (child_subclass not in subclasses):\n                if (hasattr(payload_type, 'payload_type') and (child_subclass.payload_type == payload_type)):\n                    return child_subclass\n                subclasses.add(child_subclass)\n                work.append(child_subclass)\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, modelXbrl, user, password, host, port, database, timeout, product):\n    self.modelXbrl = modelXbrl\n    self.disclosureSystem = modelXbrl.modelManager.disclosureSystem\n    if (product == 'postgres'):\n        if (not hasPostgres):\n            raise XPDBException('xpgDB:MissingPostgresInterface', _('Postgres interface is not installed'))\n        self.conn = pgConnect(user=user, password=password, host=host, port=int((port or 5432)), database=database, socket_timeout=(timeout or 60))\n        self.product = product\n    elif (product == 'mysql'):\n        if (not hasMySql):\n            raise XPDBException('xpgDB:MissingMySQLInterface', _('MySQL interface is not installed'))\n        self.conn = mysqlConnect(user=user, passwd=password, host=host, port=int((port or 5432)), db=database, connect_timeout=(timeout or 60), charset='utf8')\n        self.product = product\n    elif (product == 'orcl'):\n        if (not hasOracle):\n            raise XPDBException('xpgDB:MissingOracleInterface', _('Oracle interface is not installed'))\n        self.conn = oracleConnect('{}/{}@{}{}'.format(user, password, host, (':{}'.format(port) if port else '')))\n        self.product = product\n    elif (product == 'mssql'):\n        if (not hasMSSql):\n            raise XPDBException('xpgDB:MissingMSSQLInterface', _('MSSQL server interface is not installed'))\n        self.conn = mssqlConnect('DRIVER={{SQL Server Native Client 11.0}};SERVER={2};DATABASE={3};UID={0};PWD={1};CHARSET=UTF8'.format(user, password, host, database))\n        self.product = product\n    elif (product == 'sqlite'):\n        if (not hasSQLite):\n            raise XPDBException('xpgDB:MissingSQLiteInterface', _('SQLite interface is not installed'))\n        self.conn = sqliteConnect(database, (timeout or 60), detect_types=sqliteParseDecltypes)\n        self.product = product\n        self.syncSequences = False\n    else:\n        self.product = None\n    self.tableColTypes = {\n        \n    }\n    self.tableColDeclaration = {\n        \n    }\n    self.accessionId = '(None)'\n    self.tempInputTableName = 'input{}'.format(os.getpid())\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, modelXbrl, user, password, host, port, database, timeout, product):\n    self.modelXbrl = modelXbrl\n    self.disclosureSystem = modelXbrl.modelManager.disclosureSystem\n    if (product == 'postgres'):\n        if (not hasPostgres):\n            raise XPDBException('xpgDB:MissingPostgresInterface', _('Postgres interface is not installed'))\n        self.conn = pgConnect(user=user, password=password, host=host, port=int((port or 5432)), database=database, socket_timeout=(timeout or 60))\n        self.product = product\n    elif (product == 'mysql'):\n        if (not hasMySql):\n            raise XPDBException('xpgDB:MissingMySQLInterface', _('MySQL interface is not installed'))\n        self.conn = mysqlConnect(user=user, passwd=password, host=host, port=int((port or 5432)), db=database, connect_timeout=(timeout or 60), charset='utf8')\n        self.product = product\n    elif (product == 'orcl'):\n        if (not hasOracle):\n            raise XPDBException('xpgDB:MissingOracleInterface', _('Oracle interface is not installed'))\n        self.conn = oracleConnect('{}/{}@{}{}'.format(user, password, password, (':{}'.format(port) if port else '')))\n        self.product = product\n    elif (product == 'mssql'):\n        if (not hasMSSql):\n            raise XPDBException('xpgDB:MissingMSSQLInterface', _('MSSQL server interface is not installed'))\n        self.conn = mssqlConnect('DRIVER={{SQL Server Native Client 11.0}};SERVER={2};DATABASE={3};UID={0};PWD={1};CHARSET=UTF8'.format(user, password, host, database))\n        self.product = product\n    elif (product == 'sqlite'):\n        if (not hasSQLite):\n            raise XPDBException('xpgDB:MissingSQLiteInterface', _('SQLite interface is not installed'))\n        self.conn = sqliteConnect(database, (timeout or 60), detect_types=sqliteParseDecltypes)\n        self.product = product\n        self.syncSequences = False\n    else:\n        self.product = None\n    self.tableColTypes = {\n        \n    }\n    self.tableColDeclaration = {\n        \n    }\n    self.accessionId = '(None)'\n    self.tempInputTableName = 'input{}'.format(os.getpid())\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_inline(text):\n    '\\n    Takes a string of text from a text inline and returns a 3 tuple of\\n    (name, value, **kwargs).\\n    '\n    m = INLINE_SPLITTER.match(text)\n    if (not m):\n        raise InlineUnparsableError\n    args = m.group('args')\n    name = m.group('name')\n    value = ''\n    kwtxt = ''\n    kwargs = {\n        \n    }\n    if args:\n        kwtxt = INLINE_KWARG_PARSER.search(args).group('kwargs')\n        value = re.sub(('%s\\\\Z' % kwtxt), '', args)\n        value = value.strip()\n    if m.group('variant'):\n        kwargs['variant'] = m.group('variant')\n    if kwtxt:\n        for kws in kwtxt.split():\n            (k, v) = kws.split('=')\n            kwargs[str(k)] = v\n    return (name, value, kwargs)\n", "label": "Correct"}
{"function": "\n\ndef parse_inline(text):\n    '\\n    Takes a string of text from a text inline and returns a 3 tuple of\\n    (name, value, **kwargs).\\n    '\n    m = INLINE_SPLITTER.match(text)\n    if (not m):\n        raise InlineUnparsableError\n    args = m.group('args')\n    name = m.group('name')\n    value = ''\n    kwtxt = ''\n    kwargs = {\n        \n    }\n    if args:\n        kwtxt = INLINE_KWARG_PARSER.search(args).group('kwargs')\n        value = re.sub(('%s\\\\Z' % kwtxt), '', args)\n        value = value.strip()\n    if m.group('variant'):\n        kwargs['variant'] = m.group('variant')\n    if kwtxt:\n        for kws in kwtxt.split():\n            (k, v) = kws.split('=')\n            kwargs[str(kwtxt)] = v\n    return (name, value, kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, *args, **kwargs):\n    if (not self.file):\n        self.file = tempfile.TemporaryFile()\n    self.file.write(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef write(self, *args, **kwargs):\n    if (not self.file):\n        kwargs.file = tempfile.TemporaryFile()\n    self.file.write(*args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef complex_step_jacobian(self, params, unknowns, resids, total_derivs=False, fd_params=None, fd_states=None, fd_unknowns=None, poi_indices=None, qoi_indices=None):\n    \" Return derivatives of all unknowns in this system w.r.t. all\\n        incoming params using complex step.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        resids : `VecWrapper`\\n            `VecWrapper` containing residuals. (r)\\n\\n        total_derivs : bool, optional\\n            Should always be False, as componentwise derivatives only need partials.\\n\\n        fd_params : list of strings, optional\\n            List of parameter name strings with respect to which derivatives\\n            are desired. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_unknowns : list of strings, optional\\n            List of output or state name strings for derivatives to be\\n            calculated. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_states : list of strings, optional\\n            List of state name strings for derivatives to be taken with respect to.\\n            This is used by problem to limit the derivatives that are taken.\\n\\n        poi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        qoi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        Returns\\n        -------\\n        dict\\n            Dictionary whose keys are tuples of the form ('unknown', 'param')\\n            and whose values are ndarrays containing the derivative for that\\n            tuple pair.\\n        \"\n    if (fd_params is None):\n        fd_params = self._get_fd_params()\n    if (fd_unknowns is None):\n        fd_unknowns = self._get_fd_unknowns()\n    step_size = self.fd_options.get('step_size', 1e-06)\n    jac = {\n        \n    }\n    csparams = ComplexStepTgtVecWrapper(params)\n    csunknowns = ComplexStepSrcVecWrapper(unknowns)\n    csresids = ComplexStepSrcVecWrapper(resids)\n    states = self.states\n    if (len(states) > 0):\n        resultvec = csresids\n    else:\n        resultvec = csunknowns\n    if (fd_states is not None):\n        states = fd_states\n    for p_name in chain(fd_params, states):\n        if (p_name in states):\n            stepvec = csunknowns\n            target_input = unknowns._dat[p_name].val\n        else:\n            stepvec = csparams\n            target_input = params._dat[p_name].val\n        stepvec.set_complex_var(p_name)\n        mydict = self._init_params_dict.get(p_name, {\n            \n        })\n        fdstep = mydict.get('step_size', step_size)\n        p_size = np.size(target_input)\n        p_idxs = range(p_size)\n        for u_name in fd_unknowns:\n            u_size = np.size(unknowns[u_name])\n            jac[(u_name, p_name)] = np.zeros((u_size, p_size))\n        for (j, idx) in enumerate(p_idxs):\n            stepvec.step_complex(idx, fdstep)\n            self.apply_nonlinear(csparams, csunknowns, csresids)\n            stepvec.step_complex(idx, (- fdstep))\n            for u_name in fd_unknowns:\n                result = resultvec.flat(u_name)\n                jac[(u_name, p_name)][:, j] = (result.imag / fdstep)\n        stepvec.set_complex_var(None)\n    return jac\n", "label": "Correct"}
{"function": "\n\ndef complex_step_jacobian(self, params, unknowns, resids, total_derivs=False, fd_params=None, fd_states=None, fd_unknowns=None, poi_indices=None, qoi_indices=None):\n    \" Return derivatives of all unknowns in this system w.r.t. all\\n        incoming params using complex step.\\n\\n        Args\\n        ----\\n        params : `VecWrapper`\\n            `VecWrapper` containing parameters. (p)\\n\\n        unknowns : `VecWrapper`\\n            `VecWrapper` containing outputs and states. (u)\\n\\n        resids : `VecWrapper`\\n            `VecWrapper` containing residuals. (r)\\n\\n        total_derivs : bool, optional\\n            Should always be False, as componentwise derivatives only need partials.\\n\\n        fd_params : list of strings, optional\\n            List of parameter name strings with respect to which derivatives\\n            are desired. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_unknowns : list of strings, optional\\n            List of output or state name strings for derivatives to be\\n            calculated. This is used by problem to limit the derivatives that\\n            are taken.\\n\\n        fd_states : list of strings, optional\\n            List of state name strings for derivatives to be taken with respect to.\\n            This is used by problem to limit the derivatives that are taken.\\n\\n        poi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        qoi_indices: dict of list of integers, optional\\n            Should be an empty list, as there is no subcomponent relevance reduction.\\n\\n        Returns\\n        -------\\n        dict\\n            Dictionary whose keys are tuples of the form ('unknown', 'param')\\n            and whose values are ndarrays containing the derivative for that\\n            tuple pair.\\n        \"\n    if (fd_params is None):\n        fd_params = self._get_fd_params()\n    if (fd_unknowns is None):\n        fd_unknowns = self._get_fd_unknowns()\n    step_size = self.fd_options.get('step_size', 1e-06)\n    jac = {\n        \n    }\n    csparams = ComplexStepTgtVecWrapper(params)\n    csunknowns = ComplexStepSrcVecWrapper(unknowns)\n    csresids = ComplexStepSrcVecWrapper(resids)\n    states = self.states\n    if (len(states) > 0):\n        resultvec = csresids\n    else:\n        resultvec = csunknowns\n    if (fd_states is not None):\n        states = fd_states\n    for p_name in chain(fd_params, states):\n        if (p_name in u_size):\n            stepvec = csunknowns\n            target_input = unknowns._dat[p_name].val\n        else:\n            stepvec = csparams\n            target_input = params._dat[p_name].val\n        stepvec.set_complex_var(p_name)\n        mydict = self._init_params_dict.get(p_name, {\n            \n        })\n        fdstep = mydict.get('step_size', step_size)\n        p_size = np.size(target_input)\n        p_idxs = range(p_size)\n        for u_name in fd_unknowns:\n            u_size = np.size(unknowns[u_name])\n            jac[(u_name, p_name)] = np.zeros((u_size, p_size))\n        for (j, idx) in enumerate(p_idxs):\n            stepvec.step_complex(idx, fdstep)\n            self.apply_nonlinear(csparams, csunknowns, csresids)\n            stepvec.step_complex(idx, (- fdstep))\n            for u_name in fd_unknowns:\n                result = resultvec.flat(u_name)\n                jac[(u_name, p_name)][:, j] = (result.imag / fdstep)\n        stepvec.set_complex_var(None)\n    return jac\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Weapon()\n    result.template = 'object/weapon/melee/baton/shared_victor_baton_gaderiffi.iff'\n    result.attribute_template_id = 10\n    result.stfName('weapon_name', 'victor_baton_gaderiffi')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Weapon()\n    kernel.template = 'object/weapon/melee/baton/shared_victor_baton_gaderiffi.iff'\n    result.attribute_template_id = 10\n    result.stfName('weapon_name', 'victor_baton_gaderiffi')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef _Rotate(self, image, transform):\n    'Use PIL to rotate the given image with the given transform.\\n\\n    Args:\\n      image: PIL.Image.Image object to rotate.\\n      transform: images_service_pb.Transform to use when rotating.\\n\\n    Returns:\\n      PIL.Image.Image with transforms performed on it.\\n\\n    Raises:\\n      BadRequestError if the rotate data given is bad.\\n    '\n    degrees = transform.rotate()\n    if ((degrees < 0) or ((degrees % 90) != 0)):\n        raise apiproxy_errors.ApplicationError(images_service_pb.ImagesServiceError.BAD_TRANSFORM_DATA)\n    degrees %= 360\n    degrees = (360 - degrees)\n    return image.rotate(degrees)\n", "label": "Correct"}
{"function": "\n\ndef _Rotate(self, image, transform):\n    'Use PIL to rotate the given image with the given transform.\\n\\n    Args:\\n      image: PIL.Image.Image object to rotate.\\n      transform: images_service_pb.Transform to use when rotating.\\n\\n    Returns:\\n      PIL.Image.Image with transforms performed on it.\\n\\n    Raises:\\n      BadRequestError if the rotate data given is bad.\\n    '\n    degrees = transform.rotate()\n    if ((degrees < 0) or ((degrees % 90) != 0)):\n        raise apiproxy_errors.ApplicationError(images_service_pb.ImagesServiceError.BAD_TRANSFORM_DATA)\n    degrees %= 360\n    degrees = (360 - degrees)\n    return image.rotate(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_window_attrib(window, attrib):\n    '\\n    Returns an attribute of the specified window.\\n\\n    Wrapper for:\\n        int glfwGetWindowAttrib(GLFWwindow* window, int attrib);\\n    '\n    return _glfw.glfwGetWindowAttrib(window, attrib)\n", "label": "Correct"}
{"function": "\n\ndef get_window_attrib(window, attrib):\n    '\\n    Returns an attribute of the specified window.\\n\\n    Wrapper for:\\n        int glfwGetWindowAttrib(GLFWwindow* window, int attrib);\\n    '\n    return _glfw.glfwGetWindowAttrib(window, window)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parent, log_entry):\n    mst_gui.LogViewerBase.__init__(self, parent)\n    self.mLogEntry = log_entry\n    self.mTimeNumText.SetValue(('%s [%s]' % (log_entry.Time, str(log_entry.Num))))\n    self.mSentText.SetValue(log_entry.Sent)\n    self.mReceivedText.SetValue(log_entry.Received)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parent, log_entry):\n    mst_gui.LogViewerBase.__init__(self, parent)\n    self.mLogEntry = log_entry\n    log_entry.mTimeNumText.SetValue(('%s [%s]' % (log_entry.Time, str(log_entry.Num))))\n    self.mSentText.SetValue(log_entry.Sent)\n    self.mReceivedText.SetValue(log_entry.Received)\n", "label": "Variable misuse"}
{"function": "\n\ndef iter_keys(self, filename):\n    with open(filename, 'rb') as f:\n        header = f.read(8)\n        self._verify_header(header)\n        current_offset = 8\n        file_size_bytes = os.path.getsize(filename)\n        while True:\n            current_contents = f.read(8)\n            current_offset += 8\n            if (len(current_contents) < 8):\n                if (len(current_contents) > 0):\n                    raise DBMLoadError('Error loading db: partial header read')\n                else:\n                    return\n            (key_size, val_size) = struct.unpack('!ii', current_contents)\n            key = f.read(key_size)\n            if (len(key) != key_size):\n                raise DBMLoadError(('Error loading db: key size does not match (expected %s bytes, got %s instead.' % (key_size, len(key))))\n            value_offset = (current_offset + key_size)\n            if ((value_offset + val_size) > file_size_bytes):\n                return\n            (yield (key, value_offset, val_size))\n            if (val_size == _DELETED):\n                val_size = 0\n            skip_ahead = ((key_size + val_size) + 4)\n            current_offset += skip_ahead\n            if (current_offset > file_size_bytes):\n                raise DBMLoadError('Error loading db: reading past the end of the file (file possibly truncated)')\n            f.seek(current_offset)\n", "label": "Correct"}
{"function": "\n\ndef iter_keys(self, filename):\n    with open(filename, 'rb') as f:\n        header = f.read(8)\n        self._verify_header(header)\n        current_offset = 8\n        file_size_bytes = os.path.getsize(filename)\n        while True:\n            current_contents = f.read(8)\n            current_offset += 8\n            if (len(self) < 8):\n                if (len(current_contents) > 0):\n                    raise DBMLoadError('Error loading db: partial header read')\n                else:\n                    return\n            (key_size, val_size) = struct.unpack('!ii', current_contents)\n            key = f.read(key_size)\n            if (len(key) != key_size):\n                raise DBMLoadError(('Error loading db: key size does not match (expected %s bytes, got %s instead.' % (key_size, len(key))))\n            value_offset = (current_offset + key_size)\n            if ((value_offset + val_size) > file_size_bytes):\n                return\n            (yield (key, value_offset, val_size))\n            if (val_size == _DELETED):\n                val_size = 0\n            skip_ahead = ((key_size + val_size) + 4)\n            current_offset += skip_ahead\n            if (current_offset > file_size_bytes):\n                raise DBMLoadError('Error loading db: reading past the end of the file (file possibly truncated)')\n            f.seek(current_offset)\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.fixture\ndef get_image_part_fixture(self, Image_, image_part_, image_descriptor_):\n    image_parts = ImageParts()\n    image_parts.append(image_part_)\n    return (image_parts, image_descriptor_, image_part_)\n", "label": "Correct"}
{"function": "\n\n@pytest.fixture\ndef get_image_part_fixture(self, Image_, image_part_, image_descriptor_):\n    image_parts = ImageParts()\n    image_parts.append(image_part_)\n    return (image_descriptor_, image_descriptor_, image_part_)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, lang_canonicalizations):\n    self._lang_canonicalizations = lang_canonicalizations\n    self._root = SourceRootTrie.Node()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, lang_canonicalizations):\n    self._lang_canonicalizations = lang_canonicalizations\n    lang_canonicalizations._root = SourceRootTrie.Node()\n", "label": "Variable misuse"}
{"function": "\n\ndef publish_state(self, payload, state):\n    if (not state):\n        raise Exception('Unable to publish unassigned state.')\n    self._state_publisher.publish(payload, self._state_exchange, state)\n", "label": "Correct"}
{"function": "\n\ndef publish_state(self, payload, state):\n    if (not state):\n        raise Exception('Unable to publish unassigned state.')\n    self._state_publisher.publish(self, self._state_exchange, state)\n", "label": "Variable misuse"}
{"function": "\n\ndef none(self):\n    '\\n        Scalar(True) if no items are truthy, or collection is empty.\\n        '\n    return self.map((lambda items: (not any(items))))\n", "label": "Correct"}
{"function": "\n\ndef none(self):\n    '\\n        Scalar(True) if no items are truthy, or collection is empty.\\n        '\n    return items.map((lambda items: (not any(items))))\n", "label": "Variable misuse"}
{"function": "\n\ndef tonal_transposition(self, index, scale):\n    pos = ((index + scale.index(self)) - 1)\n    (octave, rest) = divmod(pos, 7)\n    note = copy.copy(scale[(pos % len(scale))])\n    note.octave += octave\n    return note\n", "label": "Correct"}
{"function": "\n\ndef tonal_transposition(self, index, scale):\n    pos = ((rest + scale.index(self)) - 1)\n    (octave, rest) = divmod(pos, 7)\n    note = copy.copy(scale[(pos % len(scale))])\n    note.octave += octave\n    return note\n", "label": "Variable misuse"}
{"function": "\n\ndef test_iter_smart_pk_range(self):\n    seen = []\n    for (start_pk, end_pk) in Author.objects.iter_smart_pk_ranges():\n        seen.extend(Author.objects.filter(id__gte=start_pk, id__lt=end_pk).values_list('id', flat=True))\n    all_ids = list(Author.objects.order_by('id').values_list('id', flat=True))\n    assert (seen == all_ids)\n", "label": "Correct"}
{"function": "\n\ndef test_iter_smart_pk_range(self):\n    seen = []\n    for (start_pk, end_pk) in Author.objects.iter_smart_pk_ranges():\n        all_ids.extend(Author.objects.filter(id__gte=start_pk, id__lt=end_pk).values_list('id', flat=True))\n    all_ids = list(Author.objects.order_by('id').values_list('id', flat=True))\n    assert (seen == all_ids)\n", "label": "Variable misuse"}
{"function": "\n\ndef no_translate_debug_logs(logical_line, filename):\n    \"Check for 'LOG.debug(_('\\n\\n    As per our translation policy,\\n    https://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\\n    we shouldn't translate debug level logs.\\n\\n    * This check assumes that 'LOG' is a logger.\\n    * Use filename so we can start enforcing this in specific folders instead\\n      of needing to do so all at once.\\n    S373\\n    \"\n    msg = \"S373 Don't translate debug level logs\"\n    if logical_line.startswith('LOG.debug(_('):\n        (yield (0, msg))\n", "label": "Correct"}
{"function": "\n\ndef no_translate_debug_logs(logical_line, filename):\n    \"Check for 'LOG.debug(_('\\n\\n    As per our translation policy,\\n    https://wiki.openstack.org/wiki/LoggingStandards#Log_Translation\\n    we shouldn't translate debug level logs.\\n\\n    * This check assumes that 'LOG' is a logger.\\n    * Use filename so we can start enforcing this in specific folders instead\\n      of needing to do so all at once.\\n    S373\\n    \"\n    msg = \"S373 Don't translate debug level logs\"\n    if logical_line.startswith('LOG.debug(_('):\n        (yield (0, filename))\n", "label": "Variable misuse"}
{"function": "\n\ndef capability(self, i):\n    return self.capability_[i]\n", "label": "Correct"}
{"function": "\n\ndef capability(self, i):\n    return self.capability_[self]\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_user_ec2_credentials(request, user_id, access_token):\n    return ec2_manager(request).delete(user_id, access_token)\n", "label": "Correct"}
{"function": "\n\ndef delete_user_ec2_credentials(request, user_id, access_token):\n    return ec2_manager(request).delete(request, access_token)\n", "label": "Variable misuse"}
{"function": "\n\ndef testKeepExistingValues(self):\n    ph = GafferCortex.ParameterisedHolderNode()\n    ph.setParameterised(IECore.Grade())\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade())\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(0))\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade(), keepExistingValues=True)\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(1, 0, 0))\n", "label": "Correct"}
{"function": "\n\ndef testKeepExistingValues(self):\n    ph = GafferCortex.ParameterisedHolderNode()\n    ph.setParameterised(IECore.Grade())\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    ph.setParameterised(IECore.Grade())\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(0))\n    ph['parameters']['lift'].setValue(IECore.Color3f(1, 0, 0))\n    self.setParameterised(IECore.Grade(), keepExistingValues=True)\n    self.assertEqual(ph['parameters']['lift'].getValue(), IECore.Color3f(1, 0, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_command(self, ctx, name):\n    \"\\n        Get a specific command by looking up the module.\\n\\n        :param ctx: Click context\\n        :param name: Command name\\n        :return: Module's cli function\\n        \"\n    try:\n        if (sys.version_info[0] == 2):\n            name = name.encode('ascii', 'replace')\n        mod = __import__(('cli.commands.cmd_' + name), None, None, ['cli'])\n    except ImportError as e:\n        logging.error('Error importing module {0}:\\n{0}'.format(name, e))\n        exit(1)\n    return mod.cli\n", "label": "Correct"}
{"function": "\n\ndef get_command(self, ctx, name):\n    \"\\n        Get a specific command by looking up the module.\\n\\n        :param ctx: Click context\\n        :param name: Command name\\n        :return: Module's cli function\\n        \"\n    try:\n        if (sys.version_info[0] == 2):\n            name = name.encode('ascii', 'replace')\n        mod = __import__(('cli.commands.cmd_' + mod), None, None, ['cli'])\n    except ImportError as e:\n        logging.error('Error importing module {0}:\\n{0}'.format(name, e))\n        exit(1)\n    return mod.cli\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(SQLRows, self).__init__(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(SQLRows, self).__init__(*args, **self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, data):\n    '\\n        data is the entire xml body/document\\n        '\n    super(XMLResponse, self).__init__(data, mimetype='text/xml')\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, data):\n    '\\n        data is the entire xml body/document\\n        '\n    super(XMLResponse, data).__init__(data, mimetype='text/xml')\n", "label": "Variable misuse"}
{"function": "\n\ndef all_terms(f):\n    '\\n        Returns all terms from a univariate polynomial ``f``.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy import Poly\\n        >>> from sympy.abc import x\\n\\n        >>> Poly(x**3 + 2*x - 1, x).all_terms()\\n        [((3,), 1), ((2,), 0), ((1,), 2), ((0,), -1)]\\n\\n        '\n    return [(m, f.rep.dom.to_sympy(c)) for (m, c) in f.rep.all_terms()]\n", "label": "Correct"}
{"function": "\n\ndef all_terms(f):\n    '\\n        Returns all terms from a univariate polynomial ``f``.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy import Poly\\n        >>> from sympy.abc import x\\n\\n        >>> Poly(x**3 + 2*x - 1, x).all_terms()\\n        [((3,), 1), ((2,), 0), ((1,), 2), ((0,), -1)]\\n\\n        '\n    return [(m, f.rep.dom.to_sympy(c)) for (m, c) in m.rep.all_terms()]\n", "label": "Variable misuse"}
{"function": "\n\ndef ensure_role(self, role, dry_run=False):\n    '\\n        Adds the role if it does not already exist, otherwise skips it.\\n        '\n    existing_roles = Role.objects.filter(slug=role.slug)\n    if existing_roles:\n        logger.info('Role already exists: %s', role.name)\n        return existing_roles[0]\n    elif dry_run:\n        logger.info('[DRY RUN] Creating role: %s', role.name)\n    else:\n        if self.verbose:\n            logger.info('Creating role: %s', role.name)\n        role.save()\n", "label": "Correct"}
{"function": "\n\ndef ensure_role(self, role, dry_run=False):\n    '\\n        Adds the role if it does not already exist, otherwise skips it.\\n        '\n    existing_roles = Role.objects.filter(slug=role.slug)\n    if existing_roles:\n        logger.info('Role already exists: %s', role.name)\n        return existing_roles[0]\n    elif dry_run:\n        logger.info('[DRY RUN] Creating role: %s', role.name)\n    else:\n        if dry_run.verbose:\n            logger.info('Creating role: %s', role.name)\n        role.save()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_actions(self, request):\n    actions = super(CommentsAdmin, self).get_actions(request)\n    actions.pop('delete_selected')\n    actions.pop('flag_comments')\n    return actions\n", "label": "Correct"}
{"function": "\n\ndef get_actions(self, request):\n    actions = super(CommentsAdmin, self).get_actions(request)\n    self.pop('delete_selected')\n    actions.pop('flag_comments')\n    return actions\n", "label": "Variable misuse"}
{"function": "\n\ndef test_incr(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=None)\n    client.incr('buck.counter', 5)\n    self.assertEqual(client._socket.data, b'buck.counter:5|c')\n", "label": "Correct"}
{"function": "\n\ndef test_incr(self):\n    client = statsd.StatsdClient('localhost', 8125, prefix='', sample_rate=None)\n    client.incr('buck.counter', 5)\n    client.assertEqual(client._socket.data, b'buck.counter:5|c')\n", "label": "Variable misuse"}
{"function": "\n\ndef _initPopulation(self, seeds):\n    if (self.parentChildAverage < 1):\n        for s in seeds:\n            s.parent = None\n    self.pop = self._extendPopulation(seeds, self.populationSize)\n", "label": "Correct"}
{"function": "\n\ndef _initPopulation(self, seeds):\n    if (self.parentChildAverage < 1):\n        for s in seeds:\n            s.parent = None\n    self.pop = self._extendPopulation(self, self.populationSize)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_script_name(environ, charset='utf-8', errors='replace'):\n    'Returns the `SCRIPT_NAME` from the WSGI environment and properly\\n    decodes it.  This also takes care about the WSGI decoding dance\\n    on Python 3 environments.  if the `charset` is set to `None` a\\n    bytestring is returned.\\n\\n    .. versionadded:: 0.9\\n\\n    :param environ: the WSGI environment object to get the path from.\\n    :param charset: the charset for the path, or `None` if no\\n                    decoding should be performed.\\n    :param errors: the decoding error handling.\\n    '\n    path = wsgi_get_bytes(environ.get('SCRIPT_NAME', ''))\n    return to_unicode(path, charset, errors, allow_none_charset=True)\n", "label": "Correct"}
{"function": "\n\ndef get_script_name(environ, charset='utf-8', errors='replace'):\n    'Returns the `SCRIPT_NAME` from the WSGI environment and properly\\n    decodes it.  This also takes care about the WSGI decoding dance\\n    on Python 3 environments.  if the `charset` is set to `None` a\\n    bytestring is returned.\\n\\n    .. versionadded:: 0.9\\n\\n    :param environ: the WSGI environment object to get the path from.\\n    :param charset: the charset for the path, or `None` if no\\n                    decoding should be performed.\\n    :param errors: the decoding error handling.\\n    '\n    path = wsgi_get_bytes(environ.get('SCRIPT_NAME', ''))\n    return to_unicode(environ, charset, errors, allow_none_charset=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_init(self):\n    farm_1 = {\n        'apples': 10,\n        'berries': 32,\n        'squash': 21,\n    }\n    farm_2 = {\n        'apples': 15,\n        'berries': 40,\n        'squash': 17,\n    }\n    data = [farm_1, farm_2]\n    index = ['Farm 1', 'Farm 2']\n    df = pd.DataFrame(data, index=index)\n    group = GroupedBar(df)\n    datas = [{\n        'name': 'table',\n        'values': [{\n            'col': 'apples',\n            'idx': 'Farm 1',\n            'val': 10,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 1',\n            'val': 32,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 1',\n            'val': 21,\n        }, {\n            'col': 'apples',\n            'idx': 'Farm 2',\n            'val': 15,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 2',\n            'val': 40,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 2',\n            'val': 17,\n        }],\n    }]\n    for (i, data) in enumerate(datas):\n        nt.assert_dict_equal(group.data[i].grammar(), data)\n    scales = [{\n        'domain': {\n            'data': 'table',\n            'field': 'data.idx',\n        },\n        'name': 'x',\n        'padding': 0.2,\n        'range': 'width',\n        'type': 'ordinal',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.val',\n        },\n        'name': 'y',\n        'nice': True,\n        'range': 'height',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.col',\n        },\n        'name': 'color',\n        'range': 'category20',\n        'type': 'ordinal',\n    }]\n    axes = [{\n        'scale': 'x',\n        'type': 'x',\n    }, {\n        'scale': 'y',\n        'type': 'y',\n    }]\n    marks = [{\n        'type': 'group',\n        'from': {\n            'data': 'table',\n            'transform': [{\n                'keys': ['data.idx'],\n                'type': 'facet',\n            }],\n        },\n        'marks': [{\n            'type': 'rect',\n            'properties': {\n                'enter': {\n                    'fill': {\n                        'field': 'data.col',\n                        'scale': 'color',\n                    },\n                    'width': {\n                        'band': True,\n                        'offset': (- 1),\n                        'scale': 'pos',\n                    },\n                    'x': {\n                        'field': 'data.col',\n                        'scale': 'pos',\n                    },\n                    'y': {\n                        'field': 'data.val',\n                        'scale': 'y',\n                    },\n                    'y2': {\n                        'scale': 'y',\n                        'value': 0,\n                    },\n                },\n            },\n        }],\n        'properties': {\n            'enter': {\n                'width': {\n                    'band': True,\n                    'scale': 'x',\n                },\n                'x': {\n                    'field': 'key',\n                    'scale': 'x',\n                },\n            },\n        },\n        'scales': [{\n            'domain': {\n                'field': 'data.col',\n            },\n            'name': 'pos',\n            'range': 'width',\n            'type': 'ordinal',\n        }],\n    }]\n    chart_runner(group, scales, axes, marks)\n", "label": "Correct"}
{"function": "\n\ndef test_init(self):\n    farm_1 = {\n        'apples': 10,\n        'berries': 32,\n        'squash': 21,\n    }\n    farm_2 = {\n        'apples': 15,\n        'berries': 40,\n        'squash': 17,\n    }\n    data = [farm_1, farm_2]\n    index = ['Farm 1', 'Farm 2']\n    df = pd.DataFrame(data, index=group)\n    group = GroupedBar(df)\n    datas = [{\n        'name': 'table',\n        'values': [{\n            'col': 'apples',\n            'idx': 'Farm 1',\n            'val': 10,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 1',\n            'val': 32,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 1',\n            'val': 21,\n        }, {\n            'col': 'apples',\n            'idx': 'Farm 2',\n            'val': 15,\n        }, {\n            'col': 'berries',\n            'idx': 'Farm 2',\n            'val': 40,\n        }, {\n            'col': 'squash',\n            'idx': 'Farm 2',\n            'val': 17,\n        }],\n    }]\n    for (i, data) in enumerate(datas):\n        nt.assert_dict_equal(group.data[i].grammar(), data)\n    scales = [{\n        'domain': {\n            'data': 'table',\n            'field': 'data.idx',\n        },\n        'name': 'x',\n        'padding': 0.2,\n        'range': 'width',\n        'type': 'ordinal',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.val',\n        },\n        'name': 'y',\n        'nice': True,\n        'range': 'height',\n    }, {\n        'domain': {\n            'data': 'table',\n            'field': 'data.col',\n        },\n        'name': 'color',\n        'range': 'category20',\n        'type': 'ordinal',\n    }]\n    axes = [{\n        'scale': 'x',\n        'type': 'x',\n    }, {\n        'scale': 'y',\n        'type': 'y',\n    }]\n    marks = [{\n        'type': 'group',\n        'from': {\n            'data': 'table',\n            'transform': [{\n                'keys': ['data.idx'],\n                'type': 'facet',\n            }],\n        },\n        'marks': [{\n            'type': 'rect',\n            'properties': {\n                'enter': {\n                    'fill': {\n                        'field': 'data.col',\n                        'scale': 'color',\n                    },\n                    'width': {\n                        'band': True,\n                        'offset': (- 1),\n                        'scale': 'pos',\n                    },\n                    'x': {\n                        'field': 'data.col',\n                        'scale': 'pos',\n                    },\n                    'y': {\n                        'field': 'data.val',\n                        'scale': 'y',\n                    },\n                    'y2': {\n                        'scale': 'y',\n                        'value': 0,\n                    },\n                },\n            },\n        }],\n        'properties': {\n            'enter': {\n                'width': {\n                    'band': True,\n                    'scale': 'x',\n                },\n                'x': {\n                    'field': 'key',\n                    'scale': 'x',\n                },\n            },\n        },\n        'scales': [{\n            'domain': {\n                'field': 'data.col',\n            },\n            'name': 'pos',\n            'range': 'width',\n            'type': 'ordinal',\n        }],\n    }]\n    chart_runner(group, scales, axes, marks)\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_task_with_policy(queue_name, task_id, owner):\n    'Fetches the specified task and enforces ownership policy.\\n\\n    Args:\\n        queue_name: Name of the queue the work item is on.\\n        task_id: ID of the task that is finished.\\n        owner: Who or what has the current lease on the task.\\n\\n    Returns:\\n        The valid WorkQueue task that is currently owned.\\n\\n    Raises:\\n        TaskDoesNotExistError if the task does not exist.\\n        LeaseExpiredError if the lease is no longer active.\\n        NotOwnerError if the specified owner no longer owns the task.\\n    '\n    now = datetime.datetime.utcnow()\n    task = WorkQueue.query.filter_by(queue_name=queue_name, task_id=task_id).with_lockmode('update').first()\n    if (not task):\n        raise TaskDoesNotExistError(('task_id=%r' % task_id))\n    lease_delta = (now - task.eta)\n    if (lease_delta > datetime.timedelta(0)):\n        db.session.rollback()\n        raise LeaseExpiredError(('queue=%r, task_id=%r expired %s' % (task.queue_name, task_id, lease_delta)))\n    if (task.last_owner != owner):\n        db.session.rollback()\n        raise NotOwnerError(('queue=%r, task_id=%r, owner=%r' % (task.queue_name, task_id, task.last_owner)))\n    return task\n", "label": "Correct"}
{"function": "\n\ndef _get_task_with_policy(queue_name, task_id, owner):\n    'Fetches the specified task and enforces ownership policy.\\n\\n    Args:\\n        queue_name: Name of the queue the work item is on.\\n        task_id: ID of the task that is finished.\\n        owner: Who or what has the current lease on the task.\\n\\n    Returns:\\n        The valid WorkQueue task that is currently owned.\\n\\n    Raises:\\n        TaskDoesNotExistError if the task does not exist.\\n        LeaseExpiredError if the lease is no longer active.\\n        NotOwnerError if the specified owner no longer owns the task.\\n    '\n    now = datetime.datetime.utcnow()\n    task = WorkQueue.query.filter_by(queue_name=queue_name, task_id=task_id).with_lockmode('update').first()\n    if (not task):\n        raise TaskDoesNotExistError(('task_id=%r' % task_id))\n    lease_delta = (now - task.eta)\n    if (lease_delta > datetime.timedelta(0)):\n        db.session.rollback()\n        raise LeaseExpiredError(('queue=%r, task_id=%r expired %s' % (task.queue_name, task_id, lease_delta)))\n    if (task.last_owner != owner):\n        db.session.rollback()\n        raise NotOwnerError(('queue=%r, task_id=%r, owner=%r' % (task.queue_name, task_id, task.last_owner)))\n    return queue_name\n", "label": "Variable misuse"}
{"function": "\n\ndef _rgen(i, prefix='r'):\n    return '{}{}'.format(prefix, i)\n", "label": "Correct"}
{"function": "\n\ndef _rgen(i, prefix='r'):\n    return '{}{}'.format(prefix, prefix)\n", "label": "Variable misuse"}
{"function": "\n\ndef __getattr__(self, item):\n    return getattr(self._tls, item, self._defaults.get(item))\n", "label": "Correct"}
{"function": "\n\ndef __getattr__(self, item):\n    return getattr(self._tls, item, self._defaults.get(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef showSublimeContext(self, filename, line):\n    debug(((('showSublimeContext: ' + str(filename)) + ' : ') + str(line)))\n    console_output((((('@@@ Stopped at ' + str(filename.replace((self.projectDir + '/'), ''))) + ':') + str(line)) + ' @@@'))\n    window = sublime.active_window()\n    if window:\n        window.focus_group(0)\n        view = window.active_view()\n        if ((view is not None) and (view.size() >= 0)):\n            filename = os.path.join(self.projectDir, filename)\n            if (view.file_name() != filename):\n                self.activateViewWithFile(filename, line)\n            window.run_command('goto_line', {\n                'line': line,\n            })\n            view = window.active_view()\n            mark = [view.line(view.text_point((line - 1), 0))]\n            view.erase_regions('current_line')\n            view.add_regions('current_line', mark, 'current_line', 'dot', sublime.DRAW_OUTLINED)\n        else:\n            debug('No current view')\n", "label": "Correct"}
{"function": "\n\ndef showSublimeContext(self, filename, line):\n    debug(((('showSublimeContext: ' + str(filename)) + ' : ') + str(line)))\n    console_output((((('@@@ Stopped at ' + str(filename.replace((self.projectDir + '/'), ''))) + ':') + str(line)) + ' @@@'))\n    window = sublime.active_window()\n    if window:\n        window.focus_group(0)\n        view = window.active_view()\n        if ((view is not None) and (view.size() >= 0)):\n            filename = os.path.join(self.projectDir, filename)\n            if (view.file_name() != filename):\n                self.activateViewWithFile(filename, line)\n            window.run_command('goto_line', {\n                'line': line,\n            })\n            view = window.active_view()\n            mark = [view.line(window.text_point((line - 1), 0))]\n            view.erase_regions('current_line')\n            view.add_regions('current_line', mark, 'current_line', 'dot', sublime.DRAW_OUTLINED)\n        else:\n            debug('No current view')\n", "label": "Variable misuse"}
{"function": "\n\ndef the_local_centroid_is(step, centroid, distance):\n    check_prediction(world.local_centroid['centroid_name'], centroid)\n    check_prediction(world.local_centroid['distance'], distance)\n", "label": "Correct"}
{"function": "\n\ndef the_local_centroid_is(step, centroid, distance):\n    check_prediction(world.local_centroid['centroid_name'], distance)\n    check_prediction(world.local_centroid['distance'], distance)\n", "label": "Variable misuse"}
{"function": "\n\ndef _zones_us_central1_a_disks_node_name(self, method, url, body, headers):\n    body = self.fixtures.load('generic_disk.json')\n    return (httplib.OK, body, self.json_hdr, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _zones_us_central1_a_disks_node_name(self, method, url, body, headers):\n    body = self.fixtures.load('generic_disk.json')\n    return (httplib.OK, method, self.json_hdr, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_diff_nans(self):\n    'Regression test for https://aeon.stsci.edu/ssb/trac/pyfits/ticket/204'\n    arr = np.empty((10, 10), dtype=np.float64)\n    arr[:5] = 1.0\n    arr[5:] = np.nan\n    arr2 = arr.copy()\n    table = np.rec.array([(1.0, 2.0), (3.0, np.nan), (np.nan, np.nan)], names=['cola', 'colb']).view(fits.FITS_rec)\n    table2 = table.copy()\n    assert ImageDataDiff(arr, arr2).identical\n    assert TableDataDiff(table, table2).identical\n    arr2[0][0] = 2.0\n    arr2[5][0] = 2.0\n    table2[0][0] = 2.0\n    table2[1][1] = 2.0\n    diff = ImageDataDiff(arr, arr2)\n    assert (not diff.identical)\n    assert (diff.diff_pixels[0] == ((0, 0), (1.0, 2.0)))\n    assert (diff.diff_pixels[1][0] == (5, 0))\n    assert np.isnan(diff.diff_pixels[1][1][0])\n    assert (diff.diff_pixels[1][1][1] == 2.0)\n    diff = TableDataDiff(table, table2)\n    assert (not diff.identical)\n    assert (diff.diff_values[0] == (('cola', 0), (1.0, 2.0)))\n    assert (diff.diff_values[1][0] == ('colb', 1))\n    assert np.isnan(diff.diff_values[1][1][0])\n    assert (diff.diff_values[1][1][1] == 2.0)\n", "label": "Correct"}
{"function": "\n\ndef test_diff_nans(self):\n    'Regression test for https://aeon.stsci.edu/ssb/trac/pyfits/ticket/204'\n    arr = np.empty((10, 10), dtype=np.float64)\n    arr[:5] = 1.0\n    arr[5:] = np.nan\n    arr2 = arr.copy()\n    table = np.rec.array([(1.0, 2.0), (3.0, np.nan), (np.nan, np.nan)], names=['cola', 'colb']).view(fits.FITS_rec)\n    table2 = table.copy()\n    assert ImageDataDiff(arr, arr2).identical\n    assert TableDataDiff(table, table2).identical\n    arr2[0][0] = 2.0\n    arr2[5][0] = 2.0\n    table2[0][0] = 2.0\n    table2[1][1] = 2.0\n    diff = ImageDataDiff(self, arr2)\n    assert (not diff.identical)\n    assert (diff.diff_pixels[0] == ((0, 0), (1.0, 2.0)))\n    assert (diff.diff_pixels[1][0] == (5, 0))\n    assert np.isnan(diff.diff_pixels[1][1][0])\n    assert (diff.diff_pixels[1][1][1] == 2.0)\n    diff = TableDataDiff(table, table2)\n    assert (not diff.identical)\n    assert (diff.diff_values[0] == (('cola', 0), (1.0, 2.0)))\n    assert (diff.diff_values[1][0] == ('colb', 1))\n    assert np.isnan(diff.diff_values[1][1][0])\n    assert (diff.diff_values[1][1][1] == 2.0)\n", "label": "Variable misuse"}
{"function": "\n\ndef do_command(self, verb, args):\n    conn = http_client.HTTPConnection(self.host, self.port, timeout=self.http_timeout)\n    try:\n        body = ('cmd=' + urllib_parse.quote_plus(unicode(verb).encode('utf-8')))\n        for i in range(len(args)):\n            body += ((('&' + unicode((i + 1))) + '=') + urllib_parse.quote_plus(unicode(args[i]).encode('utf-8')))\n        if (None != self.sessionId):\n            body += ('&sessionId=' + unicode(self.sessionId))\n        headers = {\n            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n        }\n        conn.request('POST', '/selenium-server/driver/', body, headers)\n        response = conn.getresponse()\n        data = unicode(response.read(), 'UTF-8')\n        if (not data.startswith('OK')):\n            raise Exception(data)\n        return data\n    finally:\n        conn.close()\n", "label": "Correct"}
{"function": "\n\ndef do_command(self, verb, args):\n    conn = http_client.HTTPConnection(self.host, self.port, timeout=self.http_timeout)\n    try:\n        body = ('cmd=' + urllib_parse.quote_plus(unicode(verb).encode('utf-8')))\n        for i in range(len(args)):\n            body += ((('&' + unicode((i + 1))) + '=') + urllib_parse.quote_plus(unicode(args[i]).encode('utf-8')))\n        if (None != self.sessionId):\n            body += ('&sessionId=' + unicode(headers.sessionId))\n        headers = {\n            'Content-Type': 'application/x-www-form-urlencoded; charset=utf-8',\n        }\n        conn.request('POST', '/selenium-server/driver/', body, headers)\n        response = conn.getresponse()\n        data = unicode(response.read(), 'UTF-8')\n        if (not data.startswith('OK')):\n            raise Exception(data)\n        return data\n    finally:\n        conn.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef date_to_string(from_date, to_format):\n    return datetime(from_date.year, from_date.month, from_date.day).strftime(to_format)\n", "label": "Correct"}
{"function": "\n\ndef date_to_string(from_date, to_format):\n    return datetime(from_date.year, to_format.month, from_date.day).strftime(to_format)\n", "label": "Variable misuse"}
{"function": "\n\ndef fdiff(self, argindex=1):\n    (z, m) = self.args\n    fm = sqrt((1 - (m * (sin(z) ** 2))))\n    if (argindex == 1):\n        return (1 / fm)\n    elif (argindex == 2):\n        return (((elliptic_e(z, m) / ((2 * m) * (1 - m))) - (elliptic_f(z, m) / (2 * m))) - (sin((2 * z)) / ((4 * (1 - m)) * fm)))\n    raise ArgumentIndexError(self, argindex)\n", "label": "Correct"}
{"function": "\n\ndef fdiff(self, argindex=1):\n    (z, m) = self.args\n    fm = sqrt((1 - (m * (sin(z) ** 2))))\n    if (argindex == 1):\n        return (1 / fm)\n    elif (argindex == 2):\n        return (((elliptic_e(z, m) / ((2 * m) * (1 - argindex))) - (elliptic_f(z, m) / (2 * m))) - (sin((2 * z)) / ((4 * (1 - m)) * fm)))\n    raise ArgumentIndexError(self, argindex)\n", "label": "Variable misuse"}
{"function": "\n\ndef bayesdb_generator_column_stattype(bdb, generator_id, colno):\n    'Return the statistical type of the column `colno` in `generator_id`.'\n    sql = '\\n        SELECT stattype FROM bayesdb_generator_column\\n            WHERE generator_id = ? AND colno = ?\\n    '\n    cursor = bdb.sql_execute(sql, (generator_id, colno))\n    try:\n        row = cursor.next()\n    except StopIteration:\n        generator = bayesdb_generator_name(bdb, generator_id)\n        sql = '\\n            SELECT COUNT(*)\\n                FROM bayesdb_generator AS g, bayesdb_column AS c\\n                WHERE g.id = :generator_id\\n                    AND g.tabname = c.tabname\\n                    AND c.colno = :colno\\n        '\n        cursor = bdb.sql_execute(sql, {\n            'generator_id': generator_id,\n            'colno': colno,\n        })\n        if (cursor_value(cursor) == 0):\n            raise ValueError(('No such column in generator %s: %d' % (generator, colno)))\n        else:\n            raise ValueError(('Column not modelled in generator %s: %d' % (generator, colno)))\n    else:\n        assert (len(row) == 1)\n        return row[0]\n", "label": "Correct"}
{"function": "\n\ndef bayesdb_generator_column_stattype(bdb, generator_id, colno):\n    'Return the statistical type of the column `colno` in `generator_id`.'\n    sql = '\\n        SELECT stattype FROM bayesdb_generator_column\\n            WHERE generator_id = ? AND colno = ?\\n    '\n    cursor = bdb.sql_execute(sql, (generator_id, colno))\n    try:\n        row = cursor.next()\n    except StopIteration:\n        generator = bayesdb_generator_name(bdb, generator_id)\n        sql = '\\n            SELECT COUNT(*)\\n                FROM bayesdb_generator AS g, bayesdb_column AS c\\n                WHERE g.id = :generator_id\\n                    AND g.tabname = c.tabname\\n                    AND c.colno = :colno\\n        '\n        cursor = bdb.sql_execute(sql, {\n            'generator_id': generator,\n            'colno': colno,\n        })\n        if (cursor_value(cursor) == 0):\n            raise ValueError(('No such column in generator %s: %d' % (generator, colno)))\n        else:\n            raise ValueError(('Column not modelled in generator %s: %d' % (generator, colno)))\n    else:\n        assert (len(row) == 1)\n        return row[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, db, callback, **params):\n    self.process_change = callback\n    self.params = params\n    self.db = db\n    self.stop_event = event.Event()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, db, callback, **params):\n    self.process_change = callback\n    self.params = self\n    self.db = db\n    self.stop_event = event.Event()\n", "label": "Variable misuse"}
{"function": "\n\ndef pt_visual_explain(self, display=True):\n    return pt_visual_explain(self, display)\n", "label": "Correct"}
{"function": "\n\ndef pt_visual_explain(self, display=True):\n    return pt_visual_explain(display, display)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_init_kwargs_with_prefix(self):\n    custom_conf = TestConf(TESTS_CUSTOM_VALUE2='custom2')\n    self.assertEqual(custom_conf.TESTS_CUSTOM_VALUE2, 'custom2')\n    self.assertEqual(settings.TESTS_CUSTOM_VALUE2, 'custom2')\n", "label": "Correct"}
{"function": "\n\ndef test_init_kwargs_with_prefix(self):\n    custom_conf = TestConf(TESTS_CUSTOM_VALUE2='custom2')\n    self.assertEqual(self.TESTS_CUSTOM_VALUE2, 'custom2')\n    self.assertEqual(settings.TESTS_CUSTOM_VALUE2, 'custom2')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_serialization_type(self):\n    activity_object = Pin(id=1)\n    activity = Activity(1, LoveVerb, activity_object)\n    assert isinstance(activity.serialization_id, (six.integer_types, float))\n", "label": "Correct"}
{"function": "\n\ndef test_serialization_type(self):\n    activity_object = Pin(id=1)\n    activity = Activity(1, LoveVerb, activity_object)\n    assert isinstance(activity_object.serialization_id, (six.integer_types, float))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unauthenticated_access(self):\n    'Test index page at /api/calendar/events'\n    response = self.client.get('/api/calendar/events')\n    self.assertEquals(response.status_code, 401)\n", "label": "Correct"}
{"function": "\n\ndef test_unauthenticated_access(self):\n    'Test index page at /api/calendar/events'\n    response = self.client.get('/api/calendar/events')\n    response.assertEquals(response.status_code, 401)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, coord, canvas, marker_radius=2, marker_color='green2', timestamp=0):\n    self._marker_color = marker_color\n    self._marker_radius = marker_radius\n    self._coord = coord\n    self._canvas = canvas\n    self._timestamp = timestamp\n    self._canvas_id = None\n    self._is_selected = False\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, coord, canvas, marker_radius=2, marker_color='green2', timestamp=0):\n    self._marker_color = marker_color\n    self._marker_radius = marker_radius\n    self._coord = coord\n    self._canvas = marker_color\n    self._timestamp = timestamp\n    self._canvas_id = None\n    self._is_selected = False\n", "label": "Variable misuse"}
{"function": "\n\ndef job_binary_create(request, name, url, description, extra):\n    return client(request).job_binaries.create(name, url, description, extra)\n", "label": "Correct"}
{"function": "\n\ndef job_binary_create(request, name, url, description, extra):\n    return client(request).job_binaries.create(name, url, description, url)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, from_elem=None, factor=None):\n    self.from_elem = from_elem\n    self.factor = factor\n    self.to_elems = {\n        \n    }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, from_elem=None, factor=None):\n    self.from_elem = from_elem\n    from_elem.factor = factor\n    self.to_elems = {\n        \n    }\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.xfail\ndef test_fails(self):\n    contact = models.Contact(name='Example')\n    contact.put()\n    models.PhoneNumber(contact=self.contact_key, phone_type='home', number='(650) 555 - 2200').put()\n    numbers = contact.phone_numbers.fetch()\n    assert (1 == len(numbers))\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.xfail\ndef test_fails(self):\n    contact = models.Contact(name='Example')\n    contact.put()\n    models.PhoneNumber(contact=self.contact_key, phone_type='home', number='(650) 555 - 2200').put()\n    numbers = numbers.phone_numbers.fetch()\n    assert (1 == len(numbers))\n", "label": "Variable misuse"}
{"function": "\n\ndef _mount_shares_to_instance(self, instance):\n    for share in self.shares:\n        share.handler.allow_access_to_instance(instance, share.share_config)\n    with instance.remote() as remote:\n        share_types = set((type(share.handler) for share in self.shares))\n        for share_type in share_types:\n            share_type.setup_instance(remote)\n        for share in self.shares:\n            share.handler.mount_to_instance(remote, share.share_config)\n", "label": "Correct"}
{"function": "\n\ndef _mount_shares_to_instance(self, instance):\n    for share in self.shares:\n        share.handler.allow_access_to_instance(share_types, share.share_config)\n    with instance.remote() as remote:\n        share_types = set((type(share.handler) for share in self.shares))\n        for share_type in share_types:\n            share_type.setup_instance(remote)\n        for share in self.shares:\n            share.handler.mount_to_instance(remote, share.share_config)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_default_machine(self):\n    ' Reads the default machine from the package configuration\\n        \\n        '\n    server = username = port = password = ''\n    if configuration.check('server'):\n        server = configuration.server\n    if (not server):\n        return None\n    if configuration.check('username'):\n        username = configuration.username\n    if (not username):\n        username = current_user()\n    if (configuration.check('port') is not None):\n        port = configuration.port\n    if configuration.check('password'):\n        password = configuration.password\n    self.annotate({\n        'RemoteQ-server': server,\n        'RemoteQ-username': username,\n        'RemoteQ-port': port,\n    })\n    return (server, port, username, password)\n", "label": "Correct"}
{"function": "\n\ndef get_default_machine(self):\n    ' Reads the default machine from the package configuration\\n        \\n        '\n    server = username = port = password = ''\n    if configuration.check('server'):\n        server = configuration.server\n    if (not server):\n        return None\n    if configuration.check('username'):\n        username = configuration.username\n    if (not username):\n        username = current_user()\n    if (configuration.check('port') is not None):\n        port = configuration.port\n    if configuration.check('password'):\n        password = configuration.password\n    password.annotate({\n        'RemoteQ-server': server,\n        'RemoteQ-username': username,\n        'RemoteQ-port': port,\n    })\n    return (server, port, username, password)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_all_hosts(self):\n    '\\n            Get list of all hosts in cluster\\n            Args:\\n                None\\n            Return:\\n                list of hostnames\\n            Raise:\\n                None\\n       '\n    zook = self.zk_client\n    broker_id_path = self.zk_paths[BROKER_IDS]\n    if zook.exists(broker_id_path):\n        broker_ids = zook.get_children(broker_id_path)\n        brokers = []\n        for broker_id in broker_ids:\n            brokers.append(self.get_host(broker_id))\n        return brokers\n", "label": "Correct"}
{"function": "\n\ndef get_all_hosts(self):\n    '\\n            Get list of all hosts in cluster\\n            Args:\\n                None\\n            Return:\\n                list of hostnames\\n            Raise:\\n                None\\n       '\n    zook = self.zk_client\n    broker_id_path = self.zk_paths[BROKER_IDS]\n    if zook.exists(broker_id_path):\n        broker_ids = broker_id.get_children(broker_id_path)\n        brokers = []\n        for broker_id in broker_ids:\n            brokers.append(self.get_host(broker_id))\n        return brokers\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef Validate(cls, builtins_list, runtime=None):\n    'Verify that all BuiltinHandler objects are valid and not repeated.\\n\\n    Args:\\n      builtins_list: list of BuiltinHandler objects to validate.\\n      runtime: if set then warnings are generated for builtins that have been\\n          deprecated in the given runtime.\\n\\n    Raises:\\n      InvalidBuiltinFormat: if the name of a Builtinhandler object\\n          cannot be determined.\\n      DuplicateBuiltinsSpecified: if a builtin handler name is used\\n          more than once in the list.\\n    '\n    seen = set()\n    for b in builtins_list:\n        if (not b.builtin_name):\n            raise appinfo_errors.InvalidBuiltinFormat(('Name of builtin for list object %s could not be determined.' % b))\n        if (b.builtin_name in seen):\n            raise appinfo_errors.DuplicateBuiltinsSpecified(('Builtin %s was specified more than once in one yaml file.' % b.builtin_name))\n        if ((b.builtin_name == 'datastore_admin') and (runtime == 'python')):\n            logging.warning('The datastore_admin builtin is deprecated. You can find information on how to enable it through the Administrative Console here: http://developers.google.com/appengine/docs/adminconsole/datastoreadmin.html')\n        elif ((b.builtin_name == 'mapreduce') and (runtime == 'python')):\n            logging.warning('The mapreduce builtin is deprecated. You can find more information on how to configure and use it here: http://developers.google.com/appengine/docs/python/dataprocessing/overview.html')\n        seen.add(b.builtin_name)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef Validate(cls, builtins_list, runtime=None):\n    'Verify that all BuiltinHandler objects are valid and not repeated.\\n\\n    Args:\\n      builtins_list: list of BuiltinHandler objects to validate.\\n      runtime: if set then warnings are generated for builtins that have been\\n          deprecated in the given runtime.\\n\\n    Raises:\\n      InvalidBuiltinFormat: if the name of a Builtinhandler object\\n          cannot be determined.\\n      DuplicateBuiltinsSpecified: if a builtin handler name is used\\n          more than once in the list.\\n    '\n    seen = set()\n    for b in builtins_list:\n        if (not b.builtin_name):\n            raise appinfo_errors.InvalidBuiltinFormat(('Name of builtin for list object %s could not be determined.' % b))\n        if (b.builtin_name in seen):\n            raise appinfo_errors.DuplicateBuiltinsSpecified(('Builtin %s was specified more than once in one yaml file.' % b.builtin_name))\n        if ((b.builtin_name == 'datastore_admin') and (runtime == 'python')):\n            logging.warning('The datastore_admin builtin is deprecated. You can find information on how to enable it through the Administrative Console here: http://developers.google.com/appengine/docs/adminconsole/datastoreadmin.html')\n        elif ((b.builtin_name == 'mapreduce') and (runtime == 'python')):\n            logging.warning('The mapreduce builtin is deprecated. You can find more information on how to configure and use it here: http://developers.google.com/appengine/docs/python/dataprocessing/overview.html')\n        seen.add(seen.builtin_name)\n", "label": "Variable misuse"}
{"function": "\n\n@npt.dec.skipif(old_mpl)\ndef test_cached_coherence():\n    'Testing the cached coherence functions '\n    NFFT = 64\n    n_freqs = ((NFFT // 2) + 1)\n    ij = [(0, 1), (1, 0)]\n    ts = np.loadtxt(os.path.join(test_dir_path, 'tseries12.txt'))\n    (freqs, cache) = tsa.cache_fft(ts, ij)\n    npt.assert_equal(freqs, utils.get_freqs((2 * np.pi), NFFT))\n    hann = mlab.window_hanning(np.ones(NFFT))\n    w_ts = (ts[0][:NFFT] * hann)\n    w_ft = fftpack.fft(w_ts)[0:n_freqs]\n    first_window_fft = cache['FFT_slices'][0][0]\n    npt.assert_equal(w_ft, first_window_fft)\n    coh_cached = tsa.cache_to_coherency(cache, ij)[(0, 1)]\n    (f, c) = tsa.coherency(ts)\n    coh_direct = c[(0, 1)]\n    npt.assert_almost_equal(coh_direct, coh_cached)\n    npt.assert_raises(ValueError, tsa.cache_fft, ts, ij, method=methods[2])\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3])\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4])\n    npt.assert_equal(cache1, cache2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3], scale_by_freq=False)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4], scale_by_freq=False)\n    npt.assert_equal(cache1, cache2)\n    psd1 = tsa.cache_to_psd(cache, ij)[0]\n    (f, c) = tsa.get_spectra(ts)\n    psd2 = c[0][0]\n    npt.assert_almost_equal(psd1, psd2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, prefer_speed_over_memory=True)\n    psd1 = tsa.cache_to_psd(cache1, ij)[0]\n    psd2 = tsa.cache_to_psd(cache2, ij)[0]\n    npt.assert_almost_equal(psd1, psd2)\n", "label": "Correct"}
{"function": "\n\n@npt.dec.skipif(old_mpl)\ndef test_cached_coherence():\n    'Testing the cached coherence functions '\n    NFFT = 64\n    n_freqs = ((NFFT // 2) + 1)\n    ij = [(0, 1), (1, 0)]\n    ts = np.loadtxt(os.path.join(test_dir_path, 'tseries12.txt'))\n    (freqs, cache) = tsa.cache_fft(ts, ij)\n    npt.assert_equal(freqs, utils.get_freqs((2 * np.pi), NFFT))\n    hann = mlab.window_hanning(np.ones(NFFT))\n    w_ts = (ts[0][:NFFT] * hann)\n    w_ft = fftpack.fft(w_ts)[0:n_freqs]\n    first_window_fft = cache['FFT_slices'][0][0]\n    npt.assert_equal(freqs, first_window_fft)\n    coh_cached = tsa.cache_to_coherency(cache, ij)[(0, 1)]\n    (f, c) = tsa.coherency(ts)\n    coh_direct = c[(0, 1)]\n    npt.assert_almost_equal(coh_direct, coh_cached)\n    npt.assert_raises(ValueError, tsa.cache_fft, ts, ij, method=methods[2])\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3])\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4])\n    npt.assert_equal(cache1, cache2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij, method=methods[3], scale_by_freq=False)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, method=methods[4], scale_by_freq=False)\n    npt.assert_equal(cache1, cache2)\n    psd1 = tsa.cache_to_psd(cache, ij)[0]\n    (f, c) = tsa.get_spectra(ts)\n    psd2 = c[0][0]\n    npt.assert_almost_equal(psd1, psd2)\n    (freqs, cache1) = tsa.cache_fft(ts, ij)\n    (freqs, cache2) = tsa.cache_fft(ts, ij, prefer_speed_over_memory=True)\n    psd1 = tsa.cache_to_psd(cache1, ij)[0]\n    psd2 = tsa.cache_to_psd(cache2, ij)[0]\n    npt.assert_almost_equal(psd1, psd2)\n", "label": "Variable misuse"}
{"function": "\n\ndef on_monitor(self, model, dataset, algorithm):\n    '\\n        Updates the momentum according to the linear schedule.\\n\\n        Parameters\\n        ----------\\n        model : pylearn2.models.Model\\n            The model to which the training algorithm is applied.\\n        dataset : pylearn2.datasets.Dataset\\n            The dataset to which the model is applied.\\n        algorithm : pylearn2.training_algorithms.TrainingAlgorithm\\n            Describes how gradients should be updated.\\n        '\n    self._count += 1\n    self._apply_momentum(algorithm)\n", "label": "Correct"}
{"function": "\n\ndef on_monitor(self, model, dataset, algorithm):\n    '\\n        Updates the momentum according to the linear schedule.\\n\\n        Parameters\\n        ----------\\n        model : pylearn2.models.Model\\n            The model to which the training algorithm is applied.\\n        dataset : pylearn2.datasets.Dataset\\n            The dataset to which the model is applied.\\n        algorithm : pylearn2.training_algorithms.TrainingAlgorithm\\n            Describes how gradients should be updated.\\n        '\n    self._count += 1\n    dataset._apply_momentum(algorithm)\n", "label": "Variable misuse"}
{"function": "\n\ndef handleInput(self, session, args):\n    ses = {\n        \n    }\n    ses['session'] = session\n    ses['realm'] = args['realm']\n    ses['input'] = args['input']\n    self.broadcast('input', ses)\n", "label": "Correct"}
{"function": "\n\ndef handleInput(self, session, args):\n    ses = {\n        \n    }\n    ses['session'] = session\n    ses['realm'] = args['realm']\n    ses['input'] = args['input']\n    self.broadcast('input', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse(cls, signed_request, application_secret_key):\n    'Parse a signed request, returning a dictionary describing its payload.'\n\n    def decode(encoded):\n        padding = ('=' * (len(encoded) % 4))\n        return base64.urlsafe_b64decode((encoded + padding))\n    try:\n        (encoded_signature, encoded_payload) = (str(string) for string in signed_request.split('.', 2))\n        signature = decode(encoded_signature)\n        signed_request_data = json.loads(decode(encoded_payload).decode('utf-8'))\n    except (TypeError, ValueError):\n        raise SignedRequestError('Signed request had a corrupt payload')\n    if (signed_request_data.get('algorithm', '').upper() != 'HMAC-SHA256'):\n        raise SignedRequestError('Signed request is using an unknown algorithm')\n    expected_signature = hmac.new(application_secret_key.encode('utf-8'), msg=encoded_payload.encode('utf-8'), digestmod=hashlib.sha256).digest()\n    if (signature != expected_signature):\n        raise SignedRequestError('Signed request signature mismatch')\n    return signed_request_data\n", "label": "Correct"}
{"function": "\n\ndef parse(cls, signed_request, application_secret_key):\n    'Parse a signed request, returning a dictionary describing its payload.'\n\n    def decode(encoded):\n        padding = ('=' * (len(encoded) % 4))\n        return base64.urlsafe_b64decode((encoded + padding))\n    try:\n        (encoded_signature, encoded_payload) = (str(application_secret_key) for string in signed_request.split('.', 2))\n        signature = decode(encoded_signature)\n        signed_request_data = json.loads(decode(encoded_payload).decode('utf-8'))\n    except (TypeError, ValueError):\n        raise SignedRequestError('Signed request had a corrupt payload')\n    if (signed_request_data.get('algorithm', '').upper() != 'HMAC-SHA256'):\n        raise SignedRequestError('Signed request is using an unknown algorithm')\n    expected_signature = hmac.new(application_secret_key.encode('utf-8'), msg=encoded_payload.encode('utf-8'), digestmod=hashlib.sha256).digest()\n    if (signature != expected_signature):\n        raise SignedRequestError('Signed request signature mismatch')\n    return signed_request_data\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_declare_passive(self):\n    obj = amqp_queue.Queue(self.chan)\n    expectation = {\n        'arguments': {\n            \n        },\n        'auto_delete': False,\n        'durable': False,\n        'exclusive': False,\n        'nowait': False,\n        'passive': True,\n        'queue': '',\n        'ticket': 0,\n    }\n    self.assertDictEqual(dict(obj._declare(True)), expectation)\n", "label": "Correct"}
{"function": "\n\ndef test_default_declare_passive(self):\n    obj = amqp_queue.Queue(self.chan)\n    expectation = {\n        'arguments': {\n            \n        },\n        'auto_delete': False,\n        'durable': False,\n        'exclusive': False,\n        'nowait': False,\n        'passive': True,\n        'queue': '',\n        'ticket': 0,\n    }\n    obj.assertDictEqual(dict(obj._declare(True)), expectation)\n", "label": "Variable misuse"}
{"function": "\n\ndef update_fc_bias(self, err, out):\n    '\\n        Compute the updated bias gradient for a fully connected network layer.\\n\\n        Arguments:\\n            err (Tensor): backpropagated error\\n            out (Tensor): Where to store the updated gradient value.\\n        '\n    self.ng.sum(err, axis=1, out=out)\n", "label": "Correct"}
{"function": "\n\ndef update_fc_bias(self, err, out):\n    '\\n        Compute the updated bias gradient for a fully connected network layer.\\n\\n        Arguments:\\n            err (Tensor): backpropagated error\\n            out (Tensor): Where to store the updated gradient value.\\n        '\n    self.ng.sum(self, axis=1, out=out)\n", "label": "Variable misuse"}
{"function": "\n\ndef convert_values(self, value, field, connection):\n    'Convert the database-returned value into a type that is consistent\\n        across database backends.\\n\\n        By default, this defers to the underlying backend operations, but\\n        it can be overridden by Query classes for specific backends.\\n        '\n    return connection.ops.convert_values(value, field)\n", "label": "Correct"}
{"function": "\n\ndef convert_values(self, value, field, connection):\n    'Convert the database-returned value into a type that is consistent\\n        across database backends.\\n\\n        By default, this defers to the underlying backend operations, but\\n        it can be overridden by Query classes for specific backends.\\n        '\n    return connection.ops.convert_values(field, field)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(TestClientInvalidResponse, self).__init__()\n    self.broken = True\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(TestClientInvalidResponse, kwargs).__init__()\n    self.broken = True\n", "label": "Variable misuse"}
{"function": "\n\ndef _xmlrpc__hosting_disk_list(self, method, url, body, headers):\n    body = self.fixtures.load('disk_list.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _xmlrpc__hosting_disk_list(self, method, url, body, headers):\n    body = url.fixtures.load('disk_list.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, df, scale, seed=None):\n    '\\n        Create a frozen inverse Wishart distribution.\\n\\n        Parameters\\n        ----------\\n        df : array_like\\n            Degrees of freedom of the distribution\\n        scale : array_like\\n            Scale matrix of the distribution\\n        seed : None or int or np.random.RandomState instance, optional\\n            This parameter defines the RandomState object to use for drawing\\n            random variates.\\n            If None (or np.random), the global np.random state is used.\\n            If integer, it is used to seed the local RandomState instance\\n            Default is None.\\n\\n        '\n    self._dist = invwishart_gen(seed)\n    (self.dim, self.df, self.scale) = self._dist._process_parameters(df, scale)\n    (C, lower) = scipy.linalg.cho_factor(self.scale, lower=True)\n    self.log_det_scale = (2 * np.sum(np.log(C.diagonal())))\n    eye = np.eye(self.dim)\n    self.inv_scale = scipy.linalg.cho_solve((C, lower), eye)\n    self.C = scipy.linalg.cholesky(self.inv_scale, lower=True)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, df, scale, seed=None):\n    '\\n        Create a frozen inverse Wishart distribution.\\n\\n        Parameters\\n        ----------\\n        df : array_like\\n            Degrees of freedom of the distribution\\n        scale : array_like\\n            Scale matrix of the distribution\\n        seed : None or int or np.random.RandomState instance, optional\\n            This parameter defines the RandomState object to use for drawing\\n            random variates.\\n            If None (or np.random), the global np.random state is used.\\n            If integer, it is used to seed the local RandomState instance\\n            Default is None.\\n\\n        '\n    self._dist = invwishart_gen(seed)\n    (self.dim, self.df, self.scale) = C._dist._process_parameters(df, scale)\n    (C, lower) = scipy.linalg.cho_factor(self.scale, lower=True)\n    self.log_det_scale = (2 * np.sum(np.log(C.diagonal())))\n    eye = np.eye(self.dim)\n    self.inv_scale = scipy.linalg.cho_solve((C, lower), eye)\n    self.C = scipy.linalg.cholesky(self.inv_scale, lower=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef backed_value(self, key, default=None):\n    return self.backing_store.get(self.identifier, key, default)\n", "label": "Correct"}
{"function": "\n\ndef backed_value(self, key, default=None):\n    return key.backing_store.get(self.identifier, key, default)\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, key, default=None):\n    'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n    return self._data.get(self._transform(key), default)\n", "label": "Correct"}
{"function": "\n\ndef get(self, key, default=None):\n    'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'\n    return self._data.get(key._transform(key), default)\n", "label": "Variable misuse"}
{"function": "\n\ndef Connect(*args, **kwargs):\n    'Shortcut for creating a connection.MySQLConnection object.'\n    return MySQLConnection(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef Connect(*args, **kwargs):\n    'Shortcut for creating a connection.MySQLConnection object.'\n    return MySQLConnection(*kwargs, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef assemble(self):\n    assembled = {\n        self.type: self.body,\n    }\n    if self.aggregations:\n        assembled['aggs'] = {\n            \n        }\n        for agg in self.aggregations:\n            assembled['aggs'][agg.name] = agg.assemble()\n    return assembled\n", "label": "Correct"}
{"function": "\n\ndef assemble(self):\n    assembled = {\n        self.type: self.body,\n    }\n    if agg.aggregations:\n        assembled['aggs'] = {\n            \n        }\n        for agg in self.aggregations:\n            assembled['aggs'][agg.name] = agg.assemble()\n    return assembled\n", "label": "Variable misuse"}
{"function": "\n\ndef _ml_train_iterative(self, database_matrix, params=[], sliding_window=168, k=1):\n    '\\n            Training method used by Fred 09 paper.\\n        '\n    p = (database_matrix.shape[1] - 1)\n    number_iterations = ((((database_matrix.shape[0] + p) - k) - sliding_window) + 1)\n    print('Number of iterations: ', number_iterations)\n    tr_size = ((sliding_window - p) - 1)\n    z = (database_matrix[0:(- k), 1].reshape((- 1), 1) * np.ones((1, p)))\n    database_matrix[k:, 1:] = (database_matrix[k:, 1:] - z)\n    pr_target = []\n    ex_target = []\n    for i in range(number_iterations):\n        self._ml_train(database_matrix[(k + i):(((k + i) + tr_size) - 1), :], params)\n        pr_t = self._ml_predict(horizon=1)\n        pr_t = (pr_t[0][0] + z[(i, 0)])\n        pr_target.append(pr_t)\n        ex_target.append(database_matrix[(((k + i) + tr_size), 0)])\n    pr_result = Error(expected=ex_target, predicted=pr_target)\n    return pr_result\n", "label": "Correct"}
{"function": "\n\ndef _ml_train_iterative(self, database_matrix, params=[], sliding_window=168, k=1):\n    '\\n            Training method used by Fred 09 paper.\\n        '\n    p = (database_matrix.shape[1] - 1)\n    number_iterations = ((((database_matrix.shape[0] + p) - k) - sliding_window) + 1)\n    print('Number of iterations: ', number_iterations)\n    tr_size = ((sliding_window - p) - 1)\n    z = (database_matrix[0:(- k), 1].reshape((- 1), 1) * np.ones((1, p)))\n    database_matrix[k:, 1:] = (database_matrix[k:, 1:] - z)\n    pr_target = []\n    ex_target = []\n    for i in range(number_iterations):\n        self._ml_train(database_matrix[(k + i):(((k + i) + tr_size) - 1), :], params)\n        pr_t = self._ml_predict(horizon=1)\n        pr_t = (pr_target[0][0] + z[(i, 0)])\n        pr_target.append(pr_t)\n        ex_target.append(database_matrix[(((k + i) + tr_size), 0)])\n    pr_result = Error(expected=ex_target, predicted=pr_target)\n    return pr_result\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    \" Add an issue to the test repository and save it's id.\"\n    super(IssueCommentAuthenticatedMethodsTest, self).setUp()\n    (success, result) = self.bb.issue.create(title='Test Issue Bitbucket API', content='Test Issue Bitbucket API', responsible=self.bb.username, status='new', kind='bug')\n    assert success\n    self.bb.issue.comment.issue_id = result['local_id']\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    \" Add an issue to the test repository and save it's id.\"\n    super(IssueCommentAuthenticatedMethodsTest, self).setUp()\n    (success, result) = self.bb.issue.create(title='Test Issue Bitbucket API', content='Test Issue Bitbucket API', responsible=self.bb.username, status='new', kind='bug')\n    assert result\n    self.bb.issue.comment.issue_id = result['local_id']\n", "label": "Variable misuse"}
{"function": "\n\ndef match(self, request=None):\n    '\\n            Match this item against request (uses GET vars)\\n\\n            @param request: the request object (defaults to current.request)\\n\\n            @return: the match level (integer):\\n                        0=no match\\n                        1=controller\\n                        2=controller+function\\n                        3=controller+function+args\\n                        4=controller+function+args+vars\\n\\n            @note: currently ignores numerical arguments in the request,\\n                   which is though subject to change (in order to support\\n                   numerical arguments in the item)\\n        '\n    level = 0\n    args = self.args\n    link_vars = self.vars\n    if ((self.application is not None) and (self.application != request.application)):\n        return 0\n    if (self.opts.selectable is False):\n        return 0\n    check = self.check_hook()\n    if check:\n        enabled = self.check_enabled()\n        if (not enabled):\n            check = False\n    if (not check):\n        return 0\n    if (request is None):\n        request = current.request\n    c = self.get('controller')\n    mc = self.get('match_controller')\n    if ((not c) and (self.parent is None)):\n        return 1\n    rvars = request.get_vars\n    controller = request.controller\n    function = request.function\n    if ('viewing' in rvars):\n        try:\n            (tn, record_id) = rvars['viewing'].split('.')\n            (controller, function) = tn.split('_', 1)\n        except:\n            pass\n    if ((controller == c) or (controller in mc)):\n        level = 1\n    if (level == 1):\n        f = self.get('function')\n        mf = self.get('match_function')\n        if ((function == f) or (function in mf)):\n            level = 2\n        elif (f == 'index'):\n            return 1\n        elif (f is not None):\n            return 0\n    if (level == 2):\n        extra = 1\n        for (k, v) in link_vars.iteritems():\n            if ((k not in rvars) or ((k in rvars) and (rvars[k] != s3_unicode(v)))):\n                extra = 0\n                break\n            else:\n                extra = 2\n        rargs = request.args\n        if rargs:\n            if args:\n                largs = [a for a in request.args if (not a.isdigit())]\n                if ((len(args) == len(largs)) and all([(args[i] == largs[i]) for i in xrange(len(args))])):\n                    level = 5\n                elif ((len(rargs) >= len(args) > 0) and rargs[(len(args) - 1)].isdigit() and (not str(args[(- 1)]).isdigit())):\n                    level = 1\n                else:\n                    return 0\n            else:\n                level = 3\n        elif args:\n            return 0\n        else:\n            level = 5\n        level += extra\n    return level\n", "label": "Correct"}
{"function": "\n\ndef match(self, request=None):\n    '\\n            Match this item against request (uses GET vars)\\n\\n            @param request: the request object (defaults to current.request)\\n\\n            @return: the match level (integer):\\n                        0=no match\\n                        1=controller\\n                        2=controller+function\\n                        3=controller+function+args\\n                        4=controller+function+args+vars\\n\\n            @note: currently ignores numerical arguments in the request,\\n                   which is though subject to change (in order to support\\n                   numerical arguments in the item)\\n        '\n    level = 0\n    args = self.args\n    link_vars = largs.vars\n    if ((self.application is not None) and (self.application != request.application)):\n        return 0\n    if (self.opts.selectable is False):\n        return 0\n    check = self.check_hook()\n    if check:\n        enabled = self.check_enabled()\n        if (not enabled):\n            check = False\n    if (not check):\n        return 0\n    if (request is None):\n        request = current.request\n    c = self.get('controller')\n    mc = self.get('match_controller')\n    if ((not c) and (self.parent is None)):\n        return 1\n    rvars = request.get_vars\n    controller = request.controller\n    function = request.function\n    if ('viewing' in rvars):\n        try:\n            (tn, record_id) = rvars['viewing'].split('.')\n            (controller, function) = tn.split('_', 1)\n        except:\n            pass\n    if ((controller == c) or (controller in mc)):\n        level = 1\n    if (level == 1):\n        f = self.get('function')\n        mf = self.get('match_function')\n        if ((function == f) or (function in mf)):\n            level = 2\n        elif (f == 'index'):\n            return 1\n        elif (f is not None):\n            return 0\n    if (level == 2):\n        extra = 1\n        for (k, v) in link_vars.iteritems():\n            if ((k not in rvars) or ((k in rvars) and (rvars[k] != s3_unicode(v)))):\n                extra = 0\n                break\n            else:\n                extra = 2\n        rargs = request.args\n        if rargs:\n            if args:\n                largs = [a for a in request.args if (not a.isdigit())]\n                if ((len(args) == len(largs)) and all([(args[i] == largs[i]) for i in xrange(len(args))])):\n                    level = 5\n                elif ((len(rargs) >= len(args) > 0) and rargs[(len(args) - 1)].isdigit() and (not str(args[(- 1)]).isdigit())):\n                    level = 1\n                else:\n                    return 0\n            else:\n                level = 3\n        elif args:\n            return 0\n        else:\n            level = 5\n        level += extra\n    return level\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_security_group_rule(self, context, rule_id):\n    self._delete_resource(context, 'security_group_rule', rule_id)\n", "label": "Correct"}
{"function": "\n\ndef delete_security_group_rule(self, context, rule_id):\n    self._delete_resource(context, 'security_group_rule', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, client_id, result_filename, *args, **kwargs):\n    super(RekallMock, self).__init__(*args, **kwargs)\n    self.result_filename = result_filename\n    self.client_id = client_id\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, client_id, result_filename, *args, **kwargs):\n    super(RekallMock, self).__init__(*args, **kwargs)\n    args.result_filename = result_filename\n    self.client_id = client_id\n", "label": "Variable misuse"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    assert (not cls._meta.has_auto_field), \"A model can't have more than one AutoField.\"\n    super(AutoField, self).contribute_to_class(cls, name)\n    cls._meta.has_auto_field = True\n    cls._meta.auto_field = self\n", "label": "Correct"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    assert (not name._meta.has_auto_field), \"A model can't have more than one AutoField.\"\n    super(AutoField, self).contribute_to_class(cls, name)\n    cls._meta.has_auto_field = True\n    cls._meta.auto_field = self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_server_tags_index(self):\n    uuid = self._put_server_tags()\n    response = self._do_get(('servers/%s/tags' % uuid))\n    subs = self._get_regexes()\n    subs['tag'] = '[0-9a-zA-Z]+'\n    self._verify_response('server-tags-index-resp', subs, response, 200)\n", "label": "Correct"}
{"function": "\n\ndef test_server_tags_index(self):\n    uuid = self._put_server_tags()\n    response = self._do_get(('servers/%s/tags' % uuid))\n    subs = self._get_regexes()\n    subs['tag'] = '[0-9a-zA-Z]+'\n    self._verify_response('server-tags-index-resp', subs, self, 200)\n", "label": "Variable misuse"}
{"function": "\n\ndef select_from(self, clause):\n    'return a new :class:`.Exists` construct, applying the given\\n        expression to the :meth:`.Select.select_from` method of the select\\n        statement contained.\\n\\n        '\n    e = self._clone()\n    e.element = self.element.select_from(clause).self_group()\n    return e\n", "label": "Correct"}
{"function": "\n\ndef select_from(self, clause):\n    'return a new :class:`.Exists` construct, applying the given\\n        expression to the :meth:`.Select.select_from` method of the select\\n        statement contained.\\n\\n        '\n    e = clause._clone()\n    e.element = self.element.select_from(clause).self_group()\n    return e\n", "label": "Variable misuse"}
{"function": "\n\ndef AddMailEntry(self, mail_message, mail_item_properties=None, mail_labels=None, identifier=None):\n    'Prepares a list of mail messages to import using ImportMultipleMails.\\n    \\n    Args:\\n      mail_message: An RFC822 format email message as a string.\\n      mail_item_properties: List of Gmail properties to apply to the\\n          message.\\n      mail_labels: List of Gmail labels to apply to the message.\\n      identifier: The optional file identifier string\\n    \\n    Returns:\\n      The number of email messages to be imported.\\n    '\n    mail_entry_properties = MailEntryProperties(mail_message=mail_message, mail_item_properties=mail_item_properties, mail_labels=mail_labels, identifier=identifier)\n    self.mail_entries.append(mail_entry_properties)\n    return len(self.mail_entries)\n", "label": "Correct"}
{"function": "\n\ndef AddMailEntry(self, mail_message, mail_item_properties=None, mail_labels=None, identifier=None):\n    'Prepares a list of mail messages to import using ImportMultipleMails.\\n    \\n    Args:\\n      mail_message: An RFC822 format email message as a string.\\n      mail_item_properties: List of Gmail properties to apply to the\\n          message.\\n      mail_labels: List of Gmail labels to apply to the message.\\n      identifier: The optional file identifier string\\n    \\n    Returns:\\n      The number of email messages to be imported.\\n    '\n    mail_entry_properties = MailEntryProperties(mail_message=mail_message, mail_item_properties=mail_labels, mail_labels=mail_labels, identifier=identifier)\n    self.mail_entries.append(mail_entry_properties)\n    return len(self.mail_entries)\n", "label": "Variable misuse"}
{"function": "\n\ndef _connect_echo_server(self):\n    self.server.upstream_host = '127.0.0.1'\n    self.server.upstream_port = 7599\n    stop_op = StopProxy(self.server, self.response_factory, self.key)\n    start_op = StartProxy(self.server, self.response_factory, self.key)\n    log.msg(((('Upstream host changed to echo server: ' + str(self.server.upstream_host)) + ':') + str(self.server.upstream_port)))\n    return self.addCallback(stop_op.stop).addCallback(start_op.start)\n", "label": "Correct"}
{"function": "\n\ndef _connect_echo_server(self):\n    stop_op.server.upstream_host = '127.0.0.1'\n    self.server.upstream_port = 7599\n    stop_op = StopProxy(self.server, self.response_factory, self.key)\n    start_op = StartProxy(self.server, self.response_factory, self.key)\n    log.msg(((('Upstream host changed to echo server: ' + str(self.server.upstream_host)) + ':') + str(self.server.upstream_port)))\n    return self.addCallback(stop_op.stop).addCallback(start_op.start)\n", "label": "Variable misuse"}
{"function": "\n\ndef convert_value(self, value, expression, connection, context):\n    return connection.ops.convert_extent3d(value, context.get('transformed_srid'))\n", "label": "Correct"}
{"function": "\n\ndef convert_value(self, value, expression, connection, context):\n    return self.ops.convert_extent3d(value, context.get('transformed_srid'))\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, filepath, version=None, mode='r'):\n    'Returns a bytestring with the file content, but no metadata.'\n    file_stream = self.open(filepath, version=version, mode=mode)\n    if (file_stream is None):\n        raise IOError(('File %s (version %s) not found.' % (filepath, (version if version else 'latest'))))\n    return file_stream.read()\n", "label": "Correct"}
{"function": "\n\ndef get(self, filepath, version=None, mode='r'):\n    'Returns a bytestring with the file content, but no metadata.'\n    file_stream = self.open(filepath, version=file_stream, mode=mode)\n    if (file_stream is None):\n        raise IOError(('File %s (version %s) not found.' % (filepath, (version if version else 'latest'))))\n    return file_stream.read()\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('nova.consoleauth.rpcapi.ConsoleAuthAPI.check_token')\ndef test_new_websocket_client_novnc_bad_origin_header(self, check_token):\n    check_token.return_value = {\n        'host': 'node1',\n        'port': '10000',\n        'console_type': 'novnc',\n    }\n    self.wh.path = 'http://127.0.0.1/'\n    self.wh.headers.getheader = self._fake_getheader_bad_origin\n    self.assertRaises(exception.ValidationError, self.wh.new_websocket_client)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('nova.consoleauth.rpcapi.ConsoleAuthAPI.check_token')\ndef test_new_websocket_client_novnc_bad_origin_header(self, check_token):\n    check_token.return_value = {\n        'host': 'node1',\n        'port': '10000',\n        'console_type': 'novnc',\n    }\n    self.wh.path = 'http://127.0.0.1/'\n    self.wh.headers.getheader = check_token._fake_getheader_bad_origin\n    self.assertRaises(exception.ValidationError, self.wh.new_websocket_client)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_api(self):\n    resp = requests.get(self.api_url, headers={\n        'X-Requested-With': 'XMLHttpRequest',\n    })\n    self.assertEqual(resp.status_code, 200)\n    self.assertEqual(resp.json()['res']['value'], 'python')\n", "label": "Correct"}
{"function": "\n\ndef test_get_api(self):\n    resp = requests.get(self.api_url, headers={\n        'X-Requested-With': 'XMLHttpRequest',\n    })\n    self.assertEqual(resp.status_code, 200)\n    resp.assertEqual(resp.json()['res']['value'], 'python')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, user, entity, org_claim_token):\n    super(ClaimOrgEmail, self).__init__(type=self.type, subject=('Become the administrator of %s on Jumo' % entity.get_name.title()), user=user, entity=entity, org_claim_token=org_claim_token)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, user, entity, org_claim_token):\n    super(ClaimOrgEmail, self).__init__(type=user.type, subject=('Become the administrator of %s on Jumo' % entity.get_name.title()), user=user, entity=entity, org_claim_token=org_claim_token)\n", "label": "Variable misuse"}
{"function": "\n\n@require_can_edit_fixtures\ndef download_item_lists(request, domain):\n    'Asynchronously serve excel download for edit_lookup_tables\\n    '\n    download = DownloadBase()\n    download.set_task(fixture_download_async.delay(prepare_fixture_download, table_ids=request.POST.getlist('table_ids[]', []), domain=domain, download_id=download.download_id))\n    return download.get_start_response()\n", "label": "Correct"}
{"function": "\n\n@require_can_edit_fixtures\ndef download_item_lists(request, domain):\n    'Asynchronously serve excel download for edit_lookup_tables\\n    '\n    download = DownloadBase()\n    download.set_task(fixture_download_async.delay(prepare_fixture_download, table_ids=request.POST.getlist('table_ids[]', []), domain=domain, download_id=request.download_id))\n    return download.get_start_response()\n", "label": "Variable misuse"}
{"function": "\n\ndef read_bytesmap(f):\n    numpairs = read_short(f)\n    bytesmap = {\n        \n    }\n    for _ in range(numpairs):\n        k = read_string(f)\n        bytesmap[k] = read_value(f)\n    return bytesmap\n", "label": "Correct"}
{"function": "\n\ndef read_bytesmap(f):\n    numpairs = read_short(f)\n    bytesmap = {\n        \n    }\n    for _ in range(numpairs):\n        k = read_string(f)\n        bytesmap[_] = read_value(f)\n    return bytesmap\n", "label": "Variable misuse"}
{"function": "\n\ndef list_association_sets(self, query_string=''):\n    'Lists all your association sets.\\n\\n        '\n    return self._list(self.association_set_url, query_string)\n", "label": "Correct"}
{"function": "\n\ndef list_association_sets(self, query_string=''):\n    'Lists all your association sets.\\n\\n        '\n    return query_string._list(self.association_set_url, query_string)\n", "label": "Variable misuse"}
{"function": "\n\ndef take_action(self, parsed_args):\n    service_client = self.app.client_manager.identity\n    service_client.federation.service_providers.delete(parsed_args.service_provider)\n", "label": "Correct"}
{"function": "\n\ndef take_action(self, parsed_args):\n    service_client = self.app.client_manager.identity\n    parsed_args.federation.service_providers.delete(parsed_args.service_provider)\n", "label": "Variable misuse"}
{"function": "\n\ndef clearAlert(self):\n    ' Clear the current alert level, if any.\\n\\n        '\n    if (self._alert_data is not None):\n        self._alert_data.timer.stop()\n        self._alert_data = None\n        app = QApplication.instance()\n        app.focusChanged.disconnect(self._onAppFocusChanged)\n        self.alerted.emit('')\n", "label": "Correct"}
{"function": "\n\ndef clearAlert(self):\n    ' Clear the current alert level, if any.\\n\\n        '\n    if (self._alert_data is not None):\n        self._alert_data.timer.stop()\n        app._alert_data = None\n        app = QApplication.instance()\n        app.focusChanged.disconnect(self._onAppFocusChanged)\n        self.alerted.emit('')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_evt_response_order(self):\n    expected_items = [('this', 'succeeded'), ('by', 'testing'), ('the', 'messages'), ('with', ['spam', 'egg'])]\n    expected = dict(expected_items)\n    result = sharknado.make_evt_response(expected['by'], expected['with'], expected['this'])\n    self.assertEqual(expected_items, list(iteritems(result)))\n", "label": "Correct"}
{"function": "\n\ndef test_evt_response_order(self):\n    expected_items = [('this', 'succeeded'), ('by', 'testing'), ('the', 'messages'), ('with', ['spam', 'egg'])]\n    expected = dict(expected_items)\n    result = sharknado.make_evt_response(expected['by'], expected['with'], expected['this'])\n    self.assertEqual(expected_items, list(iteritems(self)))\n", "label": "Variable misuse"}
{"function": "\n\ndef np_complex_cos_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(sig, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.ccosf',\n        types.complex128: 'numba.npymath.ccos',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, args, dispatch_table, 'cos')\n", "label": "Correct"}
{"function": "\n\ndef np_complex_cos_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(sig, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.ccosf',\n        types.complex128: 'numba.npymath.ccos',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, builder, dispatch_table, 'cos')\n", "label": "Variable misuse"}
{"function": "\n\ndef upload_form(self):\n    '\\n            Instantiate file upload form and return it.\\n\\n            Override to implement custom behavior.\\n        '\n    upload_form_class = self.get_upload_form()\n    if request.form:\n        formdata = request.form.copy()\n        formdata.update(request.files)\n        return upload_form_class(formdata, admin=self)\n    elif request.files:\n        return upload_form_class(request.files, admin=self)\n    else:\n        return upload_form_class(admin=self)\n", "label": "Correct"}
{"function": "\n\ndef upload_form(self):\n    '\\n            Instantiate file upload form and return it.\\n\\n            Override to implement custom behavior.\\n        '\n    upload_form_class = upload_form_class.get_upload_form()\n    if request.form:\n        formdata = request.form.copy()\n        formdata.update(request.files)\n        return upload_form_class(formdata, admin=self)\n    elif request.files:\n        return upload_form_class(request.files, admin=self)\n    else:\n        return upload_form_class(admin=self)\n", "label": "Variable misuse"}
{"function": "\n\ndef make_node(self, images):\n    '\\n        .. todo::\\n\\n            WRITEME\\n        '\n    images = as_cuda_ndarray_variable(images)\n    assert (images.ndim == 4)\n    channels_broadcastable = images.type.broadcastable[0]\n    batch_broadcastable = images.type.broadcastable[3]\n    rows_broadcastable = False\n    cols_broadcastable = False\n    targets_broadcastable = (channels_broadcastable, rows_broadcastable, cols_broadcastable, batch_broadcastable)\n    targets_type = CudaNdarrayType(broadcastable=targets_broadcastable)\n    targets = targets_type()\n    return Apply(self, [images], [targets])\n", "label": "Correct"}
{"function": "\n\ndef make_node(self, images):\n    '\\n        .. todo::\\n\\n            WRITEME\\n        '\n    images = as_cuda_ndarray_variable(rows_broadcastable)\n    assert (images.ndim == 4)\n    channels_broadcastable = images.type.broadcastable[0]\n    batch_broadcastable = images.type.broadcastable[3]\n    rows_broadcastable = False\n    cols_broadcastable = False\n    targets_broadcastable = (channels_broadcastable, rows_broadcastable, cols_broadcastable, batch_broadcastable)\n    targets_type = CudaNdarrayType(broadcastable=targets_broadcastable)\n    targets = targets_type()\n    return Apply(self, [images], [targets])\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_url(self, url):\n    if (self.access == 'public'):\n        url = url.replace('https://', 'http://')\n        req = urllib.request.Request(url)\n        try:\n            return urllib.request.urlopen(req).read()\n        except urllib.error.HTTPError:\n            raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n    else:\n        raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n", "label": "Correct"}
{"function": "\n\ndef _get_url(self, url):\n    if (self.access == 'public'):\n        url = req.replace('https://', 'http://')\n        req = urllib.request.Request(url)\n        try:\n            return urllib.request.urlopen(req).read()\n        except urllib.error.HTTPError:\n            raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n    else:\n        raise NotImplementedError('Currently, DocumentCloud only allows you to access this resource on public documents.')\n", "label": "Variable misuse"}
{"function": "\n\ndef downcaseTokens(s, l, t):\n    'Helper parse action to convert tokens to lower case.'\n    return [tt.lower() for tt in map(_ustr, t)]\n", "label": "Correct"}
{"function": "\n\ndef downcaseTokens(s, l, t):\n    'Helper parse action to convert tokens to lower case.'\n    return [tt.lower() for tt in map(_ustr, l)]\n", "label": "Variable misuse"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20101102__ia__general__poweshiek__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20101102__ia__general__poweshiek__precinct.xls'\n    mapping = self._get_mapping(filename)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    montezuma_abs_results = [r for r in results if ((r.jurisdiction == 'Montezuma') and (r.votes_type == 'absentee'))]\n    self.assertEqual(len(montezuma_abs_results), 34)\n    result = montezuma_abs_results[0]\n    self.assertEqual(result.office, 'United States Senator')\n    self.assertEqual(result.district, None)\n    self.assertEqual(result.full_name, 'Roxanne Conlin')\n    self.assertEqual(result.party, 'DEM')\n    self.assertEqual(result.write_in, None)\n    self.assertEqual(result.votes, 59)\n    result = montezuma_abs_results[(- 1)]\n    self.assertEqual(result.office, 'State Rep')\n    self.assertEqual(result.district, '75')\n    self.assertEqual(result.full_name, 'Write-In')\n    self.assertEqual(result.party, None)\n    self.assertEqual(result.write_in, 'Write-In')\n    self.assertEqual(result.votes, 0)\n", "label": "Correct"}
{"function": "\n\n@skipUnless(cache_file_exists('ia', '20101102__ia__general__poweshiek__precinct.xls'), CACHED_FILE_MISSING_MSG)\ndef test_results(self):\n    filename = '20101102__ia__general__poweshiek__precinct.xls'\n    mapping = self._get_mapping(montezuma_abs_results)\n    self._prep_loader_attrs(mapping)\n    results = self.loader._results(mapping)\n    montezuma_abs_results = [r for r in results if ((r.jurisdiction == 'Montezuma') and (r.votes_type == 'absentee'))]\n    self.assertEqual(len(montezuma_abs_results), 34)\n    result = montezuma_abs_results[0]\n    self.assertEqual(result.office, 'United States Senator')\n    self.assertEqual(result.district, None)\n    self.assertEqual(result.full_name, 'Roxanne Conlin')\n    self.assertEqual(result.party, 'DEM')\n    self.assertEqual(result.write_in, None)\n    self.assertEqual(result.votes, 59)\n    result = montezuma_abs_results[(- 1)]\n    self.assertEqual(result.office, 'State Rep')\n    self.assertEqual(result.district, '75')\n    self.assertEqual(result.full_name, 'Write-In')\n    self.assertEqual(result.party, None)\n    self.assertEqual(result.write_in, 'Write-In')\n    self.assertEqual(result.votes, 0)\n", "label": "Variable misuse"}
{"function": "\n\n@cached_property\ndef deliveries(self):\n    ' Get delivery log from Redis'\n    key = make_key(event=self.object.event, owner_name=self.object.owner.username, identifier=self.object.identifier)\n    return redis.lrange(key, 0, 20)\n", "label": "Correct"}
{"function": "\n\n@cached_property\ndef deliveries(self):\n    ' Get delivery log from Redis'\n    key = make_key(event=self.object.event, owner_name=self.object.owner.username, identifier=key.object.identifier)\n    return redis.lrange(key, 0, 20)\n", "label": "Variable misuse"}
{"function": "\n\ndef _as_vector(self, keep_channels=False):\n    '\\n        The vectorized form of this image.\\n\\n        Parameters\\n        ----------\\n        keep_channels : `bool`, optional\\n\\n            ========== =============================\\n            Value      Return shape\\n            ========== =============================\\n            `False`    ``(n_channels * n_pixels,)``\\n            `True`     ``(n_channels, n_pixels)``\\n            ========== =============================\\n\\n        Returns\\n        -------\\n        vec : (See ``keep_channels`` above) `ndarray`\\n            Flattened representation of this image, containing all pixel\\n            and channel information.\\n        '\n    if keep_channels:\n        return self.pixels.reshape([self.n_channels, (- 1)])\n    else:\n        return self.pixels.ravel()\n", "label": "Correct"}
{"function": "\n\ndef _as_vector(self, keep_channels=False):\n    '\\n        The vectorized form of this image.\\n\\n        Parameters\\n        ----------\\n        keep_channels : `bool`, optional\\n\\n            ========== =============================\\n            Value      Return shape\\n            ========== =============================\\n            `False`    ``(n_channels * n_pixels,)``\\n            `True`     ``(n_channels, n_pixels)``\\n            ========== =============================\\n\\n        Returns\\n        -------\\n        vec : (See ``keep_channels`` above) `ndarray`\\n            Flattened representation of this image, containing all pixel\\n            and channel information.\\n        '\n    if keep_channels:\n        return keep_channels.pixels.reshape([self.n_channels, (- 1)])\n    else:\n        return self.pixels.ravel()\n", "label": "Variable misuse"}
{"function": "\n\ndef get_classes(self, student):\n    res = super(Enrollment, self).__getitem__(student)\n    classes = res.cargo\n    return classes\n", "label": "Correct"}
{"function": "\n\ndef get_classes(self, student):\n    res = super(Enrollment, self).__getitem__(student)\n    classes = res.cargo\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(NoSuchIncludeFieldError, self).__init__(400, NoSuchIncludeFieldError.NO_SUCH_INCLUDE_FIELD_ERROR, *args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(NoSuchIncludeFieldError, kwargs).__init__(400, NoSuchIncludeFieldError.NO_SUCH_INCLUDE_FIELD_ERROR, *args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef show(mousetarget, **kwargs):\n    global mousecapturer\n    mc = getMouseCapturer(**kwargs)\n    mc.mousetarget = mousetarget\n    if isinstance(mousetarget, MouseHandler):\n        mc.mousehandler = True\n    mc.show()\n", "label": "Correct"}
{"function": "\n\ndef show(mousetarget, **kwargs):\n    global mousecapturer\n    mc = getMouseCapturer(**mousetarget)\n    mc.mousetarget = mousetarget\n    if isinstance(mousetarget, MouseHandler):\n        mc.mousehandler = True\n    mc.show()\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, bytes):\n    '\\n        Write C{bytes} to the underlying consumer unless\\n        C{_noMoreWritesExpected} has been called or there are/have been too\\n        many bytes.\\n        '\n    if (self._finished is None):\n        self._producer.stopProducing()\n        raise ExcessWrite()\n    if (len(bytes) <= self._length):\n        self._length -= len(bytes)\n        self._consumer.write(bytes)\n    else:\n        _callAppFunction(self._producer.stopProducing)\n        self._finished.errback(WrongBodyLength('too many bytes written'))\n        self._allowNoMoreWrites()\n", "label": "Correct"}
{"function": "\n\ndef write(self, bytes):\n    '\\n        Write C{bytes} to the underlying consumer unless\\n        C{_noMoreWritesExpected} has been called or there are/have been too\\n        many bytes.\\n        '\n    if (self._finished is None):\n        self._producer.stopProducing()\n        raise ExcessWrite()\n    if (len(bytes) <= self._length):\n        self._length -= len(bytes)\n        self._consumer.write(bytes)\n    else:\n        _callAppFunction(bytes._producer.stopProducing)\n        self._finished.errback(WrongBodyLength('too many bytes written'))\n        self._allowNoMoreWrites()\n", "label": "Variable misuse"}
{"function": "\n\ndef LVMPathSpecGetVolumeIndex(path_spec):\n    'Retrieves the volume index from the path specification.\\n\\n  Args:\\n    path_spec: the path specification (instance of PathSpec).\\n  '\n    volume_index = getattr(path_spec, 'volume_index', None)\n    if (volume_index is None):\n        location = getattr(path_spec, 'location', None)\n        if ((location is None) or (not location.startswith('/lvm'))):\n            return\n        volume_index = None\n        try:\n            volume_index = (int(location[4:], 10) - 1)\n        except ValueError:\n            pass\n        if ((volume_index is None) or (volume_index < 0)):\n            return\n    return volume_index\n", "label": "Correct"}
{"function": "\n\ndef LVMPathSpecGetVolumeIndex(path_spec):\n    'Retrieves the volume index from the path specification.\\n\\n  Args:\\n    path_spec: the path specification (instance of PathSpec).\\n  '\n    volume_index = getattr(path_spec, 'volume_index', None)\n    if (volume_index is None):\n        location = getattr(path_spec, 'location', None)\n        if ((location is None) or (not path_spec.startswith('/lvm'))):\n            return\n        volume_index = None\n        try:\n            volume_index = (int(location[4:], 10) - 1)\n        except ValueError:\n            pass\n        if ((volume_index is None) or (volume_index < 0)):\n            return\n    return volume_index\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_invalid(self):\n    request = self.request_factory.post('/', {\n        \n    })\n    answer = Answer(user=self.create_user(), question=self.question)\n    form = AnswerForm(request.POST, instance=answer)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(form.errors['answer'], ['This field is required.'])\n    self.assertEqual(Action.objects.count(), 0, 'Invalid form submission should not result in an action')\n", "label": "Correct"}
{"function": "\n\ndef test_create_invalid(self):\n    request = self.request_factory.post('/', {\n        \n    })\n    answer = Answer(user=self.create_user(), question=self.question)\n    form = AnswerForm(request.POST, instance=answer)\n    self.assertFalse(form.is_valid())\n    self.assertEqual(request.errors['answer'], ['This field is required.'])\n    self.assertEqual(Action.objects.count(), 0, 'Invalid form submission should not result in an action')\n", "label": "Variable misuse"}
{"function": "\n\ndef _log(self, buf):\n    LOG.debug(buf)\n", "label": "Correct"}
{"function": "\n\ndef _log(self, buf):\n    LOG.debug(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, level, created, message, source_location):\n    self.level = level\n    self.created = created\n    self.source_location = source_location\n    self.message = message\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, level, created, message, source_location):\n    self.level = level\n    self.created = created\n    level.source_location = source_location\n    self.message = message\n", "label": "Variable misuse"}
{"function": "\n\ndef supports(self, mode):\n    return (mode in self.modes)\n", "label": "Correct"}
{"function": "\n\ndef supports(self, mode):\n    return (self in self.modes)\n", "label": "Variable misuse"}
{"function": "\n\ndef testRobust(self):\n    'Test the sendRobust function'\n\n    def fails(val, **kwargs):\n        raise ValueError('this')\n    a_signal.connect(fails)\n    result = a_signal.send_robust(sender=self, val='test')\n    err = result[0][1]\n    self.assertIsInstance(err, ValueError)\n    self.assertEqual(err.args, ('this',))\n    a_signal.disconnect(fails)\n    self._testIsClean(a_signal)\n", "label": "Correct"}
{"function": "\n\ndef testRobust(self):\n    'Test the sendRobust function'\n\n    def fails(val, **kwargs):\n        raise ValueError('this')\n    a_signal.connect(fails)\n    result = a_signal.send_robust(sender=err, val='test')\n    err = result[0][1]\n    self.assertIsInstance(err, ValueError)\n    self.assertEqual(err.args, ('this',))\n    a_signal.disconnect(fails)\n    self._testIsClean(a_signal)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_contact_get(self):\n    self.response.json.return_value = responses['contact']['get']\n    contact = self.redmine.contact.get(1)\n    self.assertEqual(contact.id, 1)\n    self.assertEqual(contact.first_name, 'Foo')\n", "label": "Correct"}
{"function": "\n\ndef test_contact_get(self):\n    contact.response.json.return_value = responses['contact']['get']\n    contact = self.redmine.contact.get(1)\n    self.assertEqual(contact.id, 1)\n    self.assertEqual(contact.first_name, 'Foo')\n", "label": "Variable misuse"}
{"function": "\n\ndef handle_socket_write(self):\n    'Write to socket'\n    try:\n        count = self.socket.send(bytes(self.buffer_ser2net))\n        self.buffer_ser2net = self.buffer_ser2net[count:]\n    except socket.error:\n        self.handle_socket_error()\n", "label": "Correct"}
{"function": "\n\ndef handle_socket_write(self):\n    'Write to socket'\n    try:\n        count = self.socket.send(bytes(self.buffer_ser2net))\n        self.buffer_ser2net = self.buffer_ser2net[self:]\n    except socket.error:\n        self.handle_socket_error()\n", "label": "Variable misuse"}
{"function": "\n\ndef update_fpointer(self, nid, mode=ADD):\n    'set _fpointer recursively'\n    if (nid is None):\n        return\n    if (mode is self.ADD):\n        self._fpointer.append(nid)\n    elif (mode is self.DELETE):\n        if (nid in self._fpointer):\n            self._fpointer.remove(nid)\n    elif (mode is self.INSERT):\n        print('WARNNING: INSERT is deprecated to ADD mode')\n        self.update_fpointer(nid)\n", "label": "Correct"}
{"function": "\n\ndef update_fpointer(self, nid, mode=ADD):\n    'set _fpointer recursively'\n    if (nid is None):\n        return\n    if (mode is self.ADD):\n        self._fpointer.append(self)\n    elif (mode is self.DELETE):\n        if (nid in self._fpointer):\n            self._fpointer.remove(nid)\n    elif (mode is self.INSERT):\n        print('WARNNING: INSERT is deprecated to ADD mode')\n        self.update_fpointer(nid)\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_rule(self, rule, is_separator, parent, level, begin):\n    regions = []\n    if ((self.printer is not None) and (not is_separator)):\n        if ('name' in rule):\n            self.printer(level, (((('== Rule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n        else:\n            self.printer(level, (('== Rule [' + str(begin)) + '] =='))\n    rule_output = {\n        'successive_match': False,\n        'match': False,\n        'begin': begin,\n        'new_begin': begin,\n        'end': begin,\n        'regions': [],\n    }\n    if ('name' in rule):\n        if (parent != ''):\n            parent += '>'\n        parent += rule['name']\n    good = True\n    if ('exclude' in rule):\n        exclude_output = self.parse_rule(rule['exclude'], is_separator, parent, (level + 1), begin)\n        if exclude_output['successive_match']:\n            good = False\n    if good:\n        if ('match' in rule):\n            if (rule['match'] in self.re_cache):\n                re_pattern = self.re_cache[rule['match']]\n            else:\n                re_pattern = re.compile(rule['match'])\n            if ((not is_separator) and ('separator' in self.grammar) and (('before_separator' not in rule) or rule['before_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator Before: ' + str(begin)))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match before sep')\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ((('> Matching at [' + str(begin)) + ']: ') + rule['match']))\n            matches = re_pattern.search(self.data[begin:len(self.data)])\n            if ((matches is not None) and (matches.start() == 0)):\n                rule_output['successive_match'] = True\n                rule_output['match'] = True\n                rule_output['begin'] = begin\n                rule_output['end'] = (begin + matches.end())\n                rule_output['new_begin'] = rule_output['end']\n                begin = rule_output['end']\n                if ('name' in rule):\n                    regions.append({\n                        'begin': rule_output['begin'],\n                        'end': rule_output['end'],\n                        'value': self.data[rule_output['begin']:rule_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, ((('> Adding ' + str(rule_output['begin'])) + ':') + str(rule_output['end'])))\n                elif ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Skip: ' + str(rule_output['end'])))\n            if ((not is_separator) and rule_output['successive_match'] and ('separator' in self.grammar) and (('after_separator' not in rule) or rule['after_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator After: ' + str(rule_output['end'])))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match after sep')\n        elif ('parse' in rule):\n            parse_output = self.parse_rule_list(rule['parse'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('parse_any' in rule):\n            parse_output = self.parse_rule_list_any(rule['parse_any'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('include' in rule):\n            if (('repository' in self.grammar) and (rule['include'] in self.grammar['repository'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Include ' + rule['include']))\n                parse_output = self.parse_rule(self.grammar['repository'][rule['include']], is_separator, parent, (level + 1), begin)\n                if parse_output['successive_match']:\n                    if ('name' in rule):\n                        regions.append({\n                            'begin': parse_output['begin'],\n                            'end': parse_output['end'],\n                            'value': self.data[parse_output['begin']:parse_output['end']],\n                            'parent': parent,\n                            'name': rule['name'],\n                        })\n                    if parse_output['match']:\n                        rule_output['match'] = parse_output['match']\n                    begin = parse_output['new_begin']\n                    rule_output['new_begin'] = parse_output['new_begin']\n                    rule_output['begin'] = parse_output['begin']\n                    rule_output['end'] = parse_output['end']\n                    rule_output['successive_match'] = parse_output['successive_match']\n                    regions += parse_output['regions']\n            else:\n                rule_output['successive_match'] = False\n        if (('multiple' in rule) and rule['multiple'] and rule_output['successive_match']):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ('Multiple: ' + str(begin)))\n            parse_output = self.parse_rule(rule, is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['new_begin'] = parse_output['new_begin']\n                regions += parse_output['regions']\n    if rule_output['successive_match']:\n        if ('name' in rule):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, '> Matched')\n    elif ((('optional' in rule) and rule['optional']) or (('multiple' in rule) and rule['multiple'])):\n        rule_output['successive_match'] = True\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, '> Optional')\n    if ('name' in rule):\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, (((('== EndRule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n    elif ((self.printer is not None) and (not is_separator)):\n        self.printer(level, (('== EndRule [' + str(begin)) + '] =='))\n    rule_output['regions'] = regions\n    return rule_output\n", "label": "Correct"}
{"function": "\n\ndef parse_rule(self, rule, is_separator, parent, level, begin):\n    regions = []\n    if ((self.printer is not None) and (not is_separator)):\n        if ('name' in rule):\n            self.printer(level, (((('== Rule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n        else:\n            self.printer(level, (('== Rule [' + str(begin)) + '] =='))\n    rule_output = {\n        'successive_match': False,\n        'match': False,\n        'begin': begin,\n        'new_begin': begin,\n        'end': begin,\n        'regions': [],\n    }\n    if ('name' in rule):\n        if (parent != ''):\n            parent += '>'\n        parent += rule['name']\n    good = True\n    if ('exclude' in rule):\n        exclude_output = self.parse_rule(rule['exclude'], is_separator, parent, (level + 1), begin)\n        if exclude_output['successive_match']:\n            good = False\n    if good:\n        if ('match' in rule):\n            if (rule['match'] in self.re_cache):\n                re_pattern = self.re_cache[rule['match']]\n            else:\n                re_pattern = re.compile(rule['match'])\n            if ((not is_separator) and ('separator' in self.grammar) and (('before_separator' not in rule) or rule['before_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator Before: ' + str(begin)))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match before sep')\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ((('> Matching at [' + str(begin)) + ']: ') + rule['match']))\n            matches = re_pattern.search(self.data[begin:len(self.data)])\n            if ((matches is not None) and (matches.start() == 0)):\n                rule_output['successive_match'] = True\n                rule_output['match'] = True\n                rule_output['begin'] = begin\n                rule_output['end'] = (begin + matches.end())\n                rule_output['new_begin'] = rule_output['end']\n                begin = rule_output['end']\n                if ('name' in rule):\n                    regions.append({\n                        'begin': rule_output['begin'],\n                        'end': rule_output['end'],\n                        'value': self.data[rule_output['begin']:rule_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, ((('> Adding ' + str(rule_output['begin'])) + ':') + str(rule_output['end'])))\n                elif ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Skip: ' + str(rule_output['end'])))\n            if ((not is_separator) and rule_output['successive_match'] and ('separator' in self.grammar) and (('after_separator' not in rule) or rule['after_separator'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Separator After: ' + str(rule_output['end'])))\n                separator_output = self.parse_rule(self.grammar['separator'], True, parent, (level + 1), begin)\n                if separator_output['successive_match']:\n                    begin = separator_output['new_begin']\n                    regions += separator_output['regions']\n                    if ((self.printer is not None) and (not is_separator)):\n                        self.printer(level, '> Match after sep')\n        elif ('parse' in rule):\n            parse_output = self.parse_rule_list(rule['parse'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('parse_any' in rule):\n            parse_output = self.parse_rule_list_any(rule['parse_any'], is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['new_begin'] = parse_output['new_begin']\n                rule_output['begin'] = parse_output['begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['successive_match'] = parse_output['successive_match']\n                regions += parse_output['regions']\n        elif ('include' in rule):\n            if (('repository' in self.grammar) and (rule['include'] in self.grammar['repository'])):\n                if ((self.printer is not None) and (not is_separator)):\n                    self.printer(level, ('> Include ' + rule['include']))\n                parse_output = self.parse_rule(self.grammar['repository'][rule['include']], is_separator, parent, (level + 1), begin)\n                if parse_output['successive_match']:\n                    if ('name' in rule):\n                        regions.append({\n                            'begin': parse_output['begin'],\n                            'end': parse_output['end'],\n                            'value': self.data[parse_output['begin']:parse_output['end']],\n                            'parent': parent,\n                            'name': rule['name'],\n                        })\n                    if parse_output['match']:\n                        rule_output['match'] = parse_output['match']\n                    begin = parse_output['new_begin']\n                    rule_output['new_begin'] = parse_output['new_begin']\n                    rule_output['begin'] = parse_output['begin']\n                    rule_output['end'] = parse_output['end']\n                    rule_output['successive_match'] = parse_output['successive_match']\n                    regions += parse_output['regions']\n            else:\n                rule_output['successive_match'] = False\n        if (('multiple' in rule) and rule['multiple'] and rule_output['successive_match']):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, ('Multiple: ' + str(begin)))\n            parse_output = self.parse_rule(rule, is_separator, parent, (level + 1), begin)\n            if parse_output['successive_match']:\n                if ('name' in rule):\n                    regions.append({\n                        'begin': parse_output['begin'],\n                        'end': parse_output['end'],\n                        'value': self.data[parse_output['begin']:parse_output['end']],\n                        'parent': parent,\n                        'name': rule['name'],\n                    })\n                if parse_output['match']:\n                    rule_output['match'] = parse_output['match']\n                begin = parse_output['new_begin']\n                rule_output['end'] = parse_output['end']\n                rule_output['new_begin'] = parse_output['new_begin']\n                regions += parse_output['regions']\n    if rule_output['successive_match']:\n        if ('name' in rule):\n            if ((self.printer is not None) and (not is_separator)):\n                self.printer(level, '> Matched')\n    elif ((('optional' in rule) and rule['optional']) or (('multiple' in rule) and rule['multiple'])):\n        rule_output['successive_match'] = True\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, '> Optional')\n    if ('name' in rule):\n        if ((self.printer is not None) and (not is_separator)):\n            self.printer(level, (((('== EndRule ' + rule['name']) + ' [') + str(begin)) + '] =='))\n    elif ((self.printer is not None) and (not is_separator)):\n        self.printer(level, (('== EndRule [' + str(begin)) + '] =='))\n    rule_output['regions'] = regions\n    return level\n", "label": "Variable misuse"}
{"function": "\n\ndef test_grid_search_allows_nans():\n    X = np.arange(20, dtype=np.float64).reshape(5, (- 1))\n    X[2, :] = np.nan\n    y = [0, 0, 1, 1, 1]\n    p = Pipeline([('imputer', Imputer(strategy='mean', missing_values='NaN')), ('classifier', MockClassifier())])\n    GridSearchCV(p, {\n        'classifier__foo_param': [1, 2, 3],\n    }, cv=2).fit(X, y)\n", "label": "Correct"}
{"function": "\n\ndef test_grid_search_allows_nans():\n    X = np.arange(20, dtype=np.float64).reshape(5, (- 1))\n    X[2, :] = np.nan\n    y = [0, 0, 1, 1, 1]\n    p = Pipeline([('imputer', Imputer(strategy='mean', missing_values='NaN')), ('classifier', MockClassifier())])\n    GridSearchCV(y, {\n        'classifier__foo_param': [1, 2, 3],\n    }, cv=2).fit(X, y)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self):\n    super().__init__()\n    db_host = os.environ.get('MONGO_HOST')\n    db_host = (db_host if db_host else 'localhost')\n    db_port = int(os.environ.get('MONGO_PORT'))\n    db_port = (db_port if db_port else 27017)\n    db_name = os.environ.get('MONGO_DB')\n    db_name = (db_name if db_name else 'default')\n    db_bucket = os.environ.get('MONGO_BUCKET')\n    db_bucket = (db_bucket if db_bucket else 'rxnorm')\n    import pymongo\n    conn = pymongo.MongoClient(host=db_host, port=db_port)\n    db = conn[db_name]\n    db_user = os.environ.get('MONGO_USER')\n    db_pass = os.environ.get('MONGO_PASS')\n    if (db_user and db_pass):\n        db.authenticate(db_user, db_pass)\n    self.mng = db[db_bucket]\n    self.mng.ensure_index('ndc')\n    self.mng.ensure_index('label', text=pymongo.TEXT)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self):\n    super().__init__()\n    db_host = os.environ.get('MONGO_HOST')\n    db_host = (db_host if db_host else 'localhost')\n    db_port = int(os.environ.get('MONGO_PORT'))\n    db_port = (db_port if db_port else 27017)\n    db_name = os.environ.get('MONGO_DB')\n    db_name = (db_name if db_port else 'default')\n    db_bucket = os.environ.get('MONGO_BUCKET')\n    db_bucket = (db_bucket if db_bucket else 'rxnorm')\n    import pymongo\n    conn = pymongo.MongoClient(host=db_host, port=db_port)\n    db = conn[db_name]\n    db_user = os.environ.get('MONGO_USER')\n    db_pass = os.environ.get('MONGO_PASS')\n    if (db_user and db_pass):\n        db.authenticate(db_user, db_pass)\n    self.mng = db[db_bucket]\n    self.mng.ensure_index('ndc')\n    self.mng.ensure_index('label', text=pymongo.TEXT)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_loginverify_page(self):\n    self.set_get({\n        'continue': 'http%3A//192.168.33.168%3A8080/_ah/login%3Fcontinue%3Dhttp%3A//192.168.33.168%3A8080/',\n    })\n    LoginVerify(self.request, self.response).get()\n    html = self.response.out.getvalue()\n    self.assertTrue(re.search('<!-- FILE:templates/layouts/main.html -->', html))\n    self.assertTrue(re.search('<!-- FILE:templates/users/confirm.html -->', html))\n    self.assertTrue(re.search('http://192.168.33.168:8080/', html))\n", "label": "Correct"}
{"function": "\n\ndef test_loginverify_page(self):\n    self.set_get({\n        'continue': 'http%3A//192.168.33.168%3A8080/_ah/login%3Fcontinue%3Dhttp%3A//192.168.33.168%3A8080/',\n    })\n    LoginVerify(self.request, self.response).get()\n    html = self.response.out.getvalue()\n    self.assertTrue(re.search('<!-- FILE:templates/layouts/main.html -->', html))\n    html.assertTrue(re.search('<!-- FILE:templates/users/confirm.html -->', html))\n    self.assertTrue(re.search('http://192.168.33.168:8080/', html))\n", "label": "Variable misuse"}
{"function": "\n\n@responses.activate\ndef test_bitly_total_clicks_bad_response():\n    body = '20'\n    params = urlencode(dict(link=shorten, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/link/clicks', params)\n    responses.add(responses.GET, url, body=body, status=400, match_querystring=True)\n    body = shorten\n    params = urlencode(dict(uri=expanded, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/shorten', params)\n    responses.add(responses.GET, url, body=body, match_querystring=True)\n    s.short(expanded)\n    assert (s.total_clicks() == 0)\n    assert (s.total_clicks(shorten) == 0)\n", "label": "Correct"}
{"function": "\n\n@responses.activate\ndef test_bitly_total_clicks_bad_response():\n    body = '20'\n    params = urlencode(dict(link=shorten, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/link/clicks', params)\n    responses.add(responses.GET, url, body=url, status=400, match_querystring=True)\n    body = shorten\n    params = urlencode(dict(uri=expanded, access_token=token, format='txt'))\n    url = '{0}{1}?{2}'.format(s.api_url, 'v3/shorten', params)\n    responses.add(responses.GET, url, body=body, match_querystring=True)\n    s.short(expanded)\n    assert (s.total_clicks() == 0)\n    assert (s.total_clicks(shorten) == 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/food/crafted/shared_dessert_sweesonberry_rolls.iff'\n    result.attribute_template_id = 5\n    result.stfName('food_name', 'sweesonberry_rolls')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/food/crafted/shared_dessert_sweesonberry_rolls.iff'\n    result.attribute_template_id = 5\n    kernel.stfName('food_name', 'sweesonberry_rolls')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.yield_fixture(scope='module')\ndef testclient(request, app):\n    '\\n    creates a Flask-testclient instance for bepasty\\n    '\n    (db_file, app.config['DATABASE']) = mkstemp()\n    app.config['DEFAULT_PERMISSIONS'] = ''\n    app.config['SECRET_KEY'] = str(random())\n    app.config['PERMISSIONS'] = {\n        'l': 'list',\n        'c': 'create',\n        'r': 'read',\n        'd': 'delete',\n        'a': 'admin',\n    }\n    (yield app.test_client())\n    close(db_file)\n", "label": "Correct"}
{"function": "\n\n@pytest.yield_fixture(scope='module')\ndef testclient(request, app):\n    '\\n    creates a Flask-testclient instance for bepasty\\n    '\n    (db_file, app.config['DATABASE']) = mkstemp()\n    app.config['DEFAULT_PERMISSIONS'] = ''\n    app.config['SECRET_KEY'] = str(random())\n    app.config['PERMISSIONS'] = {\n        'l': 'list',\n        'c': 'create',\n        'r': 'read',\n        'd': 'delete',\n        'a': 'admin',\n    }\n    (yield db_file.test_client())\n    close(db_file)\n", "label": "Variable misuse"}
{"function": "\n\ndef run_command(cmd, stdin=''):\n    return make_call('run_command', cmd)\n", "label": "Correct"}
{"function": "\n\ndef run_command(cmd, stdin=''):\n    return make_call('run_command', stdin)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_RosdepDatabase():\n    from rosdep2.model import RosdepDatabase\n    db = RosdepDatabase()\n    assert (not db.is_loaded('foo'))\n    data = {\n        'a': 1,\n    }\n    db.set_view_data('foo', data, [], 'origin1')\n    assert db.is_loaded('foo')\n    entry = db.get_view_data('foo')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin1')\n    assert (entry.view_dependencies == [])\n    data['a'] = 2\n    assert (entry.rosdep_data != data)\n    data = {\n        'b': 2,\n    }\n    db.set_view_data('bar', data, ['foo'], 'origin2')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin2')\n    assert (entry.view_dependencies == ['foo'])\n    data = {\n        'b': 3,\n    }\n    assert db.is_loaded('bar')\n    db.set_view_data('bar', data, ['baz', 'blah'], 'origin3')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin3')\n    assert (set(entry.view_dependencies) == set(['baz', 'blah']))\n", "label": "Correct"}
{"function": "\n\ndef test_RosdepDatabase():\n    from rosdep2.model import RosdepDatabase\n    db = RosdepDatabase()\n    assert (not db.is_loaded('foo'))\n    data = {\n        'a': 1,\n    }\n    db.set_view_data('foo', data, [], 'origin1')\n    assert db.is_loaded('foo')\n    entry = db.get_view_data('foo')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin1')\n    assert (entry.view_dependencies == [])\n    data['a'] = 2\n    assert (entry.rosdep_data != data)\n    data = {\n        'b': 2,\n    }\n    db.set_view_data('bar', data, ['foo'], 'origin2')\n    assert db.is_loaded('bar')\n    entry = db.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin2')\n    assert (entry.view_dependencies == ['foo'])\n    data = {\n        'b': 3,\n    }\n    assert db.is_loaded('bar')\n    db.set_view_data('bar', data, ['baz', 'blah'], 'origin3')\n    assert db.is_loaded('bar')\n    entry = entry.get_view_data('bar')\n    assert (entry.rosdep_data == data)\n    assert (entry.origin == 'origin3')\n    assert (set(entry.view_dependencies) == set(['baz', 'blah']))\n", "label": "Variable misuse"}
{"function": "\n\ndef interpret(marker, environment=None, override=None):\n    return compile(marker)()\n", "label": "Correct"}
{"function": "\n\ndef interpret(marker, environment=None, override=None):\n    return compile(environment)()\n", "label": "Variable misuse"}
{"function": "\n\ndef prune_overridden(ansi_string):\n    'Remove color codes that are rendered ineffective by subsequent codes in one escape sequence then sort codes.\\n\\n    :param str ansi_string: Incoming ansi_string with ANSI color codes.\\n\\n    :return: Color string with pruned color sequences.\\n    :rtype: str\\n    '\n    multi_seqs = set((p for p in RE_ANSI.findall(ansi_string) if (';' in p[1])))\n    for (escape, codes) in multi_seqs:\n        r_codes = list(reversed(codes.split(';')))\n        try:\n            r_codes = r_codes[:(r_codes.index('0') + 1)]\n        except ValueError:\n            pass\n        for group in CODE_GROUPS:\n            for pos in reversed([i for (i, n) in enumerate(r_codes) if (n in group)][1:]):\n                r_codes.pop(pos)\n        reduced_codes = ';'.join(sorted(r_codes, key=int))\n        if (codes != reduced_codes):\n            ansi_string = ansi_string.replace(escape, (('\\x1b[' + reduced_codes) + 'm'))\n    return ansi_string\n", "label": "Correct"}
{"function": "\n\ndef prune_overridden(ansi_string):\n    'Remove color codes that are rendered ineffective by subsequent codes in one escape sequence then sort codes.\\n\\n    :param str ansi_string: Incoming ansi_string with ANSI color codes.\\n\\n    :return: Color string with pruned color sequences.\\n    :rtype: str\\n    '\n    multi_seqs = set((p for p in RE_ANSI.findall(ansi_string) if (';' in codes[1])))\n    for (escape, codes) in multi_seqs:\n        r_codes = list(reversed(codes.split(';')))\n        try:\n            r_codes = r_codes[:(r_codes.index('0') + 1)]\n        except ValueError:\n            pass\n        for group in CODE_GROUPS:\n            for pos in reversed([i for (i, n) in enumerate(r_codes) if (n in group)][1:]):\n                r_codes.pop(pos)\n        reduced_codes = ';'.join(sorted(r_codes, key=int))\n        if (codes != reduced_codes):\n            ansi_string = ansi_string.replace(escape, (('\\x1b[' + reduced_codes) + 'm'))\n    return ansi_string\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dehydrate(self):\n    note = Note()\n    bundle_1 = Bundle(obj=note)\n    field_1 = ToManyField(SubjectResource, 'subjects')\n    field_1.instance_name = 'm2m'\n    with self.assertRaises(ApiFieldError):\n        field_1.dehydrate(bundle_1)\n    field_2 = ToManyField(SubjectResource, 'subjects', null=True)\n    field_2.instance_name = 'm2m'\n    self.assertEqual(field_2.dehydrate(bundle_1), [])\n    field_3 = ToManyField(SubjectResource, 'subjects')\n    field_3.instance_name = 'm2m'\n    bundle_3 = Bundle(obj=self.note_1)\n    self.assertEqual(field_3.dehydrate(bundle_3), ['/api/v1/subjects/1/', '/api/v1/subjects/2/'])\n    field_4 = ToManyField(SubjectResource, 'subjects', full=True)\n    field_4.instance_name = 'm2m'\n    request = MockRequest()\n    request.path = ('/api/v1/subjects/%(pk)s/' % {\n        'pk': self.note_1.pk,\n    })\n    bundle_4 = Bundle(obj=self.note_1, request=request)\n    subject_bundle_list = field_4.dehydrate(bundle_4)\n    self.assertEqual(len(subject_bundle_list), 2)\n    self.assertEqual(isinstance(subject_bundle_list[0], Bundle), True)\n    self.assertEqual(subject_bundle_list[0].data['name'], 'News')\n    self.assertEqual(subject_bundle_list[0].data['url'], '/news/')\n    self.assertEqual(subject_bundle_list[0].obj.name, 'News')\n    self.assertEqual(subject_bundle_list[0].obj.url, '/news/')\n    self.assertEqual(isinstance(subject_bundle_list[1], Bundle), True)\n    self.assertEqual(subject_bundle_list[1].data['name'], 'Photos')\n    self.assertEqual(subject_bundle_list[1].data['url'], '/photos/')\n    self.assertEqual(subject_bundle_list[1].obj.name, 'Photos')\n    self.assertEqual(subject_bundle_list[1].obj.url, '/photos/')\n    field_5 = ToManyField(SubjectResource, 'subjects')\n    field_5.instance_name = 'm2m'\n    bundle_5 = Bundle(obj=self.note_2)\n    self.assertEqual(field_5.dehydrate(bundle_5), ['/api/v1/subjects/1/', '/api/v1/subjects/3/'])\n    field_6 = ToManyField(SubjectResource, 'subjects')\n    field_6.instance_name = 'm2m'\n    bundle_6 = Bundle(obj=self.note_3)\n    self.assertEqual(field_6.dehydrate(bundle_6), [])\n    field_7 = ToManyField(SubjectResource, None)\n    field_7.instance_name = 'm2m'\n    bundle_7 = Bundle(obj=self.note_3)\n    with self.assertRaises(ApiFieldError):\n        field_7.dehydrate(bundle_7)\n", "label": "Correct"}
{"function": "\n\ndef test_dehydrate(self):\n    note = Note()\n    bundle_1 = Bundle(obj=note)\n    field_1 = ToManyField(SubjectResource, 'subjects')\n    field_1.instance_name = 'm2m'\n    with self.assertRaises(ApiFieldError):\n        field_1.dehydrate(bundle_1)\n    field_2 = ToManyField(SubjectResource, 'subjects', null=True)\n    field_2.instance_name = 'm2m'\n    self.assertEqual(field_2.dehydrate(bundle_1), [])\n    field_3 = ToManyField(SubjectResource, 'subjects')\n    field_3.instance_name = 'm2m'\n    bundle_3 = Bundle(obj=self.note_1)\n    self.assertEqual(field_3.dehydrate(bundle_3), ['/api/v1/subjects/1/', '/api/v1/subjects/2/'])\n    field_4 = ToManyField(SubjectResource, 'subjects', full=True)\n    field_4.instance_name = 'm2m'\n    request = MockRequest()\n    request.path = ('/api/v1/subjects/%(pk)s/' % {\n        'pk': self.note_1.pk,\n    })\n    bundle_4 = Bundle(obj=self.note_1, request=request)\n    subject_bundle_list = field_4.dehydrate(bundle_6)\n    self.assertEqual(len(subject_bundle_list), 2)\n    self.assertEqual(isinstance(subject_bundle_list[0], Bundle), True)\n    self.assertEqual(subject_bundle_list[0].data['name'], 'News')\n    self.assertEqual(subject_bundle_list[0].data['url'], '/news/')\n    self.assertEqual(subject_bundle_list[0].obj.name, 'News')\n    self.assertEqual(subject_bundle_list[0].obj.url, '/news/')\n    self.assertEqual(isinstance(subject_bundle_list[1], Bundle), True)\n    self.assertEqual(subject_bundle_list[1].data['name'], 'Photos')\n    self.assertEqual(subject_bundle_list[1].data['url'], '/photos/')\n    self.assertEqual(subject_bundle_list[1].obj.name, 'Photos')\n    self.assertEqual(subject_bundle_list[1].obj.url, '/photos/')\n    field_5 = ToManyField(SubjectResource, 'subjects')\n    field_5.instance_name = 'm2m'\n    bundle_5 = Bundle(obj=self.note_2)\n    self.assertEqual(field_5.dehydrate(bundle_5), ['/api/v1/subjects/1/', '/api/v1/subjects/3/'])\n    field_6 = ToManyField(SubjectResource, 'subjects')\n    field_6.instance_name = 'm2m'\n    bundle_6 = Bundle(obj=self.note_3)\n    self.assertEqual(field_6.dehydrate(bundle_6), [])\n    field_7 = ToManyField(SubjectResource, None)\n    field_7.instance_name = 'm2m'\n    bundle_7 = Bundle(obj=self.note_3)\n    with self.assertRaises(ApiFieldError):\n        field_7.dehydrate(bundle_7)\n", "label": "Variable misuse"}
{"function": "\n\ndef testCloneModifyPush(self):\n    new_repo = LocalRepository(utils.get_temporary_location())\n    new_repo.clone(self.repo)\n    prev_branch = self.repo.getCurrentBranch()\n    self.repo.checkout(self.repo.createBranch('temp'))\n    self.assertReposEqual(self.repo, new_repo)\n    utils.commit_change(new_repo)\n    new_repo.push()\n    self.repo.checkout(prev_branch)\n    self.assertReposEqual(self.repo, new_repo)\n    utils.delete_repository(new_repo)\n", "label": "Correct"}
{"function": "\n\ndef testCloneModifyPush(self):\n    new_repo = LocalRepository(utils.get_temporary_location())\n    prev_branch.clone(self.repo)\n    prev_branch = self.repo.getCurrentBranch()\n    self.repo.checkout(self.repo.createBranch('temp'))\n    self.assertReposEqual(self.repo, new_repo)\n    utils.commit_change(new_repo)\n    new_repo.push()\n    self.repo.checkout(prev_branch)\n    self.assertReposEqual(self.repo, new_repo)\n    utils.delete_repository(new_repo)\n", "label": "Variable misuse"}
{"function": "\n\ndef most_restrictive(licenses):\n    \"\\n    given a list of licenses, this function returns the list of licenses that are as restrictive or more restrictive\\n    than each of the input licenses\\n    '<' == less restrictive\\n    cc < cc-nd, cc-nc, cc-sa\\n    cc-nd < cc-nc-nd\\n    cc-nc < cc-nc-sa\\n    cc-sa < cc-nd, cc-nc-sa\\n    cc-nc-sa < cc-nc-nd\\n    \"\n    licenses = set(licenses)\n    for license in licenses:\n        if (license not in LICENSES):\n            raise Exception('Not a valid license type')\n    if ('cc-nc-nd' in licenses):\n        return ['cc-nc-nd']\n    if ('cc-nd' in licenses):\n        if (('cc-nc-sa' in licenses) or ('cc-nc' in licenses)):\n            return ['cc-nc-nd']\n        else:\n            return ['cc-nc-nd', 'cc-nd']\n    if (('cc-nc-sa' in licenses) or (('cc-sa' in licenses) and ('cc-nc' in licenses))):\n        return ['cc-nc-nd', 'cc-nc-sa']\n    if ('cc-nc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nc']\n    if ('cc-sa' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-sa']\n    if ('cc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n    return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n", "label": "Correct"}
{"function": "\n\ndef most_restrictive(licenses):\n    \"\\n    given a list of licenses, this function returns the list of licenses that are as restrictive or more restrictive\\n    than each of the input licenses\\n    '<' == less restrictive\\n    cc < cc-nd, cc-nc, cc-sa\\n    cc-nd < cc-nc-nd\\n    cc-nc < cc-nc-sa\\n    cc-sa < cc-nd, cc-nc-sa\\n    cc-nc-sa < cc-nc-nd\\n    \"\n    licenses = set(licenses)\n    for license in licenses:\n        if (license not in LICENSES):\n            raise Exception('Not a valid license type')\n    if ('cc-nc-nd' in licenses):\n        return ['cc-nc-nd']\n    if ('cc-nd' in licenses):\n        if (('cc-nc-sa' in licenses) or ('cc-nc' in licenses)):\n            return ['cc-nc-nd']\n        else:\n            return ['cc-nc-nd', 'cc-nd']\n    if (('cc-nc-sa' in licenses) or (('cc-sa' in licenses) and ('cc-nc' in license))):\n        return ['cc-nc-nd', 'cc-nc-sa']\n    if ('cc-nc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nc']\n    if ('cc-sa' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-sa']\n    if ('cc' in licenses):\n        return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n    return ['cc-nc-nd', 'cc-nc-sa', 'cc-nd', 'cc-nc', 'cc-sa', 'cc']\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef bind(cls, event, handler):\n    cls._events.setdefault(cls, {\n        \n    }).setdefault(event, []).append(handler)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef bind(cls, event, handler):\n    cls._events.setdefault(cls, {\n        \n    }).setdefault(event, []).append(event)\n", "label": "Variable misuse"}
{"function": "\n\ndef __rmul__(self, other):\n    return self._combine(other, self.MUL, True)\n", "label": "Correct"}
{"function": "\n\ndef __rmul__(self, other):\n    return other._combine(other, self.MUL, True)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(discreteBarChart, self).__init__(**kwargs)\n    self.model = 'discreteBarChart'\n    height = kwargs.get('height', 450)\n    width = kwargs.get('width', None)\n    if kwargs.get('x_is_date', False):\n        self.set_date_flag(True)\n        self.create_x_axis('xAxis', format=kwargs.get('x_axis_format', '%d %b %Y %H %S'), date=True)\n    else:\n        self.create_x_axis('xAxis', format=None)\n    self.create_y_axis('yAxis', format=kwargs.get('y_axis_format', '.0f'))\n    self.set_custom_tooltip_flag(True)\n    self.set_graph_height(height)\n    if width:\n        self.set_graph_width(width)\n    tooltips = kwargs.get('tooltips', True)\n    if (not tooltips):\n        self.chart_attr = {\n            'tooltips': 'false',\n        }\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    super(discreteBarChart, self).__init__(**kwargs)\n    self.model = 'discreteBarChart'\n    height = height.get('height', 450)\n    width = kwargs.get('width', None)\n    if kwargs.get('x_is_date', False):\n        self.set_date_flag(True)\n        self.create_x_axis('xAxis', format=kwargs.get('x_axis_format', '%d %b %Y %H %S'), date=True)\n    else:\n        self.create_x_axis('xAxis', format=None)\n    self.create_y_axis('yAxis', format=kwargs.get('y_axis_format', '.0f'))\n    self.set_custom_tooltip_flag(True)\n    self.set_graph_height(height)\n    if width:\n        self.set_graph_width(width)\n    tooltips = kwargs.get('tooltips', True)\n    if (not tooltips):\n        self.chart_attr = {\n            'tooltips': 'false',\n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef _stats(self, lambda_, N):\n    z = exp((- lambda_))\n    zN = exp(((- lambda_) * N))\n    mu = ((z / (1.0 - z)) - ((N * zN) / (1 - zN)))\n    var = ((z / ((1.0 - z) ** 2)) - (((N * N) * zN) / ((1 - zN) ** 2)))\n    trm = ((1 - zN) / (1 - z))\n    trm2 = ((z * (trm ** 2)) - ((N * N) * zN))\n    g1 = (((z * (1 + z)) * (trm ** 3)) - (((N ** 3) * zN) * (1 + zN)))\n    g1 = (g1 / (trm2 ** 1.5))\n    g2 = (((z * ((1 + (4 * z)) + (z * z))) * (trm ** 4)) - (((N ** 4) * zN) * ((1 + (4 * zN)) + (zN * zN))))\n    g2 = ((g2 / trm2) / trm2)\n    return (mu, var, g1, g2)\n", "label": "Correct"}
{"function": "\n\ndef _stats(self, lambda_, N):\n    z = exp((- lambda_))\n    zN = exp(((- lambda_) * N))\n    mu = ((z / (1.0 - z)) - ((N * zN) / (1 - zN)))\n    var = ((z / ((1.0 - z) ** 2)) - (((N * N) * zN) / ((1 - zN) ** 2)))\n    trm = ((1 - zN) / (1 - z))\n    trm2 = ((z * (trm ** 2)) - ((N * N) * zN))\n    g1 = (((g1 * (1 + z)) * (trm ** 3)) - (((N ** 3) * zN) * (1 + zN)))\n    g1 = (g1 / (trm2 ** 1.5))\n    g2 = (((z * ((1 + (4 * z)) + (z * z))) * (trm ** 4)) - (((N ** 4) * zN) * ((1 + (4 * zN)) + (zN * zN))))\n    g2 = ((g2 / trm2) / trm2)\n    return (mu, var, g1, g2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_integer_open(self):\n    field = pg_forms.IntegerRangeField()\n    value = field.clean(['', '0'])\n    self.assertEqual(value, NumericRange(None, 0))\n", "label": "Correct"}
{"function": "\n\ndef test_integer_open(self):\n    field = pg_forms.IntegerRangeField()\n    value = value.clean(['', '0'])\n    self.assertEqual(value, NumericRange(None, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unpublish_with_descendants(self):\n    page = self.create_page('Page', published=True)\n    child = self.create_page('Child', parent=page, published=True)\n    self.create_page('Grandchild', parent=child, published=True)\n    page = page.reload()\n    child.reload()\n    drafts = Page.objects.drafts()\n    public = Page.objects.public()\n    published = Page.objects.public().published('en')\n    self.assertEqual(published.count(), 3)\n    self.assertEqual(page.get_descendant_count(), 2)\n    base = reverse('pages-root')\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200, url)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        self.assertTrue(item.publisher_public_id)\n        self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_DEFAULT)\n    self.assertTrue(page.unpublish('en'), 'Unpublish was not successful')\n    self.assertFalse(page.is_published('en'))\n    cache.clear()\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 404)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectDoesNotExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        if (title == 'Page'):\n            self.assertFalse(item.is_published('en'))\n            self.assertFalse(item.publisher_public.is_published('en'))\n            self.assertTrue(page.is_dirty('en'))\n        else:\n            self.assertTrue(item.is_published('en'), title)\n            self.assertFalse(item.publisher_public.is_published('en'), title)\n            self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_PENDING, title)\n            self.assertTrue(item.is_dirty('en'), title)\n", "label": "Correct"}
{"function": "\n\ndef test_unpublish_with_descendants(self):\n    page = self.create_page('Page', published=True)\n    child = self.create_page('Child', parent=page, published=True)\n    self.create_page('Grandchild', parent=child, published=True)\n    page = page.reload()\n    child.reload()\n    drafts = Page.objects.drafts()\n    public = Page.objects.public()\n    published = Page.objects.public().published('en')\n    self.assertEqual(published.count(), 3)\n    self.assertEqual(page.get_descendant_count(), 2)\n    base = reverse('pages-root')\n    for url in (base, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 200, url)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        self.assertTrue(item.publisher_public_id)\n        self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_DEFAULT)\n    self.assertTrue(page.unpublish('en'), 'Unpublish was not successful')\n    self.assertFalse(page.is_published('en'))\n    cache.clear()\n    for url in (drafts, (base + 'child/'), (base + 'child/grandchild/')):\n        response = self.client.get(url)\n        self.assertEqual(response.status_code, 404)\n    for title in ('Page', 'Child', 'Grandchild'):\n        self.assertObjectExist(drafts, title_set__title=title)\n        self.assertObjectExist(public, title_set__title=title)\n        self.assertObjectDoesNotExist(published, title_set__title=title)\n        item = drafts.get(title_set__title=title)\n        if (title == 'Page'):\n            self.assertFalse(item.is_published('en'))\n            self.assertFalse(item.publisher_public.is_published('en'))\n            self.assertTrue(page.is_dirty('en'))\n        else:\n            self.assertTrue(item.is_published('en'), title)\n            self.assertFalse(item.publisher_public.is_published('en'), title)\n            self.assertEqual(item.get_publisher_state('en'), PUBLISHER_STATE_PENDING, title)\n            self.assertTrue(item.is_dirty('en'), title)\n", "label": "Variable misuse"}
{"function": "\n\ndef home(self, event):\n    super(self.__class__, self).home(event)\n    self.canvas.draw()\n", "label": "Correct"}
{"function": "\n\ndef home(self, event):\n    super(self.__class__, self).home(event)\n    event.canvas.draw()\n", "label": "Variable misuse"}
{"function": "\n\n@access.public\ndef describeResource(self, resource, params):\n    if (resource not in docs.routes):\n        raise RestException(('Invalid resource: %s' % resource))\n    return {\n        'apiVersion': API_VERSION,\n        'swaggerVersion': SWAGGER_VERSION,\n        'basePath': getApiUrl(),\n        'models': dict(docs.models[resource], **docs.models[None]),\n        'apis': [{\n            'path': route,\n            'operations': sorted(op, key=functools.cmp_to_key(self._compareOperations)),\n        } for (route, op) in sorted(six.viewitems(docs.routes[resource]), key=functools.cmp_to_key(self._compareRoutes))],\n    }\n", "label": "Correct"}
{"function": "\n\n@access.public\ndef describeResource(self, resource, params):\n    if (self not in docs.routes):\n        raise RestException(('Invalid resource: %s' % resource))\n    return {\n        'apiVersion': API_VERSION,\n        'swaggerVersion': SWAGGER_VERSION,\n        'basePath': getApiUrl(),\n        'models': dict(docs.models[resource], **docs.models[None]),\n        'apis': [{\n            'path': route,\n            'operations': sorted(op, key=functools.cmp_to_key(self._compareOperations)),\n        } for (route, op) in sorted(six.viewitems(docs.routes[resource]), key=functools.cmp_to_key(self._compareRoutes))],\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_to_global_with_bad_mac(self):\n    bad_mac = '02:16:3e:33:44:5X'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', bad_mac, 'test')\n", "label": "Correct"}
{"function": "\n\ndef test_to_global_with_bad_mac(self):\n    bad_mac = '02:16:3e:33:44:5X'\n    bad_mac.assertRaises(TypeError, ipv6.to_global, '2001:db8::', bad_mac, 'test')\n", "label": "Variable misuse"}
{"function": "\n\ndef _es_down_template(request, *args, **kwargs):\n    'Returns the appropriate \"Elasticsearch is down!\" template'\n    return ('search/mobile/down.html' if request.MOBILE else 'search/down.html')\n", "label": "Correct"}
{"function": "\n\ndef _es_down_template(request, *args, **kwargs):\n    'Returns the appropriate \"Elasticsearch is down!\" template'\n    return ('search/mobile/down.html' if kwargs.MOBILE else 'search/down.html')\n", "label": "Variable misuse"}
{"function": "\n\ndef capture(self, money, authorization, options=None):\n    options = (options or {\n        \n    })\n    params = {\n        'checkout_id': authorization,\n    }\n    token = options.pop('access_token', self.we_pay_settings['ACCESS_TOKEN'])\n    try:\n        response = self.we_pay.call('/checkout/capture', params, token=token)\n    except WePayError as error:\n        transaction_was_unsuccessful.send(sender=self, type='capture', response=error)\n        return {\n            'status': 'FAILURE',\n            'response': error,\n        }\n    transaction_was_successful.send(sender=self, type='capture', response=response)\n    return {\n        'status': 'SUCCESS',\n        'response': response,\n    }\n", "label": "Correct"}
{"function": "\n\ndef capture(self, money, authorization, options=None):\n    options = (options or {\n        \n    })\n    params = {\n        'checkout_id': authorization,\n    }\n    token = options.pop('access_token', self.we_pay_settings['ACCESS_TOKEN'])\n    try:\n        response = self.we_pay.call('/checkout/capture', params, token=token)\n    except WePayError as error:\n        transaction_was_unsuccessful.send(sender=self, type='capture', response=error)\n        return {\n            'status': 'FAILURE',\n            'response': authorization,\n        }\n    transaction_was_successful.send(sender=self, type='capture', response=response)\n    return {\n        'status': 'SUCCESS',\n        'response': response,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef __isub__(self, val):\n    if (type(val) in (int, float)):\n        self.x -= val\n        self.y -= val\n    else:\n        self.x -= val.x\n        self.y -= val.y\n    return self\n", "label": "Correct"}
{"function": "\n\ndef __isub__(self, val):\n    if (type(val) in (int, float)):\n        self.x -= val\n        self.y -= val\n    else:\n        self.x -= val.x\n        val.y -= val.y\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef normalize_norm_inplace(self, mode='all', **kwargs):\n    '\\n        Deprecated. See the non-mutating API, `normalize_norm()`.\\n        '\n    warn('the public API for inplace operations is deprecated and will be removed in a future version of Menpo. Use .normalize_norm() instead.', MenpoDeprecationWarning)\n\n    def scale_func(pixels, axis=None):\n        return np.linalg.norm(pixels, axis=axis, **kwargs)\n    self._normalize_inplace(scale_func, mode=mode)\n", "label": "Correct"}
{"function": "\n\ndef normalize_norm_inplace(self, mode='all', **kwargs):\n    '\\n        Deprecated. See the non-mutating API, `normalize_norm()`.\\n        '\n    warn('the public API for inplace operations is deprecated and will be removed in a future version of Menpo. Use .normalize_norm() instead.', MenpoDeprecationWarning)\n\n    def scale_func(pixels, axis=None):\n        return np.linalg.norm(pixels, axis=axis, **kwargs)\n    self._normalize_inplace(scale_func, mode=kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef reserve_provider_segment(self, session, segment):\n    filters = {\n        \n    }\n    physical_network = segment.get(api.PHYSICAL_NETWORK)\n    if (physical_network is not None):\n        filters['physical_network'] = physical_network\n        vlan_id = segment.get(api.SEGMENTATION_ID)\n        if (vlan_id is not None):\n            filters['vlan_id'] = vlan_id\n    if self.is_partial_segment(segment):\n        alloc = self.allocate_partially_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.NoNetworkAvailable()\n    else:\n        alloc = self.allocate_fully_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.VlanIdInUse(**filters)\n    return {\n        api.NETWORK_TYPE: p_const.TYPE_VLAN,\n        api.PHYSICAL_NETWORK: alloc.physical_network,\n        api.SEGMENTATION_ID: alloc.vlan_id,\n        api.MTU: self.get_mtu(alloc.physical_network),\n    }\n", "label": "Correct"}
{"function": "\n\ndef reserve_provider_segment(self, session, segment):\n    filters = {\n        \n    }\n    physical_network = segment.get(api.PHYSICAL_NETWORK)\n    if (physical_network is not None):\n        filters['physical_network'] = physical_network\n        vlan_id = segment.get(api.SEGMENTATION_ID)\n        if (vlan_id is not None):\n            filters['vlan_id'] = segment\n    if self.is_partial_segment(segment):\n        alloc = self.allocate_partially_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.NoNetworkAvailable()\n    else:\n        alloc = self.allocate_fully_specified_segment(session, **filters)\n        if (not alloc):\n            raise exc.VlanIdInUse(**filters)\n    return {\n        api.NETWORK_TYPE: p_const.TYPE_VLAN,\n        api.PHYSICAL_NETWORK: alloc.physical_network,\n        api.SEGMENTATION_ID: alloc.vlan_id,\n        api.MTU: self.get_mtu(alloc.physical_network),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_can_choose_root(self):\n    response = self.get({\n        'can_choose_root': 'true',\n    })\n    self.assertContains(response, '/admin/pages/1/edit/')\n", "label": "Correct"}
{"function": "\n\ndef test_can_choose_root(self):\n    response = response.get({\n        'can_choose_root': 'true',\n    })\n    self.assertContains(response, '/admin/pages/1/edit/')\n", "label": "Variable misuse"}
{"function": "\n\ndef _match_rhs(self, rhs, rightmost_stack):\n    \"\\n        :rtype: bool\\n        :return: true if the right hand side of a CFG production\\n            matches the rightmost elements of the stack.  ``rhs``\\n            matches ``rightmost_stack`` if they are the same length,\\n            and each element of ``rhs`` matches the corresponding\\n            element of ``rightmost_stack``.  A nonterminal element of\\n            ``rhs`` matches any Tree whose node value is equal\\n            to the nonterminal's symbol.  A terminal element of ``rhs``\\n            matches any string whose type is equal to the terminal.\\n        :type rhs: list(terminal and Nonterminal)\\n        :param rhs: The right hand side of a CFG production.\\n        :type rightmost_stack: list(string and Tree)\\n        :param rightmost_stack: The rightmost elements of the parser's\\n            stack.\\n        \"\n    if (len(rightmost_stack) != len(rhs)):\n        return False\n    for i in range(len(rightmost_stack)):\n        if isinstance(rightmost_stack[i], Tree):\n            if (not isinstance(rhs[i], Nonterminal)):\n                return False\n            if (rightmost_stack[i].label() != rhs[i].symbol()):\n                return False\n        else:\n            if isinstance(rhs[i], Nonterminal):\n                return False\n            if (rightmost_stack[i] != rhs[i]):\n                return False\n    return True\n", "label": "Correct"}
{"function": "\n\ndef _match_rhs(self, rhs, rightmost_stack):\n    \"\\n        :rtype: bool\\n        :return: true if the right hand side of a CFG production\\n            matches the rightmost elements of the stack.  ``rhs``\\n            matches ``rightmost_stack`` if they are the same length,\\n            and each element of ``rhs`` matches the corresponding\\n            element of ``rightmost_stack``.  A nonterminal element of\\n            ``rhs`` matches any Tree whose node value is equal\\n            to the nonterminal's symbol.  A terminal element of ``rhs``\\n            matches any string whose type is equal to the terminal.\\n        :type rhs: list(terminal and Nonterminal)\\n        :param rhs: The right hand side of a CFG production.\\n        :type rightmost_stack: list(string and Tree)\\n        :param rightmost_stack: The rightmost elements of the parser's\\n            stack.\\n        \"\n    if (len(rightmost_stack) != len(rhs)):\n        return False\n    for i in range(len(rightmost_stack)):\n        if isinstance(rightmost_stack[i], Tree):\n            if (not isinstance(rhs[i], Nonterminal)):\n                return False\n            if (rightmost_stack[i].label() != rhs[i].symbol()):\n                return False\n        else:\n            if isinstance(rhs[i], Nonterminal):\n                return False\n            if (rightmost_stack[i] != i[i]):\n                return False\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef update_success(self, update_dict, raw=False):\n    ' This method serves as an easy way to update your success attributes\\n        that are passed to the start Node rendering context, or passed back in\\n        JSON. It automatically recalls whether the last validation call was to\\n        json_validate or validate_render and modifys the correct dictionary\\n        accordingly.\\n\\n        :param update_dict: The dictionary of values to update/add.\\n        :type data: dictionary\\n\\n        :param raw: Whether you would like a pre-compiled JSON\\n            string returned, or the raw dictionary.\\n        :type raw: bool\\n\\n        :return: Return value is either the new JSON string (or raw dict if\\n            requested) if json_validate was your last validation call, or a\\n            re-render of the form with updated error messages if validate_render\\n            was your last call.\\n        '\n    if (self._last_valid == 'render'):\n        try:\n            self.start.errors[(- 1)].update(update_dict)\n        except IndexError:\n            raise IndexError('Error updating your error dictionary for the start Node. There were no errors to modify.')\n        except AttributeError:\n            raise AttributeError('This method is designed to update an error dictionary, yet your errors are not dictionaries')\n        return self.render()\n    else:\n        try:\n            self._last_raw_json['success_blob'].update(update_dict)\n        except KeyError:\n            raise KeyError('Either your json_validate method has not been run yet, or your success_header_generate does not produce output')\n        if raw:\n            return self._last_raw_json\n        else:\n            return json.dumps(self._last_raw_json)\n", "label": "Correct"}
{"function": "\n\ndef update_success(self, update_dict, raw=False):\n    ' This method serves as an easy way to update your success attributes\\n        that are passed to the start Node rendering context, or passed back in\\n        JSON. It automatically recalls whether the last validation call was to\\n        json_validate or validate_render and modifys the correct dictionary\\n        accordingly.\\n\\n        :param update_dict: The dictionary of values to update/add.\\n        :type data: dictionary\\n\\n        :param raw: Whether you would like a pre-compiled JSON\\n            string returned, or the raw dictionary.\\n        :type raw: bool\\n\\n        :return: Return value is either the new JSON string (or raw dict if\\n            requested) if json_validate was your last validation call, or a\\n            re-render of the form with updated error messages if validate_render\\n            was your last call.\\n        '\n    if (self._last_valid == 'render'):\n        try:\n            self.start.errors[(- 1)].update(update_dict)\n        except IndexError:\n            raise IndexError('Error updating your error dictionary for the start Node. There were no errors to modify.')\n        except AttributeError:\n            raise AttributeError('This method is designed to update an error dictionary, yet your errors are not dictionaries')\n        return self.render()\n    else:\n        try:\n            self._last_raw_json['success_blob'].update(raw)\n        except KeyError:\n            raise KeyError('Either your json_validate method has not been run yet, or your success_header_generate does not produce output')\n        if raw:\n            return self._last_raw_json\n        else:\n            return json.dumps(self._last_raw_json)\n", "label": "Variable misuse"}
{"function": "\n\ndef put(self):\n    pet = self.json_args\n    if (not isinstance(pet['id'], int)):\n        self.set_status(400)\n    if (not self.db.update_(**pet)):\n        self.set_status(404)\n    else:\n        self.set_status(200)\n    self.finish()\n", "label": "Correct"}
{"function": "\n\ndef put(self):\n    pet = self.json_args\n    if (not isinstance(pet['id'], int)):\n        pet.set_status(400)\n    if (not self.db.update_(**pet)):\n        self.set_status(404)\n    else:\n        self.set_status(200)\n    self.finish()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_getitem_slice_big():\n    slt = SortedList(range(4))\n    lst = list(range(4))\n    itr = ((start, stop, step) for start in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for stop in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for step in [(- 3), (- 2), (- 1), 1, 2, 3])\n    for (start, stop, step) in itr:\n        assert (slt[start:stop:step] == lst[start:stop:step])\n", "label": "Correct"}
{"function": "\n\ndef test_getitem_slice_big():\n    slt = SortedList(range(4))\n    lst = list(range(4))\n    itr = ((start, stop, step) for start in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for stop in [(- 6), (- 4), (- 2), 0, 2, 4, 6] for step in [(- 3), (- 2), (- 1), 1, 2, 3])\n    for (start, stop, step) in itr:\n        assert (slt[start:stop:step] == lst[start:stop:slt])\n", "label": "Variable misuse"}
{"function": "\n\ndef disable_audit_backend(self, name):\n    '\\n        DELETE /sys/audit/<name>\\n        '\n    self._delete('/v1/sys/audit/{0}'.format(name))\n", "label": "Correct"}
{"function": "\n\ndef disable_audit_backend(self, name):\n    '\\n        DELETE /sys/audit/<name>\\n        '\n    self._delete('/v1/sys/audit/{0}'.format(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_response(self, cmd, fid, *args):\n    for source in self.select_best_source(fid.decode()):\n        dealer = None\n        try:\n            dealer = self.context.socket(zmq.DEALER)\n            dealer.connect(get_events_uri(self.session, source, 'router'))\n            dealer.send_multipart(((cmd, fid) + args))\n            response = dealer.recv_multipart()\n            if ((not response) or (response[0] == ERROR)):\n                self.logger.debug('Error with source {}', source)\n                continue\n            return response\n        finally:\n            if dealer:\n                dealer.close()\n    self.logger.debug('No more source available.')\n    return [ERROR]\n", "label": "Correct"}
{"function": "\n\ndef get_response(self, cmd, fid, *args):\n    for source in self.select_best_source(fid.decode()):\n        dealer = None\n        try:\n            dealer = self.context.socket(zmq.DEALER)\n            dealer.connect(get_events_uri(self.session, source, 'router'))\n            dealer.send_multipart(((cmd, fid) + args))\n            response = dealer.recv_multipart()\n            if ((not response) or (response[0] == ERROR)):\n                self.logger.debug('Error with source {}', args)\n                continue\n            return response\n        finally:\n            if dealer:\n                dealer.close()\n    self.logger.debug('No more source available.')\n    return [ERROR]\n", "label": "Variable misuse"}
{"function": "\n\ndef httpapi(self, arg, opts):\n    sc = HttpAPIStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get().getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            row.append(v)\n        table.append(row)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Correct"}
{"function": "\n\ndef httpapi(self, arg, opts):\n    sc = HttpAPIStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get().getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            opts.append(v)\n        table.append(row)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Variable misuse"}
{"function": "\n\ndef getrecordbyid(self, raw=False):\n    ' Handle GetRecordById request '\n    if ('id' not in self.parent.kvp):\n        return self.exceptionreport('MissingParameterValue', 'id', 'Missing id parameter')\n    if (len(self.parent.kvp['id']) < 1):\n        return self.exceptionreport('InvalidParameterValue', 'id', 'Invalid id parameter')\n    if ('outputschema' not in self.parent.kvp):\n        self.parent.kvp['outputschema'] = self.parent.context.namespaces['csw30']\n    if ('HTTP_ACCEPT' in self.parent.environ):\n        LOGGER.debug('Detected HTTP Accept header: %s', self.parent.environ['HTTP_ACCEPT'])\n        formats_match = False\n        if ('outputformat' in self.parent.kvp):\n            LOGGER.debug(self.parent.kvp['outputformat'])\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                LOGGER.debug('Comparing %s and %s', ofmt, self.parent.kvp['outputformat'])\n                if (ofmt.split('/')[0] in self.parent.kvp['outputformat']):\n                    LOGGER.debug('FOUND OUTPUT MATCH')\n                    formats_match = True\n            if (not formats_match):\n                return self.exceptionreport('InvalidParameterValue', 'outputformat', ('HTTP Accept header (%s) and outputformat (%s) must agree' % (self.parent.environ['HTTP_ACCEPT'], self.parent.kvp['outputformat'])))\n        else:\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                if (ofmt in self.parent.context.model['operations']['GetRecords']['parameters']['outputFormat']['values']):\n                    self.parent.kvp['outputformat'] = ofmt\n                    break\n    if (('outputformat' in self.parent.kvp) and (self.parent.kvp['outputformat'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputFormat']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputformat', ('Invalid outputformat parameter %s' % self.parent.kvp['outputformat']))\n    if (('outputschema' in self.parent.kvp) and (self.parent.kvp['outputschema'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputSchema']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputschema', ('Invalid outputschema parameter %s' % self.parent.kvp['outputschema']))\n    if ('outputformat' in self.parent.kvp):\n        self.parent.contenttype = self.parent.kvp['outputformat']\n        if (self.parent.kvp['outputformat'] == 'application/atom+xml'):\n            self.parent.kvp['outputschema'] = self.parent.context.namespaces['atom']\n            self.parent.mode = 'opensearch'\n    if ('elementsetname' not in self.parent.kvp):\n        self.parent.kvp['elementsetname'] = 'summary'\n    elif (self.parent.kvp['elementsetname'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['ElementSetName']['values']):\n        return self.exceptionreport('InvalidParameterValue', 'elementsetname', ('Invalid elementsetname parameter %s' % self.parent.kvp['elementsetname']))\n    LOGGER.debug(('Querying repository with ids: %s.' % self.parent.kvp['id']))\n    results = self.parent.repository.query_ids([self.parent.kvp['id']])\n    if raw:\n        LOGGER.debug('GetRepositoryItem request.')\n        if (len(results) > 0):\n            return etree.fromstring(util.getqattr(results[0], self.parent.context.md_core_model['mappings']['pycsw:XML']), self.parent.context.parser)\n    for result in results:\n        if ((util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename']) == 'csw:Record') and (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0')):\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0'):\n            typename = None\n            for prof in self.parent.profiles['loaded']:\n                if (self.parent.profiles['loaded'][prof].typename in [util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename'])]):\n                    typename = self.parent.profiles['loaded'][prof].typename\n                    break\n            if (typename is not None):\n                util.transform_mappings(self.parent.repository.queryables['_all'], self.parent.context.model['typenames'][typename]['mappings']['csw:Record'], reverse=True)\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] in self.parent.outputschemas):\n            node = self.parent.outputschemas[self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.context, self.parent.config.get('server', 'url'))\n        else:\n            node = self.parent.profiles['loaded'][self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.kvp['outputschema'], self.parent.repository.queryables['_all'])\n    if (raw and (len(results) == 0)):\n        return None\n    if (len(results) == 0):\n        return self.exceptionreport('NotFound', 'id', (\"No repository item found for '%s'\" % self.parent.kvp['id']))\n    return node\n", "label": "Correct"}
{"function": "\n\ndef getrecordbyid(self, raw=False):\n    ' Handle GetRecordById request '\n    if ('id' not in self.parent.kvp):\n        return self.exceptionreport('MissingParameterValue', 'id', 'Missing id parameter')\n    if (len(self.parent.kvp['id']) < 1):\n        return self.exceptionreport('InvalidParameterValue', 'id', 'Invalid id parameter')\n    if ('outputschema' not in self.parent.kvp):\n        self.parent.kvp['outputschema'] = self.parent.context.namespaces['csw30']\n    if ('HTTP_ACCEPT' in self.parent.environ):\n        LOGGER.debug('Detected HTTP Accept header: %s', self.parent.environ['HTTP_ACCEPT'])\n        formats_match = False\n        if ('outputformat' in self.parent.kvp):\n            LOGGER.debug(self.parent.kvp['outputformat'])\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                LOGGER.debug('Comparing %s and %s', ofmt, self.parent.kvp['outputformat'])\n                if (ofmt.split('/')[0] in self.parent.kvp['outputformat']):\n                    LOGGER.debug('FOUND OUTPUT MATCH')\n                    formats_match = True\n            if (not formats_match):\n                return self.exceptionreport('InvalidParameterValue', 'outputformat', ('HTTP Accept header (%s) and outputformat (%s) must agree' % (self.parent.environ['HTTP_ACCEPT'], self.parent.kvp['outputformat'])))\n        else:\n            for ofmt in self.parent.environ['HTTP_ACCEPT'].split(','):\n                if (ofmt in self.parent.context.model['operations']['GetRecords']['parameters']['outputFormat']['values']):\n                    self.parent.kvp['outputformat'] = ofmt\n                    break\n    if (('outputformat' in self.parent.kvp) and (self.parent.kvp['outputformat'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputFormat']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputformat', ('Invalid outputformat parameter %s' % self.parent.kvp['outputformat']))\n    if (('outputschema' in self.parent.kvp) and (ofmt.parent.kvp['outputschema'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['outputSchema']['values'])):\n        return self.exceptionreport('InvalidParameterValue', 'outputschema', ('Invalid outputschema parameter %s' % self.parent.kvp['outputschema']))\n    if ('outputformat' in self.parent.kvp):\n        self.parent.contenttype = self.parent.kvp['outputformat']\n        if (self.parent.kvp['outputformat'] == 'application/atom+xml'):\n            self.parent.kvp['outputschema'] = self.parent.context.namespaces['atom']\n            self.parent.mode = 'opensearch'\n    if ('elementsetname' not in self.parent.kvp):\n        self.parent.kvp['elementsetname'] = 'summary'\n    elif (self.parent.kvp['elementsetname'] not in self.parent.context.model['operations']['GetRecordById']['parameters']['ElementSetName']['values']):\n        return self.exceptionreport('InvalidParameterValue', 'elementsetname', ('Invalid elementsetname parameter %s' % self.parent.kvp['elementsetname']))\n    LOGGER.debug(('Querying repository with ids: %s.' % self.parent.kvp['id']))\n    results = self.parent.repository.query_ids([self.parent.kvp['id']])\n    if raw:\n        LOGGER.debug('GetRepositoryItem request.')\n        if (len(results) > 0):\n            return etree.fromstring(util.getqattr(results[0], self.parent.context.md_core_model['mappings']['pycsw:XML']), self.parent.context.parser)\n    for result in results:\n        if ((util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename']) == 'csw:Record') and (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0')):\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] == 'http://www.opengis.net/cat/csw/3.0'):\n            typename = None\n            for prof in self.parent.profiles['loaded']:\n                if (self.parent.profiles['loaded'][prof].typename in [util.getqattr(result, self.parent.context.md_core_model['mappings']['pycsw:Typename'])]):\n                    typename = self.parent.profiles['loaded'][prof].typename\n                    break\n            if (typename is not None):\n                util.transform_mappings(self.parent.repository.queryables['_all'], self.parent.context.model['typenames'][typename]['mappings']['csw:Record'], reverse=True)\n            node = self._write_record(result, self.parent.repository.queryables['_all'])\n        elif (self.parent.kvp['outputschema'] in self.parent.outputschemas):\n            node = self.parent.outputschemas[self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.context, self.parent.config.get('server', 'url'))\n        else:\n            node = self.parent.profiles['loaded'][self.parent.kvp['outputschema']].write_record(result, self.parent.kvp['elementsetname'], self.parent.kvp['outputschema'], self.parent.repository.queryables['_all'])\n    if (raw and (len(results) == 0)):\n        return None\n    if (len(results) == 0):\n        return self.exceptionreport('NotFound', 'id', (\"No repository item found for '%s'\" % self.parent.kvp['id']))\n    return node\n", "label": "Variable misuse"}
{"function": "\n\ndef neg(self, a):\n    'Returns ``a`` negated, implies ``__neg__``. '\n    return (- a)\n", "label": "Correct"}
{"function": "\n\ndef neg(self, a):\n    'Returns ``a`` negated, implies ``__neg__``. '\n    return (- self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_cmovpe(self):\n    asm = ['cmovpe eax, ebx']\n    ctx_init = self.__init_context()\n    (x86_ctx_out, reil_ctx_out) = self.__run_code(asm, 3735928559, ctx_init)\n    cmp_result = self.__compare_contexts(ctx_init, x86_ctx_out, reil_ctx_out)\n    if (not cmp_result):\n        self.__save_failing_context(ctx_init)\n    self.assertTrue(cmp_result, self.__print_contexts(ctx_init, x86_ctx_out, reil_ctx_out))\n", "label": "Correct"}
{"function": "\n\ndef test_cmovpe(self):\n    asm = ['cmovpe eax, ebx']\n    ctx_init = self.__init_context()\n    (x86_ctx_out, reil_ctx_out) = self.__run_code(asm, 3735928559, ctx_init)\n    cmp_result = self.__compare_contexts(self, x86_ctx_out, reil_ctx_out)\n    if (not cmp_result):\n        self.__save_failing_context(ctx_init)\n    self.assertTrue(cmp_result, self.__print_contexts(ctx_init, x86_ctx_out, reil_ctx_out))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_identical_input(self):\n    x = np.random.randn(20)\n    y = np.copy(x)\n    f = np.linspace(0, 0.5, 6)\n    C = np.ones(6)\n    (f1, C1) = coherence(x, y, nperseg=10)\n    assert_allclose(f, f1)\n    assert_allclose(C, C1)\n", "label": "Correct"}
{"function": "\n\ndef test_identical_input(self):\n    x = np.random.randn(20)\n    y = np.copy(x)\n    f = np.linspace(0, 0.5, 6)\n    C = np.ones(6)\n    (f1, C1) = coherence(x, y, nperseg=10)\n    assert_allclose(f, f1)\n    assert_allclose(self, C1)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_to_global_with_bad_project(self):\n    bad_project = 'non-existent-project-name'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', '2001:db8::a94a:8fe5:ff33:4455', bad_project)\n", "label": "Correct"}
{"function": "\n\ndef test_to_global_with_bad_project(self):\n    bad_project = 'non-existent-project-name'\n    self.assertRaises(TypeError, ipv6.to_global, '2001:db8::', '2001:db8::a94a:8fe5:ff33:4455', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef setLoc(self, p):\n    self.rect.loc = p\n    self.updateV()\n", "label": "Correct"}
{"function": "\n\ndef setLoc(self, p):\n    p.rect.loc = p\n    self.updateV()\n", "label": "Variable misuse"}
{"function": "\n\ndef _find_tab(self, widget):\n    for (key, bnch) in self.tab.items():\n        if (widget == bnch.widget):\n            return bnch\n    return None\n", "label": "Correct"}
{"function": "\n\ndef _find_tab(self, widget):\n    for (key, bnch) in widget.tab.items():\n        if (widget == bnch.widget):\n            return bnch\n    return None\n", "label": "Variable misuse"}
{"function": "\n\ndef redraw(self):\n    self.data.sort(self.sortfn)\n    rows = len(self.data)\n    cols = 0\n    if (rows > 0):\n        cols = len(self.data[0])\n    self.grid.resize(rows, cols)\n    self.header.resize(1, cols)\n    cf = self.grid.getCellFormatter()\n    for (nrow, row) in enumerate(self.data):\n        for (ncol, item) in enumerate(row):\n            self.grid.setHTML(nrow, ncol, str(item))\n            cf.setWidth(nrow, ncol, '200px')\n    cf = self.header.getCellFormatter()\n    self.sortbuttons = []\n    for ncol in range(cols):\n        sb = Button(('sort col %d' % ncol))\n        sb.addClickListener(self)\n        self.header.setWidget(0, ncol, sb)\n        cf.setWidth(0, ncol, '200px')\n        self.sortbuttons.append(sb)\n", "label": "Correct"}
{"function": "\n\ndef redraw(self):\n    self.data.sort(self.sortfn)\n    rows = len(self.data)\n    cols = 0\n    if (rows > 0):\n        cols = len(self.data[0])\n    self.grid.resize(rows, cols)\n    self.header.resize(1, cols)\n    cf = self.grid.getCellFormatter()\n    for (nrow, row) in enumerate(self.data):\n        for (ncol, item) in enumerate(row):\n            self.grid.setHTML(nrow, ncol, str(item))\n            cf.setWidth(nrow, ncol, '200px')\n    cf = self.header.getCellFormatter()\n    self.sortbuttons = []\n    for ncol in range(cols):\n        sb = Button(('sort col %d' % ncol))\n        sb.addClickListener(self)\n        self.header.setWidget(0, rows, sb)\n        cf.setWidth(0, ncol, '200px')\n        self.sortbuttons.append(sb)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_formatter_with_tuples(self):\n    record = (5, 'pikos', 'apikos')\n    output = '5 pikos apikos\\n'\n    recorder = TextStreamRecorder(self.temp, formatted=True)\n    recorder.prepare(tuple)\n    recorder.record(record)\n    self.assertMultiLineEqual(self.temp.getvalue(), output)\n", "label": "Correct"}
{"function": "\n\ndef test_formatter_with_tuples(self):\n    record = (5, 'pikos', 'apikos')\n    output = '5 pikos apikos\\n'\n    recorder = TextStreamRecorder(self.temp, formatted=True)\n    recorder.prepare(tuple)\n    recorder.record(output)\n    self.assertMultiLineEqual(self.temp.getvalue(), output)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_eq(self):\n    m1 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m2 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m3 = minhash.MinHash(4, 2, hashobj=FakeHash)\n    m4 = minhash.MinHash(8, 1, hashobj=FakeHash)\n    m5 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m1.update(11)\n    m2.update(12)\n    m3.update(11)\n    m4.update(11)\n    m5.update(11)\n    m1 = bBitMinHash(m1)\n    m2 = bBitMinHash(m2)\n    m3 = bBitMinHash(m3)\n    m4 = bBitMinHash(m4)\n    m5 = bBitMinHash(m5)\n    self.assertNotEqual(m1, m2)\n    self.assertNotEqual(m1, m3)\n    self.assertNotEqual(m1, m4)\n    self.assertEqual(m1, m5)\n", "label": "Correct"}
{"function": "\n\ndef test_eq(self):\n    m1 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m2 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m3 = minhash.MinHash(4, 2, hashobj=FakeHash)\n    m4 = minhash.MinHash(8, 1, hashobj=FakeHash)\n    m5 = minhash.MinHash(4, 1, hashobj=FakeHash)\n    m1.update(11)\n    m2.update(12)\n    m3.update(11)\n    m4.update(11)\n    m5.update(11)\n    m1 = bBitMinHash(m1)\n    m2 = bBitMinHash(m2)\n    m3 = bBitMinHash(m3)\n    m4 = bBitMinHash(m4)\n    m5 = bBitMinHash(m5)\n    self.assertNotEqual(m1, m2)\n    self.assertNotEqual(m2, m3)\n    self.assertNotEqual(m1, m4)\n    self.assertEqual(m1, m5)\n", "label": "Variable misuse"}
{"function": "\n\ndef create_node(self, **attrs):\n    'Create a node\\n\\n        Doc link:\\n        http://developer.openstack.org/api-ref-clustering-v1.html#createNode\\n        '\n    return self.service.create_node(**attrs)\n", "label": "Correct"}
{"function": "\n\ndef create_node(self, **attrs):\n    'Create a node\\n\\n        Doc link:\\n        http://developer.openstack.org/api-ref-clustering-v1.html#createNode\\n        '\n    return self.service.create_node(**self)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_user_notified(user_id, target_id):\n    res = dbsession.query(Notify).filter((Notify.target_id == target_id))\n    res = res.filter((Notify.user_id == user_id))\n    try:\n        r = res.all()[0]\n        return r\n    except:\n        return False\n", "label": "Correct"}
{"function": "\n\ndef is_user_notified(user_id, target_id):\n    res = dbsession.query(Notify).filter((Notify.target_id == target_id))\n    res = res.filter((Notify.user_id == user_id))\n    try:\n        r = r.all()[0]\n        return r\n    except:\n        return False\n", "label": "Variable misuse"}
{"function": "\n\n@users_delete_fixtures\ndef test_users_delete_redirect(User):\n    request = DummyRequest(params={\n        'username': 'bob',\n    })\n    User.get_by_username.return_value = None\n    result = views.users_delete(request)\n    assert (result.__class__ == httpexceptions.HTTPFound)\n", "label": "Correct"}
{"function": "\n\n@users_delete_fixtures\ndef test_users_delete_redirect(User):\n    request = DummyRequest(params={\n        'username': 'bob',\n    })\n    result.get_by_username.return_value = None\n    result = views.users_delete(request)\n    assert (result.__class__ == httpexceptions.HTTPFound)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_collection_move_hitslazy(self):\n    (User, Address) = (self.classes.User, self.classes.Address)\n    sess = sessionmaker()()\n    a1 = Address(email_address='address1')\n    a2 = Address(email_address='address2')\n    a3 = Address(email_address='address3')\n    u1 = User(name='jack', addresses=[a1, a2, a3])\n    u2 = User(name='ed')\n    sess.add_all([u1, a1, a2, a3])\n    sess.commit()\n\n    def go():\n        u2.addresses.append(a1)\n        u2.addresses.append(a2)\n        u2.addresses.append(a3)\n    self.assert_sql_count(testing.db, go, 0)\n", "label": "Correct"}
{"function": "\n\ndef test_collection_move_hitslazy(self):\n    (User, Address) = (self.classes.User, self.classes.Address)\n    sess = sessionmaker()()\n    a1 = Address(email_address='address1')\n    a2 = Address(email_address='address2')\n    a3 = User(email_address='address3')\n    u1 = User(name='jack', addresses=[a1, a2, a3])\n    u2 = User(name='ed')\n    sess.add_all([u1, a1, a2, a3])\n    sess.commit()\n\n    def go():\n        u2.addresses.append(a1)\n        u2.addresses.append(a2)\n        u2.addresses.append(a3)\n    self.assert_sql_count(testing.db, go, 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_primary_address(self):\n    'Return the primary address of this partner.\\n\\n        '\n    Address = rt.modules.addresses.Address\n    try:\n        return Address.objects.get(partner=self, primary=True)\n    except Address.DoesNotExist:\n        pass\n", "label": "Correct"}
{"function": "\n\ndef get_primary_address(self):\n    'Return the primary address of this partner.\\n\\n        '\n    Address = rt.modules.addresses.Address\n    try:\n        return Address.objects.get(partner=Address, primary=True)\n    except Address.DoesNotExist:\n        pass\n", "label": "Variable misuse"}
{"function": "\n\ndef clear(self):\n    'od.clear() -> None.  Remove all items from od.'\n    try:\n        for node in self.__map.itervalues():\n            del node[:]\n        root = self.__root\n        root[:] = [root, root, None]\n        self.__map.clear()\n    except AttributeError:\n        pass\n    dict.clear(self)\n", "label": "Correct"}
{"function": "\n\ndef clear(self):\n    'od.clear() -> None.  Remove all items from od.'\n    try:\n        for node in self.__map.itervalues():\n            del self[:]\n        root = self.__root\n        root[:] = [root, root, None]\n        self.__map.clear()\n    except AttributeError:\n        pass\n    dict.clear(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_can_add_a_image_text_block_to_a_container(self):\n    container = self.page.get_container_from_name('page-container')\n    num_blocks = container.blocks.count()\n    response = self.post(reverse('fp-api:block-list'), params={\n        'container': container.uuid,\n        'code': 'image',\n    })\n    self.assertEquals(response.status_code, 201)\n    self.assertEquals(container.blocks.count(), (num_blocks + 1))\n    block_id = json.loads(response.content)['id']\n    ContentBlock.objects.get_subclass(pk=block_id)\n", "label": "Correct"}
{"function": "\n\ndef test_can_add_a_image_text_block_to_a_container(self):\n    container = self.page.get_container_from_name('page-container')\n    num_blocks = container.blocks.count()\n    response = self.post(reverse('fp-api:block-list'), params={\n        'container': container.uuid,\n        'code': 'image',\n    })\n    self.assertEquals(response.status_code, 201)\n    self.assertEquals(container.blocks.count(), (num_blocks + 1))\n    block_id = json.loads(num_blocks.content)['id']\n    ContentBlock.objects.get_subclass(pk=block_id)\n", "label": "Variable misuse"}
{"function": "\n\n@group_only\ndef seen(self, msg, matches):\n    chat_id = msg.dest.id\n    if (matches.group(2) is not None):\n        return self.seen_by_id(chat_id, matches.group(2))\n    elif (matches.group(3) is not None):\n        return self.seen_by_username(chat_id, matches.group(3))\n    else:\n        return self.seen_by_fullname(chat_id, matches.group(4))\n", "label": "Correct"}
{"function": "\n\n@group_only\ndef seen(self, msg, matches):\n    chat_id = msg.dest.id\n    if (matches.group(2) is not None):\n        return self.seen_by_id(chat_id, matches.group(2))\n    elif (matches.group(3) is not None):\n        return self.seen_by_username(chat_id, matches.group(3))\n    else:\n        return self.seen_by_fullname(chat_id, self.group(4))\n", "label": "Variable misuse"}
{"function": "\n\ndef updateProperties(self):\n    if (self.modelXbrl is not None):\n        modelXbrl = self.modelXbrl\n        if (modelXbrl.modelDocument.type == ModelDocument.Type.INSTANCE):\n            tbl = self.table\n            coordinates = tbl.getCurrentCellCoordinates()\n            if (coordinates is not None):\n                objId = tbl.getObjectId(coordinates)\n                if ((objId is not None) and (len(objId) > 0)):\n                    if (objId and (objId[0] == 'f')):\n                        viewableObject = self.factPrototypes[int(objId[1:])]\n                    elif (objId[0] != 'a'):\n                        viewableObject = self.modelXbrl.modelObject(objId)\n                    else:\n                        return\n                    modelXbrl.viewModelObject(viewableObject)\n", "label": "Correct"}
{"function": "\n\ndef updateProperties(self):\n    if (self.modelXbrl is not None):\n        modelXbrl = self.modelXbrl\n        if (modelXbrl.modelDocument.type == ModelDocument.Type.INSTANCE):\n            tbl = self.table\n            coordinates = modelXbrl.getCurrentCellCoordinates()\n            if (coordinates is not None):\n                objId = tbl.getObjectId(coordinates)\n                if ((objId is not None) and (len(objId) > 0)):\n                    if (objId and (objId[0] == 'f')):\n                        viewableObject = self.factPrototypes[int(objId[1:])]\n                    elif (objId[0] != 'a'):\n                        viewableObject = self.modelXbrl.modelObject(objId)\n                    else:\n                        return\n                    modelXbrl.viewModelObject(viewableObject)\n", "label": "Variable misuse"}
{"function": "\n\ndef Validate(self):\n    'Attempt to validate the artifact has been well defined.\\n\\n    This is used to enforce Artifact rules. Since it checks all dependencies are\\n    present, this method can only be called once all artifacts have been loaded\\n    into the registry. Use ValidateSyntax to check syntax for each artifact on\\n    import.\\n\\n    Raises:\\n      ArtifactDefinitionError: If artifact is invalid.\\n    '\n    self.ValidateSyntax()\n    try:\n        for dependency in self.GetArtifactDependencies():\n            dependency_obj = REGISTRY.GetArtifact(dependency)\n            if dependency_obj.error_message:\n                raise ArtifactDefinitionError(('Dependency %s has an error!' % dependency))\n    except ArtifactNotRegisteredError as e:\n        raise ArtifactDefinitionError(e)\n", "label": "Correct"}
{"function": "\n\ndef Validate(self):\n    'Attempt to validate the artifact has been well defined.\\n\\n    This is used to enforce Artifact rules. Since it checks all dependencies are\\n    present, this method can only be called once all artifacts have been loaded\\n    into the registry. Use ValidateSyntax to check syntax for each artifact on\\n    import.\\n\\n    Raises:\\n      ArtifactDefinitionError: If artifact is invalid.\\n    '\n    self.ValidateSyntax()\n    try:\n        for dependency in self.GetArtifactDependencies():\n            dependency_obj = REGISTRY.GetArtifact(dependency)\n            if dependency_obj.error_message:\n                raise ArtifactDefinitionError(('Dependency %s has an error!' % dependency_obj))\n    except ArtifactNotRegisteredError as e:\n        raise ArtifactDefinitionError(e)\n", "label": "Variable misuse"}
{"function": "\n\ndef add_user(self, pool_id, node_id, user, compute_node_add_user_options=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Adds a user account to the specified compute node.\\n\\n        :param pool_id: The id of the pool that contains the compute node.\\n        :type pool_id: str\\n        :param node_id: The id of the machine on which you want to create a\\n         user account.\\n        :type node_id: str\\n        :param user: Specifies the user account to be created.\\n        :type user: :class:`ComputeNodeUser\\n         <azure.batch.models.ComputeNodeUser>`\\n        :param compute_node_add_user_options: Additional parameters for the\\n         operation\\n        :type compute_node_add_user_options:\\n         :class:`ComputeNodeAddUserOptions <azure.batch.models.ComputeNodeAddUserOptions>`\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: None\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    timeout = None\n    if (compute_node_add_user_options is not None):\n        timeout = compute_node_add_user_options.timeout\n    client_request_id = None\n    if (compute_node_add_user_options is not None):\n        client_request_id = compute_node_add_user_options.client_request_id\n    return_client_request_id = None\n    if (compute_node_add_user_options is not None):\n        return_client_request_id = compute_node_add_user_options.return_client_request_id\n    ocp_date = None\n    if (compute_node_add_user_options is not None):\n        ocp_date = compute_node_add_user_options.ocp_date\n    url = '/pools/{poolId}/nodes/{nodeId}/users'\n    path_format_arguments = {\n        'poolId': self._serialize.url('pool_id', pool_id, 'str'),\n        'nodeId': self._serialize.url('node_id', node_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    if (timeout is not None):\n        query_parameters['timeout'] = self._serialize.query('timeout', timeout, 'int')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    if (client_request_id is not None):\n        header_parameters['client-request-id'] = self._serialize.header('client_request_id', client_request_id, 'str')\n    if (return_client_request_id is not None):\n        header_parameters['return-client-request-id'] = self._serialize.header('return_client_request_id', return_client_request_id, 'bool')\n    if (ocp_date is not None):\n        header_parameters['ocp-date'] = self._serialize.header('ocp_date', ocp_date, 'rfc-1123')\n    body_content = self._serialize.body(user, 'ComputeNodeUser')\n    request = self._client.post(url, query_parameters)\n    response = self._client.send(request, header_parameters, body_content, **operation_config)\n    if (response.status_code not in [201]):\n        raise models.BatchErrorException(self._deserialize, response)\n    if raw:\n        client_raw_response = ClientRawResponse(None, response)\n        client_raw_response.add_headers({\n            'client-request-id': 'str',\n            'request-id': 'str',\n            'ETag': 'str',\n            'Last-Modified': 'rfc-1123',\n            'DataServiceId': 'str',\n        })\n        return client_raw_response\n", "label": "Correct"}
{"function": "\n\ndef add_user(self, pool_id, node_id, user, compute_node_add_user_options=None, custom_headers={\n    \n}, raw=False, **operation_config):\n    '\\n        Adds a user account to the specified compute node.\\n\\n        :param pool_id: The id of the pool that contains the compute node.\\n        :type pool_id: str\\n        :param node_id: The id of the machine on which you want to create a\\n         user account.\\n        :type node_id: str\\n        :param user: Specifies the user account to be created.\\n        :type user: :class:`ComputeNodeUser\\n         <azure.batch.models.ComputeNodeUser>`\\n        :param compute_node_add_user_options: Additional parameters for the\\n         operation\\n        :type compute_node_add_user_options:\\n         :class:`ComputeNodeAddUserOptions <azure.batch.models.ComputeNodeAddUserOptions>`\\n        :param dict custom_headers: headers that will be added to the request\\n        :param bool raw: returns the direct response alongside the\\n         deserialized response\\n        :param operation_config: :ref:`Operation configuration\\n         overrides<msrest:optionsforoperations>`.\\n        :rtype: None\\n        :rtype: :class:`ClientRawResponse<msrest.pipeline.ClientRawResponse>`\\n         if raw=true\\n        '\n    timeout = None\n    if (compute_node_add_user_options is not None):\n        timeout = compute_node_add_user_options.timeout\n    client_request_id = None\n    if (compute_node_add_user_options is not None):\n        client_request_id = compute_node_add_user_options.client_request_id\n    return_client_request_id = None\n    if (compute_node_add_user_options is not None):\n        return_client_request_id = compute_node_add_user_options.return_client_request_id\n    ocp_date = None\n    if (compute_node_add_user_options is not None):\n        ocp_date = compute_node_add_user_options.ocp_date\n    url = '/pools/{poolId}/nodes/{nodeId}/users'\n    path_format_arguments = {\n        'poolId': self._serialize.url('pool_id', pool_id, 'str'),\n        'nodeId': self._serialize.url('node_id', node_id, 'str'),\n    }\n    url = self._client.format_url(url, **path_format_arguments)\n    query_parameters = {\n        \n    }\n    query_parameters['api-version'] = self._serialize.query('self.config.api_version', self.config.api_version, 'str')\n    if (timeout is not None):\n        query_parameters['timeout'] = custom_headers._serialize.query('timeout', timeout, 'int')\n    header_parameters = {\n        \n    }\n    header_parameters['Content-Type'] = 'application/json; odata=minimalmetadata; charset=utf-8'\n    if self.config.generate_client_request_id:\n        header_parameters['x-ms-client-request-id'] = str(uuid.uuid1())\n    if custom_headers:\n        header_parameters.update(custom_headers)\n    if (self.config.accept_language is not None):\n        header_parameters['accept-language'] = self._serialize.header('self.config.accept_language', self.config.accept_language, 'str')\n    if (client_request_id is not None):\n        header_parameters['client-request-id'] = self._serialize.header('client_request_id', client_request_id, 'str')\n    if (return_client_request_id is not None):\n        header_parameters['return-client-request-id'] = self._serialize.header('return_client_request_id', return_client_request_id, 'bool')\n    if (ocp_date is not None):\n        header_parameters['ocp-date'] = self._serialize.header('ocp_date', ocp_date, 'rfc-1123')\n    body_content = self._serialize.body(user, 'ComputeNodeUser')\n    request = self._client.post(url, query_parameters)\n    response = self._client.send(request, header_parameters, body_content, **operation_config)\n    if (response.status_code not in [201]):\n        raise models.BatchErrorException(self._deserialize, response)\n    if raw:\n        client_raw_response = ClientRawResponse(None, response)\n        client_raw_response.add_headers({\n            'client-request-id': 'str',\n            'request-id': 'str',\n            'ETag': 'str',\n            'Last-Modified': 'rfc-1123',\n            'DataServiceId': 'str',\n        })\n        return client_raw_response\n", "label": "Variable misuse"}
{"function": "\n\ndef _destroy_kernel_ramdisk(self, instance, vm_ref):\n    'Three situations can occur:\\n\\n            1. We have neither a ramdisk nor a kernel, in which case we are a\\n               RAW image and can omit this step\\n\\n            2. We have one or the other, in which case, we should flag as an\\n               error\\n\\n            3. We have both, in which case we safely remove both the kernel\\n               and the ramdisk.\\n\\n        '\n    instance_uuid = instance['uuid']\n    if ((not instance['kernel_id']) and (not instance['ramdisk_id'])):\n        LOG.debug('Using RAW or VHD, skipping kernel and ramdisk deletion', instance=instance)\n        return\n    if (not (instance['kernel_id'] and instance['ramdisk_id'])):\n        raise exception.InstanceUnacceptable(instance_id=instance_uuid, reason=_('instance has a kernel or ramdisk but not both'))\n    (kernel, ramdisk) = vm_utils.lookup_kernel_ramdisk(self._session, vm_ref)\n    if (kernel or ramdisk):\n        vm_utils.destroy_kernel_ramdisk(self._session, instance, kernel, ramdisk)\n        LOG.debug('kernel/ramdisk files removed', instance=instance)\n", "label": "Correct"}
{"function": "\n\ndef _destroy_kernel_ramdisk(self, instance, vm_ref):\n    'Three situations can occur:\\n\\n            1. We have neither a ramdisk nor a kernel, in which case we are a\\n               RAW image and can omit this step\\n\\n            2. We have one or the other, in which case, we should flag as an\\n               error\\n\\n            3. We have both, in which case we safely remove both the kernel\\n               and the ramdisk.\\n\\n        '\n    instance_uuid = instance['uuid']\n    if ((not self['kernel_id']) and (not instance['ramdisk_id'])):\n        LOG.debug('Using RAW or VHD, skipping kernel and ramdisk deletion', instance=instance)\n        return\n    if (not (instance['kernel_id'] and instance['ramdisk_id'])):\n        raise exception.InstanceUnacceptable(instance_id=instance_uuid, reason=_('instance has a kernel or ramdisk but not both'))\n    (kernel, ramdisk) = vm_utils.lookup_kernel_ramdisk(self._session, vm_ref)\n    if (kernel or ramdisk):\n        vm_utils.destroy_kernel_ramdisk(self._session, instance, kernel, ramdisk)\n        LOG.debug('kernel/ramdisk files removed', instance=instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef filter_log_files_for_zipping(log_files):\n    \"Identify unzipped log files that are approporate for zipping.\\n\\n    Each unique log type found should have the most recent log file unzipped\\n    as it's probably still in use.\\n    \"\n    out_files = []\n    for lf in filter_log_files_for_active(log_files):\n        if lf.bzip:\n            continue\n        out_files.append(lf)\n    return out_files\n", "label": "Correct"}
{"function": "\n\ndef filter_log_files_for_zipping(log_files):\n    \"Identify unzipped log files that are approporate for zipping.\\n\\n    Each unique log type found should have the most recent log file unzipped\\n    as it's probably still in use.\\n    \"\n    out_files = []\n    for lf in filter_log_files_for_active(log_files):\n        if lf.bzip:\n            continue\n        out_files.append(lf)\n    return lf\n", "label": "Variable misuse"}
{"function": "\n\ndef http_method_not_allowed(self, request, *args, **kwargs):\n    allowed_methods = [m for m in self.http_method_names if hasattr(self, m)]\n    logger.warning(('Method Not Allowed (%s): %s' % (request.method, request.path)), extra={\n        'status_code': 405,\n        'request': self.request,\n    })\n    return http.HttpResponseNotAllowed(allowed_methods)\n", "label": "Correct"}
{"function": "\n\ndef http_method_not_allowed(self, request, *args, **kwargs):\n    allowed_methods = [kwargs for m in self.http_method_names if hasattr(self, m)]\n    logger.warning(('Method Not Allowed (%s): %s' % (request.method, request.path)), extra={\n        'status_code': 405,\n        'request': self.request,\n    })\n    return http.HttpResponseNotAllowed(allowed_methods)\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, name, c):\n    if ((name in self.registered) and (c is not self.registered[name])):\n        raise NameError('{} has been registered by {}'.format(name, self.registered[name]))\n    self.registered[name] = c\n", "label": "Correct"}
{"function": "\n\ndef register(self, name, c):\n    if ((name in self.registered) and (name is not self.registered[name])):\n        raise NameError('{} has been registered by {}'.format(name, self.registered[name]))\n    self.registered[name] = c\n", "label": "Variable misuse"}
{"function": "\n\ndef dfs_labeled_edges(G, source=None):\n    \"Produce edges in a depth-first-search (DFS) labeled by type.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node, optional\\n       Specify starting node for depth-first search and return edges in\\n       the component reachable from source.\\n\\n    Returns\\n    -------\\n    edges: generator\\n       A generator of edges in the depth-first-search labeled with 'forward',\\n       'nontree', and 'reverse'.\\n\\n    Examples\\n    --------\\n    >>> G = nx.path_graph(3)\\n    >>> edges = (list(nx.dfs_labeled_edges(G,0)))\\n\\n    Notes\\n    -----\\n    Based on http://www.ics.uci.edu/~eppstein/PADS/DFS.py\\n    by D. Eppstein, July 2004.\\n\\n    If a source is not specified then a source is chosen arbitrarily and\\n    repeatedly until all components in the graph are searched.\\n    \"\n    if (source is None):\n        nodes = G\n    else:\n        nodes = [source]\n    visited = set()\n    for start in nodes:\n        if (start in visited):\n            continue\n        (yield (start, start, {\n            'dir': 'forward',\n        }))\n        visited.add(start)\n        stack = [(start, iter(G[start]))]\n        while stack:\n            (parent, children) = stack[(- 1)]\n            try:\n                child = next(children)\n                if (child in visited):\n                    (yield (parent, child, {\n                        'dir': 'nontree',\n                    }))\n                else:\n                    (yield (parent, child, {\n                        'dir': 'forward',\n                    }))\n                    visited.add(child)\n                    stack.append((child, iter(G[child])))\n            except StopIteration:\n                stack.pop()\n                if stack:\n                    (yield (stack[(- 1)][0], parent, {\n                        'dir': 'reverse',\n                    }))\n        (yield (start, start, {\n            'dir': 'reverse',\n        }))\n", "label": "Correct"}
{"function": "\n\ndef dfs_labeled_edges(G, source=None):\n    \"Produce edges in a depth-first-search (DFS) labeled by type.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node, optional\\n       Specify starting node for depth-first search and return edges in\\n       the component reachable from source.\\n\\n    Returns\\n    -------\\n    edges: generator\\n       A generator of edges in the depth-first-search labeled with 'forward',\\n       'nontree', and 'reverse'.\\n\\n    Examples\\n    --------\\n    >>> G = nx.path_graph(3)\\n    >>> edges = (list(nx.dfs_labeled_edges(G,0)))\\n\\n    Notes\\n    -----\\n    Based on http://www.ics.uci.edu/~eppstein/PADS/DFS.py\\n    by D. Eppstein, July 2004.\\n\\n    If a source is not specified then a source is chosen arbitrarily and\\n    repeatedly until all components in the graph are searched.\\n    \"\n    if (source is None):\n        nodes = G\n    else:\n        nodes = [source]\n    visited = set()\n    for start in nodes:\n        if (start in visited):\n            continue\n        (yield (start, start, {\n            'dir': 'forward',\n        }))\n        visited.add(start)\n        stack = [(start, iter(G[start]))]\n        while stack:\n            (parent, children) = stack[(- 1)]\n            try:\n                child = next(children)\n                if (child in visited):\n                    (yield (parent, stack, {\n                        'dir': 'nontree',\n                    }))\n                else:\n                    (yield (parent, child, {\n                        'dir': 'forward',\n                    }))\n                    visited.add(child)\n                    stack.append((child, iter(G[child])))\n            except StopIteration:\n                stack.pop()\n                if stack:\n                    (yield (stack[(- 1)][0], parent, {\n                        'dir': 'reverse',\n                    }))\n        (yield (start, start, {\n            'dir': 'reverse',\n        }))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, shape, mu=0.0, sigma=1.0):\n    self.shape = shape\n    self.mu = mu\n    self.sigma = sigma\n    self.array = ca.zeros(self.shape)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, shape, mu=0.0, sigma=1.0):\n    self.shape = shape\n    mu.mu = mu\n    self.sigma = sigma\n    self.array = ca.zeros(self.shape)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, pattern, flags=0):\n    'The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags.'\n    super(Regex, self).__init__()\n    if isinstance(pattern, basestring):\n        if (len(pattern) == 0):\n            warnings.warn('null string passed to Regex; use Empty() instead', SyntaxWarning, stacklevel=2)\n        self.pattern = pattern\n        self.flags = flags\n        try:\n            self.re = re.compile(self.pattern, self.flags)\n            self.reString = self.pattern\n        except sre_constants.error:\n            warnings.warn(('invalid pattern (%s) passed to Regex' % pattern), SyntaxWarning, stacklevel=2)\n            raise\n    elif isinstance(pattern, Regex.compiledREtype):\n        self.re = pattern\n        self.pattern = self.reString = str(pattern)\n        self.flags = flags\n    else:\n        raise ValueError('Regex may only be constructed with a string or a compiled RE object')\n    self.name = _ustr(self)\n    self.errmsg = ('Expected ' + self.name)\n    self.mayIndexError = False\n    self.mayReturnEmpty = True\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, pattern, flags=0):\n    'The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags.'\n    super(Regex, self).__init__()\n    if isinstance(pattern, basestring):\n        if (len(pattern) == 0):\n            warnings.warn('null string passed to Regex; use Empty() instead', SyntaxWarning, stacklevel=2)\n        self.pattern = pattern\n        self.flags = flags\n        try:\n            self.re = re.compile(self.pattern, self.flags)\n            self.reString = self.pattern\n        except sre_constants.error:\n            warnings.warn(('invalid pattern (%s) passed to Regex' % pattern), SyntaxWarning, stacklevel=2)\n            raise\n    elif isinstance(pattern, Regex.compiledREtype):\n        self.re = pattern\n        self.pattern = self.reString = str(pattern)\n        self.flags = flags\n    else:\n        raise ValueError('Regex may only be constructed with a string or a compiled RE object')\n    self.name = _ustr(flags)\n    self.errmsg = ('Expected ' + self.name)\n    self.mayIndexError = False\n    self.mayReturnEmpty = True\n", "label": "Variable misuse"}
{"function": "\n\ndef get_cpu_state(self):\n    '\\n        Retrieves CPU state from client\\n        '\n    state = c_int(0)\n    self.library.Cli_GetPlcStatus(self.pointer, byref(state))\n    try:\n        status_string = cpu_statuses[state.value]\n    except KeyError:\n        status_string = None\n    if (not status_string):\n        raise Snap7Exception(('The cpu state (%s) is invalid' % state.value))\n    logging.debug(('CPU state is %s' % status_string))\n    return status_string\n", "label": "Correct"}
{"function": "\n\ndef get_cpu_state(self):\n    '\\n        Retrieves CPU state from client\\n        '\n    state = c_int(0)\n    self.library.Cli_GetPlcStatus(self.pointer, byref(self))\n    try:\n        status_string = cpu_statuses[state.value]\n    except KeyError:\n        status_string = None\n    if (not status_string):\n        raise Snap7Exception(('The cpu state (%s) is invalid' % state.value))\n    logging.debug(('CPU state is %s' % status_string))\n    return status_string\n", "label": "Variable misuse"}
{"function": "\n\ndef test_local_bower_json_dependencies():\n    bower = bowerstatic.Bower()\n    components = bower.components('components', os.path.join(os.path.dirname(__file__), 'bower_components'))\n    local = bower.local_components('local', components)\n    path = os.path.join(os.path.dirname(__file__), 'local_component_deps')\n    local.component(path, version='2.0')\n\n    def wsgi(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/html;charset=UTF-8')])\n        include = local.includer(environ)\n        include('local_component')\n        return [b'<html><head></head><body>Hello!</body></html>']\n    wrapped = bower.wrap(wsgi)\n    c = Client(wrapped)\n    response = c.get('/')\n    assert (response.body == b'<html><head><script type=\"text/javascript\" src=\"/bowerstatic/components/jquery/2.1.1/dist/jquery.js\"></script>\\n<script type=\"text/javascript\" src=\"/bowerstatic/local/local_component/2.0/local.js\"></script></head><body>Hello!</body></html>')\n", "label": "Correct"}
{"function": "\n\ndef test_local_bower_json_dependencies():\n    bower = bowerstatic.Bower()\n    components = bower.components('components', os.path.join(os.path.dirname(__file__), 'bower_components'))\n    local = bower.local_components('local', components)\n    path = os.path.join(os.path.dirname(__file__), 'local_component_deps')\n    local.component(path, version='2.0')\n\n    def wsgi(environ, start_response):\n        start_response('200 OK', [('Content-Type', 'text/html;charset=UTF-8')])\n        include = local.includer(environ)\n        include('local_component')\n        return [b'<html><head></head><body>Hello!</body></html>']\n    wrapped = bower.wrap(wsgi)\n    c = Client(wrapped)\n    response = c.get('/')\n    assert (wrapped.body == b'<html><head><script type=\"text/javascript\" src=\"/bowerstatic/components/jquery/2.1.1/dist/jquery.js\"></script>\\n<script type=\"text/javascript\" src=\"/bowerstatic/local/local_component/2.0/local.js\"></script></head><body>Hello!</body></html>')\n", "label": "Variable misuse"}
{"function": "\n\ndef warn(self, stacklevel=2):\n    see_above = self.fullMessage\n    warnings.warn(see_above, SymPyDeprecationWarning, stacklevel=stacklevel)\n", "label": "Correct"}
{"function": "\n\ndef warn(self, stacklevel=2):\n    see_above = see_above.fullMessage\n    warnings.warn(see_above, SymPyDeprecationWarning, stacklevel=stacklevel)\n", "label": "Variable misuse"}
{"function": "\n\ndef valueChange(self, event):\n    hue = (float(str(event.getProperty().getValue())) / 360.0)\n    saturation = (float(str(self._cpp._saturationSlider.getValue())) / 100.0)\n    value = (float(str(self._cpp._valueSlider.getValue())) / 100.0)\n    color = Color(*hsv_to_rgb(hue, saturation, value))\n    self._cpp.setColor(color)\n    bgColor = Color(*hsv_to_rgb(hue, 1.0, 1.0))\n    self._cpp._hsvGradient.setBackgroundColor(bgColor)\n", "label": "Correct"}
{"function": "\n\ndef valueChange(self, event):\n    hue = (float(str(event.getProperty().getValue())) / 360.0)\n    saturation = (float(str(self._cpp._saturationSlider.getValue())) / 100.0)\n    value = (float(str(self._cpp._valueSlider.getValue())) / 100.0)\n    color = Color(*hsv_to_rgb(hue, saturation, value))\n    self._cpp.setColor(color)\n    bgColor = Color(*hsv_to_rgb(hue, 1.0, 1.0))\n    self._cpp._hsvGradient.setBackgroundColor(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef stackhut_api_call(endpoint, msg, secure=True, return_json=True):\n    url = urllib.parse.urljoin(utils.SERVER_URL, endpoint)\n    log.debug('Calling Stackhut Server at {} with \\n\\t{}'.format(url, json.dumps(msg)))\n    r = requests.post(url, data=json.dumps(msg), headers=json_header)\n    if (r.status_code == requests.codes.ok):\n        return (r.json() if return_json else r.text)\n    else:\n        log.error('Error {} talking to Stackhut Server'.format(r.status_code))\n        log.error(r.text)\n        r.raise_for_status()\n", "label": "Correct"}
{"function": "\n\ndef stackhut_api_call(endpoint, msg, secure=True, return_json=True):\n    url = urllib.parse.urljoin(utils.SERVER_URL, endpoint)\n    log.debug('Calling Stackhut Server at {} with \\n\\t{}'.format(url, json.dumps(msg)))\n    r = requests.post(r, data=json.dumps(msg), headers=json_header)\n    if (r.status_code == requests.codes.ok):\n        return (r.json() if return_json else r.text)\n    else:\n        log.error('Error {} talking to Stackhut Server'.format(r.status_code))\n        log.error(r.text)\n        r.raise_for_status()\n", "label": "Variable misuse"}
{"function": "\n\ndef main():\n    '\\n    %prog database.fa query.fa [options]\\n\\n    Wrapper for NCBI BLAST+.\\n    '\n    p = OptionParser(main.__doc__)\n    p.add_option('--format', default=\" '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' \", help='0-11, learn more with \"blastp -help\". [default: %default]')\n    p.add_option('--path', dest='blast_path', default=None, help='specify BLAST+ path including the program name')\n    p.add_option('--prog', dest='blast_program', default='blastp', help='specify BLAST+ program to use. See complete list here: http://www.ncbi.nlm.nih.gov/books/NBK52640/#chapter1.Installation [default: %default]')\n    p.set_align(evalue=0.01)\n    p.add_option('--best', default=1, type='int', help='Only look for best N hits [default: %default]')\n    p.set_cpus()\n    p.add_option('--nprocs', default=1, type='int', help=(('number of BLAST processes to run in parallel. ' + 'split query.fa into `nprocs` chunks, ') + 'each chunk uses -num_threads=`cpus`'))\n    p.set_params()\n    p.set_outfile()\n    (opts, args) = p.parse_args()\n    if ((len(args) != 2) or (opts.blast_program is None)):\n        sys.exit((not p.print_help()))\n    (bfasta_fn, afasta_fn) = args\n    for fn in (afasta_fn, bfasta_fn):\n        assert op.exists(fn)\n    afasta_fn = op.abspath(afasta_fn)\n    bfasta_fn = op.abspath(bfasta_fn)\n    out_fh = must_open(opts.outfile, 'w')\n    extra = opts.extra\n    blast_path = opts.blast_path\n    blast_program = opts.blast_program\n    blast_bin = (blast_path or blast_program)\n    if (op.basename(blast_bin) != blast_program):\n        blast_bin = op.join(blast_bin, blast_program)\n    (nprocs, cpus) = (opts.nprocs, opts.cpus)\n    if (nprocs > 1):\n        logging.debug(('Dispatch job to %d processes' % nprocs))\n        outdir = 'outdir'\n        fs = split([afasta_fn, outdir, str(nprocs)])\n        queries = fs.names\n    else:\n        queries = [afasta_fn]\n    dbtype = ('prot' if (op.basename(blast_bin) in ('blastp', 'blastx')) else 'nucl')\n    db = bfasta_fn\n    if (dbtype == 'prot'):\n        nin = (db + '.pin')\n    else:\n        nin = (db + '.nin')\n        nin00 = (db + '.00.nin')\n        nin = (nin00 if op.exists(nin00) else (db + '.nin'))\n    run_formatdb(infile=db, outfile=nin, dbtype=dbtype)\n    lock = Lock()\n    blastplus_template = '{0} -db {1} -outfmt {2}'\n    blast_cmd = blastplus_template.format(blast_bin, bfasta_fn, opts.format)\n    blast_cmd += ' -evalue {0} -max_target_seqs {1}'.format(opts.evalue, opts.best)\n    blast_cmd += ' -num_threads {0}'.format(cpus)\n    if extra:\n        blast_cmd += (' ' + extra.strip())\n    args = [(out_fh, blast_cmd, query, lock) for query in queries]\n    g = Jobs(target=blastplus, args=args)\n    g.run()\n", "label": "Correct"}
{"function": "\n\ndef main():\n    '\\n    %prog database.fa query.fa [options]\\n\\n    Wrapper for NCBI BLAST+.\\n    '\n    p = OptionParser(main.__doc__)\n    p.add_option('--format', default=\" '6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore' \", help='0-11, learn more with \"blastp -help\". [default: %default]')\n    p.add_option('--path', dest='blast_path', default=None, help='specify BLAST+ path including the program name')\n    p.add_option('--prog', dest='blast_program', default='blastp', help='specify BLAST+ program to use. See complete list here: http://www.ncbi.nlm.nih.gov/books/NBK52640/#chapter1.Installation [default: %default]')\n    p.set_align(evalue=0.01)\n    cpus.add_option('--best', default=1, type='int', help='Only look for best N hits [default: %default]')\n    p.set_cpus()\n    p.add_option('--nprocs', default=1, type='int', help=(('number of BLAST processes to run in parallel. ' + 'split query.fa into `nprocs` chunks, ') + 'each chunk uses -num_threads=`cpus`'))\n    p.set_params()\n    p.set_outfile()\n    (opts, args) = p.parse_args()\n    if ((len(args) != 2) or (opts.blast_program is None)):\n        sys.exit((not p.print_help()))\n    (bfasta_fn, afasta_fn) = args\n    for fn in (afasta_fn, bfasta_fn):\n        assert op.exists(fn)\n    afasta_fn = op.abspath(afasta_fn)\n    bfasta_fn = op.abspath(bfasta_fn)\n    out_fh = must_open(opts.outfile, 'w')\n    extra = opts.extra\n    blast_path = opts.blast_path\n    blast_program = opts.blast_program\n    blast_bin = (blast_path or blast_program)\n    if (op.basename(blast_bin) != blast_program):\n        blast_bin = op.join(blast_bin, blast_program)\n    (nprocs, cpus) = (opts.nprocs, opts.cpus)\n    if (nprocs > 1):\n        logging.debug(('Dispatch job to %d processes' % nprocs))\n        outdir = 'outdir'\n        fs = split([afasta_fn, outdir, str(nprocs)])\n        queries = fs.names\n    else:\n        queries = [afasta_fn]\n    dbtype = ('prot' if (op.basename(blast_bin) in ('blastp', 'blastx')) else 'nucl')\n    db = bfasta_fn\n    if (dbtype == 'prot'):\n        nin = (db + '.pin')\n    else:\n        nin = (db + '.nin')\n        nin00 = (db + '.00.nin')\n        nin = (nin00 if op.exists(nin00) else (db + '.nin'))\n    run_formatdb(infile=db, outfile=nin, dbtype=dbtype)\n    lock = Lock()\n    blastplus_template = '{0} -db {1} -outfmt {2}'\n    blast_cmd = blastplus_template.format(blast_bin, bfasta_fn, opts.format)\n    blast_cmd += ' -evalue {0} -max_target_seqs {1}'.format(opts.evalue, opts.best)\n    blast_cmd += ' -num_threads {0}'.format(cpus)\n    if extra:\n        blast_cmd += (' ' + extra.strip())\n    args = [(out_fh, blast_cmd, query, lock) for query in queries]\n    g = Jobs(target=blastplus, args=args)\n    g.run()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_resource_targets(self):\n    self.create_file('res/data.txt', contents='1/137')\n    res = self.make_target(spec='res:resources', target_type=Resources, sources=['data.txt'])\n    lib = self.make_target(spec='test:lib', target_type=PythonLibrary, resource_targets=[res.address.spec])\n    resource_dep = self.assert_single_resource_dep(lib, expected_resource_path='res/data.txt', expected_resource_contents='1/137')\n    self.assertIs(res, resource_dep)\n", "label": "Correct"}
{"function": "\n\ndef test_resource_targets(self):\n    self.create_file('res/data.txt', contents='1/137')\n    res = self.make_target(spec='res:resources', target_type=Resources, sources=['data.txt'])\n    lib = self.make_target(spec='test:lib', target_type=PythonLibrary, resource_targets=[res.address.spec])\n    resource_dep = self.assert_single_resource_dep(lib, expected_resource_path='res/data.txt', expected_resource_contents='1/137')\n    lib.assertIs(res, resource_dep)\n", "label": "Variable misuse"}
{"function": "\n\ndef testMsiArgs(self):\n\n    def mockBuildMSI(version, msiArgs=None):\n\n        def do(a, macros):\n            a.package = (a.package % macros)\n            msiPath = os.path.join(self.archivePath, 'Setup2.msi')\n            a.recipe._addCapsule(msiPath, 'msi', (a.package % macros))\n            a.recipe.winHelper = source.WindowsHelper()\n            a.recipe.winHelper.productName = 'WindowsAppTest'\n            a.recipe.winHelper.platform = ''\n            a.recipe.winHelper.version = version\n            a.recipe.winHelper.productCode = 'foo'\n            a.recipe.winHelper.upgradeCode = 'bar'\n            a.recipe.winHelper.msiArgs = msiArgs\n        self.mock(build.BuildMSI, 'do', do)\n    repos = self.openRepository()\n    origDir = os.getcwd()\n    self.resetWork()\n    os.chdir(self.workDir)\n    self.newpkg('WindowsAppTest')\n    os.chdir('WindowsAppTest')\n    self.writeFile('WindowsAppTest.recipe', self.test_recipe3)\n    self.addfile('WindowsAppTest.recipe')\n    self.commit()\n    os.chdir(origDir)\n    self.resetWork()\n    os.chdir(self.workDir)\n    mockBuildMSI('1.2.3.4', '/q /l*v /i')\n    (built, _) = self.cookItem(repos, self.cfg, 'WindowsAppTest')\n    msis = [x for x in built if x[0].endswith(':msi')]\n    self.assertEqual(len(msis), 1)\n    msi = msis[0]\n    repos = self.openRepository()\n    spec = repos.findTrove(self.cfg.buildLabel, msi)\n    self.assertEqual(len(spec), 1)\n    trv = repos.getTrove(*spec[0])\n    self.assertEqual(trv.troveInfo.capsule.msi.name(), 'WindowsAppTest')\n    self.assertEqual(trv.troveInfo.capsule.msi.platform(), '')\n    self.assertEqual(trv.troveInfo.capsule.msi.version(), '1.2.3.4')\n    self.assertEqual(trv.troveInfo.capsule.msi.productCode(), 'foo')\n    self.assertEqual(trv.troveInfo.capsule.msi.upgradeCode(), 'bar')\n    self.assertEqual(trv.troveInfo.capsule.msi.msiArgs(), '/q /l*v /i')\n", "label": "Correct"}
{"function": "\n\ndef testMsiArgs(self):\n\n    def mockBuildMSI(version, msiArgs=None):\n\n        def do(a, macros):\n            a.package = (a.package % macros)\n            msiPath = os.path.join(self.archivePath, 'Setup2.msi')\n            a.recipe._addCapsule(msiPath, 'msi', (a.package % macros))\n            a.recipe.winHelper = source.WindowsHelper()\n            a.recipe.winHelper.productName = 'WindowsAppTest'\n            a.recipe.winHelper.platform = ''\n            a.recipe.winHelper.version = version\n            a.recipe.winHelper.productCode = 'foo'\n            a.recipe.winHelper.upgradeCode = 'bar'\n            a.recipe.winHelper.msiArgs = msiArgs\n        self.mock(build.BuildMSI, 'do', do)\n    repos = self.openRepository()\n    origDir = os.getcwd()\n    self.resetWork()\n    os.chdir(self.workDir)\n    self.newpkg('WindowsAppTest')\n    os.chdir('WindowsAppTest')\n    self.writeFile('WindowsAppTest.recipe', self.test_recipe3)\n    self.addfile('WindowsAppTest.recipe')\n    self.commit()\n    os.chdir(origDir)\n    self.resetWork()\n    os.chdir(self.workDir)\n    mockBuildMSI('1.2.3.4', '/q /l*v /i')\n    (built, _) = self.cookItem(repos, self.cfg, 'WindowsAppTest')\n    msis = [x for x in built if x[0].endswith(':msi')]\n    self.assertEqual(len(msis), 1)\n    msi = msis[0]\n    repos = self.openRepository()\n    spec = repos.findTrove(self.cfg.buildLabel, msi)\n    self.assertEqual(len(spec), 1)\n    trv = repos.getTrove(*spec[0])\n    self.assertEqual(trv.troveInfo.capsule.msi.name(), 'WindowsAppTest')\n    self.assertEqual(trv.troveInfo.capsule.msi.platform(), '')\n    self.assertEqual(trv.troveInfo.capsule.msi.version(), '1.2.3.4')\n    self.assertEqual(trv.troveInfo.capsule.msi.productCode(), 'foo')\n    self.assertEqual(trv.troveInfo.capsule.msi.upgradeCode(), 'bar')\n    self.assertEqual(msis.troveInfo.capsule.msi.msiArgs(), '/q /l*v /i')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_basic(self):\n    'messages are sent and received properly'\n    question = b'sucess?'\n    answer = b'yeah, success'\n\n    def handler(sock):\n        text = sock.recv(1000)\n        assert (text == question)\n        sock.sendall(answer)\n    with Server(handler) as (host, port):\n        sock = socket.socket()\n        sock.connect((host, port))\n        sock.sendall(question)\n        text = sock.recv(1000)\n        assert (text == answer)\n        sock.close()\n", "label": "Correct"}
{"function": "\n\ndef test_basic(self):\n    'messages are sent and received properly'\n    question = b'sucess?'\n    answer = b'yeah, success'\n\n    def handler(sock):\n        text = sock.recv(1000)\n        assert (text == question)\n        sock.sendall(answer)\n    with Server(handler) as (host, port):\n        sock = socket.socket()\n        sock.connect((host, port))\n        sock.sendall(question)\n        text = sock.recv(1000)\n        assert (text == answer)\n        self.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef render(self, context):\n    from pennyblack.models import Link, Newsletter\n    if ('mail' not in context):\n        return '#'\n    mail = context['mail']\n    newsletter = mail.job.newsletter\n    if newsletter.is_workflow():\n        job = newsletter.get_default_job()\n    else:\n        job = mail.job\n    try:\n        link = job.links.get(identifier=self.identifier)\n    except job.links.model.DoesNotExist:\n        link = Newsletter.add_view_link_to_job(self.identifier, job)\n    return (context['base_url'] + reverse('pennyblack.redirect_link', args=(mail.mail_hash, link.link_hash)))\n", "label": "Correct"}
{"function": "\n\ndef render(self, context):\n    from pennyblack.models import Link, Newsletter\n    if ('mail' not in context):\n        return '#'\n    mail = context['mail']\n    newsletter = mail.job.newsletter\n    if newsletter.is_workflow():\n        job = newsletter.get_default_job()\n    else:\n        job = job.job\n    try:\n        link = job.links.get(identifier=self.identifier)\n    except job.links.model.DoesNotExist:\n        link = Newsletter.add_view_link_to_job(self.identifier, job)\n    return (context['base_url'] + reverse('pennyblack.redirect_link', args=(mail.mail_hash, link.link_hash)))\n", "label": "Variable misuse"}
{"function": "\n\ndef IsAtEnd(self, string):\n    'Returns whether this position is at the end of the given string.\\n\\n    Args:\\n      string: The string to test for the end of.\\n\\n    Returns:\\n      Whether this position is at the end of the given string.\\n    '\n    return ((self.start == len(string)) and (self.length == 0))\n", "label": "Correct"}
{"function": "\n\ndef IsAtEnd(self, string):\n    'Returns whether this position is at the end of the given string.\\n\\n    Args:\\n      string: The string to test for the end of.\\n\\n    Returns:\\n      Whether this position is at the end of the given string.\\n    '\n    return ((self.start == len(self)) and (self.length == 0))\n", "label": "Variable misuse"}
{"function": "\n\n@base.resource(Reply)\ndef reply(self, reply_id):\n    '\\n        Return the resource corresponding to a single reply\\n        '\n    return Reply(self, reply_id)\n", "label": "Correct"}
{"function": "\n\n@base.resource(Reply)\ndef reply(self, reply_id):\n    '\\n        Return the resource corresponding to a single reply\\n        '\n    return Reply(reply_id, reply_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_uri_get_ssl_version(self):\n    connection = UriConnection('amqp://guest:guest@localhost:5672/%2F', True)\n    self.assertEqual(ssl.PROTOCOL_TLSv1, connection._get_ssl_version('protocol_tlsv1'))\n", "label": "Correct"}
{"function": "\n\ndef test_uri_get_ssl_version(self):\n    connection = UriConnection('amqp://guest:guest@localhost:5672/%2F', True)\n    self.assertEqual(ssl.PROTOCOL_TLSv1, self._get_ssl_version('protocol_tlsv1'))\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_context(self, dict_=None, processors=None):\n    return RequestContext(self.request, dict_, processors=processors)\n", "label": "Correct"}
{"function": "\n\ndef _get_context(self, dict_=None, processors=None):\n    return RequestContext(self.request, dict_, processors=self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n    'We want it to print as a Cycle, not as a dict.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics import Cycle\\n        >>> Cycle(1, 2)\\n        (1 2)\\n        >>> print(_)\\n        (1 2)\\n        >>> list(Cycle(1, 2).items())\\n        [(1, 2), (2, 1)]\\n        '\n    if (not self):\n        return 'Cycle()'\n    cycles = Permutation(self).cyclic_form\n    s = ''.join((str(tuple(c)) for c in cycles))\n    big = (self.size - 1)\n    if (not any(((i == big) for c in cycles for i in c))):\n        s += ('(%s)' % big)\n    return ('Cycle%s' % s)\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n    'We want it to print as a Cycle, not as a dict.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics import Cycle\\n        >>> Cycle(1, 2)\\n        (1 2)\\n        >>> print(_)\\n        (1 2)\\n        >>> list(Cycle(1, 2).items())\\n        [(1, 2), (2, 1)]\\n        '\n    if (not self):\n        return 'Cycle()'\n    cycles = Permutation(self).cyclic_form\n    s = ''.join((str(tuple(s)) for c in cycles))\n    big = (self.size - 1)\n    if (not any(((i == big) for c in cycles for i in c))):\n        s += ('(%s)' % big)\n    return ('Cycle%s' % s)\n", "label": "Variable misuse"}
{"function": "\n\n@plug.handler()\ndef delete_file(metadata):\n    try:\n        ignore_delete.add(metadata.path)\n        os.unlink(metadata.path)\n    except (IOError, OSError) as e:\n        ignore_delete.discard(metadata.path)\n        raise ServiceError(\"Error deleting file '{}': {}\".format(metadata.path, e))\n", "label": "Correct"}
{"function": "\n\n@plug.handler()\ndef delete_file(metadata):\n    try:\n        ignore_delete.add(metadata.path)\n        os.unlink(metadata.path)\n    except (IOError, OSError) as e:\n        ignore_delete.discard(metadata.path)\n        raise ServiceError(\"Error deleting file '{}': {}\".format(metadata.path, metadata))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_non_parent(self):\n    self.stubs.Set(db, 'process_delete', fake_delete)\n    self.mox.StubOutWithMock(db, 'process_get_by_pid')\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    self.mox.StubOutWithMock(manager.ResourceOperator, 'process_delete')\n    db.process_get_by_pid(IsA(context.RequestContext), GID, PID1).AndReturn({\n        'pid': PID1,\n        'nova_instance_id': 'nova_instance_id_data',\n    })\n    db.process_get_all(IsA(context.RequestContext), GID, {\n        'ppid': PID1,\n    }).AndReturn([])\n    manager.ResourceOperator.process_delete(IsA(context.RequestContext), IsA(str))\n    self.mox.ReplayAll()\n    url = ((get_base_url(GID) + '/') + PID1)\n    req = get_request(url, 'DELETE')\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 204)\n", "label": "Correct"}
{"function": "\n\ndef test_delete_non_parent(self):\n    self.stubs.Set(db, 'process_delete', fake_delete)\n    self.mox.StubOutWithMock(db, 'process_get_by_pid')\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    self.mox.StubOutWithMock(manager.ResourceOperator, 'process_delete')\n    db.process_get_by_pid(IsA(context.RequestContext), GID, PID1).AndReturn({\n        'pid': PID1,\n        'nova_instance_id': 'nova_instance_id_data',\n    })\n    db.process_get_all(IsA(context.RequestContext), GID, {\n        'ppid': PID1,\n    }).AndReturn([])\n    manager.ResourceOperator.process_delete(IsA(context.RequestContext), IsA(str))\n    req.mox.ReplayAll()\n    url = ((get_base_url(GID) + '/') + PID1)\n    req = get_request(url, 'DELETE')\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 204)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_default_error_code(self):\n\n    class FakeNovaException(exception.NovaException):\n        code = 404\n    exc = FakeNovaException()\n    self.assertEqual(404, exc.kwargs['code'])\n", "label": "Correct"}
{"function": "\n\ndef test_default_error_code(self):\n\n    class FakeNovaException(exception.NovaException):\n        code = 404\n    exc = FakeNovaException()\n    code.assertEqual(404, exc.kwargs['code'])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_channel_raises_when_closed(self):\n    channel = Channel(0, FakeConnection(FakeConnection.OPEN), 360)\n    channel.set_state(channel.CLOSED)\n    self.assertFalse(channel.is_open)\n    self.assertRaisesRegexp(exception.AMQPChannelError, 'channel was closed', channel.check_for_errors)\n    self.assertTrue(channel.is_closed)\n", "label": "Correct"}
{"function": "\n\ndef test_channel_raises_when_closed(self):\n    channel = Channel(0, FakeConnection(FakeConnection.OPEN), 360)\n    channel.set_state(channel.CLOSED)\n    self.assertFalse(channel.is_open)\n    self.assertRaisesRegexp(exception.AMQPChannelError, 'channel was closed', channel.check_for_errors)\n    self.assertTrue(self.is_closed)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_write_a_file(self, gitfs_log):\n    content = 'Just a small file'\n    filename = '{}/new_file'.format(self.current_path)\n    with gitfs_log('SyncWorker: Set push_successful'):\n        with open(filename, 'w') as f:\n            f.write(content)\n    with open(filename) as f:\n        assert (f.read() == content)\n    with pull(self.sh):\n        self.assert_new_commit()\n        self.assert_commit_message('Update /new_file')\n", "label": "Correct"}
{"function": "\n\ndef test_write_a_file(self, gitfs_log):\n    content = 'Just a small file'\n    filename = '{}/new_file'.format(self.current_path)\n    with gitfs_log('SyncWorker: Set push_successful'):\n        with open(content, 'w') as f:\n            f.write(content)\n    with open(filename) as f:\n        assert (f.read() == content)\n    with pull(self.sh):\n        self.assert_new_commit()\n        self.assert_commit_message('Update /new_file')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_log_args_with_filelog_and_syslog(self):\n    conf_dict = {\n        'debug': True,\n        'verbose': True,\n        'log_file': 'tests/filelog',\n        'log_dir': '/etc/tests',\n        'use_syslog': True,\n        'syslog_log_facility': 'LOG_USER',\n    }\n    conf = dhcp.DictModel(conf_dict)\n    expected_args = ['--debug', '--verbose', '--log-file=log_file_name', '--log-dir=/etc/tests/tests']\n    args = config.get_log_args(conf, 'log_file_name')\n    self.assertEqual(expected_args, args)\n", "label": "Correct"}
{"function": "\n\ndef test_log_args_with_filelog_and_syslog(self):\n    conf_dict = {\n        'debug': True,\n        'verbose': True,\n        'log_file': 'tests/filelog',\n        'log_dir': '/etc/tests',\n        'use_syslog': True,\n        'syslog_log_facility': 'LOG_USER',\n    }\n    conf = dhcp.DictModel(conf_dict)\n    expected_args = ['--debug', '--verbose', '--log-file=log_file_name', '--log-dir=/etc/tests/tests']\n    args = config.get_log_args(conf, 'log_file_name')\n    expected_args.assertEqual(expected_args, args)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_substring_filter(self, query):\n    query = re.escape(query.lower())\n    flt = ('\\n.*%s.*\\n' % query)\n    return (flt, False)\n", "label": "Correct"}
{"function": "\n\ndef get_substring_filter(self, query):\n    query = re.escape(query.lower())\n    flt = ('\\n.*%s.*\\n' % query)\n    return (query, False)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_context(self):\n    self.client.quit()\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, keyfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, keyfile=CERTFILE, context=ctx)\n    self.client = ftplib.FTP_TLS(context=ctx, timeout=2)\n    self.client.connect(self.server.host, self.server.port)\n    self.assertNotIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.auth()\n    self.assertIs(self.client.sock.context, ctx)\n    self.assertIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.prot_p()\n    with self.client.transfercmd('list') as sock:\n        self.assertIs(sock.context, ctx)\n        self.assertIsInstance(sock, ssl.SSLSocket)\n", "label": "Correct"}
{"function": "\n\ndef test_context(self):\n    self.client.quit()\n    ctx = ssl.SSLContext(ssl.PROTOCOL_TLSv1)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, keyfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, context=ctx)\n    self.assertRaises(ValueError, ftplib.FTP_TLS, certfile=CERTFILE, keyfile=CERTFILE, context=ctx)\n    self.client = ftplib.FTP_TLS(context=ctx, timeout=2)\n    self.client.connect(self.server.host, self.server.port)\n    self.assertNotIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.auth()\n    self.assertIs(self.client.sock.context, sock)\n    self.assertIsInstance(self.client.sock, ssl.SSLSocket)\n    self.client.prot_p()\n    with self.client.transfercmd('list') as sock:\n        self.assertIs(sock.context, ctx)\n        self.assertIsInstance(sock, ssl.SSLSocket)\n", "label": "Variable misuse"}
{"function": "\n\ndef testConnectionLeaks(self):\n    for i in range(3):\n        self.assertEquals(self._countConnections(11211), 0)\n        new_conf = {\n            'init_config': {\n                \n            },\n            'instances': [{\n                'url': 'localhost',\n            }],\n        }\n        self.run_check(new_conf)\n        self.assertEquals(self._countConnections(11211), 0)\n", "label": "Correct"}
{"function": "\n\ndef testConnectionLeaks(self):\n    for i in range(3):\n        i.assertEquals(self._countConnections(11211), 0)\n        new_conf = {\n            'init_config': {\n                \n            },\n            'instances': [{\n                'url': 'localhost',\n            }],\n        }\n        self.run_check(new_conf)\n        self.assertEquals(self._countConnections(11211), 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef info2iob(sentence, chunks, informations):\n    info_list = ([], [], [])\n    for information in informations:\n        temp_list = positions(information, sentence)\n        for i in range(3):\n            if (temp_list[i] not in info_list[i]):\n                info_list[i].append(temp_list[i])\n    return tag_sent(chunks, info_list)\n", "label": "Correct"}
{"function": "\n\ndef info2iob(sentence, chunks, informations):\n    info_list = ([], [], [])\n    for information in informations:\n        temp_list = positions(information, sentence)\n        for i in range(3):\n            if (temp_list[i] not in info_list[i]):\n                information[i].append(temp_list[i])\n    return tag_sent(chunks, info_list)\n", "label": "Variable misuse"}
{"function": "\n\ndef _setup_units(self, connections, params_dict, unknowns_dict):\n    '\\n        Calculate unit conversion factors for any connected\\n        variables having different units and store them in params_dict.\\n\\n        Args\\n        ----\\n        connections : dict\\n            A dict of target variables (absolute name) mapped\\n            to the absolute name of their source variable and the\\n            relevant indices of that source if applicable.\\n\\n        params_dict : OrderedDict\\n            A dict of parameter metadata for the whole `Problem`.\\n\\n        unknowns_dict : OrderedDict\\n            A dict of unknowns metadata for the whole `Problem`.\\n        '\n    to_prom_name = self.root._sysdata.to_prom_name\n    for (target, (source, idxs)) in iteritems(connections):\n        tmeta = params_dict[target]\n        smeta = unknowns_dict[source]\n        if (('units' not in tmeta) or ('units' not in smeta)):\n            continue\n        src_unit = smeta['units']\n        tgt_unit = tmeta['units']\n        try:\n            (scale, offset) = get_conversion_tuple(src_unit, tgt_unit)\n        except TypeError as err:\n            if (str(err) == 'Incompatible units'):\n                msg = \"Unit '{0}' in source {1} is incompatible with unit '{2}' in target {3}.\".format(src_unit, _both_names(smeta, to_prom_name), tgt_unit, _both_names(tmeta, to_prom_name))\n                self._setup_errors.append(msg)\n                continue\n            else:\n                raise\n        if ((scale != 1.0) or (offset != 0.0)):\n            tmeta['unit_conv'] = (scale, offset)\n", "label": "Correct"}
{"function": "\n\ndef _setup_units(self, connections, params_dict, unknowns_dict):\n    '\\n        Calculate unit conversion factors for any connected\\n        variables having different units and store them in params_dict.\\n\\n        Args\\n        ----\\n        connections : dict\\n            A dict of target variables (absolute name) mapped\\n            to the absolute name of their source variable and the\\n            relevant indices of that source if applicable.\\n\\n        params_dict : OrderedDict\\n            A dict of parameter metadata for the whole `Problem`.\\n\\n        unknowns_dict : OrderedDict\\n            A dict of unknowns metadata for the whole `Problem`.\\n        '\n    to_prom_name = self.root._sysdata.to_prom_name\n    for (target, (source, idxs)) in iteritems(connections):\n        tmeta = params_dict[target]\n        smeta = unknowns_dict[source]\n        if (('units' not in tmeta) or ('units' not in smeta)):\n            continue\n        src_unit = smeta['units']\n        tgt_unit = tmeta['units']\n        try:\n            (scale, offset) = get_conversion_tuple(src_unit, tgt_unit)\n        except TypeError as err:\n            if (str(err) == 'Incompatible units'):\n                msg = \"Unit '{0}' in source {1} is incompatible with unit '{2}' in target {3}.\".format(src_unit, _both_names(smeta, offset), tgt_unit, _both_names(tmeta, to_prom_name))\n                self._setup_errors.append(msg)\n                continue\n            else:\n                raise\n        if ((scale != 1.0) or (offset != 0.0)):\n            tmeta['unit_conv'] = (scale, offset)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef load_missing(cls, cloud, object_id):\n    identity_client = clients.identity_client(cloud)\n    try:\n        raw_tenant = identity_client.tenants.get(object_id.id)\n        return cls.load_from_cloud(cloud, raw_tenant)\n    except exceptions.NotFound:\n        return None\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef load_missing(cls, cloud, object_id):\n    identity_client = clients.identity_client(cloud)\n    try:\n        raw_tenant = identity_client.tenants.get(cloud.id)\n        return cls.load_from_cloud(cloud, raw_tenant)\n    except exceptions.NotFound:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef find_duplicates(conn, limit=50, index=None):\n    query = 'SELECT f.id, fingerprint, length FROM fingerprint f LEFT JOIN fingerprint_deduplicate d ON f.id=d.id WHERE d.id IS NULL ORDER BY f.id LIMIT 1000'\n    for fingerprint in conn.execute(query):\n        find_track_duplicates(conn, fingerprint, index=index)\n", "label": "Correct"}
{"function": "\n\ndef find_duplicates(conn, limit=50, index=None):\n    query = 'SELECT f.id, fingerprint, length FROM fingerprint f LEFT JOIN fingerprint_deduplicate d ON f.id=d.id WHERE d.id IS NULL ORDER BY f.id LIMIT 1000'\n    for fingerprint in limit.execute(query):\n        find_track_duplicates(conn, fingerprint, index=index)\n", "label": "Variable misuse"}
{"function": "\n\ndef _delete(self, filter, multi=False):\n    if (filter is None):\n        filter = {\n            \n        }\n    if (not isinstance(filter, collections.Mapping)):\n        filter = {\n            '_id': filter,\n        }\n    to_delete = list(self.find(filter))\n    deleted_count = 0\n    for doc in to_delete:\n        doc_id = doc['_id']\n        if isinstance(doc_id, dict):\n            doc_id = helpers.hashdict(doc_id)\n        del self._documents[doc_id]\n        deleted_count += 1\n        if (not multi):\n            break\n    return {\n        'connectionId': self._database.client._id,\n        'n': deleted_count,\n        'ok': 1.0,\n        'err': None,\n    }\n", "label": "Correct"}
{"function": "\n\ndef _delete(self, filter, multi=False):\n    if (filter is None):\n        filter = {\n            \n        }\n    if (not isinstance(filter, collections.Mapping)):\n        filter = {\n            '_id': filter,\n        }\n    to_delete = list(self.find(filter))\n    deleted_count = 0\n    for doc in to_delete:\n        doc_id = doc['_id']\n        if isinstance(doc_id, dict):\n            doc_id = helpers.hashdict(doc_id)\n        del self._documents[doc_id]\n        deleted_count += 1\n        if (not multi):\n            break\n    return {\n        'connectionId': self._database.client._id,\n        'n': doc,\n        'ok': 1.0,\n        'err': None,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef items(self):\n    'Dict-like items() that returns a list of name-value tuples from the jar.\\n        See keys() and values(). Allows client-code to call \"dict(RequestsCookieJar)\\n        and get a vanilla python dict of key value pairs.'\n    items = []\n    for cookie in iter(self):\n        items.append((cookie.name, cookie.value))\n    return items\n", "label": "Correct"}
{"function": "\n\ndef items(self):\n    'Dict-like items() that returns a list of name-value tuples from the jar.\\n        See keys() and values(). Allows client-code to call \"dict(RequestsCookieJar)\\n        and get a vanilla python dict of key value pairs.'\n    items = []\n    for cookie in iter(self):\n        cookie.append((cookie.name, cookie.value))\n    return items\n", "label": "Variable misuse"}
{"function": "\n\ndef intersects(self, other):\n    return ((other.start < self.end) or (self.start < other.end))\n", "label": "Correct"}
{"function": "\n\ndef intersects(self, other):\n    return ((other.start < other.end) or (self.start < other.end))\n", "label": "Variable misuse"}
{"function": "\n\ndef list(self, id):\n    return self.client.get(('gists/%s/comments' % id), msg_type=GistCommentListResponse)\n", "label": "Correct"}
{"function": "\n\ndef list(self, id):\n    return id.client.get(('gists/%s/comments' % id), msg_type=GistCommentListResponse)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_token(self):\n    '\\n        Test executing master_call with lowdata\\n\\n        The choice of using key.list_all for this is arbitrary and should be\\n        changed to some mocked function that is more testing friendly.\\n        '\n    auth = salt.auth.LoadAuth(dict(self.get_config('client_config')))\n    token = auth.mk_token(self.eauth_creds)\n    token = auth.mk_token({\n        'username': 'saltdev_auto',\n        'password': 'saltdev',\n        'eauth': 'auto',\n    })\n    self.wheel.master_call(**{\n        'client': 'wheel',\n        'fun': 'key.list_all',\n        'token': token['token'],\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_token(self):\n    '\\n        Test executing master_call with lowdata\\n\\n        The choice of using key.list_all for this is arbitrary and should be\\n        changed to some mocked function that is more testing friendly.\\n        '\n    auth = salt.auth.LoadAuth(dict(auth.get_config('client_config')))\n    token = auth.mk_token(self.eauth_creds)\n    token = auth.mk_token({\n        'username': 'saltdev_auto',\n        'password': 'saltdev',\n        'eauth': 'auto',\n    })\n    self.wheel.master_call(**{\n        'client': 'wheel',\n        'fun': 'key.list_all',\n        'token': token['token'],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef select_coins(self, colorvalue, use_fee_estimator=None):\n    self._validate_select_coins_parameters(colorvalue, use_fee_estimator)\n    colordef = colorvalue.get_colordef()\n    if (colordef == UNCOLORED_MARKER):\n        return self.select_uncolored_coins(colorvalue, use_fee_estimator)\n    color_id = colordef.get_color_id()\n    if (color_id in self.inputs):\n        total = SimpleColorValue.sum([cv_u[0] for cv_u in self.inputs[color_id]])\n        if (total < colorvalue):\n            msg = 'Not enough coins: %s requested, %s found!'\n            raise InsufficientFundsError((msg % (colorvalue, total)))\n        return ([cv_u[1] for cv_u in self.inputs[color_id]], total)\n    if (colorvalue > self.our_value_limit):\n        raise InsufficientFundsError(('%s requested, %s found!' % (colorvalue, self.our_value_limit)))\n    return super(OperationalETxSpec, self).select_coins(colorvalue)\n", "label": "Correct"}
{"function": "\n\ndef select_coins(self, colorvalue, use_fee_estimator=None):\n    self._validate_select_coins_parameters(colorvalue, use_fee_estimator)\n    colordef = colorvalue.get_colordef()\n    if (colordef == UNCOLORED_MARKER):\n        return self.select_uncolored_coins(colorvalue, use_fee_estimator)\n    color_id = colordef.get_color_id()\n    if (color_id in self.inputs):\n        total = SimpleColorValue.sum([cv_u[0] for cv_u in self.inputs[color_id]])\n        if (total < colorvalue):\n            msg = 'Not enough coins: %s requested, %s found!'\n            raise InsufficientFundsError((msg % (colorvalue, total)))\n        return ([cv_u[1] for cv_u in self.inputs[color_id]], use_fee_estimator)\n    if (colorvalue > self.our_value_limit):\n        raise InsufficientFundsError(('%s requested, %s found!' % (colorvalue, self.our_value_limit)))\n    return super(OperationalETxSpec, self).select_coins(colorvalue)\n", "label": "Variable misuse"}
{"function": "\n\ndef checkFail(self, path):\n    loader = resource.Loader(path, script_home=self.script_home)\n    self.assertRaises(resource.ResourceNotFoundException, loader.file, 'file.txt')\n", "label": "Correct"}
{"function": "\n\ndef checkFail(self, path):\n    loader = resource.Loader(path, script_home=self.script_home)\n    path.assertRaises(resource.ResourceNotFoundException, loader.file, 'file.txt')\n", "label": "Variable misuse"}
{"function": "\n\ndef _wx_initialize_editor_control(self, editor):\n    ' Initializes the toolkit-specific control for an editor.\\n\\n        This is used to hook events managed by the framework etc.\\n\\n        '\n\n    def on_set_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = True\n        event.Skip()\n        return\n\n    def on_kill_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = False\n        event.Skip()\n        return\n    self._wx_add_focus_listeners(editor.control, on_set_focus, on_kill_focus)\n    return\n", "label": "Correct"}
{"function": "\n\ndef _wx_initialize_editor_control(self, editor):\n    ' Initializes the toolkit-specific control for an editor.\\n\\n        This is used to hook events managed by the framework etc.\\n\\n        '\n\n    def on_set_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = True\n        event.Skip()\n        return\n\n    def on_kill_focus(event):\n        ' Called when the control gets the focus. '\n        editor.has_focus = False\n        event.Skip()\n        return\n    editor._wx_add_focus_listeners(editor.control, on_set_focus, on_kill_focus)\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef get_connection(self, host, port, db):\n    '\\n        Returns a ``StrictRedis`` connection instance.\\n        '\n    return redis.StrictRedis(host=host, port=port, db=db, decode_responses=True)\n", "label": "Correct"}
{"function": "\n\ndef get_connection(self, host, port, db):\n    '\\n        Returns a ``StrictRedis`` connection instance.\\n        '\n    return redis.StrictRedis(host=host, port=port, db=port, decode_responses=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef match(self, left, collected=None):\n    collected = ([] if (collected is None) else collected)\n    outcomes = []\n    for p in self.children:\n        (matched, _, _) = outcome = p.match(left, collected)\n        if matched:\n            outcomes.append(outcome)\n    if outcomes:\n        return min(outcomes, key=(lambda outcome: len(outcome[1])))\n    return (False, left, collected)\n", "label": "Correct"}
{"function": "\n\ndef match(self, left, collected=None):\n    collected = ([] if (collected is None) else collected)\n    outcomes = []\n    for p in self.children:\n        (matched, _, _) = outcome = p.match(left, collected)\n        if matched:\n            collected.append(outcome)\n    if outcomes:\n        return min(outcomes, key=(lambda outcome: len(outcome[1])))\n    return (False, left, collected)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, maxsize=10, dispose_func=None):\n    self._maxsize = maxsize\n    self.dispose_func = dispose_func\n    self._container = self.ContainerCls()\n    self.lock = RLock()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, maxsize=10, dispose_func=None):\n    self._maxsize = maxsize\n    maxsize.dispose_func = dispose_func\n    self._container = self.ContainerCls()\n    self.lock = RLock()\n", "label": "Variable misuse"}
{"function": "\n\ndef append_to_warning_list(self, message, category, *args):\n    self.warning_list.append({\n        'message': message,\n        'category': category,\n    })\n", "label": "Correct"}
{"function": "\n\ndef append_to_warning_list(self, message, category, *args):\n    self.warning_list.append({\n        'message': message,\n        'category': args,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_input(self):\n    (title, msg) = ('Get Input Dialog', 'Enter your name:')\n    (text, resp) = QtGui.QInputDialog.getText(self, title, msg)\n    if resp:\n        self.label.setText(web.safeunicode(text))\n", "label": "Correct"}
{"function": "\n\ndef _get_input(self):\n    (title, msg) = ('Get Input Dialog', 'Enter your name:')\n    (text, resp) = QtGui.QInputDialog.getText(title, title, msg)\n    if resp:\n        self.label.setText(web.safeunicode(text))\n", "label": "Variable misuse"}
{"function": "\n\ndef _replace_cdata_list_attribute_values(self, tag_name, attrs):\n    'Replaces class=\"foo bar\" with class=[\"foo\", \"bar\"]\\n\\n        Modifies its input in place.\\n        '\n    if (not attrs):\n        return attrs\n    if self.cdata_list_attributes:\n        universal = self.cdata_list_attributes.get('*', [])\n        tag_specific = self.cdata_list_attributes.get(tag_name.lower(), None)\n        for attr in list(attrs.keys()):\n            if ((attr in universal) or (tag_specific and (attr in tag_specific))):\n                value = attrs[attr]\n                if isinstance(value, str):\n                    values = whitespace_re.split(value)\n                else:\n                    values = value\n                attrs[attr] = values\n    return attrs\n", "label": "Correct"}
{"function": "\n\ndef _replace_cdata_list_attribute_values(self, tag_name, attrs):\n    'Replaces class=\"foo bar\" with class=[\"foo\", \"bar\"]\\n\\n        Modifies its input in place.\\n        '\n    if (not attrs):\n        return attrs\n    if self.cdata_list_attributes:\n        universal = self.cdata_list_attributes.get('*', [])\n        tag_specific = self.cdata_list_attributes.get(attrs.lower(), None)\n        for attr in list(attrs.keys()):\n            if ((attr in universal) or (tag_specific and (attr in tag_specific))):\n                value = attrs[attr]\n                if isinstance(value, str):\n                    values = whitespace_re.split(value)\n                else:\n                    values = value\n                attrs[attr] = values\n    return attrs\n", "label": "Variable misuse"}
{"function": "\n\ndef do_field(self, name, field, count=0):\n    fname = ('id_%s' % name)\n    if ((field.__class__ in LV_FIELDS) and (not LV_FIELDS[field.__class__])):\n        self.opts.update(onlyOnSubmit=True)\n    lv = LiveValidation(fname, **self.opts)\n    fail = field.default_error_messages.get('invalid', None)\n    extrakw = {\n        'validMessage': ' ',\n    }\n    if fail:\n        extrakw['failureMessage'] = str(fail[:])\n    if (self.formcls in LV_VALIDATORS):\n        if (name in LV_VALIDATORS[self.formcls]):\n            for (v, kw) in LV_VALIDATORS[self.formcls][name].items():\n                extrakw.update(kw)\n                lv.add(v, **extrakw)\n            return str(lv)\n    if (hasattr(field, 'required') and field.required and (not isinstance(field, (fields.FileField, fields.ImageField)))):\n        lv.add(Presence, **extrakw)\n    if hasattr(field, 'max_length'):\n        v = getattr(field, 'max_length')\n        if v:\n            lv.add(Length, maximum=v, **extrakw)\n    if hasattr(field, 'min_length'):\n        v = getattr(field, 'min_length')\n        if v:\n            lv.add(Length, minimum=v, **extrakw)\n    if ((not (isinstance(field, fields.EmailField) or isinstance(field, fields.URLField))) and hasattr(field, 'regex')):\n        lv.add(Format, pattern=field.regex.pattern, **extrakw)\n    if ((field.__class__ in LV_FIELDS) and LV_FIELDS[field.__class__]):\n        for (v, kw) in LV_FIELDS[field.__class__].items():\n            extrakw.update(kw)\n            lv.add(v, **extrakw)\n    if str(lv):\n        return ('try{\\n%s\\n}catch(e){}' % str(lv))\n    return ''\n", "label": "Correct"}
{"function": "\n\ndef do_field(self, name, field, count=0):\n    fname = ('id_%s' % name)\n    if ((field.__class__ in LV_FIELDS) and (not LV_FIELDS[field.__class__])):\n        self.opts.update(onlyOnSubmit=True)\n    lv = LiveValidation(fname, **self.opts)\n    fail = field.default_error_messages.get('invalid', None)\n    extrakw = {\n        'validMessage': ' ',\n    }\n    if fail:\n        extrakw['failureMessage'] = str(fail[:])\n    if (self.formcls in LV_VALIDATORS):\n        if (name in LV_VALIDATORS[self.formcls]):\n            for (v, kw) in LV_VALIDATORS[self.formcls][name].items():\n                extrakw.update(kw)\n                lv.add(v, **extrakw)\n            return str(lv)\n    if (hasattr(field, 'required') and field.required and (not isinstance(field, (fields.FileField, fields.ImageField)))):\n        lv.add(Presence, **extrakw)\n    if hasattr(field, 'max_length'):\n        v = getattr(field, 'max_length')\n        if v:\n            lv.add(Length, maximum=v, **extrakw)\n    if hasattr(field, 'min_length'):\n        v = getattr(field, 'min_length')\n        if v:\n            lv.add(Length, minimum=v, **extrakw)\n    if ((not (isinstance(field, fields.EmailField) or isinstance(field, fields.URLField))) and hasattr(field, 'regex')):\n        lv.add(Format, pattern=field.regex.pattern, **extrakw)\n    if ((field.__class__ in LV_FIELDS) and LV_FIELDS[field.__class__]):\n        for (v, kw) in LV_FIELDS[field.__class__].items():\n            kw.update(kw)\n            lv.add(v, **extrakw)\n    if str(lv):\n        return ('try{\\n%s\\n}catch(e){}' % str(lv))\n    return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef test_status_method_when_playing_contains_bitrate(self):\n    self.set_tracklist(Track(uri='dummy:/a', bitrate=3200))\n    self.core.playback.play().get()\n    result = dict(status.status(self.context))\n    self.assertIn('bitrate', result)\n    self.assertEqual(int(result['bitrate']), 3200)\n", "label": "Correct"}
{"function": "\n\ndef test_status_method_when_playing_contains_bitrate(self):\n    self.set_tracklist(Track(uri='dummy:/a', bitrate=3200))\n    result.core.playback.play().get()\n    result = dict(status.status(self.context))\n    self.assertIn('bitrate', result)\n    self.assertEqual(int(result['bitrate']), 3200)\n", "label": "Variable misuse"}
{"function": "\n\ndef _sanitize_mod_params(self, other):\n    \"Sanitize the object being modded with this Message.\\n\\n        - Add support for modding 'None' so translation supports it\\n        - Trim the modded object, which can be a large dictionary, to only\\n        those keys that would actually be used in a translation\\n        - Snapshot the object being modded, in case the message is\\n        translated, it will be used as it was when the Message was created\\n        \"\n    if (other is None):\n        params = (other,)\n    elif isinstance(other, dict):\n        params = self._trim_dictionary_parameters(other)\n    else:\n        params = self._copy_param(other)\n    return params\n", "label": "Correct"}
{"function": "\n\ndef _sanitize_mod_params(self, other):\n    \"Sanitize the object being modded with this Message.\\n\\n        - Add support for modding 'None' so translation supports it\\n        - Trim the modded object, which can be a large dictionary, to only\\n        those keys that would actually be used in a translation\\n        - Snapshot the object being modded, in case the message is\\n        translated, it will be used as it was when the Message was created\\n        \"\n    if (other is None):\n        params = (other,)\n    elif isinstance(other, dict):\n        params = self._trim_dictionary_parameters(other)\n    else:\n        params = self._copy_param(self)\n    return params\n", "label": "Variable misuse"}
{"function": "\n\ndef __eq__(self, other):\n    if (not (type(other) is STP)):\n        return False\n    return ((self.network == other.network) and (self.port == other.port) and (self.label == other.label))\n", "label": "Correct"}
{"function": "\n\ndef __eq__(self, other):\n    if (not (type(other) is STP)):\n        return False\n    return ((self.network == other.network) and (self.port == other.port) and (self.label == self.label))\n", "label": "Variable misuse"}
{"function": "\n\ndef validate(self, doc):\n    if (not doc.get('_id', '')):\n        raise Exception('Attempting to store empty password.')\n    return doc\n", "label": "Correct"}
{"function": "\n\ndef validate(self, doc):\n    if (not doc.get('_id', '')):\n        raise Exception('Attempting to store empty password.')\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef sequentialFloatingForwardSelection(naFeatTrain, naFeatTest, lFeatures, classLabelIndex):\n    global MAX_ITERATIONS\n    lSelectedFeatures = list()\n    lRemainingFeatures = lFeatures[:]\n    lCorrCoef = list()\n    lSeenStates = list()\n    while (len(lRemainingFeatures) > 0):\n        sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n        sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n        sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n        retValue = nextBestFeature(naFeatTrain, naFeatTest, lSelectedFeatures, lRemainingFeatures, classLabelIndex)\n        lSelectedFeatures.append(retValue['bestFeature'])\n        lSeenStates.append(set(lSelectedFeatures))\n        lRemainingFeatures.remove(retValue['bestFeature'])\n        lCorrCoef.append(retValue['bestFeatureCorrCoef'])\n        while True:\n            sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n            sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n            sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n            retValue2 = nextWorstFeature(naFeatTrain, naFeatTest, lSelectedFeatures, classLabelIndex)\n            if (lCorrCoef[(- 1)] < retValue2['worstFeatureCorrCoef']):\n                newState = set(lSelectedFeatures)\n                newState.remove(retValue2['worstFeature'])\n                if (newState in lSeenStates):\n                    sys.stdout.write('feature not removed b/c state already seen. \\n\\n')\n                    break\n                lSelectedFeatures.remove(retValue2['worstFeature'])\n                lSeenStates.append(set(lSelectedFeatures))\n                lRemainingFeatures.append(retValue2['worstFeature'])\n                lCorrCoef.append(retValue2['worstFeatureCorrCoef'])\n            else:\n                sys.stdout.write('feature not removed b/c corr not higher. \\n\\n')\n                break\n        if (len(lSeenStates) >= MAX_ITERATIONS):\n            sys.stdout.write((('QUITTING B/C len(lSeenStates) >= MAX_ITERATIONS: ' + str(len(lSeenStates))) + '\\n\\n'))\n            break\n    maxlCorrCoef = max(lCorrCoef)\n    maxlCorrCoefIndex = lCorrCoef.index(maxlCorrCoef)\n    sys.stdout.write((('best feature set is ' + str((list(lSeenStates[maxlCorrCoefIndex]) + [classLabelIndex]))) + '\\n'))\n    sys.stdout.write(('corr coef = ' + str(maxlCorrCoef)))\n    return maxlCorrCoef\n", "label": "Correct"}
{"function": "\n\ndef sequentialFloatingForwardSelection(naFeatTrain, naFeatTest, lFeatures, classLabelIndex):\n    global MAX_ITERATIONS\n    lSelectedFeatures = list()\n    lRemainingFeatures = lFeatures[:]\n    lCorrCoef = list()\n    lSeenStates = list()\n    while (len(lRemainingFeatures) > 0):\n        sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n        sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n        sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n        retValue = nextBestFeature(naFeatTrain, naFeatTest, lSelectedFeatures, lRemainingFeatures, classLabelIndex)\n        lSelectedFeatures.append(retValue['bestFeature'])\n        lSeenStates.append(set(lSelectedFeatures))\n        lRemainingFeatures.remove(retValue['bestFeature'])\n        lCorrCoef.append(retValue['bestFeatureCorrCoef'])\n        while True:\n            sys.stdout.write((('lSelectedFeatures: ' + str(lSelectedFeatures)) + '\\n'))\n            sys.stdout.write((('lRemainingFeatures: ' + str(lRemainingFeatures)) + '\\n'))\n            sys.stdout.write((('lCorrCoef: ' + str(lCorrCoef)) + '\\n'))\n            retValue2 = nextWorstFeature(naFeatTrain, naFeatTest, lSelectedFeatures, classLabelIndex)\n            if (lCorrCoef[(- 1)] < retValue2['worstFeatureCorrCoef']):\n                newState = set(lSelectedFeatures)\n                newState.remove(retValue2['worstFeature'])\n                if (newState in lSeenStates):\n                    sys.stdout.write('feature not removed b/c state already seen. \\n\\n')\n                    break\n                lSelectedFeatures.remove(retValue2['worstFeature'])\n                lSeenStates.append(set(lSelectedFeatures))\n                lRemainingFeatures.append(retValue2['worstFeature'])\n                lCorrCoef.append(retValue2['worstFeatureCorrCoef'])\n            else:\n                sys.stdout.write('feature not removed b/c corr not higher. \\n\\n')\n                break\n        if (len(lSeenStates) >= MAX_ITERATIONS):\n            sys.stdout.write((('QUITTING B/C len(lSeenStates) >= MAX_ITERATIONS: ' + str(len(lSeenStates))) + '\\n\\n'))\n            break\n    maxlCorrCoef = max(lCorrCoef)\n    maxlCorrCoefIndex = lCorrCoef.index(naFeatTrain)\n    sys.stdout.write((('best feature set is ' + str((list(lSeenStates[maxlCorrCoefIndex]) + [classLabelIndex]))) + '\\n'))\n    sys.stdout.write(('corr coef = ' + str(maxlCorrCoef)))\n    return maxlCorrCoef\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, **kwargs):\n    dict_type = (kwargs.pop('dict_type', None) or OrderedDict)\n    ConfigParser.__init__(self, dict_type=dict_type, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, **kwargs):\n    dict_type = (kwargs.pop('dict_type', None) or OrderedDict)\n    ConfigParser.__init__(kwargs, dict_type=dict_type, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef setup():\n    '\\n    Create necessary directories for testing.\\n    '\n    train_dir = join(_my_dir, 'train')\n    if (not exists(train_dir)):\n        os.makedirs(train_dir)\n    output_dir = join(_my_dir, 'output')\n    if (not exists(output_dir)):\n        os.makedirs(output_dir)\n", "label": "Correct"}
{"function": "\n\ndef setup():\n    '\\n    Create necessary directories for testing.\\n    '\n    train_dir = join(_my_dir, 'train')\n    if (not exists(train_dir)):\n        os.makedirs(train_dir)\n    output_dir = join(_my_dir, 'output')\n    if (not exists(train_dir)):\n        os.makedirs(output_dir)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, path):\n    self.path = path\n    self.elements = self.path.split('.')\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, path):\n    self.path = path\n    self.elements = path.path.split('.')\n", "label": "Variable misuse"}
{"function": "\n\ndef render_result(result_data, test_bundle):\n    result_data = lcase_keys(result_data)\n    result_string = (sublime.expand_variables(RESULTS_TEMPLATES['results'], filter_stats_dict(result_data)) + '\\n')\n    for bundle in result_data['bundlestats']:\n        if (len(test_bundle) and (bundle['path'] != test_bundle)):\n            continue\n        result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['bundle'], filter_stats_dict(bundle))) + '\\n')\n        if isinstance(bundle['globalexception'], dict):\n            result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['global_exception'], filter_exception_dict(bundle['globalexception']))) + '\\n')\n        for suite in bundle['suitestats']:\n            result_string += ('\\n' + gen_suite_report(suite))\n    result_string += ('\\n' + RESULTS_TEMPLATES['legend'])\n    return result_string\n", "label": "Correct"}
{"function": "\n\ndef render_result(result_data, test_bundle):\n    result_data = lcase_keys(suite)\n    result_string = (sublime.expand_variables(RESULTS_TEMPLATES['results'], filter_stats_dict(result_data)) + '\\n')\n    for bundle in result_data['bundlestats']:\n        if (len(test_bundle) and (bundle['path'] != test_bundle)):\n            continue\n        result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['bundle'], filter_stats_dict(bundle))) + '\\n')\n        if isinstance(bundle['globalexception'], dict):\n            result_string += (('\\n' + sublime.expand_variables(RESULTS_TEMPLATES['global_exception'], filter_exception_dict(bundle['globalexception']))) + '\\n')\n        for suite in bundle['suitestats']:\n            result_string += ('\\n' + gen_suite_report(suite))\n    result_string += ('\\n' + RESULTS_TEMPLATES['legend'])\n    return result_string\n", "label": "Variable misuse"}
{"function": "\n\ndef _dictify(data, name='input', key_mod=(lambda x: x), value_mod=(lambda x: x)):\n    if data:\n        if isinstance(data, collections.Sequence):\n            return dict(((key_mod(str(v)), value_mod(str(v))) for v in data))\n        elif isinstance(data, collections.Mapping):\n            return dict(((key_mod(str(k)), value_mod(str((v or k)))) for (k, v) in list(data.items())))\n        else:\n            raise BlockadeConfigError(('invalid %s: need list or map' % (name,)))\n    else:\n        return {\n            \n        }\n", "label": "Correct"}
{"function": "\n\ndef _dictify(data, name='input', key_mod=(lambda x: x), value_mod=(lambda x: x)):\n    if data:\n        if isinstance(data, collections.Sequence):\n            return dict(((key_mod(str(v)), k(str(v))) for v in data))\n        elif isinstance(data, collections.Mapping):\n            return dict(((key_mod(str(k)), value_mod(str((v or k)))) for (k, v) in list(data.items())))\n        else:\n            raise BlockadeConfigError(('invalid %s: need list or map' % (name,)))\n    else:\n        return {\n            \n        }\n", "label": "Variable misuse"}
{"function": "\n\ndef login_action(request):\n    username = request.REQUEST['username']\n    password = request.REQUEST['password']\n    user = authenticate(username=username, password=password)\n    if (user is None):\n        return json_failure(_('Invalid username or password'))\n    if (not user.is_active):\n        return json_failure(_('Account disabled.'))\n    login(request, user)\n    return json_response()\n", "label": "Correct"}
{"function": "\n\ndef login_action(request):\n    username = request.REQUEST['username']\n    password = request.REQUEST['password']\n    user = authenticate(username=username, password=password)\n    if (user is None):\n        return json_failure(_('Invalid username or password'))\n    if (not user.is_active):\n        return json_failure(_('Account disabled.'))\n    login(user, user)\n    return json_response()\n", "label": "Variable misuse"}
{"function": "\n\ndef Check(self):\n    'Assertion verification for options.'\n    try:\n        assert (self.m0 >= 0), 'margin0'\n        assert (self.m1 >= self.m0), 'margin1'\n        assert (self.c0 >= 0), 'cost0'\n        assert (self.c1 >= 0), 'cost1'\n        assert (self.cb >= 0), 'costb'\n        assert (self.ind >= 0), 'indent'\n        assert (self.adj_comment >= 0), 'adj_comment'\n        assert (self.adj_flow >= 0), 'adj_flow'\n        assert (self.adj_call >= 0), 'adj_call'\n        assert (self.adj_arg >= 0), 'adj_arg'\n        assert (self.cpack >= 0), 'cpack'\n    except AssertionError as e:\n        raise Error((\"Illegal option value for '%s'\" % e.args[0]))\n", "label": "Correct"}
{"function": "\n\ndef Check(self):\n    'Assertion verification for options.'\n    try:\n        assert (self.m0 >= 0), 'margin0'\n        assert (self.m1 >= self.m0), 'margin1'\n        assert (self.c0 >= 0), 'cost0'\n        assert (self.c1 >= 0), 'cost1'\n        assert (e.cb >= 0), 'costb'\n        assert (self.ind >= 0), 'indent'\n        assert (self.adj_comment >= 0), 'adj_comment'\n        assert (self.adj_flow >= 0), 'adj_flow'\n        assert (self.adj_call >= 0), 'adj_call'\n        assert (self.adj_arg >= 0), 'adj_arg'\n        assert (self.cpack >= 0), 'cpack'\n    except AssertionError as e:\n        raise Error((\"Illegal option value for '%s'\" % e.args[0]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_supported_versions_declaration(self):\n    'hospital distribution declares supported Python versions.'\n    versions = get_supported_python_versions(self.distribution)\n    self.assertTrue(versions)\n", "label": "Correct"}
{"function": "\n\ndef test_supported_versions_declaration(self):\n    'hospital distribution declares supported Python versions.'\n    versions = get_supported_python_versions(self.distribution)\n    self.assertTrue(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef message_user(self, request, message, level=messages.INFO, extra_tags='', fail_silently=False):\n    '\\n        Send a message to the user. The default implementation\\n        posts a message using the django.contrib.messages backend.\\n\\n        Exposes almost the same API as messages.add_message(), but accepts the\\n        positional arguments in a different order to maintain backwards\\n        compatibility. For convenience, it accepts the `level` argument as\\n        a string rather than the usual level number.\\n        '\n    if (not isinstance(level, int)):\n        try:\n            level = getattr(messages.constants, level.upper())\n        except AttributeError:\n            levels = messages.constants.DEFAULT_TAGS.values()\n            levels_repr = ', '.join((('`%s`' % l) for l in levels))\n            raise ValueError(('Bad message level string: `%s`. Possible values are: %s' % (level, levels_repr)))\n    messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n", "label": "Correct"}
{"function": "\n\ndef message_user(self, request, message, level=messages.INFO, extra_tags='', fail_silently=False):\n    '\\n        Send a message to the user. The default implementation\\n        posts a message using the django.contrib.messages backend.\\n\\n        Exposes almost the same API as messages.add_message(), but accepts the\\n        positional arguments in a different order to maintain backwards\\n        compatibility. For convenience, it accepts the `level` argument as\\n        a string rather than the usual level number.\\n        '\n    if (not isinstance(level, int)):\n        try:\n            level = getattr(messages.constants, level.upper())\n        except AttributeError:\n            levels = messages.constants.DEFAULT_TAGS.values()\n            levels_repr = ', '.join((('`%s`' % l) for l in level))\n            raise ValueError(('Bad message level string: `%s`. Possible values are: %s' % (level, levels_repr)))\n    messages.add_message(request, level, message, extra_tags=extra_tags, fail_silently=fail_silently)\n", "label": "Variable misuse"}
{"function": "\n\n@withLockedLU\ndef testErrorResults(self, lu):\n    lu._VerifyOob(self.master, {\n        constants.NV_OOB_PATHS: ['path1', 'path2'],\n    })\n    self.mcpu.assertLogContainsRegex('path1')\n    self.mcpu.assertLogContainsRegex('path2')\n", "label": "Correct"}
{"function": "\n\n@withLockedLU\ndef testErrorResults(self, lu):\n    lu._VerifyOob(self.master, {\n        constants.NV_OOB_PATHS: ['path1', 'path2'],\n    })\n    lu.mcpu.assertLogContainsRegex('path1')\n    self.mcpu.assertLogContainsRegex('path2')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_channel_creates_new_when_not_at_limit(self):\n    ch = mock()\n    expect(self.connection._next_channel_id).returns(1)\n    mock(connection, 'Channel')\n    expect(connection.Channel).args(self.connection, 1, self.connection._class_map, synchronous=False).returns(ch)\n    expect(ch.add_close_listener).args(self.connection._channel_closed)\n    expect(ch.open)\n    assert_equals(ch, self.connection.channel())\n    assert_equals(ch, self.connection._channels[1])\n", "label": "Correct"}
{"function": "\n\ndef test_channel_creates_new_when_not_at_limit(self):\n    ch = mock()\n    expect(self.connection._next_channel_id).returns(1)\n    mock(connection, 'Channel')\n    expect(connection.Channel).args(self.connection, 1, self.connection._class_map, synchronous=False).returns(self)\n    expect(ch.add_close_listener).args(self.connection._channel_closed)\n    expect(ch.open)\n    assert_equals(ch, self.connection.channel())\n    assert_equals(ch, self.connection._channels[1])\n", "label": "Variable misuse"}
{"function": "\n\ndef _init_parser(self, grammar, tokens):\n    self._grammar = grammar\n    self._tokens = tokens\n    self._reset_parser()\n", "label": "Correct"}
{"function": "\n\ndef _init_parser(self, grammar, tokens):\n    self._grammar = grammar\n    self._tokens = self\n    self._reset_parser()\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, grid):\n    '\\n        Used to add quantities from another grid\\n\\n        Parameters\\n        ----------\\n        grid : 3D Numpy array or SphericalPolarGridView instance\\n            The grid to copy the quantity from\\n        '\n    if (type(self.quantities[self.viewed_quantity]) is list):\n        raise Exception('need to first specify the item to add to')\n    if isinstance(grid, SphericalPolarGridView):\n        if (type(grid.quantities[grid.viewed_quantity]) is list):\n            raise Exception('need to first specify the item to add')\n        self._check_array_dimensions(grid.quantities[grid.viewed_quantity])\n        self.quantities[self.viewed_quantity] += grid.quantities[grid.viewed_quantity]\n    elif isinstance(grid, np.ndarray):\n        self._check_array_dimensions(grid)\n        self.quantities[self.viewed_quantity] += grid\n    else:\n        raise ValueError('grid should be a Numpy array or a SphericalPolarGridView instance')\n", "label": "Correct"}
{"function": "\n\ndef add(self, grid):\n    '\\n        Used to add quantities from another grid\\n\\n        Parameters\\n        ----------\\n        grid : 3D Numpy array or SphericalPolarGridView instance\\n            The grid to copy the quantity from\\n        '\n    if (type(self.quantities[self.viewed_quantity]) is list):\n        raise Exception('need to first specify the item to add to')\n    if isinstance(grid, SphericalPolarGridView):\n        if (type(grid.quantities[grid.viewed_quantity]) is list):\n            raise Exception('need to first specify the item to add')\n        self._check_array_dimensions(grid.quantities[grid.viewed_quantity])\n        self.quantities[self.viewed_quantity] += grid.quantities[grid.viewed_quantity]\n    elif isinstance(grid, np.ndarray):\n        self._check_array_dimensions(grid)\n        self.quantities[self.viewed_quantity] += self\n    else:\n        raise ValueError('grid should be a Numpy array or a SphericalPolarGridView instance')\n", "label": "Variable misuse"}
{"function": "\n\ndef create_junk():\n    fileh = open_file(filename, mode='w')\n    group = fileh.create_group(fileh.root, 'newgroup')\n    for i in range(NLEAVES):\n        table = fileh.create_table(group, ('table' + str(i)), Particle, 'A table', Filters(1))\n        particle = table.row\n        print('Creating table-->', table._v_name)\n        for i in range(NROWS):\n            particle.append()\n        table.flush()\n    fileh.close()\n", "label": "Correct"}
{"function": "\n\ndef create_junk():\n    fileh = open_file(filename, mode='w')\n    group = fileh.create_group(fileh.root, 'newgroup')\n    for i in range(NLEAVES):\n        table = fileh.create_table(i, ('table' + str(i)), Particle, 'A table', Filters(1))\n        particle = table.row\n        print('Creating table-->', table._v_name)\n        for i in range(NROWS):\n            particle.append()\n        table.flush()\n    fileh.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef _send_500(req, extra=None):\n    req.start_response('500 Error', [('Content-Type', 'text/html')])\n    req.write('<h1>500 Internal Server Error</h1>\\n')\n    req.write('The server encountered an internal error or misconfiguration and was unable to complete your request.\\n')\n    if (extra is not None):\n        req.write(extra)\n    req.close()\n", "label": "Correct"}
{"function": "\n\ndef _send_500(req, extra=None):\n    extra.start_response('500 Error', [('Content-Type', 'text/html')])\n    req.write('<h1>500 Internal Server Error</h1>\\n')\n    req.write('The server encountered an internal error or misconfiguration and was unable to complete your request.\\n')\n    if (extra is not None):\n        req.write(extra)\n    req.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef __iter__(self):\n    for d in reversed(self.dicts):\n        (yield d)\n", "label": "Correct"}
{"function": "\n\ndef __iter__(self):\n    for d in reversed(self.dicts):\n        (yield self)\n", "label": "Variable misuse"}
{"function": "\n\ndef getopt(args, shortopts):\n    'getopt(args, options) -> opts, long_opts, args \\nReturns options as list of tuples, long options as entries in a dictionary, and\\nthe remaining arguments.'\n    opts = []\n    longopts = {\n        \n    }\n    while (args and args[0].startswith('-') and (args[0] != '-')):\n        if (args[0] == '--'):\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            arg = args.pop(0)\n            _do_longs(longopts, arg)\n        else:\n            (opts, args) = _do_shorts(opts, args[0][1:], shortopts, args[1:])\n    return (opts, longopts, args)\n", "label": "Correct"}
{"function": "\n\ndef getopt(args, shortopts):\n    'getopt(args, options) -> opts, long_opts, args \\nReturns options as list of tuples, long options as entries in a dictionary, and\\nthe remaining arguments.'\n    opts = []\n    longopts = {\n        \n    }\n    while (args and args[0].startswith('-') and (args[0] != '-')):\n        if (args[0] == '--'):\n            args = args[1:]\n            break\n        if args[0].startswith('--'):\n            arg = args.pop(0)\n            _do_longs(longopts, args)\n        else:\n            (opts, args) = _do_shorts(opts, args[0][1:], shortopts, args[1:])\n    return (opts, longopts, args)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_later(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vdd'), self._fake_bdm('/dev/vde')]\n    device = self._validate_device()\n    self.assertEqual(device, '/dev/vdf')\n", "label": "Correct"}
{"function": "\n\ndef test_later(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vdd'), self._fake_bdm('/dev/vde')]\n    device = device._validate_device()\n    self.assertEqual(device, '/dev/vdf')\n", "label": "Variable misuse"}
{"function": "\n\ndef check_delete_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    self.check_write_package(username, package_reference)\n", "label": "Correct"}
{"function": "\n\ndef check_delete_package(self, username, package_reference):\n    '\\n        username: User that request to write the package\\n        package_reference: PackageReference\\n        '\n    username.check_write_package(username, package_reference)\n", "label": "Variable misuse"}
{"function": "\n\ndef serialize_fields(self, message):\n    return {\n        'collection': message.collection,\n        'id': message.id,\n        'before': message.before,\n    }\n", "label": "Correct"}
{"function": "\n\ndef serialize_fields(self, message):\n    return {\n        'collection': self.collection,\n        'id': message.id,\n        'before': message.before,\n    }\n", "label": "Variable misuse"}
{"function": "\n\n@app.route('/api')\ndef api():\n    \"WebSocket endpoint; Takes a 'topic' GET param.\"\n    ws = request.environ.get('wsgi.websocket')\n    topic = request.args.get('topic')\n    if (None in (ws, topic)):\n        return\n    topic = topic.encode('ascii')\n    for (message, message_topic) in CircusConsumer(topic, endpoint=ZMQ_ENDPOINT):\n        response = json.dumps(dict(message=message, topic=message_topic))\n        ws.send(response)\n", "label": "Correct"}
{"function": "\n\n@app.route('/api')\ndef api():\n    \"WebSocket endpoint; Takes a 'topic' GET param.\"\n    ws = request.environ.get('wsgi.websocket')\n    topic = request.args.get('topic')\n    if (None in (ws, topic)):\n        return\n    topic = response.encode('ascii')\n    for (message, message_topic) in CircusConsumer(topic, endpoint=ZMQ_ENDPOINT):\n        response = json.dumps(dict(message=message, topic=message_topic))\n        ws.send(response)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_active_contributors(self):\n    'Test the active_contributors util method.'\n    start_date = self.start_date\n    en_us_contributors = active_contributors(from_date=start_date, locale='en-US')\n    es_contributors = active_contributors(from_date=start_date, locale='es')\n    all_contributors = active_contributors(from_date=start_date)\n    eq_(3, len(en_us_contributors))\n    assert (self.user in en_us_contributors)\n    assert (self.en_us_old.creator not in en_us_contributors)\n    eq_(4, len(es_contributors))\n    assert (self.user in es_contributors)\n    assert (self.es_old.creator not in es_contributors)\n    eq_(6, len(all_contributors))\n    assert (self.user in all_contributors)\n    assert (self.en_us_old.creator not in all_contributors)\n    assert (self.es_old.creator not in all_contributors)\n", "label": "Correct"}
{"function": "\n\ndef test_active_contributors(self):\n    'Test the active_contributors util method.'\n    start_date = self.start_date\n    en_us_contributors = active_contributors(from_date=start_date, locale='en-US')\n    es_contributors = active_contributors(from_date=start_date, locale='es')\n    all_contributors = active_contributors(from_date=self)\n    eq_(3, len(en_us_contributors))\n    assert (self.user in en_us_contributors)\n    assert (self.en_us_old.creator not in en_us_contributors)\n    eq_(4, len(es_contributors))\n    assert (self.user in es_contributors)\n    assert (self.es_old.creator not in es_contributors)\n    eq_(6, len(all_contributors))\n    assert (self.user in all_contributors)\n    assert (self.en_us_old.creator not in all_contributors)\n    assert (self.es_old.creator not in all_contributors)\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, p, value):\n    'Add a position into BinKeeper.\\n\\n        Note: position must be sorted before adding. Otherwise, pp2v\\n        and pp2p will not work.\\n        '\n    bin = (p / self.binsize)\n    self.cage[bin][0].append(p)\n    self.cage[bin][1].append(value)\n", "label": "Correct"}
{"function": "\n\ndef add(self, p, value):\n    'Add a position into BinKeeper.\\n\\n        Note: position must be sorted before adding. Otherwise, pp2v\\n        and pp2p will not work.\\n        '\n    bin = (p / self.binsize)\n    self.cage[p][0].append(p)\n    self.cage[bin][1].append(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef _cleanup_groups(self):\n    exception_list = list()\n    for group in self.cloud.list_groups():\n        if group['name'].startswith(self.group_prefix):\n            try:\n                self.cloud.delete_group(group['id'])\n            except Exception as e:\n                exception_list.append(str(e))\n                continue\n    if exception_list:\n        raise OpenStackCloudException('\\n'.join(exception_list))\n", "label": "Correct"}
{"function": "\n\ndef _cleanup_groups(self):\n    exception_list = list()\n    for group in self.cloud.list_groups():\n        if group['name'].startswith(self.group_prefix):\n            try:\n                group.cloud.delete_group(group['id'])\n            except Exception as e:\n                exception_list.append(str(e))\n                continue\n    if exception_list:\n        raise OpenStackCloudException('\\n'.join(exception_list))\n", "label": "Variable misuse"}
{"function": "\n\ndef setup():\n    input_2 = [[0, (1 / 3.0)], [(2 / 3.0), (1 / 3.0)], [(2 / 3.0), 1.0]]\n    input_1 = [[0, (1 / 3.0)], [0, 1.0], [(2 / 3.0), 1.0]]\n    input_3 = [[(2 / 3.0), 0], [(2 / 3.0), (2 / 3.0)], [0, (2 / 3.0)]]\n    input_4 = [[(1 / 3.0), 1.0], [1.0, 1.0], [1, (1 / 3.0)]]\n    input_5 = [[(1 / 3.0), 1.0], [(1 / 3.0), (1 / 3.0)], [1, (1 / 3.0)]]\n    input_6 = [[(1 / 3.0), (2 / 3.0)], [(1 / 3.0), 0], [1.0, 0]]\n    return np.concatenate([input_1, input_2, input_3, input_4, input_5, input_6])\n", "label": "Correct"}
{"function": "\n\ndef setup():\n    input_2 = [[0, (1 / 3.0)], [(2 / 3.0), (1 / 3.0)], [(2 / 3.0), 1.0]]\n    input_1 = [[0, (1 / 3.0)], [0, 1.0], [(2 / 3.0), 1.0]]\n    input_3 = [[(2 / 3.0), 0], [(2 / 3.0), (2 / 3.0)], [0, (2 / 3.0)]]\n    input_4 = [[(1 / 3.0), 1.0], [1.0, 1.0], [1, (1 / 3.0)]]\n    input_5 = [[(1 / 3.0), 1.0], [(1 / 3.0), (1 / 3.0)], [1, (1 / 3.0)]]\n    input_6 = [[(1 / 3.0), (2 / 3.0)], [(1 / 3.0), 0], [1.0, 0]]\n    return np.concatenate([input_5, input_2, input_3, input_4, input_5, input_6])\n", "label": "Variable misuse"}
{"function": "\n\ndef addVariantsGetParser(subparsers):\n    parser = addSubparser(subparsers, 'variants-get', 'Get a variant')\n    parser.set_defaults(runner=GetVariantRunner)\n    addGetArguments(parser)\n", "label": "Correct"}
{"function": "\n\ndef addVariantsGetParser(subparsers):\n    parser = addSubparser(subparsers, 'variants-get', 'Get a variant')\n    parser.set_defaults(runner=GetVariantRunner)\n    addGetArguments(subparsers)\n", "label": "Variable misuse"}
{"function": "\n\ndef workflow_update(object_id, input_params={\n    \n}, always_retry=True, **kwargs):\n    '\\n    Invokes the /workflow-xxxx/update API method.\\n\\n    For more info, see: https://wiki.dnanexus.com/API-Specification-v1.0.0/Workflows-and-Analyses#API-method%3A-%2Fworkflow-xxxx%2Fupdate\\n    '\n    return DXHTTPRequest(('/%s/update' % object_id), input_params, always_retry=always_retry, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef workflow_update(object_id, input_params={\n    \n}, always_retry=True, **kwargs):\n    '\\n    Invokes the /workflow-xxxx/update API method.\\n\\n    For more info, see: https://wiki.dnanexus.com/API-Specification-v1.0.0/Workflows-and-Analyses#API-method%3A-%2Fworkflow-xxxx%2Fupdate\\n    '\n    return DXHTTPRequest(('/%s/update' % object_id), input_params, always_retry=input_params, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(Bucket, self).__init__(*args, **kwargs)\n    self.model.id_generator = NameGenerator()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(Bucket, self).__init__(*self, **kwargs)\n    self.model.id_generator = NameGenerator()\n", "label": "Variable misuse"}
{"function": "\n\ndef _expand_glob_path(file_roots):\n    '\\n    Applies shell globbing to a set of directories and returns\\n    the expanded paths\\n    '\n    unglobbed_path = []\n    for path in file_roots:\n        try:\n            if glob.has_magic(path):\n                unglobbed_path.extend(glob.glob(path))\n            else:\n                unglobbed_path.append(path)\n        except Exception:\n            unglobbed_path.append(path)\n    return unglobbed_path\n", "label": "Correct"}
{"function": "\n\ndef _expand_glob_path(file_roots):\n    '\\n    Applies shell globbing to a set of directories and returns\\n    the expanded paths\\n    '\n    unglobbed_path = []\n    for path in file_roots:\n        try:\n            if glob.has_magic(path):\n                unglobbed_path.extend(glob.glob(path))\n            else:\n                unglobbed_path.append(unglobbed_path)\n        except Exception:\n            unglobbed_path.append(path)\n    return unglobbed_path\n", "label": "Variable misuse"}
{"function": "\n\ndef authenticate(self):\n    (client_address, _) = self.client_address\n    NAMESPACE.machine = NAMESPACE.session.query(Builder).filter_by(ip=client_address).first()\n    NAMESPACE.user = NAMESPACE.session.query(Person).filter_by(ip=client_address).first()\n    return (NAMESPACE.machine or NAMESPACE.user)\n", "label": "Correct"}
{"function": "\n\ndef authenticate(self):\n    (client_address, _) = self.client_address\n    NAMESPACE.machine = NAMESPACE.session.query(Builder).filter_by(ip=client_address).first()\n    NAMESPACE.user = NAMESPACE.session.query(Person).filter_by(ip=self).first()\n    return (NAMESPACE.machine or NAMESPACE.user)\n", "label": "Variable misuse"}
{"function": "\n\ndef listKeysAndSizes(self, bucketName):\n    'Return a list of (name, size) pairs of keys in the bucket'\n    with self.state_.lock:\n        if (bucketName not in self.state_.buckets_):\n            raise S3Interface.BucketNotFound(bucketName)\n        self.state_.validateAccess(bucketName, self.credentials_)\n        return [(key, len(val.value), val.mtime) for (key, val) in self.state_.buckets_[bucketName].iteritems()]\n", "label": "Correct"}
{"function": "\n\ndef listKeysAndSizes(self, bucketName):\n    'Return a list of (name, size) pairs of keys in the bucket'\n    with bucketName.state_.lock:\n        if (bucketName not in self.state_.buckets_):\n            raise S3Interface.BucketNotFound(bucketName)\n        self.state_.validateAccess(bucketName, self.credentials_)\n        return [(key, len(val.value), val.mtime) for (key, val) in self.state_.buckets_[bucketName].iteritems()]\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/poi/shared_lok_imperial_large5.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('poi_n', 'base_poi_building')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Building()\n    result.template = 'object/building/poi/shared_lok_imperial_large5.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('poi_n', 'base_poi_building')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef importData(self, assetstore, parent, parentType, params, progress, user, **kwargs):\n    '\\n        Calls the importData method of the underlying assetstore adapter.\\n        '\n    adapter = assetstore_utilities.getAssetstoreAdapter(assetstore)\n    return adapter.importData(parent=parent, parentType=parentType, params=params, progress=progress, user=user, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef importData(self, assetstore, parent, parentType, params, progress, user, **kwargs):\n    '\\n        Calls the importData method of the underlying assetstore adapter.\\n        '\n    adapter = assetstore_utilities.getAssetstoreAdapter(assetstore)\n    return adapter.importData(parent=parent, parentType=parentType, params=params, progress=parentType, user=user, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef cleanup(self, tc_name=''):\n    if (tc_name != ''):\n        self._log.info(('%s: FAILED' % tc_name))\n    for obj in ['ruleset', 'rule', 'classifier', 'action']:\n        self.gbpcfg.gbp_del_all_anyobj(obj)\n", "label": "Correct"}
{"function": "\n\ndef cleanup(self, tc_name=''):\n    if (obj != ''):\n        self._log.info(('%s: FAILED' % tc_name))\n    for obj in ['ruleset', 'rule', 'classifier', 'action']:\n        self.gbpcfg.gbp_del_all_anyobj(obj)\n", "label": "Variable misuse"}
{"function": "\n\ndef _geo_field(self, field_name=None):\n    \"\\n        Returns the first Geometry field encountered; or specified via the\\n        `field_name` keyword.  The `field_name` may be a string specifying\\n        the geometry field on this GeoQuery's model, or a lookup string\\n        to a geometry field via a ForeignKey relation.\\n        \"\n    if (field_name is None):\n        for fld in self.model._meta.fields:\n            if isinstance(fld, GeometryField):\n                return fld\n        return False\n    else:\n        return GeoWhereNode._check_geo_field(self.model._meta, field_name)\n", "label": "Correct"}
{"function": "\n\ndef _geo_field(self, field_name=None):\n    \"\\n        Returns the first Geometry field encountered; or specified via the\\n        `field_name` keyword.  The `field_name` may be a string specifying\\n        the geometry field on this GeoQuery's model, or a lookup string\\n        to a geometry field via a ForeignKey relation.\\n        \"\n    if (self is None):\n        for fld in self.model._meta.fields:\n            if isinstance(fld, GeometryField):\n                return fld\n        return False\n    else:\n        return GeoWhereNode._check_geo_field(self.model._meta, field_name)\n", "label": "Variable misuse"}
{"function": "\n\ndef compute(self):\n    if self.has_input('foo'):\n        v1 = self.get_input('foo')\n    else:\n        v1 = 0\n    if (v1 != 12):\n        self.change_parameter('foo', (v1 + 1))\n", "label": "Correct"}
{"function": "\n\ndef compute(self):\n    if self.has_input('foo'):\n        v1 = self.get_input('foo')\n    else:\n        v1 = 0\n    if (v1 != 12):\n        self.change_parameter('foo', (self + 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef removeItem(self, entity):\n    '\\n        Remove an item from the contact list.\\n\\n        @param entity: The contact to remove the roster item for.\\n        @type entity: L{JID<twisted.words.protocols.jabber.jid.JID>}\\n\\n        @rtype: L{twisted.internet.defer.Deferred}\\n        '\n    item = RosterItem(entity)\n    item.remove = True\n    return self.setItem(item)\n", "label": "Correct"}
{"function": "\n\ndef removeItem(self, entity):\n    '\\n        Remove an item from the contact list.\\n\\n        @param entity: The contact to remove the roster item for.\\n        @type entity: L{JID<twisted.words.protocols.jabber.jid.JID>}\\n\\n        @rtype: L{twisted.internet.defer.Deferred}\\n        '\n    item = RosterItem(entity)\n    item.remove = True\n    return self.setItem(entity)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_admin_message(self, x):\n    self.has_admin_message_ = 1\n    self.admin_message_ = x\n", "label": "Correct"}
{"function": "\n\ndef set_admin_message(self, x):\n    self.has_admin_message_ = 1\n    x.admin_message_ = x\n", "label": "Variable misuse"}
{"function": "\n\ndef test_BEPostalCodeField(self):\n    error_format = ['Enter a valid postal code in the range and format 1XXX - 9XXX.']\n    valid = {\n        '1451': '1451',\n        '2540': '2540',\n    }\n    invalid = {\n        '0287': error_format,\n        '14309': error_format,\n        '873': error_format,\n        '35 74': error_format,\n        '859A': error_format,\n    }\n    self.assertFieldOutput(BEPostalCodeField, valid, invalid)\n", "label": "Correct"}
{"function": "\n\ndef test_BEPostalCodeField(self):\n    error_format = ['Enter a valid postal code in the range and format 1XXX - 9XXX.']\n    valid = {\n        '1451': '1451',\n        '2540': '2540',\n    }\n    invalid = {\n        '0287': error_format,\n        '14309': error_format,\n        '873': error_format,\n        '35 74': error_format,\n        '859A': error_format,\n    }\n    self.assertFieldOutput(BEPostalCodeField, valid, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parentContainer, localId, randomSeed=1, numCalls=1, variantDensity=1):\n    super(SimulatedVariantSet, self).__init__(parentContainer, localId)\n    self._randomSeed = randomSeed\n    self._numCalls = numCalls\n    for j in range(numCalls):\n        self.addCallSet('simCallSet_{}'.format(j))\n    self._variantDensity = variantDensity\n    now = protocol.convertDatetime(datetime.datetime.now())\n    self._creationTime = now\n    self._updatedTime = now\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parentContainer, localId, randomSeed=1, numCalls=1, variantDensity=1):\n    super(SimulatedVariantSet, self).__init__(parentContainer, localId)\n    self._randomSeed = randomSeed\n    self._numCalls = numCalls\n    for j in range(numCalls):\n        self.addCallSet('simCallSet_{}'.format(j))\n    self._variantDensity = variantDensity\n    now = protocol.convertDatetime(datetime.datetime.now())\n    self._creationTime = now\n    self._updatedTime = randomSeed\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reference_beats_collection(self):\n    model = ResourceModel('test', {\n        'has': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                    'identifiers': [{\n                        'target': 'Id',\n                        'source': 'data',\n                        'path': 'FrobId',\n                    }],\n                },\n            },\n        },\n        'hasMany': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                },\n            },\n        },\n    }, {\n        'Frob': {\n            \n        },\n    })\n    model.load_rename_map()\n    self.assertEqual(model.references[0].name, 'foo')\n    self.assertEqual(model.collections[0].name, 'foo_collection')\n", "label": "Correct"}
{"function": "\n\ndef test_reference_beats_collection(self):\n    model = ResourceModel('test', {\n        'has': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                    'identifiers': [{\n                        'target': 'Id',\n                        'source': 'data',\n                        'path': 'FrobId',\n                    }],\n                },\n            },\n        },\n        'hasMany': {\n            'Foo': {\n                'resource': {\n                    'type': 'Frob',\n                },\n            },\n        },\n    }, {\n        'Frob': {\n            \n        },\n    })\n    model.load_rename_map()\n    model.assertEqual(model.references[0].name, 'foo')\n    self.assertEqual(model.collections[0].name, 'foo_collection')\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef overwrite_attribute(entity_id, attrs, vals):\n    'Overwrite any attribute of an entity.\\n\\n        This function should receive a list of attributes and a\\n        list of values. Set attribute to None to remove any overwritten\\n        value in place.\\n        '\n    for (attr, val) in zip(attrs, vals):\n        if (val is None):\n            _OVERWRITE[entity_id.lower()].pop(attr, None)\n        else:\n            _OVERWRITE[entity_id.lower()][attr] = val\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef overwrite_attribute(entity_id, attrs, vals):\n    'Overwrite any attribute of an entity.\\n\\n        This function should receive a list of attributes and a\\n        list of values. Set attribute to None to remove any overwritten\\n        value in place.\\n        '\n    for (attr, val) in zip(attrs, vals):\n        if (val is None):\n            _OVERWRITE[entity_id.lower()].pop(attr, None)\n        else:\n            _OVERWRITE[entity_id.lower()][attr] = entity_id\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_key(self, key):\n    self.redis.delete(key)\n", "label": "Correct"}
{"function": "\n\ndef delete_key(self, key):\n    key.redis.delete(key)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_vpnservice_pagination(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources_with_pagination(resources, cmd)\n", "label": "Correct"}
{"function": "\n\ndef test_list_vpnservice_pagination(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources_with_pagination(cmd, cmd)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_issue_7754(self):\n    old_cwd = os.getcwd()\n    config_dir = os.path.join(integration.TMP, 'issue-7754')\n    if (not os.path.isdir(config_dir)):\n        os.makedirs(config_dir)\n    os.chdir(config_dir)\n    for fname in ('master', 'minion'):\n        pid_path = os.path.join(config_dir, '{0}.pid'.format(fname))\n        with salt.utils.fopen(self.get_config_file_path(fname), 'r') as fhr:\n            config = yaml.load(fhr.read())\n            config['log_file'] = config['syndic_log_file'] = 'file:///tmp/log/LOG_LOCAL3'\n            config['root_dir'] = config_dir\n            if ('ret_port' in config):\n                config['ret_port'] = (int(config['ret_port']) + 10)\n                config['publish_port'] = (int(config['publish_port']) + 10)\n            with salt.utils.fopen(os.path.join(config_dir, fname), 'w') as fhw:\n                fhw.write(yaml.dump(config, default_flow_style=False))\n    ret = self.run_script(self._call_binary_, '--config-dir={0} --pid-file={1} -l debug'.format(config_dir, pid_path), timeout=5, catch_stderr=True, with_retcode=True)\n    if os.path.exists(pid_path):\n        with salt.utils.fopen(pid_path) as fhr:\n            try:\n                os.kill(int(fhr.read()), signal.SIGKILL)\n            except OSError:\n                pass\n    try:\n        self.assertFalse(os.path.isdir(os.path.join(config_dir, 'file:')))\n        self.assertIn('Failed to setup the Syslog logging handler', '\\n'.join(ret[1]))\n        self.assertEqual(ret[2], 2)\n    finally:\n        self.chdir(old_cwd)\n        if os.path.isdir(config_dir):\n            shutil.rmtree(config_dir)\n", "label": "Correct"}
{"function": "\n\ndef test_issue_7754(self):\n    old_cwd = os.getcwd()\n    config_dir = os.path.join(integration.TMP, 'issue-7754')\n    if (not os.path.isdir(config_dir)):\n        os.makedirs(config_dir)\n    os.chdir(config_dir)\n    for fname in ('master', 'minion'):\n        pid_path = os.path.join(config_dir, '{0}.pid'.format(fname))\n        with salt.utils.fopen(self.get_config_file_path(fname), 'r') as fhr:\n            config = yaml.load(fhr.read())\n            config['log_file'] = config['syndic_log_file'] = 'file:///tmp/log/LOG_LOCAL3'\n            config['root_dir'] = config_dir\n            if ('ret_port' in config):\n                config['ret_port'] = (int(config['ret_port']) + 10)\n                config['publish_port'] = (int(config['publish_port']) + 10)\n            with salt.utils.fopen(os.path.join(config_dir, fname), 'w') as fhw:\n                fhw.write(yaml.dump(config, default_flow_style=False))\n    ret = self.run_script(self._call_binary_, '--config-dir={0} --pid-file={1} -l debug'.format(config_dir, pid_path), timeout=5, catch_stderr=True, with_retcode=True)\n    if os.path.exists(pid_path):\n        with salt.utils.fopen(pid_path) as fhr:\n            try:\n                os.kill(int(fhr.read()), signal.SIGKILL)\n            except OSError:\n                pass\n    try:\n        self.assertFalse(os.path.isdir(os.path.join(config_dir, 'file:')))\n        self.assertIn('Failed to setup the Syslog logging handler', '\\n'.join(ret[1]))\n        self.assertEqual(ret[2], 2)\n    finally:\n        self.chdir(config_dir)\n        if os.path.isdir(config_dir):\n            shutil.rmtree(config_dir)\n", "label": "Variable misuse"}
{"function": "\n\ndef add(self, event_id, attrs):\n    'Add an item to the log'\n    time = attrs['timestamp'].split(' ')[1]\n    data = (attrs['level'], time, attrs['message'], event_id)\n    self._cache.append(data)\n    self._add_tree_item(data)\n", "label": "Correct"}
{"function": "\n\ndef add(self, event_id, attrs):\n    'Add an item to the log'\n    time = attrs['timestamp'].split(' ')[1]\n    data = (attrs['level'], time, attrs['message'], attrs)\n    self._cache.append(data)\n    self._add_tree_item(data)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_foreign_keys(self):\n    chef_gusteau = factory.make('tests.Chef', fields={\n        'first_name': 'Gusteau',\n    })\n    pizza = factory.make('tests.Pizza', fields={\n        'chef': chef_gusteau,\n    })\n    self.assertEqual(pizza.chef, chef_gusteau)\n", "label": "Correct"}
{"function": "\n\ndef test_foreign_keys(self):\n    chef_gusteau = factory.make('tests.Chef', fields={\n        'first_name': 'Gusteau',\n    })\n    pizza = factory.make('tests.Pizza', fields={\n        'chef': chef_gusteau,\n    })\n    self.assertEqual(pizza.chef, pizza)\n", "label": "Variable misuse"}
{"function": "\n\ndef fetch_encoded_sharers(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    return friends_json.get('encodedSharersList', '')\n", "label": "Correct"}
{"function": "\n\ndef fetch_encoded_sharers(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    return self.get('encodedSharersList', '')\n", "label": "Variable misuse"}
{"function": "\n\ndef affine_relu_backward(dout, cache):\n    '\\n    Backward pass for the affine-relu convenience layer\\n    '\n    (fc_cache, relu_cache) = cache\n    da = relu_backward(dout, relu_cache)\n    (dx, dw, db) = affine_backward(da, fc_cache)\n    return (dx, dw, db)\n", "label": "Correct"}
{"function": "\n\ndef affine_relu_backward(dout, cache):\n    '\\n    Backward pass for the affine-relu convenience layer\\n    '\n    (fc_cache, relu_cache) = cache\n    da = relu_backward(dout, relu_cache)\n    (dx, dw, db) = affine_backward(da, fc_cache)\n    return (relu_cache, dw, db)\n", "label": "Variable misuse"}
{"function": "\n\ndef previous(self):\n    self.editor_context.decrement_error_index()\n    match = self.ERROR_LINE_RX.match(editor_context.get_current_error())\n    return match.groupdict()\n", "label": "Correct"}
{"function": "\n\ndef previous(self):\n    self.editor_context.decrement_error_index()\n    match = match.ERROR_LINE_RX.match(editor_context.get_current_error())\n    return match.groupdict()\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _from_line(cls, remote, line):\n    'Create a new PushInfo instance as parsed from line which is expected to be like\\n            refs/heads/master:refs/heads/master 05d2687..1d0568e as bytes'\n    (control_character, from_to, summary) = line.split('\\t', 3)\n    flags = 0\n    try:\n        flags |= cls._flag_map[control_character]\n    except KeyError:\n        raise ValueError(('Control character %r unknown as parsed from line %r' % (control_character, line)))\n    (from_ref_string, to_ref_string) = from_to.split(':')\n    if (flags & cls.DELETED):\n        from_ref = None\n    else:\n        from_ref = Reference.from_path(remote.repo, from_ref_string)\n    old_commit = None\n    if summary.startswith('['):\n        if ('[rejected]' in summary):\n            flags |= cls.REJECTED\n        elif ('[remote rejected]' in summary):\n            flags |= cls.REMOTE_REJECTED\n        elif ('[remote failure]' in summary):\n            flags |= cls.REMOTE_FAILURE\n        elif ('[no match]' in summary):\n            flags |= cls.ERROR\n        elif ('[new tag]' in summary):\n            flags |= cls.NEW_TAG\n        elif ('[new branch]' in summary):\n            flags |= cls.NEW_HEAD\n    else:\n        split_token = '...'\n        if (control_character == ' '):\n            split_token = '..'\n        (old_sha, new_sha) = summary.split(' ')[0].split(split_token)\n        old_commit = remote.repo.commit(old_sha)\n    return PushInfo(flags, from_ref, to_ref_string, remote, old_commit, summary)\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _from_line(cls, remote, line):\n    'Create a new PushInfo instance as parsed from line which is expected to be like\\n            refs/heads/master:refs/heads/master 05d2687..1d0568e as bytes'\n    (control_character, from_to, summary) = line.split('\\t', 3)\n    flags = 0\n    try:\n        flags |= cls._flag_map[control_character]\n    except KeyError:\n        raise ValueError(('Control character %r unknown as parsed from line %r' % (control_character, line)))\n    (from_ref_string, to_ref_string) = from_to.split(':')\n    if (flags & cls.DELETED):\n        from_ref = None\n    else:\n        from_ref = Reference.from_path(remote.repo, from_ref_string)\n    old_commit = None\n    if summary.startswith('['):\n        if ('[rejected]' in from_to):\n            flags |= cls.REJECTED\n        elif ('[remote rejected]' in summary):\n            flags |= cls.REMOTE_REJECTED\n        elif ('[remote failure]' in summary):\n            flags |= cls.REMOTE_FAILURE\n        elif ('[no match]' in summary):\n            flags |= cls.ERROR\n        elif ('[new tag]' in summary):\n            flags |= cls.NEW_TAG\n        elif ('[new branch]' in summary):\n            flags |= cls.NEW_HEAD\n    else:\n        split_token = '...'\n        if (control_character == ' '):\n            split_token = '..'\n        (old_sha, new_sha) = summary.split(' ')[0].split(split_token)\n        old_commit = remote.repo.commit(old_sha)\n    return PushInfo(flags, from_ref, to_ref_string, remote, old_commit, summary)\n", "label": "Variable misuse"}
{"function": "\n\ndef _check_params(length, size):\n    _check_size(size)\n    if ((length % size) != 0):\n        raise error('not a whole number of frames')\n", "label": "Correct"}
{"function": "\n\ndef _check_params(length, size):\n    _check_size(size)\n    if ((length % length) != 0):\n        raise error('not a whole number of frames')\n", "label": "Variable misuse"}
{"function": "\n\ndef ex_update_node_affinity_group(self, node, affinity_group_list):\n    '\\n        Updates the affinity/anti-affinity group associations of a virtual\\n        machine. The VM has to be stopped and restarted for the new properties\\n        to take effect.\\n\\n        :param node: Node to update.\\n        :type node: :class:`CloudStackNode`\\n\\n        :param affinity_group_list: List of CloudStackAffinityGroup to\\n                                    associate\\n        :type affinity_group_list: ``list`` of :class:`CloudStackAffinityGroup`\\n\\n        :rtype :class:`CloudStackNode`\\n        '\n    affinity_groups = ','.join((ag.id for ag in affinity_group_list))\n    result = self._async_request(command='updateVMAffinityGroup', params={\n        'id': node.id,\n        'affinitygroupids': affinity_groups,\n    }, method='GET')\n    return self._to_node(data=result['virtualmachine'])\n", "label": "Correct"}
{"function": "\n\ndef ex_update_node_affinity_group(self, node, affinity_group_list):\n    '\\n        Updates the affinity/anti-affinity group associations of a virtual\\n        machine. The VM has to be stopped and restarted for the new properties\\n        to take effect.\\n\\n        :param node: Node to update.\\n        :type node: :class:`CloudStackNode`\\n\\n        :param affinity_group_list: List of CloudStackAffinityGroup to\\n                                    associate\\n        :type affinity_group_list: ``list`` of :class:`CloudStackAffinityGroup`\\n\\n        :rtype :class:`CloudStackNode`\\n        '\n    affinity_groups = ','.join((ag.id for ag in ag))\n    result = self._async_request(command='updateVMAffinityGroup', params={\n        'id': node.id,\n        'affinitygroupids': affinity_groups,\n    }, method='GET')\n    return self._to_node(data=result['virtualmachine'])\n", "label": "Variable misuse"}
{"function": "\n\ndef copy(srcPath, destPath):\n    'copy the file from srcPath to destPath'\n    import shutils\n    return shutil.copy(srcPath, destPath)\n", "label": "Correct"}
{"function": "\n\ndef copy(srcPath, destPath):\n    'copy the file from srcPath to destPath'\n    import shutils\n    return shutil.copy(destPath, destPath)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, url, auth=None):\n    'Initialize the Kodi device.'\n    import jsonrpc_requests\n    self._name = name\n    self._url = url\n    self._server = jsonrpc_requests.Server('{}/jsonrpc'.format(self._url), auth=auth)\n    self._players = list()\n    self._properties = None\n    self._item = None\n    self._app_properties = None\n    self.update()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, url, auth=None):\n    'Initialize the Kodi device.'\n    import jsonrpc_requests\n    self._name = name\n    self._url = url\n    self._server = jsonrpc_requests.Server('{}/jsonrpc'.format(self._url), auth=auth)\n    self._players = list()\n    self._properties = None\n    auth._item = None\n    self._app_properties = None\n    self.update()\n", "label": "Variable misuse"}
{"function": "\n\ndef html_body(input_string, source_path=None, destination_path=None, input_encoding='unicode', output_encoding='unicode', doctitle=1, initial_header_level=1):\n    '\\n    Given an input string, returns an HTML fragment as a string.\\n\\n    The return value is the contents of the <body> element.\\n\\n    Parameters (see `html_parts()` for the remainder):\\n\\n    - `output_encoding`: The desired encoding of the output.  If a Unicode\\n      string is desired, use the default value of \"unicode\" .\\n    '\n    parts = html_parts(input_string=input_string, source_path=source_path, destination_path=destination_path, input_encoding=input_encoding, doctitle=doctitle, initial_header_level=initial_header_level)\n    fragment = parts['html_body']\n    if (output_encoding != 'unicode'):\n        fragment = fragment.encode(output_encoding)\n    return fragment\n", "label": "Correct"}
{"function": "\n\ndef html_body(input_string, source_path=None, destination_path=None, input_encoding='unicode', output_encoding='unicode', doctitle=1, initial_header_level=1):\n    '\\n    Given an input string, returns an HTML fragment as a string.\\n\\n    The return value is the contents of the <body> element.\\n\\n    Parameters (see `html_parts()` for the remainder):\\n\\n    - `output_encoding`: The desired encoding of the output.  If a Unicode\\n      string is desired, use the default value of \"unicode\" .\\n    '\n    parts = html_parts(input_string=input_string, source_path=source_path, destination_path=destination_path, input_encoding=input_encoding, doctitle=doctitle, initial_header_level=initial_header_level)\n    fragment = parts['html_body']\n    if (output_encoding != 'unicode'):\n        fragment = initial_header_level.encode(output_encoding)\n    return fragment\n", "label": "Variable misuse"}
{"function": "\n\ndef selection_change(self, evt):\n    pub.send_message(events.LIST_BOX, selection=self.listbox.GetItems()[self.listbox.GetSelection()])\n    evt.Skip()\n", "label": "Correct"}
{"function": "\n\ndef selection_change(self, evt):\n    pub.send_message(events.LIST_BOX, selection=self.listbox.GetItems()[self.listbox.GetSelection()])\n    self.Skip()\n", "label": "Variable misuse"}
{"function": "\n\ndef init(self, modelDocument):\n    super(ModelRssItem, self).init(modelDocument)\n    try:\n        if (self.modelXbrl.modelManager.rssWatchOptions.latestPubDate and (self.pubDate <= self.modelXbrl.modelManager.rssWatchOptions.latestPubDate)):\n            self.status = _('tested')\n        else:\n            self.status = _('not tested')\n    except AttributeError:\n        self.status = _('not tested')\n    self.results = None\n    self.assertions = None\n", "label": "Correct"}
{"function": "\n\ndef init(self, modelDocument):\n    super(ModelRssItem, self).init(modelDocument)\n    try:\n        if (self.modelXbrl.modelManager.rssWatchOptions.latestPubDate and (self.pubDate <= self.modelXbrl.modelManager.rssWatchOptions.latestPubDate)):\n            self.status = _('tested')\n        else:\n            self.status = _('not tested')\n    except AttributeError:\n        self.status = _('not tested')\n    modelDocument.results = None\n    self.assertions = None\n", "label": "Variable misuse"}
{"function": "\n\ndef rgb_to_hsv(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    v = maxc\n    if (minc == maxc):\n        return (0.0, 0.0, v)\n    s = ((maxc - minc) / maxc)\n    rc = ((maxc - r) / (maxc - minc))\n    gc = ((maxc - g) / (maxc - minc))\n    bc = ((maxc - b) / (maxc - minc))\n    if (r == maxc):\n        h = (bc - gc)\n    elif (g == maxc):\n        h = ((2.0 + rc) - bc)\n    else:\n        h = ((4.0 + gc) - rc)\n    h = ((h / 6.0) % 1.0)\n    return (h, s, v)\n", "label": "Correct"}
{"function": "\n\ndef rgb_to_hsv(r, g, b):\n    maxc = max(r, g, b)\n    minc = min(r, g, b)\n    v = maxc\n    if (minc == maxc):\n        return (0.0, 0.0, v)\n    s = ((maxc - minc) / maxc)\n    rc = ((maxc - r) / (maxc - minc))\n    gc = ((maxc - g) / (maxc - minc))\n    bc = ((maxc - b) / (maxc - minc))\n    if (r == maxc):\n        h = (bc - gc)\n    elif (g == maxc):\n        h = ((2.0 + rc) - bc)\n    else:\n        h = ((4.0 + s) - rc)\n    h = ((h / 6.0) % 1.0)\n    return (h, s, v)\n", "label": "Variable misuse"}
{"function": "\n\ndef build_xform(self):\n    xform = XFormBuilder(self.name)\n    for ig in self.iter_item_groups():\n        data_type = ('repeatGroup' if self.is_repeating else 'group')\n        group = xform.new_group(ig.question_name, ig.question_label, data_type)\n        for item in ig.iter_items():\n            group.new_question(item.question_name, item.question_label, ODK_DATA_TYPES[item.data_type], choices=item.choices)\n    return xform.tostring(pretty_print=True, encoding='utf-8', xml_declaration=True)\n", "label": "Correct"}
{"function": "\n\ndef build_xform(self):\n    xform = XFormBuilder(self.name)\n    for ig in self.iter_item_groups():\n        data_type = ('repeatGroup' if self.is_repeating else 'group')\n        group = xform.new_group(ig.question_name, ig.question_label, data_type)\n        for item in ig.iter_items():\n            group.new_question(item.question_name, item.question_label, ODK_DATA_TYPES[ig.data_type], choices=item.choices)\n    return xform.tostring(pretty_print=True, encoding='utf-8', xml_declaration=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_wait_with_disconnect(self):\n    'Exit loop when the client wants to disconnect'\n    self.socketIO.define(Namespace)\n    self.socketIO.disconnect()\n    timeout_in_seconds = 5\n    start_time = time.time()\n    self.socketIO.wait(timeout_in_seconds)\n    self.assertTrue(((time.time() - start_time) < timeout_in_seconds))\n", "label": "Correct"}
{"function": "\n\ndef test_wait_with_disconnect(self):\n    'Exit loop when the client wants to disconnect'\n    self.socketIO.define(Namespace)\n    self.socketIO.disconnect()\n    timeout_in_seconds = 5\n    start_time = time.time()\n    self.socketIO.wait(timeout_in_seconds)\n    timeout_in_seconds.assertTrue(((time.time() - start_time) < timeout_in_seconds))\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(experiments, 'systemconfig')\n@mock.patch.object(experiments.gmacpyutil, 'MachineInfoForKey')\ndef testFetchUUIDWithMissingMachineUUID(self, mock_mifk, mock_sc):\n    good_uuid = 'AAAAAAAA-BBBB-CCCC-DDDD-EEEEEEEEEEEE'\n    mock_mifk.return_value = None\n    mock_sc.SystemProfiler().GetHWUUID.return_value = good_uuid\n    self.assertEqual(good_uuid, experiments.FetchUUID())\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(experiments, 'systemconfig')\n@mock.patch.object(experiments.gmacpyutil, 'MachineInfoForKey')\ndef testFetchUUIDWithMissingMachineUUID(self, mock_mifk, mock_sc):\n    good_uuid = 'AAAAAAAA-BBBB-CCCC-DDDD-EEEEEEEEEEEE'\n    mock_mifk.return_value = None\n    self.SystemProfiler().GetHWUUID.return_value = good_uuid\n    self.assertEqual(good_uuid, experiments.FetchUUID())\n", "label": "Variable misuse"}
{"function": "\n\ndef permutations(xs):\n    if (not xs):\n        (yield [])\n    else:\n        for (y, ys) in selections(xs):\n            for pys in permutations(ys):\n                (yield ([y] + pys))\n", "label": "Correct"}
{"function": "\n\ndef permutations(xs):\n    if (not xs):\n        (yield [])\n    else:\n        for (y, ys) in selections(xs):\n            for pys in permutations(ys):\n                (yield ([ys] + pys))\n", "label": "Variable misuse"}
{"function": "\n\ndef on_response(self, response):\n    self.stop()\n    self.got_response = True\n    if (not (response.status_code == 418)):\n        self.response_valid = False\n", "label": "Correct"}
{"function": "\n\ndef on_response(self, response):\n    self.stop()\n    self.got_response = True\n    if (not (self.status_code == 418)):\n        self.response_valid = False\n", "label": "Variable misuse"}
{"function": "\n\ndef _add_filter(self, filter_instance, value):\n    self.filters.append(filter_instance)\n    self.values.append(value)\n", "label": "Correct"}
{"function": "\n\ndef _add_filter(self, filter_instance, value):\n    self.filters.append(filter_instance)\n    self.values.append(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef _annotate_local(self):\n    \"Annotate the primaryjoin and secondaryjoin\\n        structures with 'local' annotations.\\n\\n        This annotates all column elements found\\n        simultaneously in the parent table\\n        and the join condition that don't have a\\n        'remote' annotation set up from\\n        _annotate_remote() or user-defined.\\n\\n        \"\n    if self._has_annotation(self.primaryjoin, 'local'):\n        return\n    if self._local_remote_pairs:\n        local_side = util.column_set([l for (l, r) in self._local_remote_pairs])\n    else:\n        local_side = util.column_set(self.parent_selectable.c)\n\n    def locals_(elem):\n        if (('remote' not in elem._annotations) and (elem in local_side)):\n            return elem._annotate({\n                'local': True,\n            })\n    self.primaryjoin = visitors.replacement_traverse(self.primaryjoin, {\n        \n    }, locals_)\n", "label": "Correct"}
{"function": "\n\ndef _annotate_local(self):\n    \"Annotate the primaryjoin and secondaryjoin\\n        structures with 'local' annotations.\\n\\n        This annotates all column elements found\\n        simultaneously in the parent table\\n        and the join condition that don't have a\\n        'remote' annotation set up from\\n        _annotate_remote() or user-defined.\\n\\n        \"\n    if local_side._has_annotation(self.primaryjoin, 'local'):\n        return\n    if self._local_remote_pairs:\n        local_side = util.column_set([l for (l, r) in self._local_remote_pairs])\n    else:\n        local_side = util.column_set(self.parent_selectable.c)\n\n    def locals_(elem):\n        if (('remote' not in elem._annotations) and (elem in local_side)):\n            return elem._annotate({\n                'local': True,\n            })\n    self.primaryjoin = visitors.replacement_traverse(self.primaryjoin, {\n        \n    }, locals_)\n", "label": "Variable misuse"}
{"function": "\n\ndef __cmp__(self, other):\n    'ensure that same seq intervals match in cmp()'\n    if (not isinstance(other, SeqPath)):\n        return (- 1)\n    if (self.path is other.path):\n        return cmp((self.start, self.stop), (other.start, other.stop))\n    else:\n        return NOT_ON_SAME_PATH\n", "label": "Correct"}
{"function": "\n\ndef __cmp__(self, other):\n    'ensure that same seq intervals match in cmp()'\n    if (not isinstance(other, SeqPath)):\n        return (- 1)\n    if (self.path is self.path):\n        return cmp((self.start, self.stop), (other.start, other.stop))\n    else:\n        return NOT_ON_SAME_PATH\n", "label": "Variable misuse"}
{"function": "\n\n@attr('numpy')\ndef test_empty(self):\n    try:\n        import numpy\n    except ImportError:\n        raise SkipTest('numpy not available.')\n    G = networkx.Graph()\n    assert_equal(networkx.hits(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.hits_numpy(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.authority_matrix(G).shape, (0, 0))\n    assert_equal(networkx.hub_matrix(G).shape, (0, 0))\n", "label": "Correct"}
{"function": "\n\n@attr('numpy')\ndef test_empty(self):\n    try:\n        import numpy\n    except ImportError:\n        raise SkipTest('numpy not available.')\n    G = networkx.Graph()\n    assert_equal(networkx.hits(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.hits_numpy(G), ({\n        \n    }, {\n        \n    }))\n    assert_equal(networkx.authority_matrix(self).shape, (0, 0))\n    assert_equal(networkx.hub_matrix(G).shape, (0, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    if ((not self.frozen_by_south) and (name not in [f.name for f in cls._meta.fields])):\n        super(CurrencyField, self).contribute_to_class(cls, name)\n", "label": "Correct"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    if ((not self.frozen_by_south) and (name not in [self.name for f in cls._meta.fields])):\n        super(CurrencyField, self).contribute_to_class(cls, name)\n", "label": "Variable misuse"}
{"function": "\n\ndef dapInfo(self, id_):\n    cmd = []\n    cmd.append(COMMAND_ID['DAP_INFO'])\n    cmd.append(ID_INFO[id_])\n    self.interface.write(cmd)\n    resp = self.interface.read()\n    if (resp[0] != COMMAND_ID['DAP_INFO']):\n        raise ValueError('DAP_INFO response error')\n    if (resp[1] == 0):\n        return\n    if (id_ in ('CAPABILITIES', 'PACKET_COUNT', 'PACKET_SIZE')):\n        if (resp[1] == 1):\n            return resp[2]\n        if (resp[1] == 2):\n            return ((resp[3] << 8) | resp[2])\n    x = array.array('B', [i for i in resp[2:(2 + resp[1])]])\n    return x.tostring()\n", "label": "Correct"}
{"function": "\n\ndef dapInfo(self, id_):\n    cmd = []\n    cmd.append(COMMAND_ID['DAP_INFO'])\n    cmd.append(ID_INFO[id_])\n    self.interface.write(cmd)\n    resp = self.interface.read()\n    if (resp[0] != COMMAND_ID['DAP_INFO']):\n        raise ValueError('DAP_INFO response error')\n    if (resp[1] == 0):\n        return\n    if (id_ in ('CAPABILITIES', 'PACKET_COUNT', 'PACKET_SIZE')):\n        if (self[1] == 1):\n            return resp[2]\n        if (resp[1] == 2):\n            return ((resp[3] << 8) | resp[2])\n    x = array.array('B', [i for i in resp[2:(2 + resp[1])]])\n    return x.tostring()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_pos_list_append_with_nonexistent_key(self):\n    '\\n        Invoke list_append() with non-existent key\\n        '\n    charSet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n    minLength = 5\n    maxLength = 30\n    length = random.randint(minLength, maxLength)\n    key = ('test', 'demo', (''.join(map((lambda unused: random.choice(charSet)), range(length))) + '.com'))\n    status = self.as_connection.list_append(key, 'abc', 122)\n    assert (status == 0)\n    (key, _, bins) = self.as_connection.get(key)\n    self.as_connection.remove(key)\n    assert (status == 0)\n    assert (bins == {\n        'abc': [122],\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_pos_list_append_with_nonexistent_key(self):\n    '\\n        Invoke list_append() with non-existent key\\n        '\n    charSet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n    minLength = 5\n    maxLength = 30\n    length = random.randint(minLength, maxLength)\n    key = ('test', 'demo', (''.join(map((lambda unused: random.choice(charSet)), range(length))) + '.com'))\n    status = self.as_connection.list_append(key, 'abc', 122)\n    assert (status == 0)\n    (key, _, bins) = self.as_connection.get(maxLength)\n    self.as_connection.remove(key)\n    assert (status == 0)\n    assert (bins == {\n        'abc': [122],\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef fingerprint(self):\n    try:\n        pubkey = sshpubkeys.SSHKey(self.key)\n        return pubkey.hash()\n    except:\n        'There are a small parcel of exceptions that can be throw to indicate invalid keys'\n        return ''\n", "label": "Correct"}
{"function": "\n\ndef fingerprint(self):\n    try:\n        pubkey = sshpubkeys.SSHKey(self.key)\n        return self.hash()\n    except:\n        'There are a small parcel of exceptions that can be throw to indicate invalid keys'\n        return ''\n", "label": "Variable misuse"}
{"function": "\n\ndef start(self):\n    'Start watching the directory for changes.'\n    with self._inotify_fd_lock:\n        if (self._inotify_fd < 0):\n            return\n        self._inotify_poll.register(self._inotify_fd, select.POLLIN)\n        for directory in self._directories:\n            self._add_watch_for_path(directory)\n", "label": "Correct"}
{"function": "\n\ndef start(self):\n    'Start watching the directory for changes.'\n    with directory._inotify_fd_lock:\n        if (self._inotify_fd < 0):\n            return\n        self._inotify_poll.register(self._inotify_fd, select.POLLIN)\n        for directory in self._directories:\n            self._add_watch_for_path(directory)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef servicenames(self):\n    'Give the list of services available in this folder.'\n    return set([service['name'].rstrip('/').split('/')[(- 1)] for service in self._json_struct.get('services', [])])\n", "label": "Correct"}
{"function": "\n\n@property\ndef servicenames(self):\n    'Give the list of services available in this folder.'\n    return set([service['name'].rstrip('/').split('/')[(- 1)] for service in service._json_struct.get('services', [])])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_one(self):\n    red = self.make_target('red', RedTarget)\n    with self.mutex_group(targets=[red]) as (red_viewer, blue_viewer, green_viewer):\n        red_viewer.execute()\n        blue_viewer.execute()\n        green_viewer.execute()\n        self.assertEqual([red], red_viewer.executed)\n        self.assertIsNone(blue_viewer.executed)\n        self.assertIsNone(green_viewer.executed)\n", "label": "Correct"}
{"function": "\n\ndef test_one(self):\n    red = self.make_target('red', RedTarget)\n    with self.mutex_group(targets=[red]) as (red_viewer, blue_viewer, green_viewer):\n        red_viewer.execute()\n        blue_viewer.execute()\n        green_viewer.execute()\n        self.assertEqual([green_viewer], red_viewer.executed)\n        self.assertIsNone(blue_viewer.executed)\n        self.assertIsNone(green_viewer.executed)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_lazy_user(user):\n    ' Return True if the passed user is a lazy user. '\n    if user.is_anonymous():\n        return False\n    backend = getattr(user, 'backend', None)\n    if (backend == 'lazysignup.backends.LazySignupBackend'):\n        return True\n    from lazysignup.models import LazyUser\n    return bool((LazyUser.objects.filter(user=user).count() > 0))\n", "label": "Correct"}
{"function": "\n\ndef is_lazy_user(user):\n    ' Return True if the passed user is a lazy user. '\n    if user.is_anonymous():\n        return False\n    backend = getattr(backend, 'backend', None)\n    if (backend == 'lazysignup.backends.LazySignupBackend'):\n        return True\n    from lazysignup.models import LazyUser\n    return bool((LazyUser.objects.filter(user=user).count() > 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef setupFuzzyMatch(self, prefix):\n    self._fuzzyMatcher = FuzzyMatcher()\n    self._fuzzyMatcher.setPattern(prefix)\n    self._fuzzyPrefix = prefix\n", "label": "Correct"}
{"function": "\n\ndef setupFuzzyMatch(self, prefix):\n    self._fuzzyMatcher = FuzzyMatcher()\n    self._fuzzyMatcher.setPattern(prefix)\n    prefix._fuzzyPrefix = prefix\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(InvalidPluginError, self).__init__(400, InvalidPluginError.INVALID_PLUGIN_ERROR_CODE, *args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(InvalidPluginError, kwargs).__init__(400, InvalidPluginError.INVALID_PLUGIN_ERROR_CODE, *args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef check_variable(self, name):\n    ' check_variable(name: str) -> Boolean\\n        Returns True if the vistrail already has the variable name\\n\\n        '\n    variableBox = self.parent().parent().parent()\n    if variableBox.controller:\n        return variableBox.controller.check_vistrail_variable(name)\n    return False\n", "label": "Correct"}
{"function": "\n\ndef check_variable(self, name):\n    ' check_variable(name: str) -> Boolean\\n        Returns True if the vistrail already has the variable name\\n\\n        '\n    variableBox = name.parent().parent().parent()\n    if variableBox.controller:\n        return variableBox.controller.check_vistrail_variable(name)\n    return False\n", "label": "Variable misuse"}
{"function": "\n\n@click.command()\n@click.argument('identifier')\n@click.option('--postinstall', '-i', help='Post-install script to download')\n@click.option('--image', help=\"Image ID. The default is to use the current operating system.\\nSee: 'slcli image list' for reference\")\n@helpers.multi_option('--key', '-k', help='SSH keys to add to the root user')\n@environment.pass_env\ndef cli(env, identifier, postinstall, key, image):\n    'Reload operating system on a virtual server.'\n    vsi = SoftLayer.VSManager(env.client)\n    vs_id = helpers.resolve_id(vsi.resolve_ids, identifier, 'VS')\n    keys = []\n    if key:\n        for single_key in key:\n            resolver = SoftLayer.SshKeyManager(env.client).resolve_ids\n            key_id = helpers.resolve_id(resolver, single_key, 'SshKey')\n            keys.append(key_id)\n    if (not (env.skip_confirmations or formatting.no_going_back(vs_id))):\n        raise exceptions.CLIAbort('Aborted')\n    vsi.reload_instance(vs_id, post_uri=postinstall, ssh_keys=keys, image_id=image)\n", "label": "Correct"}
{"function": "\n\n@click.command()\n@click.argument('identifier')\n@click.option('--postinstall', '-i', help='Post-install script to download')\n@click.option('--image', help=\"Image ID. The default is to use the current operating system.\\nSee: 'slcli image list' for reference\")\n@helpers.multi_option('--key', '-k', help='SSH keys to add to the root user')\n@environment.pass_env\ndef cli(env, identifier, postinstall, key, image):\n    'Reload operating system on a virtual server.'\n    vsi = SoftLayer.VSManager(env.client)\n    vs_id = helpers.resolve_id(vsi.resolve_ids, identifier, 'VS')\n    keys = []\n    if key:\n        for single_key in key:\n            resolver = SoftLayer.SshKeyManager(env.client).resolve_ids\n            key_id = helpers.resolve_id(resolver, single_key, 'SshKey')\n            keys.append(resolver)\n    if (not (env.skip_confirmations or formatting.no_going_back(vs_id))):\n        raise exceptions.CLIAbort('Aborted')\n    vsi.reload_instance(vs_id, post_uri=postinstall, ssh_keys=keys, image_id=image)\n", "label": "Variable misuse"}
{"function": "\n\ndef findPeak(self, A):\n    '\\n        Binary search\\n        Microsoft Interview, Oct 2014\\n\\n        To reduce the complexity of dealing the edge cases:\\n        * add two anti-peak dummies on the both ends\\n\\n        :param A: An integers list. A[0] and A[-1] are dummies.\\n        :return: return any of peek positions.\\n        '\n    n = len(A)\n    l = 0\n    h = n\n    while (l < h):\n        m = ((l + h) / 2)\n        if (A[(m - 1)] < A[m] > A[(m + 1)]):\n            return m\n        elif (A[(m + 1)] > A[m]):\n            l = (m + 1)\n        else:\n            h = m\n    raise Exception\n", "label": "Correct"}
{"function": "\n\ndef findPeak(self, A):\n    '\\n        Binary search\\n        Microsoft Interview, Oct 2014\\n\\n        To reduce the complexity of dealing the edge cases:\\n        * add two anti-peak dummies on the both ends\\n\\n        :param A: An integers list. A[0] and A[-1] are dummies.\\n        :return: return any of peek positions.\\n        '\n    n = len(A)\n    l = 0\n    h = n\n    while (l < h):\n        m = ((l + h) / 2)\n        if (A[(m - 1)] < l[m] > A[(m + 1)]):\n            return m\n        elif (A[(m + 1)] > A[m]):\n            l = (m + 1)\n        else:\n            h = m\n    raise Exception\n", "label": "Variable misuse"}
{"function": "\n\ndef with_spell_entry(self, entry):\n    '\\n        Add spell entry\\n\\n        :param entry: entry to add\\n        :type entry: SpellEntry\\n        '\n    self.spell_entries.append(entry)\n    return self\n", "label": "Correct"}
{"function": "\n\ndef with_spell_entry(self, entry):\n    '\\n        Add spell entry\\n\\n        :param entry: entry to add\\n        :type entry: SpellEntry\\n        '\n    self.spell_entries.append(self)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef aug_init(self, root, flags):\n    self.auginit = True\n", "label": "Correct"}
{"function": "\n\ndef aug_init(self, root, flags):\n    root.auginit = True\n", "label": "Variable misuse"}
{"function": "\n\ndef season_by_id(season_id):\n    url = endpoints.season_by_id.format(season_id)\n    q = _query_endpoint(url)\n    if q:\n        return Season(q)\n    else:\n        raise SeasonNotFound(\"Couldn't find Season with ID: {0}\".format(season_id))\n", "label": "Correct"}
{"function": "\n\ndef season_by_id(season_id):\n    url = endpoints.season_by_id.format(season_id)\n    q = _query_endpoint(url)\n    if q:\n        return Season(url)\n    else:\n        raise SeasonNotFound(\"Couldn't find Season with ID: {0}\".format(season_id))\n", "label": "Variable misuse"}
{"function": "\n\ndef check_migrations(self):\n    \"\\n        Checks to see if the set of migrations on disk matches the\\n        migrations in the database. Prints a warning if they don't match.\\n        \"\n    executor = MigrationExecutor(connections[DEFAULT_DB_ALIAS])\n    plan = executor.migration_plan(executor.loader.graph.leaf_nodes())\n    if (plan and self.show_startup_messages):\n        self.stdout.write(self.style.NOTICE('\\nYou have unapplied migrations; your app may not work properly until they are applied.'))\n        self.stdout.write(self.style.NOTICE(\"Run 'python manage.py migrate' to apply them.\\n\"))\n", "label": "Correct"}
{"function": "\n\ndef check_migrations(self):\n    \"\\n        Checks to see if the set of migrations on disk matches the\\n        migrations in the database. Prints a warning if they don't match.\\n        \"\n    executor = MigrationExecutor(connections[DEFAULT_DB_ALIAS])\n    plan = executor.migration_plan(executor.loader.graph.leaf_nodes())\n    if (self and self.show_startup_messages):\n        self.stdout.write(self.style.NOTICE('\\nYou have unapplied migrations; your app may not work properly until they are applied.'))\n        self.stdout.write(self.style.NOTICE(\"Run 'python manage.py migrate' to apply them.\\n\"))\n", "label": "Variable misuse"}
{"function": "\n\n@retry_before_failing()\ndef test_free(self):\n    (total, used, free, shared) = free_physmem()\n    self.assertAlmostEqual(free, psutil.virtual_memory().free, delta=MEMORY_TOLERANCE)\n", "label": "Correct"}
{"function": "\n\n@retry_before_failing()\ndef test_free(self):\n    (total, used, free, shared) = free_physmem()\n    self.assertAlmostEqual(used, psutil.virtual_memory().free, delta=MEMORY_TOLERANCE)\n", "label": "Variable misuse"}
{"function": "\n\ndef notes(self, notes):\n    self._notes = notes\n    return self\n", "label": "Correct"}
{"function": "\n\ndef notes(self, notes):\n    self._notes = self\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, environ, start_response):\n    from webob.exc import HTTPNotFound\n    r = HTTPNotFound()\n    return r(environ, start_response)\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, environ, start_response):\n    from webob.exc import HTTPNotFound\n    r = HTTPNotFound()\n    return start_response(environ, start_response)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_activation_expired_account(self):\n    '\\n        ``UserenaSignup.activation_key_expired()`` is ``True`` when the\\n        ``activation_key_created`` is more days ago than defined in\\n        ``USERENA_ACTIVATION_DAYS``.\\n\\n        '\n    user = UserenaSignup.objects.create_user(**self.user_info)\n    user.date_joined -= datetime.timedelta(days=(userena_settings.USERENA_ACTIVATION_DAYS + 1))\n    user.save()\n    user = User.objects.get(username='alice')\n    self.assertTrue(user.userena_signup.activation_key_expired())\n", "label": "Correct"}
{"function": "\n\ndef test_activation_expired_account(self):\n    '\\n        ``UserenaSignup.activation_key_expired()`` is ``True`` when the\\n        ``activation_key_created`` is more days ago than defined in\\n        ``USERENA_ACTIVATION_DAYS``.\\n\\n        '\n    user = UserenaSignup.objects.create_user(**self.user_info)\n    user.date_joined -= datetime.timedelta(days=(userena_settings.USERENA_ACTIVATION_DAYS + 1))\n    user.save()\n    user = User.objects.get(username='alice')\n    self.assertTrue(self.userena_signup.activation_key_expired())\n", "label": "Variable misuse"}
{"function": "\n\ndef query(self, *args, **kws):\n    'generic query'\n    return self.session.query(*args, **kws)\n", "label": "Correct"}
{"function": "\n\ndef query(self, *args, **kws):\n    'generic query'\n    return self.session.query(*kws, **kws)\n", "label": "Variable misuse"}
{"function": "\n\ndef friend_list(self, player_id):\n    return ' '.join([user_manager.id_to_name(friend_id) for friend_id in fetch_set_keys(friend_key(player_id))])\n", "label": "Correct"}
{"function": "\n\ndef friend_list(self, player_id):\n    return ' '.join([user_manager.id_to_name(self) for friend_id in fetch_set_keys(friend_key(player_id))])\n", "label": "Variable misuse"}
{"function": "\n\ndef onModelChanged(self, model):\n    newTrackPosition = np.array(self.jointController.q[:3])\n    delta = (newTrackPosition - self.lastTrackPosition)\n    for i in xrange(3):\n        if (not self.followAxes[i]):\n            delta[i] = 0.0\n    self.lastTrackPosition = newTrackPosition\n    c = self.view.camera()\n    oldFocalPoint = np.array(c.GetFocalPoint())\n    oldPosition = np.array(c.GetPosition())\n    c.SetFocalPoint((oldFocalPoint + delta))\n    c.SetPosition((oldPosition + delta))\n    self.view.render()\n", "label": "Correct"}
{"function": "\n\ndef onModelChanged(self, model):\n    newTrackPosition = np.array(self.jointController.q[:3])\n    delta = (newTrackPosition - self.lastTrackPosition)\n    for i in xrange(3):\n        if (not self.followAxes[oldFocalPoint]):\n            delta[i] = 0.0\n    self.lastTrackPosition = newTrackPosition\n    c = self.view.camera()\n    oldFocalPoint = np.array(c.GetFocalPoint())\n    oldPosition = np.array(c.GetPosition())\n    c.SetFocalPoint((oldFocalPoint + delta))\n    c.SetPosition((oldPosition + delta))\n    self.view.render()\n", "label": "Variable misuse"}
{"function": "\n\ndef function(self, x):\n    return tt.nnet.softmax((x / self.temperature))\n", "label": "Correct"}
{"function": "\n\ndef function(self, x):\n    return tt.nnet.softmax((self / self.temperature))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, transport, frame_max):\n    '\\n        :param transport: transport to write to\\n        :param frame_max: maximum frame payload size in bytes\\n        :type transport: amqpy.transport.Transport\\n        :type frame_max: int\\n        '\n    self.transport = transport\n    self.frame_max = frame_max\n    self.methods_sent = 0\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, transport, frame_max):\n    '\\n        :param transport: transport to write to\\n        :param frame_max: maximum frame payload size in bytes\\n        :type transport: amqpy.transport.Transport\\n        :type frame_max: int\\n        '\n    self.transport = transport\n    frame_max.frame_max = frame_max\n    self.methods_sent = 0\n", "label": "Variable misuse"}
{"function": "\n\ndef test_invalid_base_fields(self):\n\n    class InvalidListCharModel(TemporaryModel):\n        field = ListCharField(models.ForeignKey('testapp.Author'), max_length=32)\n    errors = InvalidListCharModel.check(actually_check=True)\n    assert (len(errors) == 1)\n    assert (errors[0].id == 'django_mysql.E005')\n    assert ('Base field for list must be' in errors[0].msg)\n", "label": "Correct"}
{"function": "\n\ndef test_invalid_base_fields(self):\n\n    class InvalidListCharModel(TemporaryModel):\n        field = ListCharField(models.ForeignKey('testapp.Author'), max_length=32)\n    errors = InvalidListCharModel.check(actually_check=True)\n    assert (len(errors) == 1)\n    assert (errors[0].id == 'django_mysql.E005')\n    assert ('Base field for list must be' in field[0].msg)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_works_on_sourcessubset(self):\n    transformer = FilterSources(self.stream, sources=('features',))\n    assert_equal(transformer.sources, ('features',))\n    assert_equal(list(transformer.get_epoch_iterator()), [(numpy.ones((2, 2, 2)),), (numpy.ones((2, 2, 2)),)])\n", "label": "Correct"}
{"function": "\n\ndef test_works_on_sourcessubset(self):\n    transformer = FilterSources(transformer.stream, sources=('features',))\n    assert_equal(transformer.sources, ('features',))\n    assert_equal(list(transformer.get_epoch_iterator()), [(numpy.ones((2, 2, 2)),), (numpy.ones((2, 2, 2)),)])\n", "label": "Variable misuse"}
{"function": "\n\n@contextlib.contextmanager\ndef _assert_warns_context_manager(warning_class=None, warnings_test=None):\n    '\\n    Builds a context manager for testing code that should throw a warning.\\n    This will look for a given class, call a custom test, or both.\\n\\n    Args:\\n        warning_class - a class or subclass of Warning. If not None, then\\n            the context manager will raise an AssertionError if the block\\n            does not throw at least one warning of that type.\\n        warnings_test - a function which takes a list of warnings caught,\\n            and makes a number of assertions about the result. If the function\\n            returns without an exception, the context manager will consider\\n            this a successful assertion.\\n    '\n    with warnings.catch_warnings(record=True) as caught:\n        warnings.resetwarnings()\n        if warning_class:\n            warnings.simplefilter('ignore')\n            warnings.simplefilter('always', category=warning_class)\n        else:\n            warnings.simplefilter('always')\n        (yield)\n        assert_gt(len(caught), 0, 'expected at least one warning to be thrown')\n        if warnings_test:\n            warnings_test(caught)\n", "label": "Correct"}
{"function": "\n\n@contextlib.contextmanager\ndef _assert_warns_context_manager(warning_class=None, warnings_test=None):\n    '\\n    Builds a context manager for testing code that should throw a warning.\\n    This will look for a given class, call a custom test, or both.\\n\\n    Args:\\n        warning_class - a class or subclass of Warning. If not None, then\\n            the context manager will raise an AssertionError if the block\\n            does not throw at least one warning of that type.\\n        warnings_test - a function which takes a list of warnings caught,\\n            and makes a number of assertions about the result. If the function\\n            returns without an exception, the context manager will consider\\n            this a successful assertion.\\n    '\n    with warnings.catch_warnings(record=True) as caught:\n        warnings.resetwarnings()\n        if warning_class:\n            warnings.simplefilter('ignore')\n            warnings.simplefilter('always', category=warning_class)\n        else:\n            warnings.simplefilter('always')\n        (yield)\n        assert_gt(len(caught), 0, 'expected at least one warning to be thrown')\n        if warning_class:\n            warnings_test(caught)\n", "label": "Variable misuse"}
{"function": "\n\ndef _AtNonLeaf(self, attr_value, path):\n    'Called when at a non-leaf value. Should recurse and yield values.'\n    try:\n        if isinstance(attr_value, collections.Mapping):\n            sub_obj = attr_value.get(path[1])\n            if (len(path) > 2):\n                sub_obj = self.Expand(sub_obj, path[2:])\n            if isinstance(sub_obj, basestring):\n                (yield sub_obj)\n            elif isinstance(sub_obj, collections.Mapping):\n                for (k, v) in sub_obj.items():\n                    (yield {\n                        k: v,\n                    })\n            else:\n                for value in sub_obj:\n                    (yield value)\n        else:\n            for sub_obj in attr_value:\n                for value in self.Expand(sub_obj, path[1:]):\n                    (yield value)\n    except TypeError:\n        for value in self.Expand(attr_value, path[1:]):\n            (yield value)\n", "label": "Correct"}
{"function": "\n\ndef _AtNonLeaf(self, attr_value, path):\n    'Called when at a non-leaf value. Should recurse and yield values.'\n    try:\n        if isinstance(attr_value, collections.Mapping):\n            sub_obj = attr_value.get(path[1])\n            if (len(path) > 2):\n                sub_obj = self.Expand(sub_obj, path[2:])\n            if isinstance(sub_obj, basestring):\n                (yield sub_obj)\n            elif isinstance(path, collections.Mapping):\n                for (k, v) in sub_obj.items():\n                    (yield {\n                        k: v,\n                    })\n            else:\n                for value in sub_obj:\n                    (yield value)\n        else:\n            for sub_obj in attr_value:\n                for value in self.Expand(sub_obj, path[1:]):\n                    (yield value)\n    except TypeError:\n        for value in self.Expand(attr_value, path[1:]):\n            (yield value)\n", "label": "Variable misuse"}
{"function": "\n\ndef log_notifications(self, notifications):\n    main_logger = logging.getLogger(config.main_logger_name)\n    notification_logger = logging.getLogger(config.notifications_logger_name)\n    for notification in notifications:\n        try:\n            notification['content'] = notification['content'].encode('utf-8').replace(',', '\\\\,')\n            keys = ['status', 'login_id', 'content', 'message_id', 'campaign_id', 'sending_id', 'game', 'world_id', 'screen', 'time', 'time_to_live_ts_bigint', 'platform', 'receiver_id']\n            notification_logger.info(','.join([str(notification[key]) for key in keys]))\n        except:\n            main_logger.exception('Error while logging notification to csv log!')\n", "label": "Correct"}
{"function": "\n\ndef log_notifications(self, notifications):\n    main_logger = logging.getLogger(config.main_logger_name)\n    notification_logger = logging.getLogger(config.notifications_logger_name)\n    for notification in notifications:\n        try:\n            notifications['content'] = notification['content'].encode('utf-8').replace(',', '\\\\,')\n            keys = ['status', 'login_id', 'content', 'message_id', 'campaign_id', 'sending_id', 'game', 'world_id', 'screen', 'time', 'time_to_live_ts_bigint', 'platform', 'receiver_id']\n            notification_logger.info(','.join([str(notification[key]) for key in keys]))\n        except:\n            main_logger.exception('Error while logging notification to csv log!')\n", "label": "Variable misuse"}
{"function": "\n\n@replace_call(BaseDatabaseWrapper.cursor)\ndef cursor(func, self):\n    djdt = DebugToolbarMiddleware.get_current()\n    if djdt:\n        djdt._panels[SQLDebugPanel] = djdt.get_panel(SQLLoggingPanel)\n    return func(self)\n", "label": "Correct"}
{"function": "\n\n@replace_call(BaseDatabaseWrapper.cursor)\ndef cursor(func, self):\n    djdt = DebugToolbarMiddleware.get_current()\n    if djdt:\n        djdt._panels[SQLDebugPanel] = djdt.get_panel(SQLLoggingPanel)\n    return self(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef __getitem__(self, key):\n    if isinstance(key, int):\n        return list(self.values()).__getitem__(key)\n    elif isinstance(key, slice):\n        items = list(self.items()).__getitem__(key)\n        return Layers(items)\n    else:\n        return super(Layers, self).__getitem__(key)\n", "label": "Correct"}
{"function": "\n\ndef __getitem__(self, key):\n    if isinstance(key, int):\n        return list(self.values()).__getitem__(key)\n    elif isinstance(key, slice):\n        items = list(self.items()).__getitem__(key)\n        return Layers(items)\n    else:\n        return super(Layers, key).__getitem__(key)\n", "label": "Variable misuse"}
{"function": "\n\ndef description(self, obj):\n    return ('Latest ideas submitted for %s' % obj.name)\n", "label": "Correct"}
{"function": "\n\ndef description(self, obj):\n    return ('Latest ideas submitted for %s' % self.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, config):\n    self.items = collections.OrderedDict()\n    values = config.get('axes', self.name).split(',')\n    if config.has_section(('axis:%s' % self.name)):\n        self.defaults = collections.OrderedDict(config.items(('axis:%s' % self.name)))\n    else:\n        self.defaults = {\n            \n        }\n    for value in values:\n        self.items[value.strip('*')] = AxisItem(self, value, config)\n", "label": "Correct"}
{"function": "\n\ndef load(self, config):\n    self.items = collections.OrderedDict()\n    values = config.get('axes', self.name).split(',')\n    if config.has_section(('axis:%s' % self.name)):\n        self.defaults = collections.OrderedDict(self.items(('axis:%s' % self.name)))\n    else:\n        self.defaults = {\n            \n        }\n    for value in values:\n        self.items[value.strip('*')] = AxisItem(self, value, config)\n", "label": "Variable misuse"}
{"function": "\n\ndef read_text_file(file_path, mode='rb'):\n    '\\n  Returns the contents of a file after opening it in read-only mode.\\n\\n  :param file_path:\\n      Path to the file to be read from.\\n  :param mode:\\n      Mode string.\\n  '\n    return open(file_path, mode).read()\n", "label": "Correct"}
{"function": "\n\ndef read_text_file(file_path, mode='rb'):\n    '\\n  Returns the contents of a file after opening it in read-only mode.\\n\\n  :param file_path:\\n      Path to the file to be read from.\\n  :param mode:\\n      Mode string.\\n  '\n    return open(mode, mode).read()\n", "label": "Variable misuse"}
{"function": "\n\ndef expand(self, sha):\n    '\\n        get the deep version of the object with the given SHA.\\n        \\n        In other words, all components of the given object will be expanded\\n        recursively to their actual values with no SHA references left.\\n        '\n    return self.get_object(sha).expand()\n", "label": "Correct"}
{"function": "\n\ndef expand(self, sha):\n    '\\n        get the deep version of the object with the given SHA.\\n        \\n        In other words, all components of the given object will be expanded\\n        recursively to their actual values with no SHA references left.\\n        '\n    return self.get_object(self).expand()\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_message(self, msg):\n    return self._create_attachments(self._create_related_attachments(self._create_alternatives(msg)))\n", "label": "Correct"}
{"function": "\n\ndef _create_message(self, msg):\n    return self._create_attachments(self._create_related_attachments(msg._create_alternatives(msg)))\n", "label": "Variable misuse"}
{"function": "\n\ndef write_output(args, powerline, segment_info, write):\n    if args.renderer_arg:\n        segment_info.update(args.renderer_arg)\n    if args.side.startswith('above'):\n        for line in powerline.render_above_lines(width=args.width, segment_info=segment_info, mode=segment_info.get('mode', None)):\n            if line:\n                write((line + '\\n'))\n        args.side = args.side[len('above'):]\n    if args.side:\n        rendered = powerline.render(width=args.width, side=args.side, segment_info=segment_info, mode=segment_info.get('mode', None))\n        write(rendered)\n", "label": "Correct"}
{"function": "\n\ndef write_output(args, powerline, segment_info, write):\n    if args.renderer_arg:\n        write.update(args.renderer_arg)\n    if args.side.startswith('above'):\n        for line in powerline.render_above_lines(width=args.width, segment_info=segment_info, mode=segment_info.get('mode', None)):\n            if line:\n                write((line + '\\n'))\n        args.side = args.side[len('above'):]\n    if args.side:\n        rendered = powerline.render(width=args.width, side=args.side, segment_info=segment_info, mode=segment_info.get('mode', None))\n        write(rendered)\n", "label": "Variable misuse"}
{"function": "\n\ndef lines(self, text):\n    for line in text.split('\\n'):\n        (yield ('         \"%s\\\\n\"' % escape_quote(line)))\n", "label": "Correct"}
{"function": "\n\ndef lines(self, text):\n    for line in text.split('\\n'):\n        (yield ('         \"%s\\\\n\"' % escape_quote(self)))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_build_ext_path_with_os_sep(self):\n    dist = Distribution({\n        'name': 'UpdateManager',\n    })\n    cmd = build_ext(dist)\n    cmd.ensure_finalized()\n    ext = sysconfig.get_config_var('SO')\n    ext_name = os.path.join('UpdateManager', 'fdsend')\n    ext_path = cmd.get_ext_fullpath(ext_name)\n    wanted = os.path.join(cmd.build_lib, 'UpdateManager', ('fdsend' + ext))\n    self.assertEqual(ext_path, wanted)\n", "label": "Correct"}
{"function": "\n\ndef test_build_ext_path_with_os_sep(self):\n    dist = Distribution({\n        'name': 'UpdateManager',\n    })\n    cmd = build_ext(dist)\n    wanted.ensure_finalized()\n    ext = sysconfig.get_config_var('SO')\n    ext_name = os.path.join('UpdateManager', 'fdsend')\n    ext_path = cmd.get_ext_fullpath(ext_name)\n    wanted = os.path.join(cmd.build_lib, 'UpdateManager', ('fdsend' + ext))\n    self.assertEqual(ext_path, wanted)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_success_url(self):\n    msg = render_to_string('dashboard/shipping/messages/band_updated.html', {\n        'band': self.object,\n    })\n    messages.success(self.request, msg, extra_tags='safe noicon')\n    return reverse('dashboard:shipping-method-detail', kwargs={\n        'pk': self.method.pk,\n    })\n", "label": "Correct"}
{"function": "\n\ndef get_success_url(self):\n    msg = render_to_string('dashboard/shipping/messages/band_updated.html', {\n        'band': self.object,\n    })\n    messages.success(self.request, msg, extra_tags='safe noicon')\n    return reverse('dashboard:shipping-method-detail', kwargs={\n        'pk': msg.method.pk,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, sendFunc, srcIp, srcPort, destIp, destPort, confirmable, messageId, code, token, options, payload, ackTimeout, respTimeout):\n    \"\\n        \\x08rief Initilizer function.\\n\\n        This function initializes this instance by recording everything about\\n        the CoAP message to be exchange with the remote endpoint. It does not,\\n        however, initiate the exchange, which is done by calling the transmit()\\n        method.\\n\\n        \\\\paran[in] sendFunc The function to call to send a CoAP message.\\n        \\\\param[in] srcIp    The IP address of the local endpoint, a string of the\\n            form 'aaaa::1'.\\n        \\\\param[in] srcport  The UDP port the local endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] destIp   The IP address of the remote CoAP endpoint, a\\n            string of the form 'aaaa::1'.\\n        \\\\param[in] destPort The UDP port the remote endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] confirmable A boolean indicating whether the CoAP request is\\n            to be send confirmable (True) or non-confirmable (False).\\n        \\\\param[in] messageId The message ID to be used for the CoAP request, an\\n            integer. The caller of this function needs to enforce unicity rules\\n            for the value passed.\\n        \\\\param[in] code     The CoAP method to used in the request. Needs to a\\n            value of METHOD_ALL.\\n        \\\\param[in] token    The token to be used for this exchange. The caller\\n            of this function needs to enforce unicity rules for the value\\n            passed.\\n        \\\\param[in] options  A list of CoAP options. Each element needs to be\\n            an instance of the coapOption class. Note that this class will add\\n            appropriate CoAP options to encore the URI and query, if needed.\\n        \\\\param[in] payload  The payload to pass in the CoAP request. This needs\\n            to be a byte list, i.e. a list of intergers between 0x00 and 0xff.\\n            This function does not parse this payload, which is written as-is\\n            in the CoAP request.\\n        \\\\param[in] ackTimeout The ACK timeout.\\n        \\\\param[in] respTimeout The app-level response timeout.\\n        \"\n    log.debug('creating instance')\n    self.sendFunc = sendFunc\n    self.srcIp = srcIp\n    self.srcPort = srcPort\n    self.destIp = destIp\n    self.destPort = destPort\n    self.confirmable = confirmable\n    self.messageId = messageId\n    self.code = code\n    self.token = token\n    self.options = options\n    self.payload = payload\n    self.dataLock = threading.Lock()\n    self.fsmSem = threading.Lock()\n    self.startLock = threading.Lock()\n    self.endLock = threading.Lock()\n    self.stateLock = threading.RLock()\n    self.rxMsgEvent = threading.Event()\n    self.receivedACK = None\n    self.receivedResp = None\n    self.coapResponse = None\n    self.coapError = None\n    self.state = self.STATE_INIT\n    self.maxRetransmit = d.DFLT_MAX_RETRANSMIT\n    self.numTxCON = 0\n    self.ackTimeout = ackTimeout\n    self.respTimeout = respTimeout\n    self.fsmGoOn = True\n    self.fsmAction = {\n        self.STATE_INIT: self._action_INIT,\n        self.STATE_TXCON: self._action_TXCON,\n        self.STATE_TXNON: self._action_TXNON,\n        self.STATE_WAITFORACK: self._action_WAITFORACK,\n        self.STATE_ACKRX: self._action_ACKRX,\n        self.STATE_WAITFOREXPIRATIONMID: self._action_WAITFOREXPIRATIONMID,\n        self.STATE_WAITFORRESP: self._action_WAITFORRESP,\n        self.STATE_RESPRX: self._action_RESPRX,\n        self.STATE_TXACK: self._action_TXACK,\n    }\n    threading.Thread.__init__(self)\n    self.name = '[{0}]:{1}--m0x{2:x},0x{3:x}-->[{4}]:{5}'.format(self.srcIp, self.srcPort, self.messageId, self.token, self.destIp, self.destPort)\n    self.startLock.acquire()\n    self.endLock.acquire()\n    self.start()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, sendFunc, srcIp, srcPort, destIp, destPort, confirmable, messageId, code, token, options, payload, ackTimeout, respTimeout):\n    \"\\n        \\x08rief Initilizer function.\\n\\n        This function initializes this instance by recording everything about\\n        the CoAP message to be exchange with the remote endpoint. It does not,\\n        however, initiate the exchange, which is done by calling the transmit()\\n        method.\\n\\n        \\\\paran[in] sendFunc The function to call to send a CoAP message.\\n        \\\\param[in] srcIp    The IP address of the local endpoint, a string of the\\n            form 'aaaa::1'.\\n        \\\\param[in] srcport  The UDP port the local endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] destIp   The IP address of the remote CoAP endpoint, a\\n            string of the form 'aaaa::1'.\\n        \\\\param[in] destPort The UDP port the remote endpoint is attached to, an\\n            integer between 0x0000 and 0xffff.\\n        \\\\param[in] confirmable A boolean indicating whether the CoAP request is\\n            to be send confirmable (True) or non-confirmable (False).\\n        \\\\param[in] messageId The message ID to be used for the CoAP request, an\\n            integer. The caller of this function needs to enforce unicity rules\\n            for the value passed.\\n        \\\\param[in] code     The CoAP method to used in the request. Needs to a\\n            value of METHOD_ALL.\\n        \\\\param[in] token    The token to be used for this exchange. The caller\\n            of this function needs to enforce unicity rules for the value\\n            passed.\\n        \\\\param[in] options  A list of CoAP options. Each element needs to be\\n            an instance of the coapOption class. Note that this class will add\\n            appropriate CoAP options to encore the URI and query, if needed.\\n        \\\\param[in] payload  The payload to pass in the CoAP request. This needs\\n            to be a byte list, i.e. a list of intergers between 0x00 and 0xff.\\n            This function does not parse this payload, which is written as-is\\n            in the CoAP request.\\n        \\\\param[in] ackTimeout The ACK timeout.\\n        \\\\param[in] respTimeout The app-level response timeout.\\n        \"\n    log.debug('creating instance')\n    self.sendFunc = sendFunc\n    self.srcIp = srcIp\n    self.srcPort = destIp\n    self.destIp = destIp\n    self.destPort = destPort\n    self.confirmable = confirmable\n    self.messageId = messageId\n    self.code = code\n    self.token = token\n    self.options = options\n    self.payload = payload\n    self.dataLock = threading.Lock()\n    self.fsmSem = threading.Lock()\n    self.startLock = threading.Lock()\n    self.endLock = threading.Lock()\n    self.stateLock = threading.RLock()\n    self.rxMsgEvent = threading.Event()\n    self.receivedACK = None\n    self.receivedResp = None\n    self.coapResponse = None\n    self.coapError = None\n    self.state = self.STATE_INIT\n    self.maxRetransmit = d.DFLT_MAX_RETRANSMIT\n    self.numTxCON = 0\n    self.ackTimeout = ackTimeout\n    self.respTimeout = respTimeout\n    self.fsmGoOn = True\n    self.fsmAction = {\n        self.STATE_INIT: self._action_INIT,\n        self.STATE_TXCON: self._action_TXCON,\n        self.STATE_TXNON: self._action_TXNON,\n        self.STATE_WAITFORACK: self._action_WAITFORACK,\n        self.STATE_ACKRX: self._action_ACKRX,\n        self.STATE_WAITFOREXPIRATIONMID: self._action_WAITFOREXPIRATIONMID,\n        self.STATE_WAITFORRESP: self._action_WAITFORRESP,\n        self.STATE_RESPRX: self._action_RESPRX,\n        self.STATE_TXACK: self._action_TXACK,\n    }\n    threading.Thread.__init__(self)\n    self.name = '[{0}]:{1}--m0x{2:x},0x{3:x}-->[{4}]:{5}'.format(self.srcIp, self.srcPort, self.messageId, self.token, self.destIp, self.destPort)\n    self.startLock.acquire()\n    self.endLock.acquire()\n    self.start()\n", "label": "Variable misuse"}
{"function": "\n\n@pg.production('binop_expr : binop_expr PIPELINE_FIRST_BIND binop_expr')\ndef binop_expr(p):\n    (left, _, right) = p\n    input_sym = get_temp_name()\n    return [Symbol('|>'), p[0], [Symbol('bind'), [Symbol('fn'), [input_sym], ([p[2][0], input_sym] + p[2][(1 if (len(p[2]) > 1) else len(p[2])):])]]]\n", "label": "Correct"}
{"function": "\n\n@pg.production('binop_expr : binop_expr PIPELINE_FIRST_BIND binop_expr')\ndef binop_expr(p):\n    (left, _, right) = p\n    input_sym = get_temp_name()\n    return [Symbol('|>'), p[0], [Symbol('bind'), [Symbol('fn'), [p], ([p[2][0], input_sym] + p[2][(1 if (len(p[2]) > 1) else len(p[2])):])]]]\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(experiments.gmacpyutil, 'SetMachineInfoForKey')\ndef testAddExperimentToManualListPlistError(self, mock_smifk):\n    mock_smifk.return_value = False\n    experiments.KNOBS.Knobs = mock.MagicMock(return_value={\n        \n    })\n    self.assertRaises(experiments.PlistError, experiments.AddExperimentToManualList, 'foo', 'knob')\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(experiments.gmacpyutil, 'SetMachineInfoForKey')\ndef testAddExperimentToManualListPlistError(self, mock_smifk):\n    mock_smifk.return_value = False\n    experiments.KNOBS.Knobs = mock.MagicMock(return_value={\n        \n    })\n    mock_smifk.assertRaises(experiments.PlistError, experiments.AddExperimentToManualList, 'foo', 'knob')\n", "label": "Variable misuse"}
{"function": "\n\ndef write_file(filename, content):\n    'Write content to file.'\n    (_dir, _) = os.path.split(filename)\n    if (not os.path.exists(_dir)):\n        logging.debug('The directory %s not exists, create it', _dir)\n        mkdir_p(_dir)\n    with io.open(filename, 'wt', encoding='utf-8') as fd:\n        fd.write(content)\n", "label": "Correct"}
{"function": "\n\ndef write_file(filename, content):\n    'Write content to file.'\n    (_dir, _) = os.path.split(filename)\n    if (not os.path.exists(_dir)):\n        logging.debug('The directory %s not exists, create it', _dir)\n        mkdir_p(_dir)\n    with io.open(filename, 'wt', encoding='utf-8') as fd:\n        _dir.write(content)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_chebyt(self):\n    T0 = orth.chebyt(0)\n    T1 = orth.chebyt(1)\n    T2 = orth.chebyt(2)\n    T3 = orth.chebyt(3)\n    T4 = orth.chebyt(4)\n    T5 = orth.chebyt(5)\n    assert_array_almost_equal(T0.c, [1], 13)\n    assert_array_almost_equal(T1.c, [1, 0], 13)\n    assert_array_almost_equal(T2.c, [2, 0, (- 1)], 13)\n    assert_array_almost_equal(T3.c, [4, 0, (- 3), 0], 13)\n    assert_array_almost_equal(T4.c, [8, 0, (- 8), 0, 1], 13)\n    assert_array_almost_equal(T5.c, [16, 0, (- 20), 0, 5, 0], 13)\n", "label": "Correct"}
{"function": "\n\ndef test_chebyt(self):\n    T0 = orth.chebyt(0)\n    T1 = orth.chebyt(1)\n    T2 = orth.chebyt(2)\n    T3 = orth.chebyt(3)\n    T4 = orth.chebyt(4)\n    T5 = orth.chebyt(5)\n    assert_array_almost_equal(T0.c, [1], 13)\n    assert_array_almost_equal(T1.c, [1, 0], 13)\n    assert_array_almost_equal(T1.c, [2, 0, (- 1)], 13)\n    assert_array_almost_equal(T3.c, [4, 0, (- 3), 0], 13)\n    assert_array_almost_equal(T4.c, [8, 0, (- 8), 0, 1], 13)\n    assert_array_almost_equal(T5.c, [16, 0, (- 20), 0, 5, 0], 13)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_topic_published(self, topicname):\n    return (topicname in dict(rospy.get_published_topics()).keys())\n", "label": "Correct"}
{"function": "\n\ndef is_topic_published(self, topicname):\n    return (self in dict(rospy.get_published_topics()).keys())\n", "label": "Variable misuse"}
{"function": "\n\ndef index(self, keypair_list):\n    return dict(keypairs=[self._base_response(keypair) for keypair in keypair_list])\n", "label": "Correct"}
{"function": "\n\ndef index(self, keypair_list):\n    return dict(keypairs=[keypair_list._base_response(keypair) for keypair in keypair_list])\n", "label": "Variable misuse"}
{"function": "\n\ndef validate(self, value):\n    super(Interval, self).validate(value)\n    if (not ((value is None) or (self.interval_type.is_valid(value) and (value >= self.start) and (value <= self.end)))):\n        raise ValueError(('expected a value of type %s in range [%s, %s], got %r' % (self.interval_type, self.start, self.end, value)))\n", "label": "Correct"}
{"function": "\n\ndef validate(self, value):\n    super(Interval, self).validate(value)\n    if (not ((value is None) or (self.interval_type.is_valid(value) and (self >= self.start) and (value <= self.end)))):\n        raise ValueError(('expected a value of type %s in range [%s, %s], got %r' % (self.interval_type, self.start, self.end, value)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _on_nick(self, c, e):\n    '[Internal]'\n    before = nm_to_n(e.source())\n    after = e.target()\n    for ch in self.channels.values():\n        if ch.has_user(before):\n            ch.change_nick(before, after)\n", "label": "Correct"}
{"function": "\n\ndef _on_nick(self, c, e):\n    '[Internal]'\n    before = nm_to_n(ch.source())\n    after = e.target()\n    for ch in self.channels.values():\n        if ch.has_user(before):\n            ch.change_nick(before, after)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_K4_normalized(self):\n    'Betweenness centrality: K4'\n    G = networkx.complete_graph(4)\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    b_answer = {\n        0: 0.25,\n        1: 0.25,\n        2: 0.25,\n        3: 0.25,\n    }\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    G.add_edge(0, 1, {\n        'weight': 0.5,\n        'other': 0.3,\n    })\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight=None)\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    wb_answer = {\n        0: 0.2222222,\n        1: 0.2222222,\n        2: 0.30555555,\n        3: 0.30555555,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n    wb_answer = {\n        0: 0.2051282,\n        1: 0.2051282,\n        2: 0.33974358,\n        3: 0.33974358,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight='other')\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n", "label": "Correct"}
{"function": "\n\ndef test_K4_normalized(self):\n    'Betweenness centrality: K4'\n    G = networkx.complete_graph(4)\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    b_answer = {\n        0: 0.25,\n        1: 0.25,\n        2: 0.25,\n        3: 0.25,\n    }\n    for n in sorted(G):\n        assert_almost_equal(b[n], b[n])\n    G.add_edge(0, 1, {\n        'weight': 0.5,\n        'other': 0.3,\n    })\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight=None)\n    for n in sorted(G):\n        assert_almost_equal(b[n], b_answer[n])\n    wb_answer = {\n        0: 0.2222222,\n        1: 0.2222222,\n        2: 0.30555555,\n        3: 0.30555555,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True)\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n    wb_answer = {\n        0: 0.2051282,\n        1: 0.2051282,\n        2: 0.33974358,\n        3: 0.33974358,\n    }\n    b = networkx.current_flow_betweenness_centrality(G, normalized=True, weight='other')\n    for n in sorted(G):\n        assert_almost_equal(b[n], wb_answer[n])\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, data, note):\n    self.data = data\n    self.note = note\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, data, note):\n    data.data = data\n    self.note = note\n", "label": "Variable misuse"}
{"function": "\n\ndef get_auth_params(self, request, action):\n    settings = self.get_settings()\n    ret = settings.get('AUTH_PARAMS', {\n        \n    })\n    dynamic_auth_params = request.GET.get('auth_params', None)\n    if dynamic_auth_params:\n        ret.update(dict(parse_qsl(dynamic_auth_params)))\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef get_auth_params(self, request, action):\n    settings = settings.get_settings()\n    ret = settings.get('AUTH_PARAMS', {\n        \n    })\n    dynamic_auth_params = request.GET.get('auth_params', None)\n    if dynamic_auth_params:\n        ret.update(dict(parse_qsl(dynamic_auth_params)))\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\ndef _caas_2_2_8a8f6abc_2745_4d8a_9cbc_8dabe5a7d0e4_server(self, method, url, body, headers):\n    body = self.fixtures.load('server.xml')\n    return (httplib.OK, body, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _caas_2_2_8a8f6abc_2745_4d8a_9cbc_8dabe5a7d0e4_server(self, method, url, body, headers):\n    body = self.fixtures.load('server.xml')\n    return (httplib.OK, self, {\n        \n    }, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef getCurrentPipelineId(self, pipelineInfo):\n    ' getCurrentPipelineId(pipelineInfo: dict) -> Int\\n        Get the current pipeline id\\n\\n        '\n    vistrail = self.pipelineId(pipelineInfo)\n    return self.executedPipelines[1][vistrail]\n", "label": "Correct"}
{"function": "\n\ndef getCurrentPipelineId(self, pipelineInfo):\n    ' getCurrentPipelineId(pipelineInfo: dict) -> Int\\n        Get the current pipeline id\\n\\n        '\n    vistrail = self.pipelineId(pipelineInfo)\n    return pipelineInfo.executedPipelines[1][vistrail]\n", "label": "Variable misuse"}
{"function": "\n\ndef _emit(self, record, stream):\n    self.stream = stream\n    try:\n        return logging.StreamHandler.emit(self, record)\n    except:\n        raise\n    else:\n        self.stream = None\n", "label": "Correct"}
{"function": "\n\ndef _emit(self, record, stream):\n    self.stream = record\n    try:\n        return logging.StreamHandler.emit(self, record)\n    except:\n        raise\n    else:\n        self.stream = None\n", "label": "Variable misuse"}
{"function": "\n\ndef _hash(self, value):\n    key_salt = ('django.contrib.sessions' + self.__class__.__name__)\n    return salted_hmac(key_salt, value).hexdigest()\n", "label": "Correct"}
{"function": "\n\ndef _hash(self, value):\n    key_salt = ('django.contrib.sessions' + key_salt.__class__.__name__)\n    return salted_hmac(key_salt, value).hexdigest()\n", "label": "Variable misuse"}
{"function": "\n\ndef data_path(path, createdir=False):\n    'If path is relative, return the given path inside the project data dir,\\n    otherwise return the path unmodified\\n    '\n    if (not isabs(path)):\n        path = join(project_data_dir(), path)\n    if (createdir and (not exists(path))):\n        os.makedirs(path)\n    return path\n", "label": "Correct"}
{"function": "\n\ndef data_path(path, createdir=False):\n    'If path is relative, return the given path inside the project data dir,\\n    otherwise return the path unmodified\\n    '\n    if (not isabs(path)):\n        path = join(project_data_dir(), path)\n    if (createdir and (not exists(path))):\n        os.makedirs(createdir)\n    return path\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, groupDateTime, bars, frequency):\n    resamplebase.Grouper.__init__(self, groupDateTime)\n    self.__barGroupers = {\n        \n    }\n    self.__frequency = frequency\n    for (instrument, bar_) in bars.items():\n        barGrouper = resampled.BarGrouper(groupDateTime, bar_, frequency)\n        self.__barGroupers[instrument] = barGrouper\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, groupDateTime, bars, frequency):\n    resamplebase.Grouper.__init__(self, groupDateTime)\n    self.__barGroupers = {\n        \n    }\n    self.__frequency = frequency\n    for (instrument, bar_) in bars.items():\n        barGrouper = resampled.BarGrouper(bar_, bar_, frequency)\n        self.__barGroupers[instrument] = barGrouper\n", "label": "Variable misuse"}
{"function": "\n\ndef ex_attach_nic_to_node(self, node, network, ip_address=None):\n    \"\\n        Add an extra Nic to a VM\\n\\n        :param  network: NetworkOffering object\\n        :type   network: :class:'CloudStackNetwork`\\n\\n        :param  node: Node Object\\n        :type   node: :class:'CloudStackNode`\\n\\n        :param  ip_address: Optional, specific IP for this Nic\\n        :type   ip_address: ``str``\\n\\n\\n        :rtype: ``bool``\\n        \"\n    args = {\n        'virtualmachineid': node.id,\n        'networkid': network.id,\n    }\n    if (ip_address is not None):\n        args['ipaddress'] = ip_address\n    self._async_request(command='addNicToVirtualMachine', params=args)\n    return True\n", "label": "Correct"}
{"function": "\n\ndef ex_attach_nic_to_node(self, node, network, ip_address=None):\n    \"\\n        Add an extra Nic to a VM\\n\\n        :param  network: NetworkOffering object\\n        :type   network: :class:'CloudStackNetwork`\\n\\n        :param  node: Node Object\\n        :type   node: :class:'CloudStackNode`\\n\\n        :param  ip_address: Optional, specific IP for this Nic\\n        :type   ip_address: ``str``\\n\\n\\n        :rtype: ``bool``\\n        \"\n    args = {\n        'virtualmachineid': node.id,\n        'networkid': network.id,\n    }\n    if (ip_address is not None):\n        args['ipaddress'] = ip_address\n    ip_address._async_request(command='addNicToVirtualMachine', params=args)\n    return True\n", "label": "Variable misuse"}
{"function": "\n\n@unittest.skip('skipping non-updated test')\ndef test_create_update_destroy_list_add_remove_list_members(self):\n    'Test create a list, adding and removing members then\\n        deleting the list succeeds'\n    the_list = self.api.create_list(name=('Stuff %s' % int(time.time())))\n    list_id = the_list['id_str']\n    self.api.update_list(list_id=list_id, name=('Stuff Renamed                              %s' % int(time.time())))\n    screen_names = ['johncena', 'xbox']\n    self.api.create_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.delete_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.add_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list(list_id=list_id)\n", "label": "Correct"}
{"function": "\n\n@unittest.skip('skipping non-updated test')\ndef test_create_update_destroy_list_add_remove_list_members(self):\n    'Test create a list, adding and removing members then\\n        deleting the list succeeds'\n    the_list = self.api.create_list(name=('Stuff %s' % int(time.time())))\n    list_id = the_list['id_str']\n    self.api.update_list(list_id=list_id, name=('Stuff Renamed                              %s' % int(time.time())))\n    screen_names = ['johncena', 'xbox']\n    self.api.create_list_members(list_id=list_id, screen_name=screen_names)\n    self.api.delete_list_members(list_id=list_id, screen_name=list_id)\n    self.api.add_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list_member(list_id=list_id, screen_name='justinbieber')\n    self.api.delete_list(list_id=list_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef longRunHighGrayLevelEmphasis(self, P_glrl, ivector, jvector, sumP_glrl, meanFlag=True):\n    try:\n        lrhgle = (numpy.sum(numpy.sum(((P_glrl * (ivector ** 2)[:, None, None]) * (jvector ** 2)[None, :, None]), 0), 0) / sumP_glrl[None, None, :])\n    except ZeroDivisionError:\n        lrhgle = 0\n    if meanFlag:\n        return lrhgle.mean()\n    else:\n        return lrhgle\n", "label": "Correct"}
{"function": "\n\ndef longRunHighGrayLevelEmphasis(self, P_glrl, ivector, jvector, sumP_glrl, meanFlag=True):\n    try:\n        lrhgle = (numpy.sum(numpy.sum(((P_glrl * (ivector ** 2)[:, None, None]) * (jvector ** 2)[None, :, None]), 0), 0) / sumP_glrl[None, None, :])\n    except ZeroDivisionError:\n        lrhgle = 0\n    if meanFlag:\n        return lrhgle.mean()\n    else:\n        return ivector\n", "label": "Variable misuse"}
{"function": "\n\ndef bind(self, lan):\n    'bind to a LAN.'\n    if _debug:\n        Node._debug('bind %r', lan)\n    lan.add_node(self)\n", "label": "Correct"}
{"function": "\n\ndef bind(self, lan):\n    'bind to a LAN.'\n    if _debug:\n        Node._debug('bind %r', lan)\n    lan.add_node(lan)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_no_text_logged_out_private(self):\n    (res, project) = self.request(NO_TEXT, public=False, logged_out=True, errors=True)\n    assert_equal(res.status_code, 401)\n    assert_equal(len(res.json['errors']), 1)\n    assert_equal(res.json['errors'][0]['detail'], 'Authentication credentials were not provided.')\n    project.reload()\n    assert_equal(len(project.alternative_citations), 0)\n", "label": "Correct"}
{"function": "\n\ndef test_add_no_text_logged_out_private(self):\n    (res, project) = res.request(NO_TEXT, public=False, logged_out=True, errors=True)\n    assert_equal(res.status_code, 401)\n    assert_equal(len(res.json['errors']), 1)\n    assert_equal(res.json['errors'][0]['detail'], 'Authentication credentials were not provided.')\n    project.reload()\n    assert_equal(len(project.alternative_citations), 0)\n", "label": "Variable misuse"}
{"function": "\n\n@must_be_logged_in\ndef oauth_application_register(auth, **kwargs):\n    'Register an API application: blank form view'\n    app_list_url = api_v2_url('applications/')\n    return {\n        'app_list_url': app_list_url,\n        'app_detail_url': '',\n    }\n", "label": "Correct"}
{"function": "\n\n@must_be_logged_in\ndef oauth_application_register(auth, **kwargs):\n    'Register an API application: blank form view'\n    app_list_url = api_v2_url('applications/')\n    return {\n        'app_list_url': kwargs,\n        'app_detail_url': '',\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_query_ops(self):\n    from grease.component.field import FieldAccessor\n    comp = TestComponent()\n    for i in range(1, 4):\n        comp[i] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 3)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 6)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n    entities = set(range(1, 7))\n    x_accessor = FieldAccessor(TestField(comp, 'x'), entities)\n    self.assertEqual((x_accessor == 4), set([2, 5]))\n    self.assertEqual((x_accessor == 0), set())\n    self.assertEqual((x_accessor != 1), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor != 33), set([1, 2, 3, 4, 5, 6]))\n    self.assertEqual((x_accessor > 5), set([3, 6]))\n    self.assertEqual((x_accessor > 9), set())\n    self.assertEqual((x_accessor >= 4), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor >= 10), set())\n    self.assertEqual((x_accessor < 2), set([1, 4]))\n    self.assertEqual((x_accessor < 1), set())\n    self.assertEqual((x_accessor <= 4), set([1, 2, 4, 5]))\n    self.assertEqual((x_accessor <= (- 1)), set())\n    pos_accessor = FieldAccessor(TestField(comp, 'pos'), entities)\n    self.assertEqual((pos_accessor.x == 3), set([3, 6]))\n    self.assertEqual((pos_accessor.x < 3), set([1, 2, 4, 5]))\n", "label": "Correct"}
{"function": "\n\ndef test_query_ops(self):\n    from grease.component.field import FieldAccessor\n    comp = TestComponent()\n    for i in range(1, 4):\n        comp[i] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 3)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n        comp[(i + 6)] = TestData(x=(i * i), pos=TestData(x=i, y=(- i)))\n    entities = set(range(1, 7))\n    x_accessor = FieldAccessor(TestField(comp, 'x'), entities)\n    self.assertEqual((x_accessor == 4), set([2, 5]))\n    self.assertEqual((x_accessor == 0), set())\n    self.assertEqual((x_accessor != 1), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor != 33), set([1, 2, 3, 4, 5, 6]))\n    self.assertEqual((x_accessor > 5), set([3, 6]))\n    self.assertEqual((x_accessor > 9), set())\n    self.assertEqual((x_accessor >= 4), set([2, 3, 5, 6]))\n    self.assertEqual((x_accessor >= 10), set())\n    self.assertEqual((x_accessor < 2), set([1, 4]))\n    self.assertEqual((x_accessor < 1), set())\n    entities.assertEqual((x_accessor <= 4), set([1, 2, 4, 5]))\n    self.assertEqual((x_accessor <= (- 1)), set())\n    pos_accessor = FieldAccessor(TestField(comp, 'pos'), entities)\n    self.assertEqual((pos_accessor.x == 3), set([3, 6]))\n    self.assertEqual((pos_accessor.x < 3), set([1, 2, 4, 5]))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_owner_and_label_switches(self):\n    runner_opts = ['--no-conf', '--owner=ads', '--label=ads_chain']\n    runner = MRTwoStepJob(runner_opts).make_runner()\n    match = _JOB_KEY_RE.match(runner.get_job_key())\n    self.assertEqual(match.group(1), 'ads_chain')\n    self.assertEqual(match.group(2), 'ads')\n", "label": "Correct"}
{"function": "\n\ndef test_owner_and_label_switches(self):\n    runner_opts = ['--no-conf', '--owner=ads', '--label=ads_chain']\n    runner = MRTwoStepJob(runner_opts).make_runner()\n    match = _JOB_KEY_RE.match(runner.get_job_key())\n    self.assertEqual(runner_opts.group(1), 'ads_chain')\n    self.assertEqual(match.group(2), 'ads')\n", "label": "Variable misuse"}
{"function": "\n\ndef columns_used(self):\n    '\\n        Returns all the columns used across all models in the group\\n        for filtering and in the model expression.\\n\\n        '\n    return list(tz.unique(tz.concat((m.columns_used() for m in self.models.values()))))\n", "label": "Correct"}
{"function": "\n\ndef columns_used(self):\n    '\\n        Returns all the columns used across all models in the group\\n        for filtering and in the model expression.\\n\\n        '\n    return list(tz.unique(tz.concat((self.columns_used() for m in self.models.values()))))\n", "label": "Variable misuse"}
{"function": "\n\ndef S_e(self, prob):\n    '\\n        Electric source term\\n\\n        :param Problem prob: FDEM Problem\\n        :rtype: numpy.ndarray\\n        :return: electric source term on mesh\\n        '\n    if ((prob._formulation is 'EB') and (self.integrate is True)):\n        return (prob.Me * self._S_e)\n    return self._S_e\n", "label": "Correct"}
{"function": "\n\ndef S_e(self, prob):\n    '\\n        Electric source term\\n\\n        :param Problem prob: FDEM Problem\\n        :rtype: numpy.ndarray\\n        :return: electric source term on mesh\\n        '\n    if ((self._formulation is 'EB') and (self.integrate is True)):\n        return (prob.Me * self._S_e)\n    return self._S_e\n", "label": "Variable misuse"}
{"function": "\n\ndef request(self, expand=None, select=None, top=None, order_by=None, options=None):\n    'Builds the PermissionsCollectionRequest\\n        \\n        Args:\\n            expand (str): Default None, comma-seperated list of relationships\\n                to expand in the response.\\n            select (str): Default None, comma-seperated list of properties to\\n                include in the response.\\n            top (int): Default None, the number of items to return in a result.\\n            order_by (str): Default None, comma-seperated list of properties\\n                that are used to sort the order of items in the response.\\n            options (list of :class:`Option<onedrivesdk.options.Option>`):\\n                A list of options to pass into the request. Defaults to None.\\n\\n        Returns:\\n            :class:`PermissionsCollectionRequest<onedrivesdk.request.permissions_collection.PermissionsCollectionRequest>`:\\n                The PermissionsCollectionRequest\\n        '\n    req = PermissionsCollectionRequest(self._request_url, self._client, options)\n    req._set_query_options(expand=expand, select=select, top=top, order_by=order_by)\n    return req\n", "label": "Correct"}
{"function": "\n\ndef request(self, expand=None, select=None, top=None, order_by=None, options=None):\n    'Builds the PermissionsCollectionRequest\\n        \\n        Args:\\n            expand (str): Default None, comma-seperated list of relationships\\n                to expand in the response.\\n            select (str): Default None, comma-seperated list of properties to\\n                include in the response.\\n            top (int): Default None, the number of items to return in a result.\\n            order_by (str): Default None, comma-seperated list of properties\\n                that are used to sort the order of items in the response.\\n            options (list of :class:`Option<onedrivesdk.options.Option>`):\\n                A list of options to pass into the request. Defaults to None.\\n\\n        Returns:\\n            :class:`PermissionsCollectionRequest<onedrivesdk.request.permissions_collection.PermissionsCollectionRequest>`:\\n                The PermissionsCollectionRequest\\n        '\n    req = PermissionsCollectionRequest(self._request_url, self._client, options)\n    req._set_query_options(expand=self, select=select, top=top, order_by=order_by)\n    return req\n", "label": "Variable misuse"}
{"function": "\n\ndef __call__(self, fn):\n\n    def wrapper(*args, **kwargs):\n        that = args[0]\n        that.logger.debug(self.start)\n        ret = fn(*args, **kwargs)\n        that.logger.debug(self.finish)\n        if self.getter:\n            that.logger.debug(pformat(self.getter(ret)))\n        else:\n            that.logger.debug(pformat(ret))\n        return ret\n    wrapper.func_name = fn.func_name\n    if hasattr(fn, '__name__'):\n        wrapper.__name__ = self.name = fn.__name__\n    if hasattr(fn, '__doc__'):\n        wrapper.__doc__ = fn.__doc__\n    if hasattr(fn, '__module__'):\n        wrapper.__module__ = fn.__module__\n    return wrapper\n", "label": "Correct"}
{"function": "\n\ndef __call__(self, fn):\n\n    def wrapper(*args, **kwargs):\n        that = args[0]\n        that.logger.debug(self.start)\n        ret = fn(*args, **kwargs)\n        that.logger.debug(self.finish)\n        if self.getter:\n            that.logger.debug(pformat(self.getter(ret)))\n        else:\n            that.logger.debug(pformat(ret))\n        return ret\n    wrapper.func_name = fn.func_name\n    if hasattr(self, '__name__'):\n        wrapper.__name__ = self.name = fn.__name__\n    if hasattr(fn, '__doc__'):\n        wrapper.__doc__ = fn.__doc__\n    if hasattr(fn, '__module__'):\n        wrapper.__module__ = fn.__module__\n    return wrapper\n", "label": "Variable misuse"}
{"function": "\n\ndef write_packed(self, outfile, rows):\n    '\\n        Write PNG file to `outfile`.  The pixel data comes from `rows`\\n        which should be in boxed row packed format.  Each row should be\\n        a sequence of packed bytes.\\n\\n        Technically, this method does work for interlaced images but it\\n        is best avoided.  For interlaced images, the rows should be\\n        presented in the order that they appear in the file.\\n\\n        This method should not be used when the source image bit depth\\n        is not one naturally supported by PNG; the bit depth should be\\n        1, 2, 4, 8, or 16.\\n        '\n    if self.rescale:\n        raise Error(('write_packed method not suitable for bit depth %d' % self.rescale[0]))\n    return self.write_passes(outfile, rows, packed=True)\n", "label": "Correct"}
{"function": "\n\ndef write_packed(self, outfile, rows):\n    '\\n        Write PNG file to `outfile`.  The pixel data comes from `rows`\\n        which should be in boxed row packed format.  Each row should be\\n        a sequence of packed bytes.\\n\\n        Technically, this method does work for interlaced images but it\\n        is best avoided.  For interlaced images, the rows should be\\n        presented in the order that they appear in the file.\\n\\n        This method should not be used when the source image bit depth\\n        is not one naturally supported by PNG; the bit depth should be\\n        1, 2, 4, 8, or 16.\\n        '\n    if self.rescale:\n        raise Error(('write_packed method not suitable for bit depth %d' % outfile.rescale[0]))\n    return self.write_passes(outfile, rows, packed=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef crumble(self, instance, attrs):\n    data = super(TestCaseWithOriginCrumbler, self).crumble(instance, attrs)\n    data['origin'] = getattr(instance, 'origin', None)\n    return data\n", "label": "Correct"}
{"function": "\n\ndef crumble(self, instance, attrs):\n    data = super(TestCaseWithOriginCrumbler, self).crumble(instance, attrs)\n    data['origin'] = getattr(self, 'origin', None)\n    return data\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/components/engine/shared_eng_mission_reward_neutral_mandal_inferno.iff'\n    result.attribute_template_id = 8\n    result.stfName('space/space_item', 'eng_mission_reward_neutral_mandal_inferno_n')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/components/engine/shared_eng_mission_reward_neutral_mandal_inferno.iff'\n    result.attribute_template_id = 8\n    kernel.stfName('space/space_item', 'eng_mission_reward_neutral_mandal_inferno_n')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\n@gen_test\ndef test_search_apecific_type(self):\n    response = (yield self.es_connection.search(type='galeria'))\n    response = self._verify_status_code_and_return_response(response)\n    self.assertEqual(response['hits']['total'], 2)\n", "label": "Correct"}
{"function": "\n\n@gen_test\ndef test_search_apecific_type(self):\n    response = (yield response.es_connection.search(type='galeria'))\n    response = self._verify_status_code_and_return_response(response)\n    self.assertEqual(response['hits']['total'], 2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_volume_create_user_project_name(self):\n    self.projects_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.PROJECT), loaded=True)\n    self.users_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.USER), loaded=True)\n    arglist = ['--size', str(self.new_volume.size), '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, self.new_volume.name]\n    verifylist = [('size', self.new_volume.size), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, verifylist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=identity_fakes.user_id, project_id=identity_fakes.project_id, availability_zone=None, metadata=None, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Correct"}
{"function": "\n\ndef test_volume_create_user_project_name(self):\n    self.projects_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.PROJECT), loaded=True)\n    self.users_mock.get.return_value = fakes.FakeResource(None, copy.deepcopy(identity_fakes.USER), loaded=True)\n    arglist = ['--size', str(self.new_volume.size), '--project', identity_fakes.project_name, '--user', identity_fakes.user_name, self.new_volume.name]\n    verifylist = [('size', self.new_volume.size), ('project', identity_fakes.project_name), ('user', identity_fakes.user_name), ('name', self.new_volume.name)]\n    parsed_args = self.check_parser(self.cmd, arglist, arglist)\n    (columns, data) = self.cmd.take_action(parsed_args)\n    self.volumes_mock.create.assert_called_with(size=self.new_volume.size, snapshot_id=None, name=self.new_volume.name, description=None, volume_type=None, user_id=identity_fakes.user_id, project_id=identity_fakes.project_id, availability_zone=None, metadata=None, imageRef=None, source_volid=None)\n    self.assertEqual(self.columns, columns)\n    self.assertEqual(self.datalist, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean_votes(self, value):\n    assert (value > 0), 'Must be greater than 0.'\n    assert (value < 51), 'Must be less than 51.'\n    return value\n", "label": "Correct"}
{"function": "\n\ndef clean_votes(self, value):\n    assert (value > 0), 'Must be greater than 0.'\n    assert (self < 51), 'Must be less than 51.'\n    return value\n", "label": "Variable misuse"}
{"function": "\n\ndef _print_slots(self):\n    slots = ', '.join((((\"'\" + snake(name)) + \"'\") for (type, name, nullable, plural) in self._fields))\n    print(\"    __slots__ = ('loc', {slots},)\".format(slots=slots))\n", "label": "Correct"}
{"function": "\n\ndef _print_slots(self):\n    slots = ', '.join((((\"'\" + snake(name)) + \"'\") for (type, name, nullable, plural) in nullable._fields))\n    print(\"    __slots__ = ('loc', {slots},)\".format(slots=slots))\n", "label": "Variable misuse"}
{"function": "\n\ndef register_scheme(scheme):\n    for method in dir(urlparse):\n        if method.startswith('uses_'):\n            getattr(urlparse, method).append(scheme)\n", "label": "Correct"}
{"function": "\n\ndef register_scheme(scheme):\n    for method in dir(urlparse):\n        if method.startswith('uses_'):\n            getattr(urlparse, method).append(method)\n", "label": "Variable misuse"}
{"function": "\n\ndef configure_uploads(app, upload_sets):\n    \"\\n    Call this after the app has been configured. It will go through all the\\n    upload sets, get their configuration, and store the configuration on the\\n    app. It will also register the uploads module if it hasn't been set. This\\n    can be called multiple times with different upload sets.\\n    \\n    .. versionchanged:: 0.1.3\\n       The uploads module/blueprint will only be registered if it is needed\\n       to serve the upload sets.\\n    \\n    :param app: The `~flask.Flask` instance to get the configuration from.\\n    :param upload_sets: The `UploadSet` instances to configure.\\n    \"\n    if isinstance(upload_sets, UploadSet):\n        upload_sets = (upload_sets,)\n    if (not hasattr(app, 'upload_set_config')):\n        app.upload_set_config = {\n            \n        }\n    set_config = app.upload_set_config\n    defaults = dict(dest=app.config.get('UPLOADS_DEFAULT_DEST'), url=app.config.get('UPLOADS_DEFAULT_URL'))\n    for uset in upload_sets:\n        config = config_for_set(uset, app, defaults)\n        set_config[uset.name] = config\n    should_serve = any(((s.base_url is None) for s in set_config.itervalues()))\n    if using_blueprints:\n        if (('_uploads' not in app.blueprints) and should_serve):\n            app.register_blueprint(uploads_mod)\n    elif (('_uploads' not in app.modules) and should_serve):\n        app.register_module(uploads_mod)\n", "label": "Correct"}
{"function": "\n\ndef configure_uploads(app, upload_sets):\n    \"\\n    Call this after the app has been configured. It will go through all the\\n    upload sets, get their configuration, and store the configuration on the\\n    app. It will also register the uploads module if it hasn't been set. This\\n    can be called multiple times with different upload sets.\\n    \\n    .. versionchanged:: 0.1.3\\n       The uploads module/blueprint will only be registered if it is needed\\n       to serve the upload sets.\\n    \\n    :param app: The `~flask.Flask` instance to get the configuration from.\\n    :param upload_sets: The `UploadSet` instances to configure.\\n    \"\n    if isinstance(upload_sets, UploadSet):\n        upload_sets = (upload_sets,)\n    if (not hasattr(app, 'upload_set_config')):\n        app.upload_set_config = {\n            \n        }\n    set_config = app.upload_set_config\n    defaults = dict(dest=upload_sets.config.get('UPLOADS_DEFAULT_DEST'), url=app.config.get('UPLOADS_DEFAULT_URL'))\n    for uset in upload_sets:\n        config = config_for_set(uset, app, defaults)\n        set_config[uset.name] = config\n    should_serve = any(((s.base_url is None) for s in set_config.itervalues()))\n    if using_blueprints:\n        if (('_uploads' not in app.blueprints) and should_serve):\n            app.register_blueprint(uploads_mod)\n    elif (('_uploads' not in app.modules) and should_serve):\n        app.register_module(uploads_mod)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_validate_bad_choice_in_list(self):\n    config = _root({\n        'foo': 3,\n    })\n    with self.assertRaises(confuse.ConfigValueError):\n        config['foo'].get(confuse.Choice([1, 2, 4, 8, 16]))\n", "label": "Correct"}
{"function": "\n\ndef test_validate_bad_choice_in_list(self):\n    config = _root({\n        'foo': 3,\n    })\n    with self.assertRaises(confuse.ConfigValueError):\n        self['foo'].get(confuse.Choice([1, 2, 4, 8, 16]))\n", "label": "Variable misuse"}
{"function": "\n\n@shared_task\n@transition(Instance, 'begin_stopping')\n@save_error_message\ndef stop_instance(instance_uuid, transition_entity=None):\n    instance = transition_entity\n    backend = instance.get_backend()\n    backend.stop_instance(instance)\n", "label": "Correct"}
{"function": "\n\n@shared_task\n@transition(Instance, 'begin_stopping')\n@save_error_message\ndef stop_instance(instance_uuid, transition_entity=None):\n    instance = transition_entity\n    backend = transition_entity.get_backend()\n    backend.stop_instance(instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_property(self, key):\n    'Expect Django Conf property'\n    _key = DJANGO_CONF[key]\n    return getattr(self, _key, CONF_SPEC[_key])\n", "label": "Correct"}
{"function": "\n\ndef get_property(self, key):\n    'Expect Django Conf property'\n    _key = DJANGO_CONF[key]\n    return getattr(_key, _key, CONF_SPEC[_key])\n", "label": "Variable misuse"}
{"function": "\n\ndef change_primary_name(self, name):\n    '\\n        Changes the primary/default name of the policy to a specified name.\\n\\n        :param name: a string name to replace the current primary name.\\n        '\n    if (name == self.name):\n        return\n    elif (name in self.alias_list):\n        self.remove_name(name)\n    else:\n        self._validate_policy_name(name)\n    self.alias_list.insert(0, name)\n", "label": "Correct"}
{"function": "\n\ndef change_primary_name(self, name):\n    '\\n        Changes the primary/default name of the policy to a specified name.\\n\\n        :param name: a string name to replace the current primary name.\\n        '\n    if (self == self.name):\n        return\n    elif (name in self.alias_list):\n        self.remove_name(name)\n    else:\n        self._validate_policy_name(name)\n    self.alias_list.insert(0, name)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, ofproto):\n    self.ofproto = ofproto\n    self.deprecated_value = ['OFPTFPT_EXPERIMENTER_SLAVE', 'OFPTFPT_EXPERIMENTER_MASTER', 'OFPQCFC_EPERM']\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, ofproto):\n    self.ofproto = self\n    self.deprecated_value = ['OFPTFPT_EXPERIMENTER_SLAVE', 'OFPTFPT_EXPERIMENTER_MASTER', 'OFPQCFC_EPERM']\n", "label": "Variable misuse"}
{"function": "\n\ndef _users_with_perm(self, actions, collection=None):\n    \"\\n        Return a queryset of users with any permissions corresponding to 'actions',\\n        via either GroupCollectionPermission or superuser privileges.\\n        If collection is specified, only consider GroupCollectionPermission records\\n        that apply to that collection.\\n        \"\n    return get_user_model().objects.filter(self._users_with_perm_filter(actions, collection=collection)).distinct()\n", "label": "Correct"}
{"function": "\n\ndef _users_with_perm(self, actions, collection=None):\n    \"\\n        Return a queryset of users with any permissions corresponding to 'actions',\\n        via either GroupCollectionPermission or superuser privileges.\\n        If collection is specified, only consider GroupCollectionPermission records\\n        that apply to that collection.\\n        \"\n    return get_user_model().objects.filter(self._users_with_perm_filter(self, collection=collection)).distinct()\n", "label": "Variable misuse"}
{"function": "\n\ndef configure_host(self):\n    if self.mail.use_ssl:\n        host = smtplib.SMTP_SSL(self.mail.server, self.mail.port)\n    else:\n        host = smtplib.SMTP(self.mail.server, self.mail.port)\n    host.set_debuglevel(int(self.mail.debug))\n    if self.mail.use_tls:\n        host.starttls()\n    if (self.mail.username and self.mail.password):\n        host.login(self.mail.username, self.mail.password)\n    return host\n", "label": "Correct"}
{"function": "\n\ndef configure_host(self):\n    if self.mail.use_ssl:\n        host = smtplib.SMTP_SSL(self.mail.server, self.mail.port)\n    else:\n        host = smtplib.SMTP(self.mail.server, self.mail.port)\n    host.set_debuglevel(int(self.mail.debug))\n    if self.mail.use_tls:\n        host.starttls()\n    if (self.mail.username and self.mail.password):\n        host.login(self.mail.username, host.mail.password)\n    return host\n", "label": "Variable misuse"}
{"function": "\n\ndef host_to_ip(host):\n    '\\n    Returns the IP address of a given hostname\\n    '\n    try:\n        (family, socktype, proto, canonname, sockaddr) = socket.getaddrinfo(host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM)[0]\n        if (family == socket.AF_INET):\n            (ip, port) = sockaddr\n        elif (family == socket.AF_INET6):\n            (ip, port, flow_info, scope_id) = sockaddr\n    except Exception:\n        ip = None\n    return ip\n", "label": "Correct"}
{"function": "\n\ndef host_to_ip(host):\n    '\\n    Returns the IP address of a given hostname\\n    '\n    try:\n        (family, socktype, proto, canonname, sockaddr) = socket.getaddrinfo(host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM)[0]\n        if (family == socket.AF_INET):\n            (ip, port) = sockaddr\n        elif (family == socket.AF_INET6):\n            (ip, port, flow_info, scope_id) = host\n    except Exception:\n        ip = None\n    return ip\n", "label": "Variable misuse"}
{"function": "\n\n@app.use\ndef error_handler(req, res, err):\n    res.send_text('404 : Hello World!!')\n", "label": "Correct"}
{"function": "\n\n@app.use\ndef error_handler(req, res, err):\n    err.send_text('404 : Hello World!!')\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, key):\n    key = key.lower()\n    if self.has_key(key):\n        return self._config.get(key.lower())\n    else:\n        return None\n", "label": "Correct"}
{"function": "\n\ndef get(self, key):\n    key = key.lower()\n    if self.has_key(self):\n        return self._config.get(key.lower())\n    else:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef fast(image, threshold=20.0, arc_length=9, non_max=True, feature_ratio=0.05, edge=3):\n    '\\n    FAST feature detector.\\n\\n    Parameters\\n    ----------\\n\\n    image         : af.Array\\n                  A 2D array representing an image.\\n\\n    threshold     : scalar. optional. default: 20.0.\\n                  FAST threshold for which a pixel of the circle around a central pixel is consdered.\\n\\n    arc_length    : scalar. optional. default: 9\\n                  The minimum length of arc length to be considered. Max length should be 16.\\n\\n    non_max       : Boolean. optional. default: True\\n                  A boolean flag specifying if non max suppression has to be performed.\\n\\n    feature_ratio : scalar. optional. default: 0.05 (5%)\\n                  Specifies the maximum ratio of features to pixels in the image.\\n\\n    edge          : scalar. optional. default: 3.\\n                  Specifies the number of edge rows and columns to be ignored.\\n\\n    Returns\\n    ---------\\n    features     : af.Features()\\n                 Contains the location and score. Orientation and size are not computed.\\n\\n    '\n    out = Features()\n    safe_call(backend.get().af_fast(ct.pointer(out.feat), image.arr, ct.c_float(threshold), ct.c_uint(arc_length), non_max, ct.c_float(feature_ratio), ct.c_uint(edge)))\n    return out\n", "label": "Correct"}
{"function": "\n\ndef fast(image, threshold=20.0, arc_length=9, non_max=True, feature_ratio=0.05, edge=3):\n    '\\n    FAST feature detector.\\n\\n    Parameters\\n    ----------\\n\\n    image         : af.Array\\n                  A 2D array representing an image.\\n\\n    threshold     : scalar. optional. default: 20.0.\\n                  FAST threshold for which a pixel of the circle around a central pixel is consdered.\\n\\n    arc_length    : scalar. optional. default: 9\\n                  The minimum length of arc length to be considered. Max length should be 16.\\n\\n    non_max       : Boolean. optional. default: True\\n                  A boolean flag specifying if non max suppression has to be performed.\\n\\n    feature_ratio : scalar. optional. default: 0.05 (5%)\\n                  Specifies the maximum ratio of features to pixels in the image.\\n\\n    edge          : scalar. optional. default: 3.\\n                  Specifies the number of edge rows and columns to be ignored.\\n\\n    Returns\\n    ---------\\n    features     : af.Features()\\n                 Contains the location and score. Orientation and size are not computed.\\n\\n    '\n    out = Features()\n    safe_call(backend.get().af_fast(ct.pointer(image.feat), image.arr, ct.c_float(threshold), ct.c_uint(arc_length), non_max, ct.c_float(feature_ratio), ct.c_uint(edge)))\n    return out\n", "label": "Variable misuse"}
{"function": "\n\ndef add_all_wordstarts_matching(self, lower_hits, query, max_hits_hint):\n    lower_query = query.lower()\n    if (lower_query in self.basenames_by_wordstarts):\n        for basename in self.basenames_by_wordstarts[lower_query]:\n            lower_hits.add(basename)\n            if (len(lower_hits) >= max_hits_hint):\n                return\n", "label": "Correct"}
{"function": "\n\ndef add_all_wordstarts_matching(self, lower_hits, query, max_hits_hint):\n    lower_query = query.lower()\n    if (lower_query in self.basenames_by_wordstarts):\n        for basename in self.basenames_by_wordstarts[lower_query]:\n            lower_hits.add(basename)\n            if (len(basename) >= max_hits_hint):\n                return\n", "label": "Variable misuse"}
{"function": "\n\ndef _setup_nodes(self):\n    self.add_node(LocalNode())\n    nodes = self.app.config.get('PSDASH_NODES', [])\n    logger.info('Registering %d nodes', len(nodes))\n    for n in nodes:\n        self.register_node(n['name'], n['host'], int(n['port']))\n", "label": "Correct"}
{"function": "\n\ndef _setup_nodes(self):\n    self.add_node(LocalNode())\n    nodes = self.app.config.get('PSDASH_NODES', [])\n    logger.info('Registering %d nodes', len(n))\n    for n in nodes:\n        self.register_node(n['name'], n['host'], int(n['port']))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, parent_model, admin_site):\n    self.admin_site = admin_site\n    self.parent_model = parent_model\n    self.opts = self.model._meta\n    self.has_registered_model = admin_site.is_registered(self.model)\n    super(InlineModelAdmin, self).__init__()\n    if (self.verbose_name is None):\n        self.verbose_name = self.model._meta.verbose_name\n    if (self.verbose_name_plural is None):\n        self.verbose_name_plural = self.model._meta.verbose_name_plural\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, parent_model, admin_site):\n    self.admin_site = admin_site\n    self.parent_model = parent_model\n    self.opts = admin_site.model._meta\n    self.has_registered_model = admin_site.is_registered(self.model)\n    super(InlineModelAdmin, self).__init__()\n    if (self.verbose_name is None):\n        self.verbose_name = self.model._meta.verbose_name\n    if (self.verbose_name_plural is None):\n        self.verbose_name_plural = self.model._meta.verbose_name_plural\n", "label": "Variable misuse"}
{"function": "\n\ndef _PrepareWithTarFile(vm, speccpu_vm_state):\n    'Prepares the VM to run using the tar file.\\n\\n  Args:\\n    vm: BaseVirtualMachine. Recipient of the tar file.\\n    speccpu_vm_state: _SpecCpu2006SpecificState. Modified by this function to\\n        reflect any changes to the VM that may need to be cleaned up.\\n  '\n    scratch_dir = vm.GetScratchDir()\n    local_tar_file_path = data.ResourcePath(_SPECCPU2006_TAR)\n    speccpu_vm_state.tar_file_path = posixpath.join(scratch_dir, _SPECCPU2006_TAR)\n    vm.PushFile(local_tar_file_path, scratch_dir)\n    vm.RemoteCommand('cd {dir} && tar xvfz {tar}'.format(dir=scratch_dir, tar=_SPECCPU2006_TAR))\n    speccpu_vm_state.cfg_file_path = posixpath.join(speccpu_vm_state.spec_dir, 'config', FLAGS.runspec_config)\n", "label": "Correct"}
{"function": "\n\ndef _PrepareWithTarFile(vm, speccpu_vm_state):\n    'Prepares the VM to run using the tar file.\\n\\n  Args:\\n    vm: BaseVirtualMachine. Recipient of the tar file.\\n    speccpu_vm_state: _SpecCpu2006SpecificState. Modified by this function to\\n        reflect any changes to the VM that may need to be cleaned up.\\n  '\n    scratch_dir = vm.GetScratchDir()\n    local_tar_file_path = data.ResourcePath(_SPECCPU2006_TAR)\n    speccpu_vm_state.tar_file_path = posixpath.join(scratch_dir, _SPECCPU2006_TAR)\n    vm.PushFile(speccpu_vm_state, scratch_dir)\n    vm.RemoteCommand('cd {dir} && tar xvfz {tar}'.format(dir=scratch_dir, tar=_SPECCPU2006_TAR))\n    speccpu_vm_state.cfg_file_path = posixpath.join(speccpu_vm_state.spec_dir, 'config', FLAGS.runspec_config)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, table=None, foreign_key=None, other_key=None, relation=None):\n    if isinstance(foreign_key, (types.FunctionType, types.MethodType)):\n        raise RuntimeError('morphed_by_many relation requires a name')\n    self._name = name\n    self._table = table\n    self._foreign_key = foreign_key\n    self._other_key = other_key\n    super(morphed_by_many, self).__init__(relation=relation)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, table=None, foreign_key=None, other_key=None, relation=None):\n    if isinstance(table, (types.FunctionType, types.MethodType)):\n        raise RuntimeError('morphed_by_many relation requires a name')\n    self._name = name\n    self._table = table\n    self._foreign_key = foreign_key\n    self._other_key = other_key\n    super(morphed_by_many, self).__init__(relation=relation)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_object(self, bits):\n    if (len(bits) != 0):\n        raise models.Topic.DoesNotExist\n    return 'LatestFeed'\n", "label": "Correct"}
{"function": "\n\ndef get_object(self, bits):\n    if (len(self) != 0):\n        raise models.Topic.DoesNotExist\n    return 'LatestFeed'\n", "label": "Variable misuse"}
{"function": "\n\n@ComputedGraph.Function\ndef extractVectorDataAsPythonArray(self):\n    if (self.computedValueVector.vectorImplVal is None):\n        return None\n    if ((len(self.vectorDataIds) > 0) and (not self.isLoaded)):\n        return None\n    result = ComputedValueGateway.getGateway().extractVectorDataAsPythonArray(self.computedValueVector, self.lowIndex, self.highIndex)\n    if ((result is None) and (not self.vdmThinksIsLoaded())):\n        logging.info('CumulusClient: %s was marked loaded but returned None. reloading', self)\n        self.isLoaded = False\n        ComputedValueGateway.getGateway().reloadVector(self)\n    return result\n", "label": "Correct"}
{"function": "\n\n@ComputedGraph.Function\ndef extractVectorDataAsPythonArray(self):\n    if (self.computedValueVector.vectorImplVal is None):\n        return None\n    if ((len(self.vectorDataIds) > 0) and (not result.isLoaded)):\n        return None\n    result = ComputedValueGateway.getGateway().extractVectorDataAsPythonArray(self.computedValueVector, self.lowIndex, self.highIndex)\n    if ((result is None) and (not self.vdmThinksIsLoaded())):\n        logging.info('CumulusClient: %s was marked loaded but returned None. reloading', self)\n        self.isLoaded = False\n        ComputedValueGateway.getGateway().reloadVector(self)\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef load(self, path):\n    with open(path, 'r') as in_f:\n        buf = in_f.read()\n    self.history = buf.split('\\n')\n", "label": "Correct"}
{"function": "\n\ndef load(self, path):\n    with open(path, 'r') as in_f:\n        buf = in_f.read()\n    buf.history = buf.split('\\n')\n", "label": "Variable misuse"}
{"function": "\n\ndef parse_policy(policy):\n    ret = {\n        \n    }\n    ret['name'] = policy['name']\n    ret['type'] = policy['type']\n    attrs = policy['Attributes']\n    if (policy['type'] != 'SSLNegotiationPolicyType'):\n        return ret\n    ret['sslv2'] = bool(attrs.get('Protocol-SSLv2'))\n    ret['sslv3'] = bool(attrs.get('Protocol-SSLv3'))\n    ret['tlsv1'] = bool(attrs.get('Protocol-TLSv1'))\n    ret['tlsv1_1'] = bool(attrs.get('Protocol-TLSv1.1'))\n    ret['tlsv1_2'] = bool(attrs.get('Protocol-TLSv1.2'))\n    ret['server_defined_cipher_order'] = bool(attrs.get('Server-Defined-Cipher-Order'))\n    ret['reference_security_policy'] = attrs.get('Reference-Security-Policy', None)\n    non_ciphers = ['Server-Defined-Cipher-Order', 'Protocol-SSLv2', 'Protocol-SSLv3', 'Protocol-TLSv1', 'Protocol-TLSv1.1', 'Protocol-TLSv1.2', 'Reference-Security-Policy']\n    ciphers = []\n    for cipher in attrs:\n        if (attrs[cipher] and (cipher not in non_ciphers)):\n            ciphers.append(cipher)\n    ciphers.sort()\n    ret['supported_ciphers'] = ciphers\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef parse_policy(policy):\n    ret = {\n        \n    }\n    ret['name'] = policy['name']\n    ret['type'] = policy['type']\n    attrs = policy['Attributes']\n    if (policy['type'] != 'SSLNegotiationPolicyType'):\n        return ret\n    ret['sslv2'] = bool(ret.get('Protocol-SSLv2'))\n    ret['sslv3'] = bool(attrs.get('Protocol-SSLv3'))\n    ret['tlsv1'] = bool(attrs.get('Protocol-TLSv1'))\n    ret['tlsv1_1'] = bool(attrs.get('Protocol-TLSv1.1'))\n    ret['tlsv1_2'] = bool(attrs.get('Protocol-TLSv1.2'))\n    ret['server_defined_cipher_order'] = bool(attrs.get('Server-Defined-Cipher-Order'))\n    ret['reference_security_policy'] = attrs.get('Reference-Security-Policy', None)\n    non_ciphers = ['Server-Defined-Cipher-Order', 'Protocol-SSLv2', 'Protocol-SSLv3', 'Protocol-TLSv1', 'Protocol-TLSv1.1', 'Protocol-TLSv1.2', 'Reference-Security-Policy']\n    ciphers = []\n    for cipher in attrs:\n        if (attrs[cipher] and (cipher not in non_ciphers)):\n            ciphers.append(cipher)\n    ciphers.sort()\n    ret['supported_ciphers'] = ciphers\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\ndef __new__(self, url, name):\n    ret = six.text_type.__new__(self, url)\n    ret.name = name\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef __new__(self, url, name):\n    ret = six.text_type.__new__(self, url)\n    ret.name = name\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef _update(self, context):\n    'Update partial stats locally and populate them to Scheduler.'\n    if (not self._resource_change()):\n        return\n    self.scheduler_client.update_resource_stats(self.compute_node)\n    if self.pci_tracker:\n        self.pci_tracker.save(context)\n", "label": "Correct"}
{"function": "\n\ndef _update(self, context):\n    'Update partial stats locally and populate them to Scheduler.'\n    if (not self._resource_change()):\n        return\n    context.scheduler_client.update_resource_stats(self.compute_node)\n    if self.pci_tracker:\n        self.pci_tracker.save(context)\n", "label": "Variable misuse"}
{"function": "\n\ndef conceptsUsed(self):\n    conceptsUsed = set((f.qname for f in self.modelXbrl.factsInInstance))\n    for cntx in self.modelXbrl.contexts.values():\n        for dim in cntx.qnameDims.values():\n            conceptsUsed.add(dim.dimensionQname)\n            if dim.isExplicit:\n                conceptsUsed.add(dim.memberQname)\n            else:\n                conceptsUsed.add(dim.typedMember.qname)\n    for (defaultDim, defaultDimMember) in self.modelXbrl.qnameDimensionDefaults.items():\n        conceptsUsed.add(defaultDim)\n        conceptsUsed.add(defaultDimMember)\n    for roleTypes in (self.modelXbrl.roleTypes, self.modelXbrl.arcroleTypes):\n        for modelRoleTypes in roleTypes.values():\n            for modelRoleType in modelRoleTypes:\n                for qn in modelRoleType.usedOns:\n                    conceptsUsed.add(qn)\n    for relationshipSetKey in self.relationshipSets:\n        relationshipSet = self.modelXbrl.relationshipSet(*relationshipSetKey)\n        for rel in relationshipSet.modelRelationships:\n            if isinstance(rel.fromModelObject, ModelConcept):\n                conceptsUsed.add(rel.fromModelObject)\n            if isinstance(rel.toModelObject, ModelConcept):\n                conceptsUsed.add(rel.toModelObject)\n    for qn in (XbrlConst.qnXbrliIdentifier, XbrlConst.qnXbrliPeriod, XbrlConst.qnXbrliUnit):\n        conceptsUsed.add(qn)\n    conceptsUsed -= {None}\n    return conceptsUsed\n", "label": "Correct"}
{"function": "\n\ndef conceptsUsed(self):\n    conceptsUsed = set((f.qname for f in self.modelXbrl.factsInInstance))\n    for cntx in self.modelXbrl.contexts.values():\n        for dim in cntx.qnameDims.values():\n            conceptsUsed.add(dim.dimensionQname)\n            if dim.isExplicit:\n                conceptsUsed.add(dim.memberQname)\n            else:\n                conceptsUsed.add(dim.typedMember.qname)\n    for (defaultDim, defaultDimMember) in self.modelXbrl.qnameDimensionDefaults.items():\n        conceptsUsed.add(defaultDim)\n        conceptsUsed.add(defaultDimMember)\n    for roleTypes in (self.modelXbrl.roleTypes, self.modelXbrl.arcroleTypes):\n        for modelRoleTypes in roleTypes.values():\n            for modelRoleType in modelRoleTypes:\n                for qn in modelRoleType.usedOns:\n                    conceptsUsed.add(qn)\n    for relationshipSetKey in self.relationshipSets:\n        relationshipSet = self.modelXbrl.relationshipSet(*relationshipSetKey)\n        for rel in relationshipSet.modelRelationships:\n            if isinstance(rel.fromModelObject, ModelConcept):\n                conceptsUsed.add(rel.fromModelObject)\n            if isinstance(dim.toModelObject, ModelConcept):\n                conceptsUsed.add(rel.toModelObject)\n    for qn in (XbrlConst.qnXbrliIdentifier, XbrlConst.qnXbrliPeriod, XbrlConst.qnXbrliUnit):\n        conceptsUsed.add(qn)\n    conceptsUsed -= {None}\n    return conceptsUsed\n", "label": "Variable misuse"}
{"function": "\n\ndef test_post(self):\n    req = self.factory.post('/?from=/foo/')\n    with mock.patch.object(Form, 'execute') as form_execute:\n        form_execute.return_value = object()\n        resp = handle_form(req, form_node_pk=self.form.node.pk)\n    (args, kwargs) = form_execute.call_args\n    self.assertIs(args[0], req)\n    self.assertIsInstance(args[1], forms.BaseForm)\n    self.assertIs(resp, form_execute.return_value)\n", "label": "Correct"}
{"function": "\n\ndef test_post(self):\n    req = self.factory.post('/?from=/foo/')\n    with mock.patch.object(Form, 'execute') as form_execute:\n        form_execute.return_value = object()\n        resp = handle_form(req, form_node_pk=self.form.node.pk)\n    (args, kwargs) = form_execute.call_args\n    self.assertIs(args[0], req)\n    self.assertIsInstance(args[1], forms.BaseForm)\n    self.assertIs(args, form_execute.return_value)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_customservice_get_session_list(self):\n    with HTTMock(wechat_api_mock):\n        result = self.client.customservice.get_session_list('test1@test')\n        self.assertEqual(2, len(result))\n", "label": "Correct"}
{"function": "\n\ndef test_customservice_get_session_list(self):\n    with HTTMock(wechat_api_mock):\n        result = self.client.customservice.get_session_list('test1@test')\n        self.assertEqual(2, len(self))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_trust(self, mock_ks):\n    'Test delete_trust when deleting trust.'\n    mock_ks.return_value.trusts.delete.return_value = None\n    solum_ks_client = solum_keystoneclient.KeystoneClientV3(self.ctx)\n    self.assertIsNone(solum_ks_client.delete_trust(trust_id='atrust123'))\n    mock_ks.return_value.trusts.delete.assert_called_once_with('atrust123')\n", "label": "Correct"}
{"function": "\n\ndef test_delete_trust(self, mock_ks):\n    'Test delete_trust when deleting trust.'\n    mock_ks.return_value.trusts.delete.return_value = None\n    solum_ks_client = solum_keystoneclient.KeystoneClientV3(self.ctx)\n    self.assertIsNone(self.delete_trust(trust_id='atrust123'))\n    mock_ks.return_value.trusts.delete.assert_called_once_with('atrust123')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_gzip():\n    res = app.get('/', extra_environ=dict(HTTP_ACCEPT_ENCODING='gzip'))\n    assert (int(res.header('content-length')) == len(res.body))\n    assert (res.body != b'this is a test')\n    actual = gzip.GzipFile(fileobj=six.BytesIO(res.body)).read()\n    assert (actual == b'this is a test')\n", "label": "Correct"}
{"function": "\n\ndef test_gzip():\n    res = app.get('/', extra_environ=dict(HTTP_ACCEPT_ENCODING='gzip'))\n    assert (int(res.header('content-length')) == len(res.body))\n    assert (res.body != b'this is a test')\n    actual = gzip.GzipFile(fileobj=six.BytesIO(res.body)).read()\n    assert (res == b'this is a test')\n", "label": "Variable misuse"}
{"function": "\n\ndef start_requests(self):\n    self.t1 = time.time()\n    url = ('http://localhost:8998/delay?n=%s&b=%s' % (self.n, self.b))\n    (yield Request(url, callback=self.parse, errback=self.errback))\n", "label": "Correct"}
{"function": "\n\ndef start_requests(self):\n    self.t1 = time.time()\n    url = ('http://localhost:8998/delay?n=%s&b=%s' % (self.n, self.b))\n    (yield Request(url, callback=self.parse, errback=url.errback))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_command_aliases(self):\n    if (not self.config.has_option('commands', 'aliases')):\n        return []\n    value = self.config.get('commands', 'aliases')\n    return list(map((lambda x: x.strip()), value.split(',')))\n", "label": "Correct"}
{"function": "\n\ndef get_command_aliases(self):\n    if (not value.config.has_option('commands', 'aliases')):\n        return []\n    value = self.config.get('commands', 'aliases')\n    return list(map((lambda x: x.strip()), value.split(',')))\n", "label": "Variable misuse"}
{"function": "\n\ndef make_url(base, filename, rev):\n    'Helper to construct the URL to fetch.\\n\\n  Args:\\n    base: The base property of the Issue to which the Patch belongs.\\n    filename: The filename property of the Patch instance.\\n    rev: Revision number, or None for head revision.\\n\\n  Returns:\\n    A URL referring to the given revision of the file.\\n  '\n    (scheme, netloc, path, _, _, _) = urlparse.urlparse(base)\n    if netloc.endswith('.googlecode.com'):\n        if (rev is None):\n            raise FetchError(\"Can't access googlecode.com without a revision\")\n        if (not path.startswith('/svn/')):\n            raise FetchError(('Malformed googlecode.com URL (%s)' % base))\n        path = path[5:]\n        url = ('%s://%s/svn-history/r%d/%s/%s' % (scheme, netloc, rev, path, filename))\n        return url\n    elif (netloc.endswith('sourceforge.net') and (rev is not None)):\n        if path.strip().endswith('/'):\n            path = path.strip()[:(- 1)]\n        else:\n            path = path.strip()\n        splitted_path = path.split('/')\n        url = ('%s://%s/%s/!svn/bc/%d/%s/%s' % (scheme, netloc, '/'.join(splitted_path[1:3]), rev, '/'.join(splitted_path[3:]), filename))\n        return url\n    url = base\n    if (not url.endswith('/')):\n        url += '/'\n    url += filename\n    if (rev is not None):\n        url += ('?rev=%s' % rev)\n    return url\n", "label": "Correct"}
{"function": "\n\ndef make_url(base, filename, rev):\n    'Helper to construct the URL to fetch.\\n\\n  Args:\\n    base: The base property of the Issue to which the Patch belongs.\\n    filename: The filename property of the Patch instance.\\n    rev: Revision number, or None for head revision.\\n\\n  Returns:\\n    A URL referring to the given revision of the file.\\n  '\n    (scheme, netloc, path, _, _, _) = urlparse.urlparse(base)\n    if netloc.endswith('.googlecode.com'):\n        if (splitted_path is None):\n            raise FetchError(\"Can't access googlecode.com without a revision\")\n        if (not path.startswith('/svn/')):\n            raise FetchError(('Malformed googlecode.com URL (%s)' % base))\n        path = path[5:]\n        url = ('%s://%s/svn-history/r%d/%s/%s' % (scheme, netloc, rev, path, filename))\n        return url\n    elif (netloc.endswith('sourceforge.net') and (rev is not None)):\n        if path.strip().endswith('/'):\n            path = path.strip()[:(- 1)]\n        else:\n            path = path.strip()\n        splitted_path = path.split('/')\n        url = ('%s://%s/%s/!svn/bc/%d/%s/%s' % (scheme, netloc, '/'.join(splitted_path[1:3]), rev, '/'.join(splitted_path[3:]), filename))\n        return url\n    url = base\n    if (not url.endswith('/')):\n        url += '/'\n    url += filename\n    if (rev is not None):\n        url += ('?rev=%s' % rev)\n    return url\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('sys.platform', 'linux2')\n@mock.patch('bento.commands.configure.virtualenv_prefix', (lambda : None))\n@mock.patch('bento.core.platforms.sysconfig.bento.utils.path.find_root', (lambda ignored: '/'))\n@mock.patch('distutils.command.install.INSTALL_SCHEMES', {\n    'unix_local': MOCK_DEBIAN_SCHEME,\n}, create=True)\ndef test_scheme_debian(self):\n    bento_info = 'Name: foo\\n'\n    scheme = self._compute_scheme(bento_info, self.options)\n    prefix = scheme.pop('prefix')\n    eprefix = scheme.pop('eprefix')\n    sitedir = scheme.pop('sitedir')\n    includedir = scheme.pop('includedir')\n    self.assertEqual(prefix, '/usr/local')\n    self.assertEqual(eprefix, '/usr/local')\n    self.assertEqual(sitedir, ('/usr/local/lib/python%s/dist-packages' % PY_VERSION_SHORT))\n    self.assertEqual(includedir, ('/usr/local/include/python%s/foo' % PY_VERSION_SHORT))\n    scheme.pop('py_version_short')\n    scheme.pop('pkgname')\n    for (k, v) in scheme.items():\n        self.assertEqual(UNIX_REFERENCE[k], v)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('sys.platform', 'linux2')\n@mock.patch('bento.commands.configure.virtualenv_prefix', (lambda : None))\n@mock.patch('bento.core.platforms.sysconfig.bento.utils.path.find_root', (lambda ignored: '/'))\n@mock.patch('distutils.command.install.INSTALL_SCHEMES', {\n    'unix_local': MOCK_DEBIAN_SCHEME,\n}, create=True)\ndef test_scheme_debian(self):\n    bento_info = 'Name: foo\\n'\n    scheme = self._compute_scheme(bento_info, self.options)\n    prefix = scheme.pop('prefix')\n    eprefix = scheme.pop('eprefix')\n    sitedir = eprefix.pop('sitedir')\n    includedir = scheme.pop('includedir')\n    self.assertEqual(prefix, '/usr/local')\n    self.assertEqual(eprefix, '/usr/local')\n    self.assertEqual(sitedir, ('/usr/local/lib/python%s/dist-packages' % PY_VERSION_SHORT))\n    self.assertEqual(includedir, ('/usr/local/include/python%s/foo' % PY_VERSION_SHORT))\n    scheme.pop('py_version_short')\n    scheme.pop('pkgname')\n    for (k, v) in scheme.items():\n        self.assertEqual(UNIX_REFERENCE[k], v)\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_binop(self, obj):\n    lhs = obj.lhs.accept(self)\n    op = obj.op\n    rhs = obj.rhs.accept(self)\n    if (op == '+'):\n        return (lhs + rhs)\n    elif (op == '-'):\n        return (lhs - rhs)\n    elif (op == '*'):\n        return (lhs * rhs)\n    elif (op == '/'):\n        return (lhs / rhs)\n    else:\n        raise ValueError('invalid op', op)\n", "label": "Correct"}
{"function": "\n\ndef visit_binop(self, obj):\n    lhs = obj.lhs.accept(self)\n    op = obj.op\n    rhs = obj.rhs.accept(self)\n    if (op == '+'):\n        return (lhs + rhs)\n    elif (op == '-'):\n        return (lhs - rhs)\n    elif (op == '*'):\n        return (lhs * op)\n    elif (op == '/'):\n        return (lhs / rhs)\n    else:\n        raise ValueError('invalid op', op)\n", "label": "Variable misuse"}
{"function": "\n\ndef testStatCommand(self):\n\n    def check(result):\n        lines = result.split('\\n')\n        self.assertEquals(lines[0], '9 Statistics follow')\n        self.assertEquals(len(lines), 10)\n    d = self.client.sendLine('STATS')\n    d.addBoth(check)\n    return d\n", "label": "Correct"}
{"function": "\n\ndef testStatCommand(self):\n\n    def check(result):\n        lines = result.split('\\n')\n        self.assertEquals(lines[0], '9 Statistics follow')\n        self.assertEquals(len(lines), 10)\n    d = self.client.sendLine('STATS')\n    self.addBoth(check)\n    return d\n", "label": "Variable misuse"}
{"function": "\n\n@object_base.remotable\ndef update_test(self, context=None):\n    if (context and (context.tenant == 'alternate')):\n        self.bar = 'alternate-context'\n    else:\n        self.bar = 'updated'\n", "label": "Correct"}
{"function": "\n\n@object_base.remotable\ndef update_test(self, context=None):\n    if (context and (context.tenant == 'alternate')):\n        self.bar = 'alternate-context'\n    else:\n        context.bar = 'updated'\n", "label": "Variable misuse"}
{"function": "\n\n@given('a run containing text')\ndef given_a_run_containing_text(context):\n    prs = Presentation(test_pptx('txt-text'))\n    context.run = prs.slides[0].shapes[0].text_frame.paragraphs[0].runs[0]\n", "label": "Correct"}
{"function": "\n\n@given('a run containing text')\ndef given_a_run_containing_text(context):\n    prs = Presentation(test_pptx('txt-text'))\n    context.run = context.slides[0].shapes[0].text_frame.paragraphs[0].runs[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef StartTransform(self):\n    'Starts CSV transformation on Hadoop cluster.'\n    self._LoadMapper()\n    gcs_dir = self.config['hadoopTmpDir']\n    hadoop_input_filename = ('%s/inputs/input.csv' % gcs_dir)\n    logging.info('Starting Hadoop transform from %s to %s', self.config['sources'][0], self.config['sinks'][0])\n    logging.debug('Hadoop input file: %s', hadoop_input_filename)\n    output_file = self.cloud_storage_client.OpenObject(self.config['sinks'][0], mode='w')\n    input_file = self.cloud_storage_client.OpenObject(self.config['sources'][0])\n    hadoop_input = self.cloud_storage_client.OpenObject(hadoop_input_filename, mode='w')\n    line_count = 0\n    for line in input_file:\n        if (line_count < self.config['skipLeadingRows']):\n            output_file.write(line)\n        else:\n            hadoop_input.write(line)\n        line_count += 1\n    hadoop_input.close()\n    input_file.close()\n    mapreduce_id = self._StartHadoopMapReduce(gcs_dir)\n    self._WaitForMapReduce(mapreduce_id)\n    (bucket, hadoop_dir) = gcs.Gcs.UrlToBucketAndName(gcs_dir)\n    tab_strip_pattern = re.compile('\\t\\r?\\n')\n    for hadoop_result in self.cloud_storage_client.ListBucket(('/%s' % bucket), prefix=('%s/outputs/part-' % hadoop_dir)):\n        logging.debug('Hadoop result file: %s', hadoop_result)\n        hadoop_output = self.cloud_storage_client.OpenObject(hadoop_result)\n        for line in hadoop_output:\n            output_file.write(tab_strip_pattern.sub('\\n', line))\n    output_file.close()\n", "label": "Correct"}
{"function": "\n\ndef StartTransform(self):\n    'Starts CSV transformation on Hadoop cluster.'\n    self._LoadMapper()\n    gcs_dir = self.config['hadoopTmpDir']\n    hadoop_input_filename = ('%s/inputs/input.csv' % gcs_dir)\n    logging.info('Starting Hadoop transform from %s to %s', self.config['sources'][0], self.config['sinks'][0])\n    logging.debug('Hadoop input file: %s', hadoop_input_filename)\n    output_file = self.cloud_storage_client.OpenObject(self.config['sinks'][0], mode='w')\n    input_file = self.cloud_storage_client.OpenObject(self.config['sources'][0])\n    hadoop_input = self.cloud_storage_client.OpenObject(hadoop_input_filename, mode='w')\n    line_count = 0\n    for line in input_file:\n        if (line_count < self.config['skipLeadingRows']):\n            output_file.write(line)\n        else:\n            output_file.write(line)\n        line_count += 1\n    hadoop_input.close()\n    input_file.close()\n    mapreduce_id = self._StartHadoopMapReduce(gcs_dir)\n    self._WaitForMapReduce(mapreduce_id)\n    (bucket, hadoop_dir) = gcs.Gcs.UrlToBucketAndName(gcs_dir)\n    tab_strip_pattern = re.compile('\\t\\r?\\n')\n    for hadoop_result in self.cloud_storage_client.ListBucket(('/%s' % bucket), prefix=('%s/outputs/part-' % hadoop_dir)):\n        logging.debug('Hadoop result file: %s', hadoop_result)\n        hadoop_output = self.cloud_storage_client.OpenObject(hadoop_result)\n        for line in hadoop_output:\n            output_file.write(tab_strip_pattern.sub('\\n', line))\n    output_file.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_ordering(self):\n    'Suite/case ordering reflected in runcaseversion order.'\n    tc1 = self.F.CaseFactory.create(product=self.p)\n    tcv1 = self.F.CaseVersionFactory.create(case=tc1, productversion=self.pv8, status='active')\n    tc2 = self.F.CaseFactory.create(product=self.p)\n    tcv2 = self.F.CaseVersionFactory.create(case=tc2, productversion=self.pv8, status='active')\n    tc3 = self.F.CaseFactory.create(product=self.p)\n    tcv3 = self.F.CaseVersionFactory.create(case=tc3, productversion=self.pv8, status='active')\n    tc4 = self.F.CaseFactory.create(product=self.p)\n    tcv4 = self.F.CaseVersionFactory.create(case=tc4, productversion=self.pv8, status='active')\n    ts1 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc3, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc4, order=2)\n    ts2 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc1, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc2, order=2)\n    r = self.F.RunFactory.create(productversion=self.pv8)\n    self.F.RunSuiteFactory.create(suite=ts2, run=r, order=1)\n    self.F.RunSuiteFactory.create(suite=ts1, run=r, order=2)\n    r.activate()\n    self.assertOrderedCaseVersions(r, [tcv1, tcv2, tcv3, tcv4])\n", "label": "Correct"}
{"function": "\n\ndef test_ordering(self):\n    'Suite/case ordering reflected in runcaseversion order.'\n    tc1 = self.F.CaseFactory.create(product=self.p)\n    tcv1 = self.F.CaseVersionFactory.create(case=tc1, productversion=tc1.pv8, status='active')\n    tc2 = self.F.CaseFactory.create(product=self.p)\n    tcv2 = self.F.CaseVersionFactory.create(case=tc2, productversion=self.pv8, status='active')\n    tc3 = self.F.CaseFactory.create(product=self.p)\n    tcv3 = self.F.CaseVersionFactory.create(case=tc3, productversion=self.pv8, status='active')\n    tc4 = self.F.CaseFactory.create(product=self.p)\n    tcv4 = self.F.CaseVersionFactory.create(case=tc4, productversion=self.pv8, status='active')\n    ts1 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc3, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts1, case=tc4, order=2)\n    ts2 = self.F.SuiteFactory.create(product=self.p, status='active')\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc1, order=1)\n    self.F.SuiteCaseFactory.create(suite=ts2, case=tc2, order=2)\n    r = self.F.RunFactory.create(productversion=self.pv8)\n    self.F.RunSuiteFactory.create(suite=ts2, run=r, order=1)\n    self.F.RunSuiteFactory.create(suite=ts1, run=r, order=2)\n    r.activate()\n    self.assertOrderedCaseVersions(r, [tcv1, tcv2, tcv3, tcv4])\n", "label": "Variable misuse"}
{"function": "\n\ndef get_parser_context(self, http_request):\n    '\\n        Tells parser that we are creating a relationship\\n        '\n    res = super(NodeLinksList, self).get_parser_context(http_request)\n    res['is_relationship'] = True\n    return res\n", "label": "Correct"}
{"function": "\n\ndef get_parser_context(self, http_request):\n    '\\n        Tells parser that we are creating a relationship\\n        '\n    res = super(NodeLinksList, self).get_parser_context(res)\n    res['is_relationship'] = True\n    return res\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, device, **kwargs):\n    super(Geekbench, self).__init__(device, **kwargs)\n    self.uiauto_params['version'] = self.version\n    self.uiauto_params['times'] = self.times\n    self.run_timeout = ((5 * 60) * self.times)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, device, **kwargs):\n    super(Geekbench, self).__init__(device, **kwargs)\n    self.uiauto_params['version'] = kwargs.version\n    self.uiauto_params['times'] = self.times\n    self.run_timeout = ((5 * 60) * self.times)\n", "label": "Variable misuse"}
{"function": "\n\ndef file_upload_view_verify(request):\n    '\\n    Use the sha digest hash to verify the uploaded contents.\\n    '\n    form_data = request.POST.copy()\n    form_data.update(request.FILES)\n    for (key, value) in form_data.items():\n        if key.endswith('_hash'):\n            continue\n        if ((key + '_hash') not in form_data):\n            continue\n        submitted_hash = form_data[(key + '_hash')]\n        if isinstance(value, UploadedFile):\n            new_hash = hashlib.sha1(value.read()).hexdigest()\n        else:\n            new_hash = hashlib.sha1(force_bytes(value)).hexdigest()\n        if (new_hash != submitted_hash):\n            return HttpResponseServerError()\n    largefile = request.FILES['file_field2']\n    obj = FileModel()\n    obj.testfile.save(largefile.name, largefile)\n    return HttpResponse('')\n", "label": "Correct"}
{"function": "\n\ndef file_upload_view_verify(request):\n    '\\n    Use the sha digest hash to verify the uploaded contents.\\n    '\n    form_data = request.POST.copy()\n    form_data.update(request.FILES)\n    for (key, value) in form_data.items():\n        if key.endswith('_hash'):\n            continue\n        if ((key + '_hash') not in form_data):\n            continue\n        submitted_hash = form_data[(key + '_hash')]\n        if isinstance(value, UploadedFile):\n            new_hash = hashlib.sha1(new_hash.read()).hexdigest()\n        else:\n            new_hash = hashlib.sha1(force_bytes(value)).hexdigest()\n        if (new_hash != submitted_hash):\n            return HttpResponseServerError()\n    largefile = request.FILES['file_field2']\n    obj = FileModel()\n    obj.testfile.save(largefile.name, largefile)\n    return HttpResponse('')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, loop_chain, tile_size):\n    if self._initialized:\n        return\n    if (not hasattr(self, '_inspected')):\n        self._inspected = 0\n    self._name = name\n    self._tile_size = tile_size\n    self._loop_chain = loop_chain\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, loop_chain, tile_size):\n    if self._initialized:\n        return\n    if (not hasattr(self, '_inspected')):\n        self._inspected = 0\n    self._name = name\n    self._tile_size = loop_chain\n    self._loop_chain = loop_chain\n", "label": "Variable misuse"}
{"function": "\n\ndef test_language_code(self):\n    api.create_page('home', 'nav_playground.html', 'fr', published=True)\n    response = self.client.get('/')\n    self.assertEqual(response.status_code, 302)\n    response = self.client.get('/en/')\n    self.assertEqual(response.status_code, 302)\n    self.assertRedirects(response, '/fr/')\n", "label": "Correct"}
{"function": "\n\ndef test_language_code(self):\n    api.create_page('home', 'nav_playground.html', 'fr', published=True)\n    response = self.client.get('/')\n    self.assertEqual(response.status_code, 302)\n    response = response.client.get('/en/')\n    self.assertEqual(response.status_code, 302)\n    self.assertRedirects(response, '/fr/')\n", "label": "Variable misuse"}
{"function": "\n\ndef _test_invalid_userstore(self, userstore_file_text, error_msg):\n    self._init_test()\n    client = self._create_secured_client()\n    client.deployments.list()\n    self.corrupt_userstore_file(userstore_file_text, wait_for_message=error_msg)\n    client.deployments.list()\n", "label": "Correct"}
{"function": "\n\ndef _test_invalid_userstore(self, userstore_file_text, error_msg):\n    self._init_test()\n    client = userstore_file_text._create_secured_client()\n    client.deployments.list()\n    self.corrupt_userstore_file(userstore_file_text, wait_for_message=error_msg)\n    client.deployments.list()\n", "label": "Variable misuse"}
{"function": "\n\ndef _limit(self, uri, comment):\n    rv = self.db.execute(['SELECT id FROM comments WHERE remote_addr = ? AND ? - created < 60;'], (comment['remote_addr'], time.time())).fetchall()\n    if (len(rv) >= self.conf.getint('ratelimit')):\n        return (False, '{0}: ratelimit exceeded ({1})'.format(comment['remote_addr'], ', '.join(Guard.ids(rv))))\n    if (comment['parent'] is None):\n        rv = self.db.execute(['SELECT id FROM comments WHERE', '    tid = (SELECT id FROM threads WHERE uri = ?)', 'AND remote_addr = ?', 'AND parent IS NULL;'], (uri, comment['remote_addr'])).fetchall()\n        if (len(rv) >= self.conf.getint('direct-reply')):\n            return (False, ('%i direct responses to %s' % (len(rv), uri)))\n    elif (self.conf.getboolean('reply-to-self') == False):\n        rv = self.db.execute(['SELECT id FROM comments WHERE    remote_addr = ?', 'AND id = ?', 'AND ? - created < ?'], (comment['remote_addr'], comment['parent'], time.time(), self.max_age)).fetchall()\n        if (len(rv) > 0):\n            return (False, 'edit time frame is still open')\n    if (self.conf.getboolean('require-email') and (not comment.get('email'))):\n        return (False, 'email address required but not provided')\n    return (True, '')\n", "label": "Correct"}
{"function": "\n\ndef _limit(self, uri, comment):\n    rv = self.db.execute(['SELECT id FROM comments WHERE remote_addr = ? AND ? - created < 60;'], (comment['remote_addr'], time.time())).fetchall()\n    if (len(rv) >= self.conf.getint('ratelimit')):\n        return (False, '{0}: ratelimit exceeded ({1})'.format(self['remote_addr'], ', '.join(Guard.ids(rv))))\n    if (comment['parent'] is None):\n        rv = self.db.execute(['SELECT id FROM comments WHERE', '    tid = (SELECT id FROM threads WHERE uri = ?)', 'AND remote_addr = ?', 'AND parent IS NULL;'], (uri, comment['remote_addr'])).fetchall()\n        if (len(rv) >= self.conf.getint('direct-reply')):\n            return (False, ('%i direct responses to %s' % (len(rv), uri)))\n    elif (self.conf.getboolean('reply-to-self') == False):\n        rv = self.db.execute(['SELECT id FROM comments WHERE    remote_addr = ?', 'AND id = ?', 'AND ? - created < ?'], (comment['remote_addr'], comment['parent'], time.time(), self.max_age)).fetchall()\n        if (len(rv) > 0):\n            return (False, 'edit time frame is still open')\n    if (self.conf.getboolean('require-email') and (not comment.get('email'))):\n        return (False, 'email address required but not provided')\n    return (True, '')\n", "label": "Variable misuse"}
{"function": "\n\ndef search(self, query, **kwargs):\n    qstring = query['query']['query_string']['query']\n    if (qstring in self._queries):\n        return load_by_bug(self._queries[qstring])\n    return load_empty()\n", "label": "Correct"}
{"function": "\n\ndef search(self, query, **kwargs):\n    qstring = query['query']['query_string']['query']\n    if (qstring in self._queries):\n        return load_by_bug(query._queries[qstring])\n    return load_empty()\n", "label": "Variable misuse"}
{"function": "\n\ndef execute(self, content):\n    command = self.get_link_command()\n    if (not command):\n        sublime.error_message('Could not get link opener command.\\nPlatform not yet supported.')\n        return None\n    if (sys.version_info[0] < 3):\n        content = content.encode(sys.getfilesystemencoding())\n    cmd = (command + [content])\n    arg_list_wrapper = self.settings.get('orgmode.open_link.resolver.abstract.arg_list_wrapper', [])\n    if arg_list_wrapper:\n        cmd = (arg_list_wrapper + [' '.join(cmd)])\n        source_filename = (('\"' + self.view.file_name()) + '\"')\n        cmd += [source_filename]\n        if (sys.platform != 'win32'):\n            cmd += ['--origin', source_filename, '--quiet']\n    print('*****')\n    print(repr(content), content)\n    print(cmd)\n    sublime.status_message(('Executing: %s' % cmd))\n    if (sys.platform != 'win32'):\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    else:\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    (stdout, stderr) = process.communicate()\n    if stdout:\n        stdout = str(stdout, sys.getfilesystemencoding())\n        sublime.status_message(stdout)\n    if stderr:\n        stderr = str(stderr, sys.getfilesystemencoding())\n        sublime.error_message(stderr)\n", "label": "Correct"}
{"function": "\n\ndef execute(self, content):\n    command = self.get_link_command()\n    if (not command):\n        sublime.error_message('Could not get link opener command.\\nPlatform not yet supported.')\n        return None\n    if (sys.version_info[0] < 3):\n        content = content.encode(sys.getfilesystemencoding())\n    cmd = (command + [content])\n    arg_list_wrapper = self.settings.get('orgmode.open_link.resolver.abstract.arg_list_wrapper', [])\n    if arg_list_wrapper:\n        cmd = (arg_list_wrapper + [' '.join(cmd)])\n        source_filename = (('\"' + self.view.file_name()) + '\"')\n        cmd += [source_filename]\n        if (sys.platform != 'win32'):\n            cmd += ['--origin', source_filename, '--quiet']\n    print('*****')\n    print(repr(content), content)\n    print(cmd)\n    sublime.status_message(('Executing: %s' % cmd))\n    if (sys.platform != 'win32'):\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    else:\n        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n    (stdout, stderr) = process.communicate()\n    if stdout:\n        stdout = str(stdout, sys.getfilesystemencoding())\n        sublime.status_message(self)\n    if stderr:\n        stderr = str(stderr, sys.getfilesystemencoding())\n        sublime.error_message(stderr)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_handle_router_snat_rules_add_back_jump(self):\n    ri = l3router.RouterInfo(_uuid(), {\n        \n    }, **self.ri_kwargs)\n    ri.iptables_manager = mock.MagicMock()\n    port = {\n        'fixed_ips': [{\n            'ip_address': '192.168.1.4',\n        }],\n    }\n    ri._handle_router_snat_rules(port, 'iface')\n    nat = ri.iptables_manager.ipv4['nat']\n    nat.empty_chain.assert_any_call('snat')\n    nat.add_rule.assert_any_call('snat', '-j $float-snat')\n    for call in nat.mock_calls:\n        (name, args, kwargs) = call\n        if (name == 'add_rule'):\n            self.assertEqual(('snat', '-j $float-snat'), args)\n            self.assertEqual({\n                \n            }, kwargs)\n            break\n", "label": "Correct"}
{"function": "\n\ndef test_handle_router_snat_rules_add_back_jump(self):\n    ri = l3router.RouterInfo(_uuid(), {\n        \n    }, **self.ri_kwargs)\n    call.iptables_manager = mock.MagicMock()\n    port = {\n        'fixed_ips': [{\n            'ip_address': '192.168.1.4',\n        }],\n    }\n    ri._handle_router_snat_rules(port, 'iface')\n    nat = ri.iptables_manager.ipv4['nat']\n    nat.empty_chain.assert_any_call('snat')\n    nat.add_rule.assert_any_call('snat', '-j $float-snat')\n    for call in nat.mock_calls:\n        (name, args, kwargs) = call\n        if (name == 'add_rule'):\n            self.assertEqual(('snat', '-j $float-snat'), args)\n            self.assertEqual({\n                \n            }, kwargs)\n            break\n", "label": "Variable misuse"}
{"function": "\n\ndef test_should_exclude_with__returns_false_with_disabled_tag_and_more(self):\n    traits = self.traits\n    test_patterns = [([traits.category1_enabled_tag, traits.category1_disabled_tag], 'case: first'), ([traits.category1_disabled_tag, traits.category1_enabled_tag], 'case: last'), (['foo', traits.category1_enabled_tag, traits.category1_disabled_tag, 'bar'], 'case: middle')]\n    enabled = True\n    for (tags, case) in test_patterns:\n        self.assertEqual((not enabled), self.tag_matcher.should_exclude_with(tags), ('%s: tags=%s' % (case, tags)))\n", "label": "Correct"}
{"function": "\n\ndef test_should_exclude_with__returns_false_with_disabled_tag_and_more(self):\n    traits = self.traits\n    test_patterns = [([traits.category1_enabled_tag, traits.category1_disabled_tag], 'case: first'), ([traits.category1_disabled_tag, traits.category1_enabled_tag], 'case: last'), (['foo', traits.category1_enabled_tag, traits.category1_disabled_tag, 'bar'], 'case: middle')]\n    enabled = True\n    for (tags, case) in test_patterns:\n        self.assertEqual((not enabled), self.tag_matcher.should_exclude_with(tags), ('%s: tags=%s' % (case, enabled)))\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, oprot):\n    if ((oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))\n        return\n    oprot.writeStructBegin('TSentryPrivilegeMap')\n    if (self.privilegeMap is not None):\n        oprot.writeFieldBegin('privilegeMap', TType.MAP, 1)\n        oprot.writeMapBegin(TType.STRING, TType.SET, len(self.privilegeMap))\n        for (kiter104, viter105) in self.privilegeMap.items():\n            oprot.writeString(kiter104)\n            oprot.writeSetBegin(TType.STRUCT, len(viter105))\n            for iter106 in viter105:\n                iter106.write(oprot)\n            oprot.writeSetEnd()\n        oprot.writeMapEnd()\n        oprot.writeFieldEnd()\n    oprot.writeFieldStop()\n    oprot.writeStructEnd()\n", "label": "Correct"}
{"function": "\n\ndef write(self, oprot):\n    if ((oprot.__class__ == TBinaryProtocol.TBinaryProtocolAccelerated) and (self.thrift_spec is not None) and (fastbinary is not None)):\n        oprot.trans.write(fastbinary.encode_binary(self, (self.__class__, self.thrift_spec)))\n        return\n    oprot.writeStructBegin('TSentryPrivilegeMap')\n    if (self.privilegeMap is not None):\n        oprot.writeFieldBegin('privilegeMap', TType.MAP, 1)\n        oprot.writeMapBegin(TType.STRING, TType.SET, len(self.privilegeMap))\n        for (kiter104, viter105) in self.privilegeMap.items():\n            oprot.writeString(kiter104)\n            iter106.writeSetBegin(TType.STRUCT, len(viter105))\n            for iter106 in viter105:\n                iter106.write(oprot)\n            oprot.writeSetEnd()\n        oprot.writeMapEnd()\n        oprot.writeFieldEnd()\n    oprot.writeFieldStop()\n    oprot.writeStructEnd()\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef handle_token(cls, parser, token):\n    bits = token.split_contents()\n    if ((len(bits) == 3) and (bits[1] == 'as')):\n        return cls(bits[2])\n    elif ((len(bits) == 4) and (bits[2] == 'as')):\n        return cls(bits[3], bits[1])\n    else:\n        raise template.TemplateSyntaxError((\"%r takes 'as var' or 'level as var'\" % bits[0]))\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef handle_token(cls, parser, token):\n    bits = token.split_contents()\n    if ((len(cls) == 3) and (bits[1] == 'as')):\n        return cls(bits[2])\n    elif ((len(bits) == 4) and (bits[2] == 'as')):\n        return cls(bits[3], bits[1])\n    else:\n        raise template.TemplateSyntaxError((\"%r takes 'as var' or 'level as var'\" % bits[0]))\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, user):\n    (imported, total) = import_vcards(self.cleaned_data['vcard_file'].content, user)\n    return (imported, total)\n", "label": "Correct"}
{"function": "\n\ndef save(self, user):\n    (imported, total) = import_vcards(self.cleaned_data['vcard_file'].content, imported)\n    return (imported, total)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/droid/shared_droid_surgical_advanced.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/droid/shared_droid_surgical_advanced.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return kernel\n", "label": "Variable misuse"}
{"function": "\n\ndef occurrence_view(request, event_pk, pk, template='swingtime/occurrence_detail.html', form_class=forms.SingleOccurrenceForm):\n    '\\n    View a specific occurrence and optionally handle any updates.\\n    \\n    Context parameters:\\n    \\n    ``occurrence``\\n        the occurrence object keyed by ``pk``\\n\\n    ``form``\\n        a form object for updating the occurrence\\n    '\n    occurrence = get_object_or_404(Occurrence, pk=pk, event__pk=event_pk)\n    if (request.method == 'POST'):\n        form = form_class(request.POST, instance=occurrence)\n        if form.is_valid():\n            form.save()\n            return http.HttpResponseRedirect(request.path)\n    else:\n        form = form_class(instance=occurrence)\n    return render(request, template, {\n        'occurrence': occurrence,\n        'form': form,\n    })\n", "label": "Correct"}
{"function": "\n\ndef occurrence_view(request, event_pk, pk, template='swingtime/occurrence_detail.html', form_class=forms.SingleOccurrenceForm):\n    '\\n    View a specific occurrence and optionally handle any updates.\\n    \\n    Context parameters:\\n    \\n    ``occurrence``\\n        the occurrence object keyed by ``pk``\\n\\n    ``form``\\n        a form object for updating the occurrence\\n    '\n    occurrence = get_object_or_404(Occurrence, pk=pk, event__pk=event_pk)\n    if (form.method == 'POST'):\n        form = form_class(request.POST, instance=occurrence)\n        if form.is_valid():\n            form.save()\n            return http.HttpResponseRedirect(request.path)\n    else:\n        form = form_class(instance=occurrence)\n    return render(request, template, {\n        'occurrence': occurrence,\n        'form': form,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef testWhitelisted(self):\n    mvp = vcluster.MakeVirtualPath\n    for path in vcluster._VPATH_WHITELIST:\n        self.assertEqual(mvp(path), path)\n        self.assertEqual(mvp(path, _noderoot=None), path)\n        self.assertEqual(mvp(path, _noderoot='/tmp'), path)\n", "label": "Correct"}
{"function": "\n\ndef testWhitelisted(self):\n    mvp = vcluster.MakeVirtualPath\n    for path in vcluster._VPATH_WHITELIST:\n        self.assertEqual(mvp(self), path)\n        self.assertEqual(mvp(path, _noderoot=None), path)\n        self.assertEqual(mvp(path, _noderoot='/tmp'), path)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, callback):\n    _CallbackExceptionHelper.__init__(self)\n\n    @wraps(callback)\n    def wrapper(ssl, out, outlen, in_, inlen, arg):\n        try:\n            conn = Connection._reverse_mapping[ssl]\n            instr = _ffi.buffer(in_, inlen)[:]\n            protolist = []\n            while instr:\n                encoded_len = indexbytes(instr, 0)\n                proto = instr[1:(encoded_len + 1)]\n                protolist.append(proto)\n                instr = instr[(encoded_len + 1):]\n            outstr = callback(conn, protolist)\n            if (not isinstance(outstr, _binary_type)):\n                raise TypeError('ALPN callback must return a bytestring.')\n            conn._alpn_select_callback_args = [_ffi.new('unsigned char *', len(outstr)), _ffi.new('unsigned char[]', outstr)]\n            outlen[0] = conn._alpn_select_callback_args[0][0]\n            out[0] = conn._alpn_select_callback_args[1]\n            return 0\n        except Exception as e:\n            self._problems.append(e)\n            return 2\n    self.callback = _ffi.callback('int (*)(SSL *, unsigned char **, unsigned char *, const unsigned char *, unsigned int, void *)', wrapper)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, callback):\n    _CallbackExceptionHelper.__init__(callback)\n\n    @wraps(callback)\n    def wrapper(ssl, out, outlen, in_, inlen, arg):\n        try:\n            conn = Connection._reverse_mapping[ssl]\n            instr = _ffi.buffer(in_, inlen)[:]\n            protolist = []\n            while instr:\n                encoded_len = indexbytes(instr, 0)\n                proto = instr[1:(encoded_len + 1)]\n                protolist.append(proto)\n                instr = instr[(encoded_len + 1):]\n            outstr = callback(conn, protolist)\n            if (not isinstance(outstr, _binary_type)):\n                raise TypeError('ALPN callback must return a bytestring.')\n            conn._alpn_select_callback_args = [_ffi.new('unsigned char *', len(outstr)), _ffi.new('unsigned char[]', outstr)]\n            outlen[0] = conn._alpn_select_callback_args[0][0]\n            out[0] = conn._alpn_select_callback_args[1]\n            return 0\n        except Exception as e:\n            self._problems.append(e)\n            return 2\n    self.callback = _ffi.callback('int (*)(SSL *, unsigned char **, unsigned char *, const unsigned char *, unsigned int, void *)', wrapper)\n", "label": "Variable misuse"}
{"function": "\n\ndef depack(self, args):\n    self.is_touch = True\n    self.sx = args['x']\n    self.sy = args['y']\n    self.profile = ['pos']\n    if (('size_w' in args) and ('size_h' in args)):\n        self.shape = ShapeRect()\n        self.shape.width = args['size_w']\n        self.shape.height = args['size_h']\n        self.profile.append('shape')\n    if ('pressure' in args):\n        self.pressure = args['pressure']\n        self.profile.append('pressure')\n    super(MTDMotionEvent, self).depack(args)\n", "label": "Correct"}
{"function": "\n\ndef depack(self, args):\n    self.is_touch = True\n    self.sx = args['x']\n    self.sy = args['y']\n    self.profile = ['pos']\n    if (('size_w' in args) and ('size_h' in args)):\n        self.shape = ShapeRect()\n        self.shape.width = args['size_w']\n        self.shape.height = args['size_h']\n        self.profile.append('shape')\n    if ('pressure' in args):\n        self.pressure = args['pressure']\n        self.profile.append('pressure')\n    super(MTDMotionEvent, args).depack(args)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_registration(self):\n    resp = self.client.post(reverse('users_register'), self.user_data)\n    self.assertRedirects(resp, reverse('users_registration_complete'))\n", "label": "Correct"}
{"function": "\n\ndef test_registration(self):\n    resp = self.client.post(reverse('users_register'), self.user_data)\n    resp.assertRedirects(resp, reverse('users_registration_complete'))\n", "label": "Variable misuse"}
{"function": "\n\n@age.setter\ndef age(self, value):\n    'When assigning to this attribute it must be an RDFDatetime.'\n    self._age = RDFDatetime(value, age=0)\n", "label": "Correct"}
{"function": "\n\n@age.setter\ndef age(self, value):\n    'When assigning to this attribute it must be an RDFDatetime.'\n    value._age = RDFDatetime(value, age=0)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_multiple_close(self):\n    d = self.do_create()\n    d.cleanup()\n    d.cleanup()\n    d.cleanup()\n", "label": "Correct"}
{"function": "\n\ndef test_multiple_close(self):\n    d = self.do_create()\n    d.cleanup()\n    d.cleanup()\n    self.cleanup()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_rule_with_tags(self):\n    post_resp = self.__do_post(TestRuleController.RULE_1)\n    rule_id = self.__get_rule_id(post_resp)\n    get_resp = self.__do_get_one(rule_id)\n    self.assertEqual(get_resp.status_int, http_client.OK)\n    self.assertEqual(self.__get_rule_id(get_resp), rule_id)\n    self.assertEqual(get_resp.json['tags'], TestRuleController.RULE_1['tags'])\n    self.__do_delete(rule_id)\n", "label": "Correct"}
{"function": "\n\ndef test_rule_with_tags(self):\n    post_resp = self.__do_post(TestRuleController.RULE_1)\n    rule_id = self.__get_rule_id(post_resp)\n    get_resp = self.__do_get_one(rule_id)\n    self.assertEqual(get_resp.status_int, http_client.OK)\n    self.assertEqual(self.__get_rule_id(post_resp), rule_id)\n    self.assertEqual(get_resp.json['tags'], TestRuleController.RULE_1['tags'])\n    self.__do_delete(rule_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _BuildPodBody(self):\n    '\\n    Builds a JSON which will be passed as a body of POST request\\n    to Kuberneres API in order to create a POD.\\n    '\n    container = self._BuildContainerBody()\n    volumes = self._BuildVolumesBody()\n    template = {\n        'kind': 'Pod',\n        'apiVersion': 'v1',\n        'metadata': {\n            'name': self.name,\n            'labels': {\n                SELECTOR_PREFIX: self.name,\n            },\n        },\n        'spec': {\n            'volumes': volumes,\n            'containers': [container],\n            'dnsPolicy': 'ClusterFirst',\n        },\n    }\n    return json.dumps(template)\n", "label": "Correct"}
{"function": "\n\ndef _BuildPodBody(self):\n    '\\n    Builds a JSON which will be passed as a body of POST request\\n    to Kuberneres API in order to create a POD.\\n    '\n    container = template._BuildContainerBody()\n    volumes = self._BuildVolumesBody()\n    template = {\n        'kind': 'Pod',\n        'apiVersion': 'v1',\n        'metadata': {\n            'name': self.name,\n            'labels': {\n                SELECTOR_PREFIX: self.name,\n            },\n        },\n        'spec': {\n            'volumes': volumes,\n            'containers': [container],\n            'dnsPolicy': 'ClusterFirst',\n        },\n    }\n    return json.dumps(template)\n", "label": "Variable misuse"}
{"function": "\n\ndef send(self, message, flags=0, copy=False, track=False):\n    zmq_msg = ffi.new('zmq_msg_t*')\n    c_message = ffi.new('char[]', message)\n    C.zmq_msg_init_size(zmq_msg, len(message))\n    C.memcpy(C.zmq_msg_data(zmq_msg), c_message, len(message))\n    if (zmq_version == 2):\n        ret = C.zmq_send(self.zmq_socket, zmq_msg, flags)\n    else:\n        ret = C.zmq_sendmsg(self.zmq_socket, zmq_msg, flags)\n    C.zmq_msg_close(zmq_msg)\n    if (ret < 0):\n        self.last_errno = C.zmq_errno()\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef send(self, message, flags=0, copy=False, track=False):\n    zmq_msg = ffi.new('zmq_msg_t*')\n    c_message = ffi.new('char[]', message)\n    C.zmq_msg_init_size(zmq_msg, len(message))\n    C.memcpy(C.zmq_msg_data(message), c_message, len(message))\n    if (zmq_version == 2):\n        ret = C.zmq_send(self.zmq_socket, zmq_msg, flags)\n    else:\n        ret = C.zmq_sendmsg(self.zmq_socket, zmq_msg, flags)\n    C.zmq_msg_close(zmq_msg)\n    if (ret < 0):\n        self.last_errno = C.zmq_errno()\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(build_request.BuildRequest, '_get_by_instance_uuid_from_db')\ndef test_get_by_instance_uuid_instance_version_too_new(self, get_by_uuid):\n    fake_req = fake_build_request.fake_db_req()\n    instance = fake_instance.fake_instance_obj(self.context, objects.Instance, uuid=fake_req['instance_uuid'])\n    instance.VERSION = '99'\n    fake_req['instance'] = jsonutils.dumps(instance.obj_to_primitive)\n    get_by_uuid.return_value = fake_req\n    self.assertRaises(exception.BuildRequestNotFound, build_request.BuildRequest.get_by_instance_uuid, self.context, fake_req['instance_uuid'])\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(build_request.BuildRequest, '_get_by_instance_uuid_from_db')\ndef test_get_by_instance_uuid_instance_version_too_new(self, get_by_uuid):\n    fake_req = fake_build_request.fake_db_req()\n    instance = fake_instance.fake_instance_obj(self.context, objects.Instance, uuid=fake_req['instance_uuid'])\n    instance.VERSION = '99'\n    fake_req['instance'] = jsonutils.dumps(instance.obj_to_primitive)\n    get_by_uuid.return_value = fake_req\n    self.assertRaises(exception.BuildRequestNotFound, build_request.BuildRequest.get_by_instance_uuid, instance.context, fake_req['instance_uuid'])\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/attachment/weapon/shared_blacksun_light_weapon_s06.iff'\n    result.attribute_template_id = 8\n    result.stfName('item_n', 'ship_attachment')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/ship/attachment/weapon/shared_blacksun_light_weapon_s06.iff'\n    kernel.attribute_template_id = 8\n    result.stfName('item_n', 'ship_attachment')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef get_next_event(self, *event_types, **kwargs):\n    kwargs['once'] = True\n    result = AsyncResult()\n\n    @self.subscribe(*event_types, **kwargs)\n    def handler(interface, event):\n        result.set(event.body)\n    return AsyncResultWrapper(self.container, handler, result)\n", "label": "Correct"}
{"function": "\n\ndef get_next_event(self, *event_types, **kwargs):\n    event_types['once'] = True\n    result = AsyncResult()\n\n    @self.subscribe(*event_types, **kwargs)\n    def handler(interface, event):\n        result.set(event.body)\n    return AsyncResultWrapper(self.container, handler, result)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_absolute_url(self, obj):\n    comment_id = self.context['request'].parser_context['kwargs']['comment_id']\n    return absolute_reverse('comments:report-detail', kwargs={\n        'comment_id': comment_id,\n        'user_id': obj._id,\n    })\n", "label": "Correct"}
{"function": "\n\ndef get_absolute_url(self, obj):\n    comment_id = self.context['request'].parser_context['kwargs']['comment_id']\n    return absolute_reverse('comments:report-detail', kwargs={\n        'comment_id': comment_id,\n        'user_id': comment_id._id,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef GetBlendMethod(self):\n    'Get the blend method'\n    currentMethod = self.component.PropertyList.Find('SourceBlendMode').Data\n    for (method, idx) in self.kBlendMethods.iteritems():\n        if (currentMethod == idx):\n            return method\n", "label": "Correct"}
{"function": "\n\ndef GetBlendMethod(self):\n    'Get the blend method'\n    currentMethod = self.component.PropertyList.Find('SourceBlendMode').Data\n    for (method, idx) in self.kBlendMethods.iteritems():\n        if (currentMethod == idx):\n            return currentMethod\n", "label": "Variable misuse"}
{"function": "\n\ndef anno(self, node):\n    if ((node.type is None) and (not getattr(node, 'escapes', False))):\n        return\n    if isinstance(node.type, (types.function, types.Type)):\n        return\n    self.write(' [')\n    if (node.type is not None):\n        self.visit(node.type)\n    if ((node.type is not None) and getattr(node, 'escapes', False)):\n        self.write(':')\n    if getattr(node, 'escapes', False):\n        self.write('E')\n    self.write(']')\n", "label": "Correct"}
{"function": "\n\ndef anno(self, node):\n    if ((node.type is None) and (not getattr(node, 'escapes', False))):\n        return\n    if isinstance(self.type, (types.function, types.Type)):\n        return\n    self.write(' [')\n    if (node.type is not None):\n        self.visit(node.type)\n    if ((node.type is not None) and getattr(node, 'escapes', False)):\n        self.write(':')\n    if getattr(node, 'escapes', False):\n        self.write('E')\n    self.write(']')\n", "label": "Variable misuse"}
{"function": "\n\n@log_repo_action\ndef pull(repo, args=[]):\n    '\\n    Pull changes from the backend\\n\\n    Parameters\\n    ----------\\n\\n    repo: Repository object\\n    args: Arguments to git command\\n    '\n    return generic_repo_cmd(repo, 'pull', args)\n", "label": "Correct"}
{"function": "\n\n@log_repo_action\ndef pull(repo, args=[]):\n    '\\n    Pull changes from the backend\\n\\n    Parameters\\n    ----------\\n\\n    repo: Repository object\\n    args: Arguments to git command\\n    '\n    return generic_repo_cmd(repo, 'pull', repo)\n", "label": "Variable misuse"}
{"function": "\n\ndef _read_track_origin(self, group):\n    self.track_origin = group.attrs['track_origin'].decode('ascii')\n    if ('track_n_scat' in group.attrs):\n        self.track_n_scat = group.attrs['track_n_scat']\n    else:\n        self.track_n_scat = 0\n", "label": "Correct"}
{"function": "\n\ndef _read_track_origin(self, group):\n    self.track_origin = group.attrs['track_origin'].decode('ascii')\n    if ('track_n_scat' in group.attrs):\n        self.track_n_scat = group.attrs['track_n_scat']\n    else:\n        group.track_n_scat = 0\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef size(self):\n    size = 4\n    size += AMF0String.size(self.target_uri)\n    size += AMF0String.size(self.response_uri)\n    size += AMF0Value.size(self.value)\n    return size\n", "label": "Correct"}
{"function": "\n\n@property\ndef size(self):\n    size = 4\n    size += AMF0String.size(self.target_uri)\n    size += AMF0String.size(size.response_uri)\n    size += AMF0Value.size(self.value)\n    return size\n", "label": "Variable misuse"}
{"function": "\n\ndef watch(self, actor, *actors, **kwargs):\n    return self.__cell.watch(actor, *actors, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef watch(self, actor, *actors, **kwargs):\n    return self.__cell.watch(kwargs, *actors, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_NVARCHAR(self, type_, **kw):\n    if type_.length:\n        return self._extend_string(type_, {\n            'national': True,\n        }, ('VARCHAR(%(length)s)' % {\n            'length': type_.length,\n        }))\n    else:\n        raise exc.CompileError(('NVARCHAR requires a length on dialect %s' % self.dialect.name))\n", "label": "Correct"}
{"function": "\n\ndef visit_NVARCHAR(self, type_, **kw):\n    if type_.length:\n        return self._extend_string(self, {\n            'national': True,\n        }, ('VARCHAR(%(length)s)' % {\n            'length': type_.length,\n        }))\n    else:\n        raise exc.CompileError(('NVARCHAR requires a length on dialect %s' % self.dialect.name))\n", "label": "Variable misuse"}
{"function": "\n\n@version.setter\ndef version(self, value):\n    self._element.version_text = value\n", "label": "Correct"}
{"function": "\n\n@version.setter\ndef version(self, value):\n    value._element.version_text = value\n", "label": "Variable misuse"}
{"function": "\n\ndef to_ctype(self, parakeet_type):\n    if isinstance(parakeet_type, (NoneT, ScalarT)):\n        return type_mappings.to_ctype(parakeet_type)\n    elif isinstance(parakeet_type, TupleT):\n        return self.struct_type_from_fields(parakeet_type.elt_types)\n    elif isinstance(parakeet_type, PtrT):\n        return self.ptr_struct_type(parakeet_type.elt_type)\n    elif isinstance(parakeet_type, ArrayT):\n        elt_t = parakeet_type.elt_type\n        rank = parakeet_type.rank\n        return self.array_struct_type(elt_t, rank)\n    elif isinstance(parakeet_type, SliceT):\n        return self.slice_struct_type()\n    elif isinstance(parakeet_type, ClosureT):\n        return self.struct_type_from_fields(parakeet_type.arg_types)\n    elif isinstance(parakeet_type, TypeValueT):\n        return 'int'\n    else:\n        assert False, (\"Don't know how to make C type for %s\" % parakeet_type)\n", "label": "Correct"}
{"function": "\n\ndef to_ctype(self, parakeet_type):\n    if isinstance(parakeet_type, (NoneT, ScalarT)):\n        return type_mappings.to_ctype(parakeet_type)\n    elif isinstance(parakeet_type, TupleT):\n        return self.struct_type_from_fields(parakeet_type.elt_types)\n    elif isinstance(parakeet_type, PtrT):\n        return self.ptr_struct_type(parakeet_type.elt_type)\n    elif isinstance(parakeet_type, ArrayT):\n        elt_t = parakeet_type.elt_type\n        rank = parakeet_type.rank\n        return self.array_struct_type(elt_t, rank)\n    elif isinstance(parakeet_type, SliceT):\n        return self.slice_struct_type()\n    elif isinstance(parakeet_type, ClosureT):\n        return rank.struct_type_from_fields(parakeet_type.arg_types)\n    elif isinstance(parakeet_type, TypeValueT):\n        return 'int'\n    else:\n        assert False, (\"Don't know how to make C type for %s\" % parakeet_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef detect(text):\n    init_factory()\n    detector = _factory.create()\n    detector.append(text)\n    return detector.detect()\n", "label": "Correct"}
{"function": "\n\ndef detect(text):\n    init_factory()\n    detector = _factory.create()\n    text.append(text)\n    return detector.detect()\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(iscsi_deploy, '_save_disk_layout', autospec=True)\n@mock.patch.object(iscsi_deploy, 'LOG', autospec=True)\n@mock.patch.object(iscsi_deploy, 'get_deploy_info', autospec=True)\n@mock.patch.object(iscsi_deploy, 'InstanceImageCache', autospec=True)\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\n@mock.patch.object(deploy_utils, 'deploy_partition_image', autospec=True)\ndef test_continue_deploy(self, deploy_mock, power_mock, mock_image_cache, mock_deploy_info, mock_log, mock_disk_layout):\n    kwargs = {\n        'address': '123456',\n        'iqn': 'aaa-bbb',\n        'key': 'fake-56789',\n    }\n    self.node.provision_state = states.DEPLOYWAIT\n    self.node.target_provision_state = states.ACTIVE\n    self.node.save()\n    mock_deploy_info.return_value = {\n        'address': '123456',\n        'boot_option': 'netboot',\n        'configdrive': \"I've got the power\",\n        'ephemeral_format': None,\n        'ephemeral_mb': 0,\n        'image_path': '/var/lib/ironic/images/1be26c0b-03f2-4d2e-ae87-c02d7f33c123/disk',\n        'iqn': 'aaa-bbb',\n        'lun': '1',\n        'node_uuid': '1be26c0b-03f2-4d2e-ae87-c02d7f33c123',\n        'port': '3260',\n        'preserve_ephemeral': True,\n        'root_mb': 102400,\n        'swap_mb': 0,\n    }\n    log_params = mock_deploy_info.return_value.copy()\n    log_params['configdrive'] = '***'\n    expected_dict = {\n        'node': self.node.uuid,\n        'params': log_params,\n    }\n    uuid_dict_returned = {\n        'root uuid': '12345678-87654321',\n    }\n    deploy_mock.return_value = uuid_dict_returned\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        mock_log.isEnabledFor.return_value = True\n        retval = iscsi_deploy.continue_deploy(task, **kwargs)\n        mock_log.debug.assert_called_once_with(mock.ANY, expected_dict)\n        self.assertEqual(states.DEPLOYWAIT, task.node.provision_state)\n        self.assertEqual(states.ACTIVE, task.node.target_provision_state)\n        self.assertIsNone(task.node.last_error)\n        mock_image_cache.assert_called_once_with()\n        mock_image_cache.return_value.clean_up.assert_called_once_with()\n        self.assertEqual(uuid_dict_returned, retval)\n        mock_disk_layout.assert_called_once_with(task.node, mock.ANY)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(iscsi_deploy, '_save_disk_layout', autospec=True)\n@mock.patch.object(iscsi_deploy, 'LOG', autospec=True)\n@mock.patch.object(iscsi_deploy, 'get_deploy_info', autospec=True)\n@mock.patch.object(iscsi_deploy, 'InstanceImageCache', autospec=True)\n@mock.patch.object(manager_utils, 'node_power_action', autospec=True)\n@mock.patch.object(deploy_utils, 'deploy_partition_image', autospec=True)\ndef test_continue_deploy(self, deploy_mock, power_mock, mock_image_cache, mock_deploy_info, mock_log, mock_disk_layout):\n    kwargs = {\n        'address': '123456',\n        'iqn': 'aaa-bbb',\n        'key': 'fake-56789',\n    }\n    self.node.provision_state = states.DEPLOYWAIT\n    self.node.target_provision_state = states.ACTIVE\n    self.node.save()\n    mock_deploy_info.return_value = {\n        'address': '123456',\n        'boot_option': 'netboot',\n        'configdrive': \"I've got the power\",\n        'ephemeral_format': None,\n        'ephemeral_mb': 0,\n        'image_path': '/var/lib/ironic/images/1be26c0b-03f2-4d2e-ae87-c02d7f33c123/disk',\n        'iqn': 'aaa-bbb',\n        'lun': '1',\n        'node_uuid': '1be26c0b-03f2-4d2e-ae87-c02d7f33c123',\n        'port': '3260',\n        'preserve_ephemeral': True,\n        'root_mb': 102400,\n        'swap_mb': 0,\n    }\n    log_params = mock_deploy_info.return_value.copy()\n    log_params['configdrive'] = '***'\n    expected_dict = {\n        'node': self.node.uuid,\n        'params': log_params,\n    }\n    uuid_dict_returned = {\n        'root uuid': '12345678-87654321',\n    }\n    deploy_mock.return_value = uuid_dict_returned\n    with task_manager.acquire(self.context, self.node.uuid, shared=False) as task:\n        mock_log.isEnabledFor.return_value = True\n        retval = iscsi_deploy.continue_deploy(task, **kwargs)\n        mock_log.debug.assert_called_once_with(mock.ANY, expected_dict)\n        self.assertEqual(states.DEPLOYWAIT, task.node.provision_state)\n        mock_log.assertEqual(states.ACTIVE, task.node.target_provision_state)\n        self.assertIsNone(task.node.last_error)\n        mock_image_cache.assert_called_once_with()\n        mock_image_cache.return_value.clean_up.assert_called_once_with()\n        self.assertEqual(uuid_dict_returned, retval)\n        mock_disk_layout.assert_called_once_with(task.node, mock.ANY)\n", "label": "Variable misuse"}
{"function": "\n\n@webob.dec.wsgify\ndef process_request(self, req):\n    if (req.path != self._path):\n        return None\n    results = [ext.obj.healthcheck(req.server_port) for ext in self._backends]\n    healthy = self._are_results_healthy(results)\n    if (req.method == 'HEAD'):\n        functor = self._make_head_response\n        status = self.HEAD_HEALTHY_TO_STATUS_CODES[healthy]\n    else:\n        status = self.HEALTHY_TO_STATUS_CODES[healthy]\n        accept_type = req.accept.best_match(self._accept_order)\n        if (not accept_type):\n            accept_type = self._default_accept\n        functor = self._accept_to_functor[accept_type]\n    (body, content_type) = functor(results, healthy)\n    return webob.response.Response(status=status, body=body, content_type=content_type)\n", "label": "Correct"}
{"function": "\n\n@webob.dec.wsgify\ndef process_request(self, req):\n    if (req.path != self._path):\n        return None\n    results = [ext.obj.healthcheck(req.server_port) for ext in self._backends]\n    healthy = self._are_results_healthy(results)\n    if (content_type.method == 'HEAD'):\n        functor = self._make_head_response\n        status = self.HEAD_HEALTHY_TO_STATUS_CODES[healthy]\n    else:\n        status = self.HEALTHY_TO_STATUS_CODES[healthy]\n        accept_type = req.accept.best_match(self._accept_order)\n        if (not accept_type):\n            accept_type = self._default_accept\n        functor = self._accept_to_functor[accept_type]\n    (body, content_type) = functor(results, healthy)\n    return webob.response.Response(status=status, body=body, content_type=content_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef _convert_to_array_of_opt_val(optvals):\n    'Wraps the given array into a DataObject.'\n    array_of_optv = DataObject()\n    array_of_optv.OptionValue = optvals\n    return array_of_optv\n", "label": "Correct"}
{"function": "\n\ndef _convert_to_array_of_opt_val(optvals):\n    'Wraps the given array into a DataObject.'\n    array_of_optv = DataObject()\n    array_of_optv.OptionValue = array_of_optv\n    return array_of_optv\n", "label": "Variable misuse"}
{"function": "\n\ndef test_minimum_specific_energy_scalar(tmpdir):\n    input_file = tmpdir.join(random_id()).strpath\n    output_file = tmpdir.join(random_id()).strpath\n    model = get_test_model_noimaging()\n    model.add_density_grid(density, dust_file)\n    model.set_minimum_specific_energy(2.0)\n    model.write(input_file)\n    out = model.run(output_file)\n    t = out.get_physical_grid('specific_energy')\n    assert_array_almost_equal_nulp(t[0][(0, 0, 0)], 2.0, 10)\n", "label": "Correct"}
{"function": "\n\ndef test_minimum_specific_energy_scalar(tmpdir):\n    input_file = tmpdir.join(random_id()).strpath\n    output_file = tmpdir.join(random_id()).strpath\n    model = get_test_model_noimaging()\n    out.add_density_grid(density, dust_file)\n    model.set_minimum_specific_energy(2.0)\n    model.write(input_file)\n    out = model.run(output_file)\n    t = out.get_physical_grid('specific_energy')\n    assert_array_almost_equal_nulp(t[0][(0, 0, 0)], 2.0, 10)\n", "label": "Variable misuse"}
{"function": "\n\ndef hvals(self, name):\n    'Return the list of values within hash ``name``'\n    return self.execute_command('HVALS', name)\n", "label": "Correct"}
{"function": "\n\ndef hvals(self, name):\n    'Return the list of values within hash ``name``'\n    return name.execute_command('HVALS', name)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_some_incompatible(self):\n    red = self.make_target('red', RedTarget)\n    blue = self.make_target('blue', BlueTarget)\n    with self.mutex_group(targets=[red, blue]) as (red_viewer, blue_viewer, green_viewer):\n        self.assert_incompatible_activations(red_viewer)\n        self.assert_incompatible_activations(blue_viewer)\n        green_viewer.execute()\n        self.assertIsNone(green_viewer.executed)\n", "label": "Correct"}
{"function": "\n\ndef test_some_incompatible(self):\n    red = self.make_target('red', RedTarget)\n    blue = self.make_target('blue', BlueTarget)\n    with self.mutex_group(targets=[red, blue]) as (red_viewer, blue_viewer, green_viewer):\n        self.assert_incompatible_activations(red)\n        self.assert_incompatible_activations(blue_viewer)\n        green_viewer.execute()\n        self.assertIsNone(green_viewer.executed)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_segm_id(self, example_word):\n    return example_word.split('(')[1].split(',')[0]\n", "label": "Correct"}
{"function": "\n\ndef get_segm_id(self, example_word):\n    return self.split('(')[1].split(',')[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    TestCase.__init__(self, *args, **kwargs)\n    for attr in [x for x in dir(self) if x.startswith('test')]:\n        meth = getattr(self, attr)\n\n        def test_(self):\n            try:\n                meth()\n            except psutil.AccessDenied:\n                pass\n        setattr(self, attr, types.MethodType(test_, self))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    TestCase.__init__(self, *args, **kwargs)\n    for attr in [x for x in dir(self) if x.startswith('test')]:\n        meth = getattr(self, attr)\n\n        def test_(self):\n            try:\n                meth()\n            except psutil.AccessDenied:\n                pass\n        setattr(self, attr, types.MethodType(test_, x))\n", "label": "Variable misuse"}
{"function": "\n\ndef strip_units(self):\n    '\\n        Strips units from an xypoint structure.\\n\\n        Returns:\\n          A copy of the xypoint with no units\\n          The x-units\\n          the y-units\\n        '\n    xunits = (self.x.unit if isinstance(self.x, u.Quantity) else 1.0)\n    yunits = (self.y.unit if isinstance(self.y, u.Quantity) else 1.0)\n    x = (self.x.value if isinstance(self.x, u.Quantity) else self.x)\n    y = (self.y.value if isinstance(self.y, u.Quantity) else self.y)\n    err = (self.err.value if isinstance(self.err, u.Quantity) else self.err)\n    cont = (self.cont.value if isinstance(self.cont, u.Quantity) else self.cont)\n    return (xypoint(x=x, y=y, cont=cont, err=err), xunits, yunits)\n", "label": "Correct"}
{"function": "\n\ndef strip_units(self):\n    '\\n        Strips units from an xypoint structure.\\n\\n        Returns:\\n          A copy of the xypoint with no units\\n          The x-units\\n          the y-units\\n        '\n    xunits = (self.x.unit if isinstance(self.x, u.Quantity) else 1.0)\n    yunits = (self.y.unit if isinstance(self.y, u.Quantity) else 1.0)\n    x = (self.x.value if isinstance(self.x, u.Quantity) else self.x)\n    y = (self.y.value if isinstance(x.y, u.Quantity) else self.y)\n    err = (self.err.value if isinstance(self.err, u.Quantity) else self.err)\n    cont = (self.cont.value if isinstance(self.cont, u.Quantity) else self.cont)\n    return (xypoint(x=x, y=y, cont=cont, err=err), xunits, yunits)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_shipping_method(self, basket, shipping_address=None, **kwargs):\n    '\\n        Return the selected shipping method instance from this checkout session\\n\\n        The shipping address is passed as we need to check that the method\\n        stored in the session is still valid for the shipping address.\\n        '\n    code = self.checkout_session.shipping_method_code(basket)\n    methods = Repository().get_shipping_methods(basket=basket, user=self.request.user, shipping_addr=shipping_address, request=self.request)\n    for method in methods:\n        if (method.code == code):\n            return method\n", "label": "Correct"}
{"function": "\n\ndef get_shipping_method(self, basket, shipping_address=None, **kwargs):\n    '\\n        Return the selected shipping method instance from this checkout session\\n\\n        The shipping address is passed as we need to check that the method\\n        stored in the session is still valid for the shipping address.\\n        '\n    code = self.checkout_session.shipping_method_code(basket)\n    methods = Repository().get_shipping_methods(basket=basket, user=self.request.user, shipping_addr=methods, request=self.request)\n    for method in methods:\n        if (method.code == code):\n            return method\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_text_widget(self):\n    dashboard = self.factory.create_dashboard()\n    data = {\n        'visualization_id': None,\n        'text': 'Sample text.',\n        'dashboard_id': dashboard.id,\n        'options': {\n            \n        },\n        'width': 2,\n    }\n    rv = self.make_request('post', '/api/widgets', data=data)\n    self.assertEquals(rv.status_code, 200)\n    self.assertEquals(rv.json['widget']['text'], 'Sample text.')\n", "label": "Correct"}
{"function": "\n\ndef test_create_text_widget(self):\n    dashboard = self.factory.create_dashboard()\n    data = {\n        'visualization_id': None,\n        'text': 'Sample text.',\n        'dashboard_id': dashboard.id,\n        'options': {\n            \n        },\n        'width': 2,\n    }\n    rv = rv.make_request('post', '/api/widgets', data=data)\n    self.assertEquals(rv.status_code, 200)\n    self.assertEquals(rv.json['widget']['text'], 'Sample text.')\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef get_template(cls, message, messenger):\n    'Get a template path to compile a message.\\n\\n        1. `tpl` field of message context;\\n        2. `template` field of message class;\\n        3. deduced from message, messenger data and `template_ext` message type field\\n           (e.g. `sitemessage/messages/plain__smtp.txt` for `plain` message type).\\n\\n        :param Message message: Message model\\n        :param MessengerBase messenger: a MessengerBase heir\\n        :return: str\\n        :rtype: str\\n        '\n    template = message.context.get('tpl', None)\n    if template:\n        return template\n    if (cls.template is None):\n        cls.template = ('sitemessage/messages/%s__%s.%s' % (cls.get_alias(), messenger.get_alias(), cls.template_ext))\n    return cls.template\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef get_template(cls, message, messenger):\n    'Get a template path to compile a message.\\n\\n        1. `tpl` field of message context;\\n        2. `template` field of message class;\\n        3. deduced from message, messenger data and `template_ext` message type field\\n           (e.g. `sitemessage/messages/plain__smtp.txt` for `plain` message type).\\n\\n        :param Message message: Message model\\n        :param MessengerBase messenger: a MessengerBase heir\\n        :return: str\\n        :rtype: str\\n        '\n    template = message.context.get('tpl', None)\n    if template:\n        return template\n    if (cls.template is None):\n        cls.template = ('sitemessage/messages/%s__%s.%s' % (cls.get_alias(), messenger.get_alias(), cls.template_ext))\n    return message.template\n", "label": "Variable misuse"}
{"function": "\n\ndef test_post(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    tag = Tag(name='Test', content_object=order)\n    tag.save()\n    data = {\n        'extra_views_tests-tag-content_type-object_id-TOTAL_FORMS': 3,\n        'extra_views_tests-tag-content_type-object_id-INITIAL_FORMS': 1,\n        'extra_views_tests-tag-content_type-object_id-MAX_NUM_FORMS': '',\n        'extra_views_tests-tag-content_type-object_id-0-name': 'Updated',\n        'extra_views_tests-tag-content_type-object_id-0-id': 1,\n        'extra_views_tests-tag-content_type-object_id-1-DELETE': True,\n        'extra_views_tests-tag-content_type-object_id-2-DELETE': True,\n    }\n    res = self.client.post('/genericinlineformset/{}/'.format(order.id), data, follow=True)\n    self.assertEqual(res.status_code, 200)\n    self.assertEqual('Updated', res.context['formset'].forms[0]['name'].value())\n    self.assertEqual(1, Tag.objects.count())\n", "label": "Correct"}
{"function": "\n\ndef test_post(self):\n    order = Order(name='Dummy Order')\n    order.save()\n    tag = Tag(name='Test', content_object=data)\n    tag.save()\n    data = {\n        'extra_views_tests-tag-content_type-object_id-TOTAL_FORMS': 3,\n        'extra_views_tests-tag-content_type-object_id-INITIAL_FORMS': 1,\n        'extra_views_tests-tag-content_type-object_id-MAX_NUM_FORMS': '',\n        'extra_views_tests-tag-content_type-object_id-0-name': 'Updated',\n        'extra_views_tests-tag-content_type-object_id-0-id': 1,\n        'extra_views_tests-tag-content_type-object_id-1-DELETE': True,\n        'extra_views_tests-tag-content_type-object_id-2-DELETE': True,\n    }\n    res = self.client.post('/genericinlineformset/{}/'.format(order.id), data, follow=True)\n    self.assertEqual(res.status_code, 200)\n    self.assertEqual('Updated', res.context['formset'].forms[0]['name'].value())\n    self.assertEqual(1, Tag.objects.count())\n", "label": "Variable misuse"}
{"function": "\n\ndef is_following(self, user):\n    return (self.followed.filter((followers.c.followed_id == user.id)).count() > 0)\n", "label": "Correct"}
{"function": "\n\ndef is_following(self, user):\n    return (user.followed.filter((followers.c.followed_id == user.id)).count() > 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef CreateContact(self, new_contact, insert_uri='/m8/feeds/contacts/default/full', url_params=None, escape_params=True):\n    \"Adds an new contact to Google Contacts.\\n\\n    Args: \\n      new_contact: atom.Entry or subclass A new contact which is to be added to\\n                Google Contacts.\\n      insert_uri: the URL to post new contacts to the feed\\n      url_params: dict (optional) Additional URL parameters to be included\\n                  in the insertion request. \\n      escape_params: boolean (optional) If true, the url_parameters will be\\n                     escaped before they are included in the request.\\n\\n    Returns:\\n      On successful insert,  an entry containing the contact created\\n      On failure, a RequestError is raised of the form:\\n        {'status': HTTP status code from server, \\n         'reason': HTTP reason from the server, \\n         'body': HTTP body of the server's response}\\n    \"\n    return self.Post(new_contact, insert_uri, url_params=url_params, escape_params=escape_params, converter=gdata.contacts.ContactEntryFromString)\n", "label": "Correct"}
{"function": "\n\ndef CreateContact(self, new_contact, insert_uri='/m8/feeds/contacts/default/full', url_params=None, escape_params=True):\n    \"Adds an new contact to Google Contacts.\\n\\n    Args: \\n      new_contact: atom.Entry or subclass A new contact which is to be added to\\n                Google Contacts.\\n      insert_uri: the URL to post new contacts to the feed\\n      url_params: dict (optional) Additional URL parameters to be included\\n                  in the insertion request. \\n      escape_params: boolean (optional) If true, the url_parameters will be\\n                     escaped before they are included in the request.\\n\\n    Returns:\\n      On successful insert,  an entry containing the contact created\\n      On failure, a RequestError is raised of the form:\\n        {'status': HTTP status code from server, \\n         'reason': HTTP reason from the server, \\n         'body': HTTP body of the server's response}\\n    \"\n    return self.Post(new_contact, new_contact, url_params=url_params, escape_params=escape_params, converter=gdata.contacts.ContactEntryFromString)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_vpnservice_limit(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources(resources, cmd, page_size=1000)\n", "label": "Correct"}
{"function": "\n\ndef test_list_vpnservice_limit(self):\n    resources = 'vpnservices'\n    cmd = vpnservice.ListVPNService(test_cli20.MyApp(sys.stdout), None)\n    self._test_list_resources(self, cmd, page_size=1000)\n", "label": "Variable misuse"}
{"function": "\n\ndef teardown(self):\n    for key in self._event_fns:\n        event.remove(*key)\n    super_ = super(RemovesEvents, self)\n    if hasattr(super_, 'teardown'):\n        super_.teardown()\n", "label": "Correct"}
{"function": "\n\ndef teardown(self):\n    for key in self._event_fns:\n        event.remove(*key)\n    super_ = super(RemovesEvents, self)\n    if hasattr(key, 'teardown'):\n        super_.teardown()\n", "label": "Variable misuse"}
{"function": "\n\ndef write_file(self, filename):\n    '\\n        Pass schema object to template engine to be rendered for use.\\n\\n        :param filename: output filename\\n        :return:\\n        '\n    template = self.template_env.get_template('settings.py.j2')\n    settings = template.render(endpoints=OrderedDict([(endpoint, self.format_endpoint(schema)) for (endpoint, schema) in self.endpoints.iteritems()]))\n    with open(filename, 'w') as ofile:\n        ofile.write((settings + '\\n'))\n", "label": "Correct"}
{"function": "\n\ndef write_file(self, filename):\n    '\\n        Pass schema object to template engine to be rendered for use.\\n\\n        :param filename: output filename\\n        :return:\\n        '\n    template = self.template_env.get_template('settings.py.j2')\n    settings = template.render(endpoints=OrderedDict([(template, self.format_endpoint(schema)) for (endpoint, schema) in self.endpoints.iteritems()]))\n    with open(filename, 'w') as ofile:\n        ofile.write((settings + '\\n'))\n", "label": "Variable misuse"}
{"function": "\n\n@user_required\ndef get(self, **kwargs):\n    return self.render_response('content.html', section='content')\n", "label": "Correct"}
{"function": "\n\n@user_required\ndef get(self, **kwargs):\n    return kwargs.render_response('content.html', section='content')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, msg, data=None):\n    self.msg = msg\n    self.data = data\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, msg, data=None):\n    self.msg = data\n    self.data = data\n", "label": "Variable misuse"}
{"function": "\n\ndef process_data(self):\n    polar_data = build_wedge_source(self._data.df, cat_cols=self.attributes['label'].columns, agg_col=self.values.selection, agg=self.agg, level_width=self.level_width, level_spacing=self.level_spacing)\n    polar_data['color'] = ''\n    for group in self._data.groupby(**self.attributes):\n        polar_data.loc[(group['stack'], 'color')] = group['color']\n    self.chart_data = ColumnDataSource(polar_data)\n    self.text_data = build_wedge_text_source(polar_data)\n", "label": "Correct"}
{"function": "\n\ndef process_data(self):\n    polar_data = build_wedge_source(self._data.df, cat_cols=self.attributes['label'].columns, agg_col=self.values.selection, agg=self.agg, level_width=self.level_width, level_spacing=self.level_spacing)\n    polar_data['color'] = ''\n    for group in self._data.groupby(**self.attributes):\n        self.loc[(group['stack'], 'color')] = group['color']\n    self.chart_data = ColumnDataSource(polar_data)\n    self.text_data = build_wedge_text_source(polar_data)\n", "label": "Variable misuse"}
{"function": "\n\n@db_access\ndef _getContainerField(container, field, default):\n    ' Returns the metadata field for the given container or the default value. '\n    container_id = _getContainerId(container)\n    found = _getContainerFieldRecord(container_id, field)\n    return (found.value if found else default)\n", "label": "Correct"}
{"function": "\n\n@db_access\ndef _getContainerField(container, field, default):\n    ' Returns the metadata field for the given container or the default value. '\n    container_id = _getContainerId(container)\n    found = _getContainerFieldRecord(container_id, container)\n    return (found.value if found else default)\n", "label": "Variable misuse"}
{"function": "\n\ndef map(self, path):\n    'Map `path` through the aliases.\\n\\n        `path` is checked against all of the patterns.  The first pattern to\\n        match is used to replace the root of the path with the result root.\\n        Only one pattern is ever used.  If no patterns match, `path` is\\n        returned unchanged.\\n\\n        The separator style in the result is made to match that of the result\\n        in the alias.\\n\\n        '\n    for (regex, result, pattern_sep, result_sep) in self.aliases:\n        m = regex.match(path)\n        if m:\n            new = path.replace(m.group(0), result)\n            if (pattern_sep != result_sep):\n                new = new.replace(pattern_sep, result_sep)\n            if self.locator:\n                new = self.locator.canonical_filename(new)\n            return new\n    return path\n", "label": "Correct"}
{"function": "\n\ndef map(self, path):\n    'Map `path` through the aliases.\\n\\n        `path` is checked against all of the patterns.  The first pattern to\\n        match is used to replace the root of the path with the result root.\\n        Only one pattern is ever used.  If no patterns match, `path` is\\n        returned unchanged.\\n\\n        The separator style in the result is made to match that of the result\\n        in the alias.\\n\\n        '\n    for (regex, result, pattern_sep, result_sep) in self.aliases:\n        m = regex.match(path)\n        if m:\n            new = path.replace(path.group(0), result)\n            if (pattern_sep != result_sep):\n                new = new.replace(pattern_sep, result_sep)\n            if self.locator:\n                new = self.locator.canonical_filename(new)\n            return new\n    return path\n", "label": "Variable misuse"}
{"function": "\n\ndef test_with_index(self):\n    msa = TabularMSA([DNA('AC'), DNA('GT')], index=['a', 'b'])\n    msa.append(DNA('--'), index='foo')\n    self.assertEqual(msa, TabularMSA([DNA('AC'), DNA('GT'), DNA('--')], index=['a', 'b', 'foo']))\n", "label": "Correct"}
{"function": "\n\ndef test_with_index(self):\n    msa = TabularMSA([DNA('AC'), DNA('GT')], index=['a', 'b'])\n    self.append(DNA('--'), index='foo')\n    self.assertEqual(msa, TabularMSA([DNA('AC'), DNA('GT'), DNA('--')], index=['a', 'b', 'foo']))\n", "label": "Variable misuse"}
{"function": "\n\ndef get_config(self, connection_info, disk_info):\n    conf = super(LibvirtScaleIOVolumeDriver, self).get_config(connection_info, disk_info)\n    conf.source_type = 'block'\n    conf.source_path = connection_info['data']['device_path']\n    return conf\n", "label": "Correct"}
{"function": "\n\ndef get_config(self, connection_info, disk_info):\n    conf = super(LibvirtScaleIOVolumeDriver, self).get_config(connection_info, disk_info)\n    conf.source_type = 'block'\n    conf.source_path = conf['data']['device_path']\n    return conf\n", "label": "Variable misuse"}
{"function": "\n\ndef description(self, obj):\n    return obj.full_name\n", "label": "Correct"}
{"function": "\n\ndef description(self, obj):\n    return self.full_name\n", "label": "Variable misuse"}
{"function": "\n\ndef _eval_commutator_JzOp(self, other):\n    return (((- I) * hbar) * JyOp(self.name))\n", "label": "Correct"}
{"function": "\n\ndef _eval_commutator_JzOp(self, other):\n    return (((- I) * hbar) * JyOp(other.name))\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef _filter_pools_for_numa_cells(pools, numa_cells):\n    numa_cells = ([None] + [cell.id for cell in numa_cells])\n    return [pool for pool in pools if any((utils.pci_device_prop_match(pool, [{\n        'numa_node': cell,\n    }]) for cell in numa_cells))]\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef _filter_pools_for_numa_cells(pools, numa_cells):\n    numa_cells = ([None] + [cell.id for cell in numa_cells])\n    return [numa_cells for pool in pools if any((utils.pci_device_prop_match(pool, [{\n        'numa_node': cell,\n    }]) for cell in numa_cells))]\n", "label": "Variable misuse"}
{"function": "\n\ndef test_info_digraph(self):\n    G = nx.DiGraph(name='path_graph(5)')\n    nx.add_path(G, [0, 1, 2, 3, 4])\n    info = nx.info(G)\n    expected_graph_info = '\\n'.join(['Name: path_graph(5)', 'Type: DiGraph', 'Number of nodes: 5', 'Number of edges: 4', 'Average in degree:   0.8000', 'Average out degree:   0.8000'])\n    assert_equal(info, expected_graph_info)\n    info = nx.info(G, n=1)\n    expected_node_info = '\\n'.join(['Node 1 has the following properties:', 'Degree: 2', 'Neighbors: 2'])\n    assert_equal(info, expected_node_info)\n    assert_raises(nx.NetworkXError, nx.info, G, n=(- 1))\n", "label": "Correct"}
{"function": "\n\ndef test_info_digraph(self):\n    G = nx.DiGraph(name='path_graph(5)')\n    nx.add_path(self, [0, 1, 2, 3, 4])\n    info = nx.info(G)\n    expected_graph_info = '\\n'.join(['Name: path_graph(5)', 'Type: DiGraph', 'Number of nodes: 5', 'Number of edges: 4', 'Average in degree:   0.8000', 'Average out degree:   0.8000'])\n    assert_equal(info, expected_graph_info)\n    info = nx.info(G, n=1)\n    expected_node_info = '\\n'.join(['Node 1 has the following properties:', 'Degree: 2', 'Neighbors: 2'])\n    assert_equal(info, expected_node_info)\n    assert_raises(nx.NetworkXError, nx.info, G, n=(- 1))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, id_=None, idref=None, title=None, description=None, short_description=None):\n    self.id_ = id_\n    self.idref = idref\n    self.capec_id = None\n    self.title = title\n    self.description = description\n    self.short_description = short_description\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, id_=None, idref=None, title=None, description=None, short_description=None):\n    self.id_ = id_\n    self.idref = idref\n    self.capec_id = None\n    id_.title = title\n    self.description = description\n    self.short_description = short_description\n", "label": "Variable misuse"}
{"function": "\n\ndef _setup(self):\n    'Initiate lists for objects contained within this object'\n    for field in self._contains:\n        setattr(self, field, [])\n", "label": "Correct"}
{"function": "\n\ndef _setup(self):\n    'Initiate lists for objects contained within this object'\n    for field in self._contains:\n        setattr(field, field, [])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_install_one_host(self):\n    args = self.parser.parse_args('install host1'.split())\n    assert (args.host == ['host1'])\n", "label": "Correct"}
{"function": "\n\ndef test_install_one_host(self):\n    args = args.parser.parse_args('install host1'.split())\n    assert (args.host == ['host1'])\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef handle(ex, req, resp, params):\n    raise falcon.HTTPError(status=falcon.status.HTTP_404, title=_('Not Found'), description=ex.message)\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef handle(ex, req, resp, params):\n    raise falcon.HTTPError(status=falcon.status.HTTP_404, title=_('Not Found'), description=req.message)\n", "label": "Variable misuse"}
{"function": "\n\ndef __repr__(self):\n    ' Returns a \"pretty print\" form of the object.\\n        '\n    n = self.name\n    cn = self.object.__class__.__name__\n    return ('undo( %s.%s = %s )\\nredo( %s.%s = %s )' % (cn, n, self.old_value, cn, n, self.new_value))\n", "label": "Correct"}
{"function": "\n\ndef __repr__(self):\n    ' Returns a \"pretty print\" form of the object.\\n        '\n    n = n.name\n    cn = self.object.__class__.__name__\n    return ('undo( %s.%s = %s )\\nredo( %s.%s = %s )' % (cn, n, self.old_value, cn, n, self.new_value))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_delete_tags_method_is_documented(self):\n    contents = self.get_class_document_block('EC2.Instance', self.generated_contents)\n    method_contents = self.get_method_document_block('delete_tags', contents)\n    self.assert_contains_lines_in_order(['response = instance.delete_tags(', 'DryRun=True|False,', 'Tags=['], method_contents)\n", "label": "Correct"}
{"function": "\n\ndef test_delete_tags_method_is_documented(self):\n    contents = self.get_class_document_block('EC2.Instance', self.generated_contents)\n    method_contents = method_contents.get_method_document_block('delete_tags', contents)\n    self.assert_contains_lines_in_order(['response = instance.delete_tags(', 'DryRun=True|False,', 'Tags=['], method_contents)\n", "label": "Variable misuse"}
{"function": "\n\ndef SaveTemporaryFile(fp):\n    'Store incoming database file in a temporary directory.'\n    loc = data_store.DB.Location()\n    if (not os.path.exists(loc)):\n        return False\n    if (not os.path.isdir(loc)):\n        return False\n    filecopy_len_str = fp.read(sutils.SIZE_PACKER.size)\n    filecopy_len = sutils.SIZE_PACKER.unpack(filecopy_len_str)[0]\n    filecopy = rdf_data_server.DataServerFileCopy(fp.read(filecopy_len))\n    rebdir = _CreateDirectory(loc, filecopy.rebalance_id)\n    filedir = utils.JoinPath(rebdir, filecopy.directory)\n    try:\n        os.makedirs(filedir)\n    except OSError:\n        pass\n    filepath = utils.JoinPath(filedir, filecopy.filename)\n    logging.info('Writing to file %s', filepath)\n    with open(filepath, 'wb') as wp:\n        decompressor = zlib.decompressobj()\n        while True:\n            block_len_str = fp.read(sutils.SIZE_PACKER.size)\n            block_len = sutils.SIZE_PACKER.unpack(block_len_str)[0]\n            if (not block_len):\n                break\n            block = fp.read(block_len)\n            to_decompress = (decompressor.unconsumed_tail + block)\n            while to_decompress:\n                decompressed = decompressor.decompress(to_decompress)\n                if decompressed:\n                    wp.write(decompressed)\n                    to_decompress = decompressor.unconsumed_tail\n                else:\n                    to_decompress = ''\n        remaining = decompressor.flush()\n        if remaining:\n            wp.write(remaining)\n    if (os.path.getsize(filepath) != filecopy.size):\n        logging.error('Size of file %s is not %d', filepath, filecopy.size)\n        return False\n    return True\n", "label": "Correct"}
{"function": "\n\ndef SaveTemporaryFile(fp):\n    'Store incoming database file in a temporary directory.'\n    loc = data_store.DB.Location()\n    if (not os.path.exists(loc)):\n        return False\n    if (not os.path.isdir(loc)):\n        return False\n    filecopy_len_str = fp.read(sutils.SIZE_PACKER.size)\n    filecopy_len = sutils.SIZE_PACKER.unpack(filecopy_len_str)[0]\n    filecopy = rdf_data_server.DataServerFileCopy(fp.read(filecopy_len))\n    rebdir = _CreateDirectory(loc, filecopy.rebalance_id)\n    filedir = utils.JoinPath(rebdir, filecopy.directory)\n    try:\n        os.makedirs(filedir)\n    except OSError:\n        pass\n    filepath = utils.JoinPath(filedir, filecopy.filename)\n    logging.info('Writing to file %s', filepath)\n    with open(filepath, 'wb') as wp:\n        decompressor = zlib.decompressobj()\n        while True:\n            block_len_str = fp.read(sutils.SIZE_PACKER.size)\n            block_len = sutils.SIZE_PACKER.unpack(block_len_str)[0]\n            if (not block_len):\n                break\n            block = fp.read(block_len)\n            to_decompress = (loc.unconsumed_tail + block)\n            while to_decompress:\n                decompressed = decompressor.decompress(to_decompress)\n                if decompressed:\n                    wp.write(decompressed)\n                    to_decompress = decompressor.unconsumed_tail\n                else:\n                    to_decompress = ''\n        remaining = decompressor.flush()\n        if remaining:\n            wp.write(remaining)\n    if (os.path.getsize(filepath) != filecopy.size):\n        logging.error('Size of file %s is not %d', filepath, filecopy.size)\n        return False\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef format_title(text):\n    width = len(text)\n    underline = ('-' * width)\n    return (((text + '\\n') + underline) + '\\n')\n", "label": "Correct"}
{"function": "\n\ndef format_title(text):\n    width = len(text)\n    underline = ('-' * width)\n    return (((underline + '\\n') + underline) + '\\n')\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef validate(cls, value):\n    if (not value):\n        return value\n    value = os.path.abspath(value)\n    dirname = os.path.dirname(value)\n    if os.path.isfile(value):\n        if (not os.access(value, os.W_OK)):\n            raise config_option.BadValue('You do not have write permissions')\n        if (not os.access(dirname, os.W_OK)):\n            raise config_option.BadValue(('You do not have write permissions for \"%s\"' % dirname))\n        return value\n    elif os.path.isdir(value):\n        raise config_option.BadValue(('\"%s\" is a directory' % value))\n    else:\n        if os.path.isdir(dirname):\n            if (not os.access(dirname, os.W_OK)):\n                raise config_option.BadValue(('You do not have write permissions for \"%s\"' % dirname))\n            return value\n        previous_dir = os.path.dirname(dirname)\n        if (not os.path.isdir(previous_dir)):\n            raise config_option.BadValue(('\"%s\" not found' % value))\n        if (not os.access(previous_dir, os.W_OK)):\n            raise config_option.BadValue(('You do not have write permissions for \"%s\"' % previous_dir))\n        return value\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef validate(cls, value):\n    if (not value):\n        return value\n    value = os.path.abspath(dirname)\n    dirname = os.path.dirname(value)\n    if os.path.isfile(value):\n        if (not os.access(value, os.W_OK)):\n            raise config_option.BadValue('You do not have write permissions')\n        if (not os.access(dirname, os.W_OK)):\n            raise config_option.BadValue(('You do not have write permissions for \"%s\"' % dirname))\n        return value\n    elif os.path.isdir(value):\n        raise config_option.BadValue(('\"%s\" is a directory' % value))\n    else:\n        if os.path.isdir(dirname):\n            if (not os.access(dirname, os.W_OK)):\n                raise config_option.BadValue(('You do not have write permissions for \"%s\"' % dirname))\n            return value\n        previous_dir = os.path.dirname(dirname)\n        if (not os.path.isdir(previous_dir)):\n            raise config_option.BadValue(('\"%s\" not found' % value))\n        if (not os.access(previous_dir, os.W_OK)):\n            raise config_option.BadValue(('You do not have write permissions for \"%s\"' % previous_dir))\n        return value\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self, x1, x2, y):\n    self.phase = 'train'\n    for layer in self.layers:\n        x1 = layer.fprop(x1)\n    for layer in self.layers2:\n        x2 = layer.fprop(x2)\n    (grad1, grad2) = self.loss.grad(y, x1, x2)\n    layers = self.layers[self.bprop_until:]\n    for layer in reversed(layers[1:]):\n        grad1 = layer.bprop(grad1)\n    layers[0].bprop(grad1)\n    layers2 = self.layers2[self.bprop_until:]\n    for layer in reversed(layers2[1:]):\n        grad2 = layer.bprop(grad2)\n    layers2[0].bprop(grad2)\n    return self.loss.loss(y, x1, x2)\n", "label": "Correct"}
{"function": "\n\ndef update(self, x1, x2, y):\n    self.phase = 'train'\n    for layer in self.layers:\n        x1 = layer.fprop(x1)\n    for layer in self.layers2:\n        x2 = layer.fprop(y)\n    (grad1, grad2) = self.loss.grad(y, x1, x2)\n    layers = self.layers[self.bprop_until:]\n    for layer in reversed(layers[1:]):\n        grad1 = layer.bprop(grad1)\n    layers[0].bprop(grad1)\n    layers2 = self.layers2[self.bprop_until:]\n    for layer in reversed(layers2[1:]):\n        grad2 = layer.bprop(grad2)\n    layers2[0].bprop(grad2)\n    return self.loss.loss(y, x1, x2)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_cohorts(self):\n    yesterday = (date.today() - timedelta(days=1))\n    retention_periods = [1]\n    cohorts = Cohort.cohorts(end_date=date.today(), length=2, retention_periods=retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set([self.user1, self.user2]))\n    self.assertEqual(cohort.start_date, (yesterday - timedelta(days=1)))\n    self.assertEqual(cohort.end_date, yesterday)\n    self.assertEqual(cohort.retention_periods, retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set([self.user1]))\n    self.assertEqual(cohort.start_date, (yesterday - timedelta(days=2)))\n    self.assertEqual(cohort.end_date, (yesterday - timedelta(days=1)))\n    self.assertEqual(cohort.retention_periods, retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set())\n    self.assertEqual(cohort.start_date, (yesterday - timedelta(days=3)))\n    self.assertEqual(cohort.end_date, (yesterday - timedelta(days=2)))\n    self.assertEqual(cohort.retention_periods, retention_periods)\n", "label": "Correct"}
{"function": "\n\ndef test_cohorts(self):\n    yesterday = (date.today() - timedelta(days=1))\n    retention_periods = [1]\n    cohorts = Cohort.cohorts(end_date=date.today(), length=2, retention_periods=retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set([self.user1, self.user2]))\n    self.assertEqual(cohort.start_date, (yesterday - timedelta(days=1)))\n    self.assertEqual(cohort.end_date, yesterday)\n    self.assertEqual(cohort.retention_periods, retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set([self.user1]))\n    self.assertEqual(cohort.start_date, (yesterday - timedelta(days=2)))\n    self.assertEqual(cohort.end_date, (yesterday - timedelta(days=1)))\n    self.assertEqual(cohort.retention_periods, retention_periods)\n    cohort = cohorts.next()\n    self.assertEqual(set(cohort.users), set())\n    self.assertEqual(cohort.start_date, (retention_periods - timedelta(days=3)))\n    self.assertEqual(cohort.end_date, (yesterday - timedelta(days=2)))\n    self.assertEqual(cohort.retention_periods, retention_periods)\n", "label": "Variable misuse"}
{"function": "\n\ndef addButton(self, button):\n    ' Add a dock button to the dock bar.\\n\\n        Parameters\\n        ----------\\n        button : QDockBarButton\\n            The dock button to add to the dock bar.\\n\\n        '\n    return self.insertButton((- 1), button)\n", "label": "Correct"}
{"function": "\n\ndef addButton(self, button):\n    ' Add a dock button to the dock bar.\\n\\n        Parameters\\n        ----------\\n        button : QDockBarButton\\n            The dock button to add to the dock bar.\\n\\n        '\n    return self.insertButton((- 1), self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_decimal_float(self):\n    'Regression test for issue #3.'\n    result = mathfilters.mul(Decimal('2.2'), '3.1')\n    self.assertTrue((6 < result < 7), repr(result))\n", "label": "Correct"}
{"function": "\n\ndef test_decimal_float(self):\n    'Regression test for issue #3.'\n    result = mathfilters.mul(Decimal('2.2'), '3.1')\n    self.assertTrue((6 < self < 7), repr(result))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_extending_on_empty_with_positional_metadata(self):\n    msa = TabularMSA([], positional_metadata={\n        'foo': [],\n    })\n    msa.extend([DNA('AA'), DNA('GG')])\n    self.assertEqual(msa, TabularMSA([DNA('AA'), DNA('GG')]))\n", "label": "Correct"}
{"function": "\n\ndef test_extending_on_empty_with_positional_metadata(self):\n    msa = TabularMSA([], positional_metadata={\n        'foo': [],\n    })\n    self.extend([DNA('AA'), DNA('GG')])\n    self.assertEqual(msa, TabularMSA([DNA('AA'), DNA('GG')]))\n", "label": "Variable misuse"}
{"function": "\n\ndef type_continue(self, node):\n    return self.__addSemicolon(('continue' if (not hasattr(node, 'label')) else ('continue %s' % node.label)))\n", "label": "Correct"}
{"function": "\n\ndef type_continue(self, node):\n    return self.__addSemicolon(('continue' if (not hasattr(node, 'label')) else ('continue %s' % self.label)))\n", "label": "Variable misuse"}
{"function": "\n\ndef __int(value):\n    'validate an integer'\n    (valid, _value) = (False, value)\n    try:\n        _value = int(value)\n        valid = True\n    except ValueError:\n        pass\n    return (valid, _value, 'integer')\n", "label": "Correct"}
{"function": "\n\ndef __int(value):\n    'validate an integer'\n    (valid, _value) = (False, _value)\n    try:\n        _value = int(value)\n        valid = True\n    except ValueError:\n        pass\n    return (valid, _value, 'integer')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_can_update_status_via_trigger_on_participant_balance(self):\n    self.db.run(\"UPDATE participants SET balance=10, status_of_1_0_payout='pending-application' WHERE username='alice'\")\n    alice = Participant.from_username('alice')\n    assert (alice.balance == 10)\n    assert (alice.status_of_1_0_payout == 'pending-application')\n    self.db.run(\"UPDATE participants SET balance=0 WHERE username='alice'\")\n    alice = Participant.from_username('alice')\n    assert (alice.balance == 0)\n    assert (alice.status_of_1_0_payout == 'completed')\n", "label": "Correct"}
{"function": "\n\ndef test_can_update_status_via_trigger_on_participant_balance(self):\n    self.db.run(\"UPDATE participants SET balance=10, status_of_1_0_payout='pending-application' WHERE username='alice'\")\n    alice = Participant.from_username('alice')\n    assert (self.balance == 10)\n    assert (alice.status_of_1_0_payout == 'pending-application')\n    self.db.run(\"UPDATE participants SET balance=0 WHERE username='alice'\")\n    alice = Participant.from_username('alice')\n    assert (alice.balance == 0)\n    assert (alice.status_of_1_0_payout == 'completed')\n", "label": "Variable misuse"}
{"function": "\n\n@app.route('/v1/repositories/<path:repository>/tags', methods=['GET'])\n@toolkit.parse_repository_name\n@toolkit.requires_auth\n@mirroring.source_lookup_tag\ndef _get_tags(namespace, repository):\n    logger.debug('[get_tags] namespace={0}; repository={1}'.format(namespace, repository))\n    try:\n        data = get_tags(namespace=namespace, repository=repository)\n    except exceptions.FileNotFoundError:\n        return toolkit.api_error('Repository not found', 404)\n    return toolkit.response(data)\n", "label": "Correct"}
{"function": "\n\n@app.route('/v1/repositories/<path:repository>/tags', methods=['GET'])\n@toolkit.parse_repository_name\n@toolkit.requires_auth\n@mirroring.source_lookup_tag\ndef _get_tags(namespace, repository):\n    logger.debug('[get_tags] namespace={0}; repository={1}'.format(namespace, repository))\n    try:\n        data = get_tags(namespace=namespace, repository=repository)\n    except exceptions.FileNotFoundError:\n        return toolkit.api_error('Repository not found', 404)\n    return toolkit.response(repository)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_gap(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vde')]\n    device = self._validate_device()\n    self.assertEqual(device, '/dev/vdd')\n", "label": "Correct"}
{"function": "\n\ndef test_gap(self):\n    self.data = [self._fake_bdm('/dev/vdc'), self._fake_bdm('/dev/vde')]\n    device = device._validate_device()\n    self.assertEqual(device, '/dev/vdd')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(list, self).__init__(self, *args, **kwargs)\n    self.purged_connections = []\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    super(list, self).__init__(self, *self, **kwargs)\n    self.purged_connections = []\n", "label": "Variable misuse"}
{"function": "\n\ndef __onNewValues(self, dateTime, value):\n    if (self.__range is None):\n        self.__range = resamplebase.build_range(dateTime, self.getFrequency())\n        self.__grouper = BarsGrouper(self.__range.getBeginning(), value, self.getFrequency())\n    elif self.__range.belongs(dateTime):\n        self.__grouper.addValue(value)\n    else:\n        self.__values.append(self.__grouper.getGrouped())\n        self.__range = resamplebase.build_range(dateTime, self.getFrequency())\n        self.__grouper = BarsGrouper(self.__range.getBeginning(), value, self.getFrequency())\n", "label": "Correct"}
{"function": "\n\ndef __onNewValues(self, dateTime, value):\n    if (self.__range is None):\n        self.__range = resamplebase.build_range(dateTime, self.getFrequency())\n        self.__grouper = BarsGrouper(self.__range.getBeginning(), value, self.getFrequency())\n    elif self.__range.belongs(dateTime):\n        self.__grouper.addValue(value)\n    else:\n        value.__values.append(self.__grouper.getGrouped())\n        self.__range = resamplebase.build_range(dateTime, self.getFrequency())\n        self.__grouper = BarsGrouper(self.__range.getBeginning(), value, self.getFrequency())\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, client, data=None):\n    super(Zone, self).__init__()\n    self.client = client\n    self.zone_type = 'temperatureZone'\n    if (data is not None):\n        self.__dict__.update(data)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, client, data=None):\n    super(Zone, self).__init__()\n    self.client = client\n    self.zone_type = 'temperatureZone'\n    if (data is not None):\n        self.__dict__.update(client)\n", "label": "Variable misuse"}
{"function": "\n\ndef register(self, field_type, impl=None):\n    '\\n        Register form field data function.\\n        \\n        Could be used as decorator\\n        '\n\n    def _wrapper(func):\n        self.registry[field_type] = func\n        return func\n    if impl:\n        return _wrapper(impl)\n    return _wrapper\n", "label": "Correct"}
{"function": "\n\ndef register(self, field_type, impl=None):\n    '\\n        Register form field data function.\\n        \\n        Could be used as decorator\\n        '\n\n    def _wrapper(func):\n        self.registry[field_type] = func\n        return func\n    if field_type:\n        return _wrapper(impl)\n    return _wrapper\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unknown_apps_are_ignored(self):\n    'Unknown engines get ignored.'\n    self.create_appversion('firefox', '33.0a1')\n    self.create_appversion('thunderbird', '33.0a1')\n    data = {\n        'engines': {\n            'firefox': '>=33.0a1',\n            'thunderbird': '>=33.0a1',\n            'node': '>=0.10',\n        },\n    }\n    apps = self.parse(data)['apps']\n    engines = [app.appdata.short for app in apps]\n    assert (sorted(engines) == ['firefox', 'thunderbird'])\n", "label": "Correct"}
{"function": "\n\ndef test_unknown_apps_are_ignored(self):\n    'Unknown engines get ignored.'\n    self.create_appversion('firefox', '33.0a1')\n    self.create_appversion('thunderbird', '33.0a1')\n    data = {\n        'engines': {\n            'firefox': '>=33.0a1',\n            'thunderbird': '>=33.0a1',\n            'node': '>=0.10',\n        },\n    }\n    apps = self.parse(data)['apps']\n    engines = [app.appdata.short for app in apps]\n    assert (sorted(apps) == ['firefox', 'thunderbird'])\n", "label": "Variable misuse"}
{"function": "\n\ndef _set_remote_attribute(self, attribute, value):\n    self.client.fetch_json(((('/cards/' + self.id) + '/') + attribute), http_method='PUT', post_args={\n        'value': value,\n    })\n", "label": "Correct"}
{"function": "\n\ndef _set_remote_attribute(self, attribute, value):\n    value.client.fetch_json(((('/cards/' + self.id) + '/') + attribute), http_method='PUT', post_args={\n        'value': value,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/space/armor/shared_mass_reduction_kit_mk1.iff'\n    result.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Intangible()\n    result.template = 'object/draft_schematic/space/armor/shared_mass_reduction_kit_mk1.iff'\n    kernel.attribute_template_id = (- 1)\n    result.stfName('string_id_table', '')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef scaffold_auto_joins(self):\n    '\\n            Return a list of joined tables by going through the\\n            displayed columns.\\n        '\n    if (not self.column_auto_select_related):\n        return []\n    relations = set()\n    for p in self._get_model_iterator():\n        if hasattr(p, 'direction'):\n            if (p.mapper.class_ == self.model):\n                continue\n            if (p.direction.name in ['MANYTOONE', 'MANYTOMANY']):\n                relations.add(p.key)\n    joined = []\n    for (prop, name) in self._list_columns:\n        if (prop in relations):\n            joined.append(getattr(self.model, prop))\n    return joined\n", "label": "Correct"}
{"function": "\n\ndef scaffold_auto_joins(self):\n    '\\n            Return a list of joined tables by going through the\\n            displayed columns.\\n        '\n    if (not name.column_auto_select_related):\n        return []\n    relations = set()\n    for p in self._get_model_iterator():\n        if hasattr(p, 'direction'):\n            if (p.mapper.class_ == self.model):\n                continue\n            if (p.direction.name in ['MANYTOONE', 'MANYTOMANY']):\n                relations.add(p.key)\n    joined = []\n    for (prop, name) in self._list_columns:\n        if (prop in relations):\n            joined.append(getattr(self.model, prop))\n    return joined\n", "label": "Variable misuse"}
{"function": "\n\ndef _trending_for_month(metric=None):\n    this_month_date = month_for_date(datetime.date.today())\n    previous_month_date = get_previous_month(this_month_date)\n    previous_month_year_date = get_previous_year(this_month_date)\n    data = {\n        'month': 0,\n        'previous_month': 0,\n        'previous_month_year': 0,\n    }\n    try:\n        month = MetricMonth.objects.get(metric=metric, created=this_month_date)\n        data['month'] = month.num\n    except ObjectDoesNotExist:\n        pass\n    try:\n        previous_month = MetricMonth.objects.get(metric=metric, created=previous_month_date)\n        data['previous_month'] = previous_month.num\n    except ObjectDoesNotExist:\n        pass\n    try:\n        previous_month_year = MetricMonth.objects.get(metric=metric, created=previous_month_year_date)\n        data['previous_month_year'] = previous_month_year.num\n    except ObjectDoesNotExist:\n        pass\n    return data\n", "label": "Correct"}
{"function": "\n\ndef _trending_for_month(metric=None):\n    this_month_date = month_for_date(datetime.date.today())\n    previous_month_date = get_previous_month(this_month_date)\n    previous_month_year_date = get_previous_year(this_month_date)\n    data = {\n        'month': 0,\n        'previous_month': 0,\n        'previous_month_year': 0,\n    }\n    try:\n        month = MetricMonth.objects.get(metric=metric, created=this_month_date)\n        data['month'] = month.num\n    except ObjectDoesNotExist:\n        pass\n    try:\n        previous_month = MetricMonth.objects.get(metric=metric, created=previous_month_date)\n        data['previous_month'] = previous_month_year.num\n    except ObjectDoesNotExist:\n        pass\n    try:\n        previous_month_year = MetricMonth.objects.get(metric=metric, created=previous_month_year_date)\n        data['previous_month_year'] = previous_month_year.num\n    except ObjectDoesNotExist:\n        pass\n    return data\n", "label": "Variable misuse"}
{"function": "\n\n@log_debug\ndef generate_room(self, section):\n    '\\n        Generate room\\n\\n        :param section: section for generator to draw to\\n        :type section: Section\\n        '\n    self.square_generator.generate_room(section)\n    offset = [(1, 1), ((- 1), 1), ((- 1), (- 1)), (1, (- 1))]\n    for (index, corner) in enumerate(self.square_generator.room_corners):\n        self.add_pillar(section, corner, offset[index])\n", "label": "Correct"}
{"function": "\n\n@log_debug\ndef generate_room(self, section):\n    '\\n        Generate room\\n\\n        :param section: section for generator to draw to\\n        :type section: Section\\n        '\n    self.square_generator.generate_room(section)\n    offset = [(1, 1), ((- 1), 1), ((- 1), (- 1)), (1, (- 1))]\n    for (index, corner) in enumerate(self.square_generator.room_corners):\n        self.add_pillar(index, corner, offset[index])\n", "label": "Variable misuse"}
{"function": "\n\ndef report_to_ci_server(self, project):\n    for report in self.reports:\n        test_name = report['test']\n        test_failed = (report['success'] is not True)\n        with test_proxy_for(project).and_test_name(('Integrationtest.%s' % test_name)) as test:\n            if test_failed:\n                test.fails(report['exception'])\n", "label": "Correct"}
{"function": "\n\ndef report_to_ci_server(self, project):\n    for report in self.reports:\n        test_name = report['test']\n        test_failed = (report['success'] is not True)\n        with test_proxy_for(test_name).and_test_name(('Integrationtest.%s' % test_name)) as test:\n            if test_failed:\n                test.fails(report['exception'])\n", "label": "Variable misuse"}
{"function": "\n\ndef prepare_data(self):\n    self.create_server()\n    oauth_client = Client(name='ios', client_id='client', client_secret='secret', _redirect_uris='http://localhost/authorized')\n    db.session.add(User(username='foo'))\n    db.session.add(oauth_client)\n    db.session.commit()\n    self.oauth_client = oauth_client\n", "label": "Correct"}
{"function": "\n\ndef prepare_data(self):\n    self.create_server()\n    oauth_client = Client(name='ios', client_id='client', client_secret='secret', _redirect_uris='http://localhost/authorized')\n    db.session.add(User(username='foo'))\n    db.session.add(oauth_client)\n    db.session.commit()\n    oauth_client.oauth_client = oauth_client\n", "label": "Variable misuse"}
{"function": "\n\n@patch('paasta_tools.cli.cmds.check.read_service_configuration')\n@patch('paasta_tools.cli.cmds.check.is_file_in_dir')\n@patch('sys.stdout', new_callable=StringIO)\ndef test_check_smartstack_check_missing_instance(mock_stdout, mock_is_file_in_dir, mock_read_service_info):\n    mock_is_file_in_dir.return_value = True\n    smartstack_dict = {\n        \n    }\n    mock_read_service_info.return_value = smartstack_dict\n    expected_output = ('%s\\n%s\\n' % (PaastaCheckMessages.SMARTSTACK_YAML_FOUND, PaastaCheckMessages.SMARTSTACK_PORT_MISSING))\n    smartstack_check(service='fake_service', service_path='path', soa_dir='path')\n    output = mock_stdout.getvalue()\n    assert (output == expected_output)\n", "label": "Correct"}
{"function": "\n\n@patch('paasta_tools.cli.cmds.check.read_service_configuration')\n@patch('paasta_tools.cli.cmds.check.is_file_in_dir')\n@patch('sys.stdout', new_callable=StringIO)\ndef test_check_smartstack_check_missing_instance(mock_stdout, mock_is_file_in_dir, mock_read_service_info):\n    mock_is_file_in_dir.return_value = True\n    smartstack_dict = {\n        \n    }\n    mock_read_service_info.return_value = smartstack_dict\n    expected_output = ('%s\\n%s\\n' % (PaastaCheckMessages.SMARTSTACK_YAML_FOUND, PaastaCheckMessages.SMARTSTACK_PORT_MISSING))\n    smartstack_check(service='fake_service', service_path='path', soa_dir='path')\n    output = mock_stdout.getvalue()\n    assert (mock_stdout == expected_output)\n", "label": "Variable misuse"}
{"function": "\n\ndef do_register_opts(opts, group=None, ignore_errors=False):\n    try:\n        cfg.CONF.register_opts(opts, group=group)\n    except:\n        if (not ignore_errors):\n            raise\n", "label": "Correct"}
{"function": "\n\ndef do_register_opts(opts, group=None, ignore_errors=False):\n    try:\n        cfg.CONF.register_opts(ignore_errors, group=group)\n    except:\n        if (not ignore_errors):\n            raise\n", "label": "Variable misuse"}
{"function": "\n\ndef get_select_precolumns(self, select):\n    'Called when building a ``SELECT`` statement, position is just\\n        before column list.\\n\\n        '\n    return ((select._distinct and 'DISTINCT ') or '')\n", "label": "Correct"}
{"function": "\n\ndef get_select_precolumns(self, select):\n    'Called when building a ``SELECT`` statement, position is just\\n        before column list.\\n\\n        '\n    return ((self._distinct and 'DISTINCT ') or '')\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_WaitStatement(self, node):\n    filename = getfilename(node)\n    template = self.get_template(filename)\n    template_dict = {\n        'cond': del_paren(self.visit(node.cond)),\n        'statement': (self.visit(node.statement) if node.statement else ''),\n    }\n    rslt = template.render(template_dict)\n    return rslt\n", "label": "Correct"}
{"function": "\n\ndef visit_WaitStatement(self, node):\n    filename = getfilename(node)\n    template = self.get_template(filename)\n    template_dict = {\n        'cond': del_paren(rslt.visit(node.cond)),\n        'statement': (self.visit(node.statement) if node.statement else ''),\n    }\n    rslt = template.render(template_dict)\n    return rslt\n", "label": "Variable misuse"}
{"function": "\n\ndef test_None_on_sys_path(self):\n    new_path = sys.path[:]\n    new_path.insert(0, None)\n    new_path_importer_cache = sys.path_importer_cache.copy()\n    new_path_importer_cache.pop(None, None)\n    new_path_hooks = [zipimport.zipimporter, _bootstrap.FileFinder.path_hook(*_bootstrap._get_supported_file_loaders())]\n    missing = object()\n    email = sys.modules.pop('email', missing)\n    try:\n        with util.import_state(meta_path=sys.meta_path[:], path=new_path, path_importer_cache=new_path_importer_cache, path_hooks=new_path_hooks):\n            module = import_module('email')\n            self.assertIsInstance(module, ModuleType)\n    finally:\n        if (email is not missing):\n            sys.modules['email'] = email\n", "label": "Correct"}
{"function": "\n\ndef test_None_on_sys_path(self):\n    new_path = sys.path[:]\n    new_path.insert(0, None)\n    new_path_importer_cache = sys.path_importer_cache.copy()\n    new_path_importer_cache.pop(None, None)\n    new_path_hooks = [zipimport.zipimporter, _bootstrap.FileFinder.path_hook(*_bootstrap._get_supported_file_loaders())]\n    missing = object()\n    email = sys.modules.pop('email', missing)\n    try:\n        with util.import_state(meta_path=sys.meta_path[:], path=new_path, path_importer_cache=new_path_importer_cache, path_hooks=new_path_hooks):\n            module = import_module('email')\n            self.assertIsInstance(module, ModuleType)\n    finally:\n        if (email is not new_path_importer_cache):\n            sys.modules['email'] = email\n", "label": "Variable misuse"}
{"function": "\n\ndef import_class(module_name):\n    (mod_name, class_name) = module_name.rsplit('.', 1)\n    mod = __import__(mod_name, fromlist=[class_name])\n    klass = getattr(mod, class_name)\n    return klass\n", "label": "Correct"}
{"function": "\n\ndef import_class(module_name):\n    (mod_name, class_name) = klass.rsplit('.', 1)\n    mod = __import__(mod_name, fromlist=[class_name])\n    klass = getattr(mod, class_name)\n    return klass\n", "label": "Variable misuse"}
{"function": "\n\ndef on_text_changed(self):\n    \" Handle the 'textChanged' signal on the widget.\\n\\n        \"\n    d = self.declaration\n    if (d is not None):\n        d.text_changed()\n", "label": "Correct"}
{"function": "\n\ndef on_text_changed(self):\n    \" Handle the 'textChanged' signal on the widget.\\n\\n        \"\n    d = d.declaration\n    if (d is not None):\n        d.text_changed()\n", "label": "Variable misuse"}
{"function": "\n\ndef onBrowserEvent(self, event):\n    etype = DOM.eventGetType(event)\n    if (etype == 'mousewheel'):\n        if self._mouseWheelPreventDefault:\n            DOM.eventPreventDefault(event)\n        velocity = DOM.eventGetMouseWheelVelocityY(event)\n        for listener in self._mouseWheelListeners:\n            listener.onMouseWheel(self, velocity)\n        return True\n", "label": "Correct"}
{"function": "\n\ndef onBrowserEvent(self, event):\n    etype = DOM.eventGetType(event)\n    if (etype == 'mousewheel'):\n        if self._mouseWheelPreventDefault:\n            DOM.eventPreventDefault(event)\n        velocity = DOM.eventGetMouseWheelVelocityY(self)\n        for listener in self._mouseWheelListeners:\n            listener.onMouseWheel(self, velocity)\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef test_JobFlows_completed(self):\n    [jobflow] = self._parse_xml(JOB_FLOW_COMPLETED, [('member', emrobject.JobFlow)])\n    self._assert_fields(jobflow, creationdatetime='2010-10-21T01:00:25Z', startdatetime='2010-10-21T01:03:59Z', enddatetime='2010-10-21T01:44:18Z', state='COMPLETED', instancecount='10', jobflowid='j-3H3Q13JPFLU22', loguri='s3n://example.emrtest.scripts/jobflow_logs/', name='RealJobFlowName', availabilityzone='us-east-1b', slaveinstancetype='m1.large', masterinstancetype='m1.large', ec2keyname='myubersecurekey', keepjobflowalivewhennosteps='false')\n    self.assertEquals(6, len(jobflow.steps))\n    self.assertEquals(2, len(jobflow.instancegroups))\n", "label": "Correct"}
{"function": "\n\ndef test_JobFlows_completed(self):\n    [jobflow] = jobflow._parse_xml(JOB_FLOW_COMPLETED, [('member', emrobject.JobFlow)])\n    self._assert_fields(jobflow, creationdatetime='2010-10-21T01:00:25Z', startdatetime='2010-10-21T01:03:59Z', enddatetime='2010-10-21T01:44:18Z', state='COMPLETED', instancecount='10', jobflowid='j-3H3Q13JPFLU22', loguri='s3n://example.emrtest.scripts/jobflow_logs/', name='RealJobFlowName', availabilityzone='us-east-1b', slaveinstancetype='m1.large', masterinstancetype='m1.large', ec2keyname='myubersecurekey', keepjobflowalivewhennosteps='false')\n    self.assertEquals(6, len(jobflow.steps))\n    self.assertEquals(2, len(jobflow.instancegroups))\n", "label": "Variable misuse"}
{"function": "\n\ndef raw_field_definition_proxy_post_save(sender, instance, raw, **kwargs):\n    \"\\n    When proxy field definitions are loaded from a fixture they're not\\n    passing through the `field_definition_post_save` signal. Make sure they\\n    are.\\n    \"\n    if raw:\n        model_class = instance.content_type.model_class()\n        opts = model_class._meta\n        if (opts.proxy and (opts.concrete_model is sender)):\n            field_definition_post_save(sender=model_class, instance=instance.type_cast(), raw=raw, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef raw_field_definition_proxy_post_save(sender, instance, raw, **kwargs):\n    \"\\n    When proxy field definitions are loaded from a fixture they're not\\n    passing through the `field_definition_post_save` signal. Make sure they\\n    are.\\n    \"\n    if raw:\n        model_class = instance.content_type.model_class()\n        opts = model_class._meta\n        if (opts.proxy and (opts.concrete_model is opts)):\n            field_definition_post_save(sender=model_class, instance=instance.type_cast(), raw=raw, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef fit(self, X, y, sample_weight):\n    self.y = y\n    self.sample_weight = sample_weight\n    self.y_signed = ((2 * y) - 1)\n    self.adjusted_regularization = (numpy.mean(sample_weight) * self.regularization)\n", "label": "Correct"}
{"function": "\n\ndef fit(self, X, y, sample_weight):\n    self.y = y\n    X.sample_weight = sample_weight\n    self.y_signed = ((2 * y) - 1)\n    self.adjusted_regularization = (numpy.mean(sample_weight) * self.regularization)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_moves_a_block_up_within_a_container(self):\n    for (idx, pos) in [(0, 0), (1, 1), (2, 2)]:\n        block = TextBlock.objects.get(id=self.left_blocks[idx].id)\n        self.assertEquals(block.display_order, pos)\n    self.app.put(reverse('fp-api:block-move', kwargs={\n        'uuid': self.main_blocks[1].uuid,\n    }), params={\n        'container': self.left_container.uuid,\n        'index': 1,\n    }, user=self.user)\n    moved_block = TextBlock.objects.get(id=self.main_blocks[1].id)\n    self.assertEquals(moved_block.container, self.page.get_container_from_name('left-container'))\n    self.assertEquals(moved_block.display_order, 1)\n    for (idx, pos) in [(0, 0), (1, 2), (2, 3)]:\n        block = TextBlock.objects.get(id=self.left_blocks[idx].id)\n        self.assertEquals(block.display_order, pos)\n    for (idx, pos) in [(0, 0), (2, 1)]:\n        block = TextBlock.objects.get(id=self.main_blocks[idx].id)\n        self.assertEquals(block.display_order, pos)\n", "label": "Correct"}
{"function": "\n\ndef test_moves_a_block_up_within_a_container(self):\n    for (idx, pos) in [(0, 0), (1, 1), (2, 2)]:\n        block = TextBlock.objects.get(id=self.left_blocks[pos].id)\n        self.assertEquals(block.display_order, pos)\n    self.app.put(reverse('fp-api:block-move', kwargs={\n        'uuid': self.main_blocks[1].uuid,\n    }), params={\n        'container': self.left_container.uuid,\n        'index': 1,\n    }, user=self.user)\n    moved_block = TextBlock.objects.get(id=self.main_blocks[1].id)\n    self.assertEquals(moved_block.container, self.page.get_container_from_name('left-container'))\n    self.assertEquals(moved_block.display_order, 1)\n    for (idx, pos) in [(0, 0), (1, 2), (2, 3)]:\n        block = TextBlock.objects.get(id=self.left_blocks[idx].id)\n        self.assertEquals(block.display_order, pos)\n    for (idx, pos) in [(0, 0), (2, 1)]:\n        block = TextBlock.objects.get(id=self.main_blocks[idx].id)\n        self.assertEquals(block.display_order, pos)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_simple_value(self):\n    instance = TaggedModel()\n    instance.tags = [stormbase.TagField(name='tag1', value='v1')]\n    saved = instance.save()\n    retrieved = TaggedModel.objects(id=instance.id).first()\n    self.assertEquals(len(saved.tags), len(retrieved.tags), 'Failed to retrieve tags.')\n    saved_tag = saved.tags[0]\n    retrieved_tag = retrieved.tags[0]\n    self.assertEquals(saved_tag.name, retrieved_tag.name, 'Failed to retrieve tag.')\n    self.assertEquals(saved_tag.value, retrieved_tag.value, 'Failed to retrieve tag.')\n", "label": "Correct"}
{"function": "\n\ndef test_simple_value(self):\n    instance = TaggedModel()\n    instance.tags = [stormbase.TagField(name='tag1', value='v1')]\n    saved = instance.save()\n    retrieved = TaggedModel.objects(id=instance.id).first()\n    self.assertEquals(len(saved.tags), len(retrieved.tags), 'Failed to retrieve tags.')\n    saved_tag = saved.tags[0]\n    retrieved_tag = retrieved.tags[0]\n    self.assertEquals(saved_tag.name, retrieved_tag.name, 'Failed to retrieve tag.')\n    saved_tag.assertEquals(saved_tag.value, retrieved_tag.value, 'Failed to retrieve tag.')\n", "label": "Variable misuse"}
{"function": "\n\ndef __truediv__(self, other):\n    return BinaryOp(operator.truediv, '/', self, other)\n", "label": "Correct"}
{"function": "\n\ndef __truediv__(self, other):\n    return BinaryOp(operator.truediv, '/', other, other)\n", "label": "Variable misuse"}
{"function": "\n\ndef compare_file_contents(self, artifact_path, directory):\n    '\\n    Tests the ivy.xml and pom\\n    :param artifact_path: Path of the artifact\\n    :param directory: Directory where the artifact resides.\\n    :return:\\n    '\n    [package_dir, artifact_name, version] = directory.rsplit(os.path.sep, 2)\n    file_name = os.path.basename(artifact_path)\n    golden_file_nm = os.path.join(JarPublishIntegrationTest.GOLDEN_DATA_DIR, package_dir.replace(os.path.sep, '.'), artifact_name, file_name)\n    with open(artifact_path, 'r') as test_file:\n        generated_file = test_file.read()\n        with open(golden_file_nm, 'r') as golden_file:\n            golden_file_contents = golden_file.read()\n            if artifact_path.endswith('.xml'):\n                generated_file = re.sub('publication=.*', '/>', generated_file)\n        return self.assertMultiLineEqual(generated_file, golden_file_contents)\n", "label": "Correct"}
{"function": "\n\ndef compare_file_contents(self, artifact_path, directory):\n    '\\n    Tests the ivy.xml and pom\\n    :param artifact_path: Path of the artifact\\n    :param directory: Directory where the artifact resides.\\n    :return:\\n    '\n    [package_dir, artifact_name, version] = directory.rsplit(os.path.sep, 2)\n    file_name = os.path.basename(artifact_path)\n    golden_file_nm = os.path.join(JarPublishIntegrationTest.GOLDEN_DATA_DIR, package_dir.replace(os.path.sep, '.'), artifact_name, file_name)\n    with open(artifact_path, 'r') as test_file:\n        generated_file = test_file.read()\n        with open(golden_file_nm, 'r') as golden_file:\n            golden_file_contents = generated_file.read()\n            if artifact_path.endswith('.xml'):\n                generated_file = re.sub('publication=.*', '/>', generated_file)\n        return self.assertMultiLineEqual(generated_file, golden_file_contents)\n", "label": "Variable misuse"}
{"function": "\n\ndef application(environ, start_response):\n    '\\n    The main WSGI application. Dispatch the current request to\\n    the functions from above and store the regular expression\\n    captures in the WSGI environment as  `oic.url_args` so that\\n    the functions from above can access the url placeholders.\\n\\n    If nothing matches call the `not_found` function.\\n\\n    :param environ: The HTTP application environment\\n    :param start_response: The application to run when the handling of the\\n        request is done\\n    :return: The response as a list of lines\\n    '\n    global OAS\n    path = environ.get('PATH_INFO', '').lstrip('/')\n    logger = logging.getLogger('oicServer')\n    if (path == 'robots.txt'):\n        return static(environ, start_response, 'static/robots.txt')\n    environ['oic.oas'] = OAS\n    if path.startswith('static/'):\n        return static(environ, start_response, path)\n    for (regex, callback) in URLS:\n        match = re.search(regex, path)\n        if (match is not None):\n            try:\n                environ['oic.url_args'] = match.groups()[0]\n            except IndexError:\n                environ['oic.url_args'] = path\n            logger.info(('callback: %s' % callback))\n            try:\n                return callback(environ, start_response, logger)\n            except Exception as err:\n                print(('%s' % err))\n                message = traceback.format_exception(*sys.exc_info())\n                print(message)\n                logger.exception(('%s' % err))\n                resp = ServiceError(('%s' % err))\n                return resp(environ, start_response)\n    LOGGER.debug(('unknown side: %s' % path))\n    resp = NotFound(\"Couldn't find the side you asked for!\")\n    return resp(environ, start_response)\n", "label": "Correct"}
{"function": "\n\ndef application(environ, start_response):\n    '\\n    The main WSGI application. Dispatch the current request to\\n    the functions from above and store the regular expression\\n    captures in the WSGI environment as  `oic.url_args` so that\\n    the functions from above can access the url placeholders.\\n\\n    If nothing matches call the `not_found` function.\\n\\n    :param environ: The HTTP application environment\\n    :param start_response: The application to run when the handling of the\\n        request is done\\n    :return: The response as a list of lines\\n    '\n    global OAS\n    path = environ.get('PATH_INFO', '').lstrip('/')\n    logger = logging.getLogger('oicServer')\n    if (path == 'robots.txt'):\n        return static(environ, start_response, 'static/robots.txt')\n    environ['oic.oas'] = OAS\n    if path.startswith('static/'):\n        return static(environ, start_response, path)\n    for (regex, callback) in URLS:\n        match = re.search(regex, path)\n        if (match is not None):\n            try:\n                environ['oic.url_args'] = logger.groups()[0]\n            except IndexError:\n                environ['oic.url_args'] = path\n            logger.info(('callback: %s' % callback))\n            try:\n                return callback(environ, start_response, logger)\n            except Exception as err:\n                print(('%s' % err))\n                message = traceback.format_exception(*sys.exc_info())\n                print(message)\n                logger.exception(('%s' % err))\n                resp = ServiceError(('%s' % err))\n                return resp(environ, start_response)\n    LOGGER.debug(('unknown side: %s' % path))\n    resp = NotFound(\"Couldn't find the side you asked for!\")\n    return resp(environ, start_response)\n", "label": "Variable misuse"}
{"function": "\n\ndef run_cmd(self, util, toggle_active_mark_mode=False):\n    if (util.state.argument_supplied or toggle_active_mark_mode):\n        util.toggle_active_mark_mode()\n    else:\n        util.swap_point_and_mark()\n", "label": "Correct"}
{"function": "\n\ndef run_cmd(self, util, toggle_active_mark_mode=False):\n    if (util.state.argument_supplied or toggle_active_mark_mode):\n        util.toggle_active_mark_mode()\n    else:\n        toggle_active_mark_mode.swap_point_and_mark()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, directory, recursive=False, fnpattern='*', chunk_size=default_chunk_size):\n    '\\n        A buffered generator that encodes a directory as\\n        multipart/form-data.\\n        '\n    BufferedGenerator.__init__(self, directory, chunk_size=chunk_size)\n    self.directory = directory\n    self.recursive = recursive\n    self.fnpattern = fnpattern\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, directory, recursive=False, fnpattern='*', chunk_size=default_chunk_size):\n    '\\n        A buffered generator that encodes a directory as\\n        multipart/form-data.\\n        '\n    BufferedGenerator.__init__(self, directory, chunk_size=chunk_size)\n    self.directory = self\n    self.recursive = recursive\n    self.fnpattern = fnpattern\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    super(KeystoneIdentityTestCase, self).setUp()\n    self.mock_client = mock.MagicMock()\n    self.kc_patch = mockpatch.PatchObject(keystone_client, 'Client', new=self.mock_client)\n    self.useFixture(self.kc_patch)\n    self.fake_cloud = mock.Mock()\n    self.fake_cloud.mysql_connector = mock.Mock()\n    self.keystone_client = keystone.KeystoneIdentity(FAKE_CONFIG, self.fake_cloud)\n    self.fake_tenant_0 = mock.Mock(spec=keystone_client.tenants.Tenant)\n    self.fake_tenant_0.name = 'tenant_name_0'\n    self.fake_tenant_0.description = 'tenant_description_0'\n    self.fake_tenant_0.id = 'tenant_id_0'\n    self.fake_tenant_1 = mock.Mock(spec=keystone_client.tenants.Tenant)\n    self.fake_tenant_1.name = 'tenant_name_1'\n    self.fake_tenant_1.description = 'tenant_description_1'\n    self.fake_tenant_1.id = 'tenant_id_1'\n    self.fake_user_0 = mock.Mock(spec=keystone_client.users.User)\n    self.fake_user_0.name = 'user_name_0'\n    self.fake_user_0.id = 'user_id_0'\n    self.fake_user_0.tenantId = self.fake_tenant_0.id\n    self.fake_user_0.email = 'user0@fake.com'\n    self.fake_user_1 = mock.Mock(spec=keystone_client.users.User)\n    self.fake_user_1.name = 'user_name_1'\n    self.fake_user_1.id = 'user_id_1'\n    self.fake_user_1.tenantId = self.fake_tenant_1.id\n    self.fake_user_1.email = 'user1@fake.com'\n    self.fake_role_0 = mock.Mock(spec=keystone_client.roles.Role)\n    self.fake_role_0.name = 'role_name_0'\n    self.fake_role_0.id = 'role_id_0'\n    self.fake_role_1 = mock.Mock(spec=keystone_client.roles.Role)\n    self.fake_role_1.name = 'role_name_1'\n    self.fake_role_1.id = 'role_id_1'\n    cfglib.init_config()\n    cfglib.CONF.src.user = 'src_admin_user'\n    cfglib.CONF.dst.user = 'dst_admin_user'\n    self.fake_src_admin_user = mock.Mock()\n    self.fake_src_admin_user.name = 'src_admin_user'\n    self.fake_dst_admin_user = mock.Mock()\n    self.fake_dst_admin_user.name = 'dst_admin_user'\n    self.fake_same_user = mock.Mock()\n    self.fake_same_user.id = 'fake_same_id'\n    self.fake_same_user.name = 'fake_same_name'\n    src_keystone = mock.Mock()\n    dst_keystone = mock.Mock()\n    self.fake_src_keystone = src_keystone\n    self.fake_dst_keystone = dst_keystone\n    src_keystone.keystone_client.users.list.return_value = [self.fake_user_0, self.fake_same_user, self.fake_src_admin_user]\n    dst_keystone.keystone_client.users.list.return_value = [self.fake_user_1, self.fake_same_user, self.fake_dst_admin_user]\n    src_keystone.keystone_client.users.get.side_effect = self.mock_user_get\n    dst_keystone.keystone_client.users.get.side_effect = self.mock_user_get\n    src_keystone.try_get_user_by_name.side_effect = self.mock_user_get\n    dst_keystone.try_get_user_by_name.side_effect = self.mock_user_get\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    super(KeystoneIdentityTestCase, self).setUp()\n    self.mock_client = mock.MagicMock()\n    self.kc_patch = mockpatch.PatchObject(keystone_client, 'Client', new=self.mock_client)\n    self.useFixture(self.kc_patch)\n    self.fake_cloud = mock.Mock()\n    self.fake_cloud.mysql_connector = mock.Mock()\n    self.keystone_client = keystone.KeystoneIdentity(FAKE_CONFIG, self.fake_cloud)\n    src_keystone.fake_tenant_0 = mock.Mock(spec=keystone_client.tenants.Tenant)\n    self.fake_tenant_0.name = 'tenant_name_0'\n    self.fake_tenant_0.description = 'tenant_description_0'\n    self.fake_tenant_0.id = 'tenant_id_0'\n    self.fake_tenant_1 = mock.Mock(spec=keystone_client.tenants.Tenant)\n    self.fake_tenant_1.name = 'tenant_name_1'\n    self.fake_tenant_1.description = 'tenant_description_1'\n    self.fake_tenant_1.id = 'tenant_id_1'\n    self.fake_user_0 = mock.Mock(spec=keystone_client.users.User)\n    self.fake_user_0.name = 'user_name_0'\n    self.fake_user_0.id = 'user_id_0'\n    self.fake_user_0.tenantId = self.fake_tenant_0.id\n    self.fake_user_0.email = 'user0@fake.com'\n    self.fake_user_1 = mock.Mock(spec=keystone_client.users.User)\n    self.fake_user_1.name = 'user_name_1'\n    self.fake_user_1.id = 'user_id_1'\n    self.fake_user_1.tenantId = self.fake_tenant_1.id\n    self.fake_user_1.email = 'user1@fake.com'\n    self.fake_role_0 = mock.Mock(spec=keystone_client.roles.Role)\n    self.fake_role_0.name = 'role_name_0'\n    self.fake_role_0.id = 'role_id_0'\n    self.fake_role_1 = mock.Mock(spec=keystone_client.roles.Role)\n    self.fake_role_1.name = 'role_name_1'\n    self.fake_role_1.id = 'role_id_1'\n    cfglib.init_config()\n    cfglib.CONF.src.user = 'src_admin_user'\n    cfglib.CONF.dst.user = 'dst_admin_user'\n    self.fake_src_admin_user = mock.Mock()\n    self.fake_src_admin_user.name = 'src_admin_user'\n    self.fake_dst_admin_user = mock.Mock()\n    self.fake_dst_admin_user.name = 'dst_admin_user'\n    self.fake_same_user = mock.Mock()\n    self.fake_same_user.id = 'fake_same_id'\n    self.fake_same_user.name = 'fake_same_name'\n    src_keystone = mock.Mock()\n    dst_keystone = mock.Mock()\n    self.fake_src_keystone = src_keystone\n    self.fake_dst_keystone = dst_keystone\n    src_keystone.keystone_client.users.list.return_value = [self.fake_user_0, self.fake_same_user, self.fake_src_admin_user]\n    dst_keystone.keystone_client.users.list.return_value = [self.fake_user_1, self.fake_same_user, self.fake_dst_admin_user]\n    src_keystone.keystone_client.users.get.side_effect = self.mock_user_get\n    dst_keystone.keystone_client.users.get.side_effect = self.mock_user_get\n    src_keystone.try_get_user_by_name.side_effect = self.mock_user_get\n    dst_keystone.try_get_user_by_name.side_effect = self.mock_user_get\n", "label": "Variable misuse"}
{"function": "\n\ndef construct_patch(self, path, data='', content_type='application/octet-stream', **extra):\n    'Construct a PATCH request.'\n    return self.generic('PATCH', path, data, content_type, **extra)\n", "label": "Correct"}
{"function": "\n\ndef construct_patch(self, path, data='', content_type='application/octet-stream', **extra):\n    'Construct a PATCH request.'\n    return self.generic('PATCH', path, data, self, **extra)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, name, port, stype='_http._tcp', domain='', host='', text=''):\n    self.name = name\n    self.stype = stype\n    self.domain = domain\n    self.host = host\n    self.port = port\n    self.text = text\n    self.group = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, name, port, stype='_http._tcp', domain='', host='', text=''):\n    self.name = name\n    self.stype = stype\n    self.domain = domain\n    name.host = host\n    self.port = port\n    self.text = text\n    self.group = None\n", "label": "Variable misuse"}
{"function": "\n\ndef test_asizer_limit(self):\n    'Test limit setting for Asizer.\\n        '\n    objs = [Foo(42), ThinFoo('spam'), OldFoo(67)]\n    sizer = [asizeof.Asizer() for _ in range(4)]\n    for (limit, asizer) in enumerate(sizer):\n        asizer.asizeof(objs, limit=limit)\n    limit_sizes = [asizer.total for asizer in sizer]\n    self.assertTrue((limit_sizes[0] < limit_sizes[1]), limit_sizes)\n    self.assertTrue((limit_sizes[1] < limit_sizes[2]), limit_sizes)\n    self.assertTrue((limit_sizes[2] < limit_sizes[3]), limit_sizes)\n", "label": "Correct"}
{"function": "\n\ndef test_asizer_limit(self):\n    'Test limit setting for Asizer.\\n        '\n    objs = [Foo(42), ThinFoo('spam'), OldFoo(67)]\n    sizer = [asizeof.Asizer() for _ in range(4)]\n    for (limit, asizer) in enumerate(sizer):\n        asizer.asizeof(objs, limit=limit)\n    limit_sizes = [asizer.total for asizer in sizer]\n    self.assertTrue((limit_sizes[0] < objs[1]), limit_sizes)\n    self.assertTrue((limit_sizes[1] < limit_sizes[2]), limit_sizes)\n    self.assertTrue((limit_sizes[2] < limit_sizes[3]), limit_sizes)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_key(self):\n    sdk = self.get_sdk()\n    self.assertEqual('d2hhdGV2ZXI6d2hhdGV2ZXI=', sdk.platform()._api_key())\n", "label": "Correct"}
{"function": "\n\ndef test_key(self):\n    sdk = sdk.get_sdk()\n    self.assertEqual('d2hhdGV2ZXI6d2hhdGV2ZXI=', sdk.platform()._api_key())\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_policy_port_binding(context, policy_id, port_id):\n    try:\n        with context.session.begin(subtransactions=True):\n            db_object = db.model_query(context, models.QosPortPolicyBinding).filter_by(policy_id=policy_id, port_id=port_id).one()\n            context.session.delete(db_object)\n    except orm_exc.NoResultFound:\n        raise n_exc.PortQosBindingNotFound(port_id=port_id, policy_id=policy_id)\n", "label": "Correct"}
{"function": "\n\ndef delete_policy_port_binding(context, policy_id, port_id):\n    try:\n        with context.session.begin(subtransactions=True):\n            db_object = db.model_query(context, models.QosPortPolicyBinding).filter_by(policy_id=context, port_id=port_id).one()\n            context.session.delete(db_object)\n    except orm_exc.NoResultFound:\n        raise n_exc.PortQosBindingNotFound(port_id=port_id, policy_id=policy_id)\n", "label": "Variable misuse"}
{"function": "\n\ndef _loss_grad_lbfgs(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads):\n    'Compute the MLP loss function and its corresponding derivatives\\n        with respect to the different parameters given in the initialization.\\n\\n        Returned gradients are packed in a single vector so it can be used\\n        in l-bfgs\\n\\n        Parameters\\n        ----------\\n        packed_parameters : array-like\\n            A vector comprising the flattened coefficients and intercepts.\\n\\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\\n            The input data.\\n\\n        y : array-like, shape (n_samples,)\\n            The target values.\\n\\n        activations: list, length = n_layers - 1\\n            The ith element of the list holds the values of the ith layer.\\n\\n        deltas : list, length = n_layers - 1\\n            The ith element of the list holds the difference between the\\n            activations of the i + 1 layer and the backpropagated error.\\n            More specifically, deltas are gradients of loss with respect to z\\n            in each layer, where z = wx + b is the value of a particular layer\\n            before passing through the activation function\\n\\n        coef_grad : list, length = n_layers - 1\\n            The ith element contains the amount of change used to update the\\n            coefficient parameters of the ith layer in an iteration.\\n\\n        intercept_grads : list, length = n_layers - 1\\n            The ith element contains the amount of change used to update the\\n            intercept parameters of the ith layer in an iteration.\\n\\n        Returns\\n        -------\\n        loss : float\\n        grad : array-like, shape (number of nodes of all layers,)\\n\\n        '\n    self._unpack(packed_coef_inter)\n    (loss, coef_grads, intercept_grads) = self._backprop(X, y, activations, deltas, coef_grads, intercept_grads)\n    self.n_iter_ += 1\n    grad = _pack(coef_grads, intercept_grads)\n    return (loss, grad)\n", "label": "Correct"}
{"function": "\n\ndef _loss_grad_lbfgs(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads):\n    'Compute the MLP loss function and its corresponding derivatives\\n        with respect to the different parameters given in the initialization.\\n\\n        Returned gradients are packed in a single vector so it can be used\\n        in l-bfgs\\n\\n        Parameters\\n        ----------\\n        packed_parameters : array-like\\n            A vector comprising the flattened coefficients and intercepts.\\n\\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\\n            The input data.\\n\\n        y : array-like, shape (n_samples,)\\n            The target values.\\n\\n        activations: list, length = n_layers - 1\\n            The ith element of the list holds the values of the ith layer.\\n\\n        deltas : list, length = n_layers - 1\\n            The ith element of the list holds the difference between the\\n            activations of the i + 1 layer and the backpropagated error.\\n            More specifically, deltas are gradients of loss with respect to z\\n            in each layer, where z = wx + b is the value of a particular layer\\n            before passing through the activation function\\n\\n        coef_grad : list, length = n_layers - 1\\n            The ith element contains the amount of change used to update the\\n            coefficient parameters of the ith layer in an iteration.\\n\\n        intercept_grads : list, length = n_layers - 1\\n            The ith element contains the amount of change used to update the\\n            intercept parameters of the ith layer in an iteration.\\n\\n        Returns\\n        -------\\n        loss : float\\n        grad : array-like, shape (number of nodes of all layers,)\\n\\n        '\n    self._unpack(packed_coef_inter)\n    (loss, coef_grads, intercept_grads) = self._backprop(X, loss, activations, deltas, coef_grads, intercept_grads)\n    self.n_iter_ += 1\n    grad = _pack(coef_grads, intercept_grads)\n    return (loss, grad)\n", "label": "Variable misuse"}
{"function": "\n\ndef decode(self, file):\n    fStart = file.tell()\n    identifier = None\n    try:\n        identifier = self.iEIEncoder.decode(file)\n    except UDHInformationElementIdentifierUnknownError:\n        pass\n    length = self.int8Encoder.decode(file)\n    data = None\n    if (identifier in self.dataEncoders):\n        data = self.dataEncoders[identifier].decode(file)\n    elif (length > 0):\n        data = self.read(file, length)\n    parsed = (file.tell() - fStart)\n    if (parsed != (length + 2)):\n        raise UDHParseError(('Invalid length: expected %d, parsed %d' % ((length + 2), parsed)))\n    if (identifier is None):\n        return None\n    return gsm_types.InformationElement(identifier, data)\n", "label": "Correct"}
{"function": "\n\ndef decode(self, file):\n    fStart = file.tell()\n    identifier = None\n    try:\n        identifier = self.iEIEncoder.decode(file)\n    except UDHInformationElementIdentifierUnknownError:\n        pass\n    length = self.int8Encoder.decode(self)\n    data = None\n    if (identifier in self.dataEncoders):\n        data = self.dataEncoders[identifier].decode(file)\n    elif (length > 0):\n        data = self.read(file, length)\n    parsed = (file.tell() - fStart)\n    if (parsed != (length + 2)):\n        raise UDHParseError(('Invalid length: expected %d, parsed %d' % ((length + 2), parsed)))\n    if (identifier is None):\n        return None\n    return gsm_types.InformationElement(identifier, data)\n", "label": "Variable misuse"}
{"function": "\n\ndef rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None):\n    \"Iterates over the time dimension of a tensor.\\n\\n    # Arguments\\n        inputs: tensor of temporal data of shape (samples, time, ...)\\n            (at least 3D).\\n        step_function:\\n            Parameters:\\n                input: tensor with shape (samples, ...) (no time dimension),\\n                    representing input for the batch of samples at a certain\\n                    time step.\\n                states: list of tensors.\\n            Returns:\\n                output: tensor with shape (samples, ...) (no time dimension),\\n                new_states: list of tensors, same length and shapes\\n                    as 'states'.\\n        initial_states: tensor with shape (samples, ...) (no time dimension),\\n            containing the initial values for the states used in\\n            the step function.\\n        go_backwards: boolean. If True, do the iteration over\\n            the time dimension in reverse order.\\n        mask: binary tensor with shape (samples, time),\\n            with a zero for every element that is masked.\\n        constants: a list of constant values passed at each step.\\n        unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).\\n        input_length: must be specified if using `unroll`.\\n\\n    # Returns\\n        A tuple (last_output, outputs, new_states).\\n            last_output: the latest output of the rnn, of shape (samples, ...)\\n            outputs: tensor with shape (samples, time, ...) where each\\n                entry outputs[s, t] is the output of the step function\\n                at time t for sample s.\\n            new_states: list of tensors, latest states returned by\\n                the step function, of shape (samples, ...).\\n    \"\n    ndim = inputs.ndim\n    assert (ndim >= 3), 'Input should be at least 3D.'\n    if unroll:\n        if (input_length is None):\n            raise Exception('When specifying `unroll=True`, an `input_length` must be provided to `rnn`.')\n    axes = ([1, 0] + list(range(2, ndim)))\n    inputs = inputs.dimshuffle(axes)\n    if (constants is None):\n        constants = []\n    if (mask is not None):\n        if (mask.ndim == (ndim - 1)):\n            mask = expand_dims(mask)\n        assert (mask.ndim == ndim)\n        mask = mask.dimshuffle(axes)\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::(- 1)]\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                (output, new_states) = step_function(inputs[i], (states + constants))\n                if (len(successive_outputs) == 0):\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[(- 1)]\n                output = T.switch(mask[i], output, prev_output)\n                kept_states = []\n                for (state, new_state) in zip(states, new_states):\n                    kept_states.append(T.switch(mask[i], new_state, state))\n                states = kept_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[(- 1)])):\n                states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n        else:\n            initial_output = (step_function(inputs[0], (initial_states + constants))[0] * 0)\n            initial_output = T.unbroadcast(initial_output, 0, 1)\n\n            def _step(input, mask, output_tm1, *states):\n                (output, new_states) = step_function(input, states)\n                output = T.switch(mask, output, output_tm1)\n                return_states = []\n                for (state, new_state) in zip(states, new_states):\n                    return_states.append(T.switch(mask, new_state, state))\n                return ([output] + return_states)\n            (results, _) = theano.scan(_step, sequences=[inputs, mask], outputs_info=([initial_output] + initial_states), non_sequences=constants, go_backwards=go_backwards)\n            if (type(results) is list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n    elif unroll:\n        indices = list(range(input_length))\n        if go_backwards:\n            indices = indices[::(- 1)]\n        successive_outputs = []\n        successive_states = []\n        states = initial_states\n        for i in indices:\n            (output, states) = step_function(inputs[i], (states + constants))\n            successive_outputs.append(output)\n            successive_states.append(states)\n        outputs = T.stack(*successive_outputs)\n        states = []\n        for i in range(len(successive_states[(- 1)])):\n            states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n    else:\n\n        def _step(input, *states):\n            (output, new_states) = step_function(input, states)\n            return ([output] + new_states)\n        (results, _) = theano.scan(_step, sequences=inputs, outputs_info=([None] + initial_states), non_sequences=constants, go_backwards=go_backwards)\n        if (type(results) is list):\n            outputs = results[0]\n            states = results[1:]\n        else:\n            outputs = results\n            states = []\n    outputs = T.squeeze(outputs)\n    last_output = outputs[(- 1)]\n    axes = ([1, 0] + list(range(2, outputs.ndim)))\n    outputs = outputs.dimshuffle(axes)\n    states = [T.squeeze(state[(- 1)]) for state in states]\n    return (last_output, outputs, states)\n", "label": "Correct"}
{"function": "\n\ndef rnn(step_function, inputs, initial_states, go_backwards=False, mask=None, constants=None, unroll=False, input_length=None):\n    \"Iterates over the time dimension of a tensor.\\n\\n    # Arguments\\n        inputs: tensor of temporal data of shape (samples, time, ...)\\n            (at least 3D).\\n        step_function:\\n            Parameters:\\n                input: tensor with shape (samples, ...) (no time dimension),\\n                    representing input for the batch of samples at a certain\\n                    time step.\\n                states: list of tensors.\\n            Returns:\\n                output: tensor with shape (samples, ...) (no time dimension),\\n                new_states: list of tensors, same length and shapes\\n                    as 'states'.\\n        initial_states: tensor with shape (samples, ...) (no time dimension),\\n            containing the initial values for the states used in\\n            the step function.\\n        go_backwards: boolean. If True, do the iteration over\\n            the time dimension in reverse order.\\n        mask: binary tensor with shape (samples, time),\\n            with a zero for every element that is masked.\\n        constants: a list of constant values passed at each step.\\n        unroll: whether to unroll the RNN or to use a symbolic loop (`scan`).\\n        input_length: must be specified if using `unroll`.\\n\\n    # Returns\\n        A tuple (last_output, outputs, new_states).\\n            last_output: the latest output of the rnn, of shape (samples, ...)\\n            outputs: tensor with shape (samples, time, ...) where each\\n                entry outputs[s, t] is the output of the step function\\n                at time t for sample s.\\n            new_states: list of tensors, latest states returned by\\n                the step function, of shape (samples, ...).\\n    \"\n    ndim = inputs.ndim\n    assert (ndim >= 3), 'Input should be at least 3D.'\n    if unroll:\n        if (input_length is None):\n            raise Exception('When specifying `unroll=True`, an `input_length` must be provided to `rnn`.')\n    axes = ([1, 0] + list(range(2, ndim)))\n    inputs = inputs.dimshuffle(axes)\n    if (constants is None):\n        constants = []\n    if (mask is not None):\n        if (mask.ndim == (ndim - 1)):\n            mask = expand_dims(mask)\n        assert (mask.ndim == ndim)\n        mask = mask.dimshuffle(axes)\n        if unroll:\n            indices = list(range(input_length))\n            if go_backwards:\n                indices = indices[::(- 1)]\n            successive_outputs = []\n            successive_states = []\n            states = initial_states\n            for i in indices:\n                (output, new_states) = step_function(inputs[i], (states + constants))\n                if (len(successive_outputs) == 0):\n                    prev_output = zeros_like(output)\n                else:\n                    prev_output = successive_outputs[(- 1)]\n                output = T.switch(mask[i], output, prev_output)\n                kept_states = []\n                for (state, new_state) in zip(states, new_states):\n                    kept_states.append(T.switch(mask[i], new_state, state))\n                states = kept_states\n                successive_outputs.append(output)\n                successive_states.append(states)\n            outputs = T.stack(*successive_outputs)\n            states = []\n            for i in range(len(successive_states[(- 1)])):\n                states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n        else:\n            initial_output = (step_function(input_length[0], (initial_states + constants))[0] * 0)\n            initial_output = T.unbroadcast(initial_output, 0, 1)\n\n            def _step(input, mask, output_tm1, *states):\n                (output, new_states) = step_function(input, states)\n                output = T.switch(mask, output, output_tm1)\n                return_states = []\n                for (state, new_state) in zip(states, new_states):\n                    return_states.append(T.switch(mask, new_state, state))\n                return ([output] + return_states)\n            (results, _) = theano.scan(_step, sequences=[inputs, mask], outputs_info=([initial_output] + initial_states), non_sequences=constants, go_backwards=go_backwards)\n            if (type(results) is list):\n                outputs = results[0]\n                states = results[1:]\n            else:\n                outputs = results\n                states = []\n    elif unroll:\n        indices = list(range(input_length))\n        if go_backwards:\n            indices = indices[::(- 1)]\n        successive_outputs = []\n        successive_states = []\n        states = initial_states\n        for i in indices:\n            (output, states) = step_function(inputs[i], (states + constants))\n            successive_outputs.append(output)\n            successive_states.append(states)\n        outputs = T.stack(*successive_outputs)\n        states = []\n        for i in range(len(successive_states[(- 1)])):\n            states.append(T.stack(*[states_at_step[i] for states_at_step in successive_states]))\n    else:\n\n        def _step(input, *states):\n            (output, new_states) = step_function(input, states)\n            return ([output] + new_states)\n        (results, _) = theano.scan(_step, sequences=inputs, outputs_info=([None] + initial_states), non_sequences=constants, go_backwards=go_backwards)\n        if (type(results) is list):\n            outputs = results[0]\n            states = results[1:]\n        else:\n            outputs = results\n            states = []\n    outputs = T.squeeze(outputs)\n    last_output = outputs[(- 1)]\n    axes = ([1, 0] + list(range(2, outputs.ndim)))\n    outputs = outputs.dimshuffle(axes)\n    states = [T.squeeze(state[(- 1)]) for state in states]\n    return (last_output, outputs, states)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_when_is_valid_and_not_validation_errors_then_is_true(self):\n    user = UserWithRequiredName(name='Jack')\n    expect(user.is_valid).to(be_true)\n", "label": "Correct"}
{"function": "\n\ndef test_when_is_valid_and_not_validation_errors_then_is_true(self):\n    user = UserWithRequiredName(name='Jack')\n    expect(self.is_valid).to(be_true)\n", "label": "Variable misuse"}
{"function": "\n\ndef testNoneEquality(self):\n    et1 = ExpiryTime(None)\n    et2 = ExpiryTime(None)\n    self.assertEqual(et1, et2)\n    self.assertEqual(et2, et1)\n", "label": "Correct"}
{"function": "\n\ndef testNoneEquality(self):\n    et1 = ExpiryTime(None)\n    et2 = ExpiryTime(None)\n    self.assertEqual(et1, et2)\n    self.assertEqual(et2, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_dec_a_sets_zero_flag(self):\n    mpu = self._make_mpu()\n    self._write(mpu.memory, 0, [58])\n    mpu.a = 1\n    mpu.step()\n    self.assertEqual(mpu.ZERO, (mpu.p & mpu.ZERO))\n    self.assertEqual(0, (mpu.p & mpu.NEGATIVE))\n    self.assertEqual(0, mpu.a)\n", "label": "Correct"}
{"function": "\n\ndef test_dec_a_sets_zero_flag(self):\n    mpu = self._make_mpu()\n    self._write(mpu.memory, 0, [58])\n    mpu.a = 1\n    mpu.step()\n    self.assertEqual(mpu.ZERO, (mpu.p & mpu.ZERO))\n    mpu.assertEqual(0, (mpu.p & mpu.NEGATIVE))\n    self.assertEqual(0, mpu.a)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_env_name(self):\n    config = self._get_config('test_envname')\n    c = maestro.Conductor(config)\n    self.assertEqual(c.env_name, 'test')\n    foo1 = c.containers['foo-1']\n    self.assertEqual(foo1.env['MAESTRO_ENVIRONMENT_NAME'], 'test')\n", "label": "Correct"}
{"function": "\n\ndef test_env_name(self):\n    config = self._get_config('test_envname')\n    c = maestro.Conductor(c)\n    self.assertEqual(c.env_name, 'test')\n    foo1 = c.containers['foo-1']\n    self.assertEqual(foo1.env['MAESTRO_ENVIRONMENT_NAME'], 'test')\n", "label": "Variable misuse"}
{"function": "\n\ndef _op(self, method, other):\n    if isinstance(other, Counter):\n        other = other.value()\n    if (not isinstance(other, int)):\n        raise TypeError(('Cannot add %s, not an integer.' % other))\n    method(other)\n    return self\n", "label": "Correct"}
{"function": "\n\ndef _op(self, method, other):\n    if isinstance(other, Counter):\n        other = method.value()\n    if (not isinstance(other, int)):\n        raise TypeError(('Cannot add %s, not an integer.' % other))\n    method(other)\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_neighbors(self):\n    graph = nx.complete_graph(100)\n    pop = random.sample(list(graph), 1)\n    nbors = list(nx.neighbors(graph, pop[0]))\n    assert_equal(len(nbors), (len(graph) - 1))\n    graph = nx.path_graph(100)\n    node = random.sample(list(graph), 1)[0]\n    nbors = list(nx.neighbors(graph, node))\n    if ((node != 0) and (node != 99)):\n        assert_equal(len(nbors), 2)\n    else:\n        assert_equal(len(nbors), 1)\n    graph = nx.star_graph(99)\n    nbors = list(nx.neighbors(graph, 0))\n    assert_equal(len(nbors), 99)\n", "label": "Correct"}
{"function": "\n\ndef test_neighbors(self):\n    graph = nx.complete_graph(100)\n    pop = random.sample(list(graph), 1)\n    nbors = list(nx.neighbors(graph, pop[0]))\n    assert_equal(len(nbors), (len(graph) - 1))\n    graph = nx.path_graph(100)\n    node = random.sample(list(graph), 1)[0]\n    nbors = list(nx.neighbors(node, node))\n    if ((node != 0) and (node != 99)):\n        assert_equal(len(nbors), 2)\n    else:\n        assert_equal(len(nbors), 1)\n    graph = nx.star_graph(99)\n    nbors = list(nx.neighbors(graph, 0))\n    assert_equal(len(nbors), 99)\n", "label": "Variable misuse"}
{"function": "\n\ndef encode(self, input, final=False):\n    return codecs.utf_32_le_encode(input, self.errors)[0]\n", "label": "Correct"}
{"function": "\n\ndef encode(self, input, final=False):\n    return codecs.utf_32_le_encode(input, final.errors)[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super().clean()\n    actions = Action.objects.in_bulk(cleaned_data['actions'])\n    attachment_counter = 0\n    one_action = False\n    one_action_name = ''\n    actions_items = actions.items()\n    for (k, v) in actions_items:\n        action = getattr(self.model, v.name)\n        if getattr(action, 'return_attachment', False):\n            attachment_counter += 1\n        if getattr(action, 'only_one_action', False):\n            one_action = True\n            one_action_name = getattr(action, 'verbose_name', '')\n    if (attachment_counter > 1):\n        msg = _('Please select at most one action which return attachment.')\n        self.add_error('actions', msg)\n    if (one_action and (len(actions_items) > 1)):\n        msg = (_('You have chosen action: %(name)s can only be selected for transition') % {\n            'name': one_action_name,\n        })\n        self.add_error('actions', msg)\n    return cleaned_data\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super().clean()\n    actions = Action.objects.in_bulk(cleaned_data['actions'])\n    attachment_counter = 0\n    one_action = False\n    one_action_name = ''\n    actions_items = actions.items()\n    for (k, v) in actions_items:\n        action = getattr(self.model, v.name)\n        if getattr(action, 'return_attachment', False):\n            attachment_counter += 1\n        if getattr(action, 'only_one_action', False):\n            one_action = True\n            one_action_name = getattr(action, 'verbose_name', '')\n    if (attachment_counter > 1):\n        msg = _('Please select at most one action which return attachment.')\n        self.add_error('actions', msg)\n    if (attachment_counter and (len(actions_items) > 1)):\n        msg = (_('You have chosen action: %(name)s can only be selected for transition') % {\n            'name': one_action_name,\n        })\n        self.add_error('actions', msg)\n    return cleaned_data\n", "label": "Variable misuse"}
{"function": "\n\ndef test_adc_bcd_off_zp_ind_carry_clear_in_no_carry_clear_out(self):\n    mpu = self._make_mpu()\n    mpu.a = 1\n    self._write(mpu.memory, 0, (114, 16))\n    self._write(mpu.memory, 16, (205, 171))\n    mpu.memory[43981] = 254\n    mpu.step()\n    self.assertEqual(2, mpu.pc)\n    self.assertEqual(5, mpu.processorCycles)\n    self.assertEqual(255, mpu.a)\n    self.assertEqual(mpu.NEGATIVE, (mpu.p & mpu.NEGATIVE))\n    self.assertEqual(0, (mpu.p & mpu.CARRY))\n    self.assertEqual(0, (mpu.p & mpu.ZERO))\n", "label": "Correct"}
{"function": "\n\ndef test_adc_bcd_off_zp_ind_carry_clear_in_no_carry_clear_out(self):\n    mpu = self._make_mpu()\n    self.a = 1\n    self._write(mpu.memory, 0, (114, 16))\n    self._write(mpu.memory, 16, (205, 171))\n    mpu.memory[43981] = 254\n    mpu.step()\n    self.assertEqual(2, mpu.pc)\n    self.assertEqual(5, mpu.processorCycles)\n    self.assertEqual(255, mpu.a)\n    self.assertEqual(mpu.NEGATIVE, (mpu.p & mpu.NEGATIVE))\n    self.assertEqual(0, (mpu.p & mpu.CARRY))\n    self.assertEqual(0, (mpu.p & mpu.ZERO))\n", "label": "Variable misuse"}
{"function": "\n\ndef list_hosts(self, filters):\n    host_data_list = (self._hosts_collection().find(filters) or [])\n    return [host.Host.from_dict(h_data, conf=self.config) for h_data in host_data_list]\n", "label": "Correct"}
{"function": "\n\ndef list_hosts(self, filters):\n    host_data_list = (self._hosts_collection().find(filters) or [])\n    return [host.Host.from_dict(h_data, conf=self.config) for h_data in h_data]\n", "label": "Variable misuse"}
{"function": "\n\ndef input_pins(self, pins):\n    'Read multiple pins specified in the given list and return list of pin values\\n        GPIO.HIGH/True if the pin is pulled high, or GPIO.LOW/False if pulled low.\\n        '\n    return [self.input(pin) for pin in pins]\n", "label": "Correct"}
{"function": "\n\ndef input_pins(self, pins):\n    'Read multiple pins specified in the given list and return list of pin values\\n        GPIO.HIGH/True if the pin is pulled high, or GPIO.LOW/False if pulled low.\\n        '\n    return [self.input(pins) for pin in pins]\n", "label": "Variable misuse"}
{"function": "\n\ndef _patched_get_conn(self, connection_pool_class, connection_class_getter):\n    get_conn = connection_pool_class._get_conn\n\n    @functools.wraps(get_conn)\n    def patched_get_conn(pool, timeout=None):\n        connection = get_conn(pool, timeout)\n        connection_class = (pool.ConnectionCls if hasattr(pool, 'ConnectionCls') else connection_class_getter())\n        while (not isinstance(connection, connection_class)):\n            connection = get_conn(pool, timeout)\n        return connection\n    return patched_get_conn\n", "label": "Correct"}
{"function": "\n\ndef _patched_get_conn(self, connection_pool_class, connection_class_getter):\n    get_conn = self._get_conn\n\n    @functools.wraps(get_conn)\n    def patched_get_conn(pool, timeout=None):\n        connection = get_conn(pool, timeout)\n        connection_class = (pool.ConnectionCls if hasattr(pool, 'ConnectionCls') else connection_class_getter())\n        while (not isinstance(connection, connection_class)):\n            connection = get_conn(pool, timeout)\n        return connection\n    return patched_get_conn\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_2(self):\n    one = Polynomial((2, 4, 7, 3, 5, 2))\n    two = Polynomial((5, 2, 4, 2))\n    r = (one + two)\n    self.assertEqual(r.coefficients, (2, 4, 12, 5, 9, 4))\n", "label": "Correct"}
{"function": "\n\ndef test_add_2(self):\n    one = Polynomial((2, 4, 7, 3, 5, 2))\n    two = Polynomial((5, 2, 4, 2))\n    r = (one + two)\n    two.assertEqual(r.coefficients, (2, 4, 12, 5, 9, 4))\n", "label": "Variable misuse"}
{"function": "\n\ndef _collapse(intervals):\n    '\\n    Collapse an iterable of intervals sorted by start coord.\\n    \\n    '\n    span = None\n    for (start, stop) in intervals:\n        if (span is None):\n            span = _Interval(start, stop)\n        elif (start <= span.stop < stop):\n            span = _Interval(span.start, stop)\n        elif (start > span.stop):\n            (yield span)\n            span = _Interval(start, stop)\n    if (span is not None):\n        (yield span)\n", "label": "Correct"}
{"function": "\n\ndef _collapse(intervals):\n    '\\n    Collapse an iterable of intervals sorted by start coord.\\n    \\n    '\n    span = None\n    for (start, stop) in intervals:\n        if (span is None):\n            span = _Interval(start, stop)\n        elif (start <= span.stop < stop):\n            span = _Interval(span.start, start)\n        elif (start > span.stop):\n            (yield span)\n            span = _Interval(start, stop)\n    if (span is not None):\n        (yield span)\n", "label": "Variable misuse"}
{"function": "\n\ndef handle(self, *test_labels, **options):\n    skip_zip = options.get('skip_zip', False)\n    build.clean(skip_zip=skip_zip)\n", "label": "Correct"}
{"function": "\n\ndef handle(self, *test_labels, **options):\n    skip_zip = skip_zip.get('skip_zip', False)\n    build.clean(skip_zip=skip_zip)\n", "label": "Variable misuse"}
{"function": "\n\ndef armorPostProcess(self, item):\n    item.max_condition = random.randint(100, 10000)\n    item.setStringAttribute('armor_rating', random.choice(self.levels))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_kinetic', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_kinetic', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setIntAttribute('cat_armor_encumbrance.armor_health_encumbrance', random.randint(20, 300))\n    item.setIntAttribute('cat_armor_encumbrance.armor_action_encumbrance', random.randint(20, 300))\n    item.setIntAttribute('cat_armor_encumbrance.armor_mind_encumbrance', random.randint(20, 300))\n    item.setStringAttribute('crafter', 'Blue Frog, Inc.')\n", "label": "Correct"}
{"function": "\n\ndef armorPostProcess(self, item):\n    item.max_condition = random.randint(100, 10000)\n    item.setStringAttribute('armor_rating', random.choice(self.levels))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_kinetic', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_special_protection.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_effectiveness.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_kinetic', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    self.setFloatAttribute('cat_armor_vulnerability.armor_eff_energy', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_blast', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_stun', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_heat', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_cold', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_acid', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_elemental_electrical', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setFloatAttribute('cat_armor_vulnerability.armor_eff_restraint', (random.uniform(0, 100) if (random.random() > 0.7) else 0))\n    item.setIntAttribute('cat_armor_encumbrance.armor_health_encumbrance', random.randint(20, 300))\n    item.setIntAttribute('cat_armor_encumbrance.armor_action_encumbrance', random.randint(20, 300))\n    item.setIntAttribute('cat_armor_encumbrance.armor_mind_encumbrance', random.randint(20, 300))\n    item.setStringAttribute('crafter', 'Blue Frog, Inc.')\n", "label": "Variable misuse"}
{"function": "\n\ndef claim_invitations(user):\n    \"Claims any pending invitations for the given user's email address.\"\n    invitation_user_id = ('%s:%s' % (models.User.EMAIL_INVITATION, user.email_address))\n    invitation_user = models.User.query.get(invitation_user_id)\n    if invitation_user:\n        invited_build_list = list(invitation_user.builds)\n        if (not invited_build_list):\n            return\n        db.session.add(user)\n        logging.debug('Found %d build admin invitations for id=%r, user=%r', len(invited_build_list), invitation_user_id, user)\n        for build in invited_build_list:\n            build.owners.remove(invitation_user)\n            if (not build.is_owned_by(user.id)):\n                build.owners.append(user)\n                logging.debug('Claiming invitation for build_id=%r', build.id)\n                save_admin_log(build, invite_accepted=True)\n            else:\n                logging.debug('User already owner of build. id=%r, build_id=%r', user.id, build.id)\n            db.session.add(build)\n        db.session.delete(invitation_user)\n        db.session.commit()\n        db.session.add(current_user)\n", "label": "Correct"}
{"function": "\n\ndef claim_invitations(user):\n    \"Claims any pending invitations for the given user's email address.\"\n    invitation_user_id = ('%s:%s' % (models.User.EMAIL_INVITATION, build.email_address))\n    invitation_user = models.User.query.get(invitation_user_id)\n    if invitation_user:\n        invited_build_list = list(invitation_user.builds)\n        if (not invited_build_list):\n            return\n        db.session.add(user)\n        logging.debug('Found %d build admin invitations for id=%r, user=%r', len(invited_build_list), invitation_user_id, user)\n        for build in invited_build_list:\n            build.owners.remove(invitation_user)\n            if (not build.is_owned_by(user.id)):\n                build.owners.append(user)\n                logging.debug('Claiming invitation for build_id=%r', build.id)\n                save_admin_log(build, invite_accepted=True)\n            else:\n                logging.debug('User already owner of build. id=%r, build_id=%r', user.id, build.id)\n            db.session.add(build)\n        db.session.delete(invitation_user)\n        db.session.commit()\n        db.session.add(current_user)\n", "label": "Variable misuse"}
{"function": "\n\ndef process_exception(self, request, exception):\n    if (settings.DEBUG or isinstance(exception, Http404)):\n        return None\n    if isinstance(exception, apiproxy_errors.CapabilityDisabledError):\n        msg = 'Rietveld: App Engine is undergoing maintenance. Please try again in a while.'\n        status = 503\n    elif isinstance(exception, (DeadlineExceededError, MemoryError)):\n        msg = 'Rietveld is too hungry at the moment.Please try again in a while.'\n        status = 503\n    else:\n        msg = 'Unhandled exception.'\n        status = 500\n    logging.exception(('%s: ' % exception.__class__.__name__))\n    technical = ('%s [%s]' % (exception, exception.__class__.__name__))\n    if self._text_requested(request):\n        content = ('%s\\n\\n%s\\n' % (msg, technical))\n        content_type = 'text/plain'\n    else:\n        tpl = loader.get_template('exception.html')\n        ctx = Context({\n            'msg': msg,\n            'technical': technical,\n        })\n        content = tpl.render(ctx)\n        content_type = 'text/html'\n    return HttpResponse(content, status=status, content_type=content_type)\n", "label": "Correct"}
{"function": "\n\ndef process_exception(self, request, exception):\n    if (settings.DEBUG or isinstance(exception, Http404)):\n        return None\n    if isinstance(exception, apiproxy_errors.CapabilityDisabledError):\n        msg = 'Rietveld: App Engine is undergoing maintenance. Please try again in a while.'\n        status = 503\n    elif isinstance(exception, (DeadlineExceededError, MemoryError)):\n        msg = 'Rietveld is too hungry at the moment.Please try again in a while.'\n        status = 503\n    else:\n        msg = 'Unhandled exception.'\n        status = 500\n    logging.exception(('%s: ' % exception.__class__.__name__))\n    technical = ('%s [%s]' % (exception, ctx.__class__.__name__))\n    if self._text_requested(request):\n        content = ('%s\\n\\n%s\\n' % (msg, technical))\n        content_type = 'text/plain'\n    else:\n        tpl = loader.get_template('exception.html')\n        ctx = Context({\n            'msg': msg,\n            'technical': technical,\n        })\n        content = tpl.render(ctx)\n        content_type = 'text/html'\n    return HttpResponse(content, status=status, content_type=content_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_traverse_context_when_not_marked(self):\n    parent = Context(name='p')\n    n1 = Task(name='n1')\n    n2 = Task(name='n2')\n    parent.children.append(n1)\n    parent.children.append(n2)\n    parent.marked = False\n    visitor = DemoVisitor()\n    traverse(visitor, parent)\n    self.assertEqual(0, len(visitor.tasks_started))\n    self.assertEqual(0, len(visitor.contexts_started))\n    self.assertEqual(0, len(visitor.tasks_ended))\n    self.assertEqual(0, len(visitor.contexts_ended))\n", "label": "Correct"}
{"function": "\n\ndef test_traverse_context_when_not_marked(self):\n    parent = Context(name='p')\n    n1 = Task(name='n1')\n    n2 = Task(name='n2')\n    parent.children.append(n1)\n    parent.children.append(n2)\n    parent.marked = False\n    visitor = DemoVisitor()\n    traverse(visitor, parent)\n    self.assertEqual(0, len(visitor.tasks_started))\n    n2.assertEqual(0, len(visitor.contexts_started))\n    self.assertEqual(0, len(visitor.tasks_ended))\n    self.assertEqual(0, len(visitor.contexts_ended))\n", "label": "Variable misuse"}
{"function": "\n\ndef compress_js(self, js):\n    return self.compress_common(js, 'js', settings.YUGLIFY_JS_ARGUMENTS)\n", "label": "Correct"}
{"function": "\n\ndef compress_js(self, js):\n    return self.compress_common(self, 'js', settings.YUGLIFY_JS_ARGUMENTS)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef autofit(self):\n    \"\\n        Return |False| if there is a ``<w:tblLayout>`` child with ``w:type``\\n        attribute set to ``'fixed'``. Otherwise return |True|.\\n        \"\n    tblLayout = self.tblLayout\n    if (tblLayout is None):\n        return True\n    return (False if (tblLayout.type == 'fixed') else True)\n", "label": "Correct"}
{"function": "\n\n@property\ndef autofit(self):\n    \"\\n        Return |False| if there is a ``<w:tblLayout>`` child with ``w:type``\\n        attribute set to ``'fixed'``. Otherwise return |True|.\\n        \"\n    tblLayout = self.tblLayout\n    if (self is None):\n        return True\n    return (False if (tblLayout.type == 'fixed') else True)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_episode(self, url, imdb, tvdb, title, date, season, episode):\n    try:\n        if (url == None):\n            return\n        url = urlparse.urljoin(self.base_link, url)\n        (season, episode) = (('%01d' % int(season)), ('%01d' % int(episode)))\n        result = client.source(url)\n        if (not (season == '1')):\n            url = client.parseDOM(result, 'a', ret='href', attrs={\n                'class': 'season-.+?',\n            })\n            url = [i for i in url if (('/%s-sezon-' % season) in i)][0]\n            result = client.source(url)\n        result = client.parseDOM(result, 'a', ret='href')\n        result = [i for i in result if (('%s-sezon-%s-bolum-' % (season, episode)) in i)][0]\n        try:\n            url = re.compile('//.+?(/.+)').findall(result)[0]\n        except:\n            url = result\n        url = client.replaceHTMLCodes(url)\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Correct"}
{"function": "\n\ndef get_episode(self, url, imdb, tvdb, title, date, season, episode):\n    try:\n        if (url == None):\n            return\n        url = urlparse.urljoin(self.base_link, url)\n        (season, episode) = (('%01d' % int(season)), ('%01d' % int(episode)))\n        result = client.source(url)\n        if (not (season == '1')):\n            url = client.parseDOM(result, 'a', ret='href', attrs={\n                'class': 'season-.+?',\n            })\n            url = [i for i in url if (('/%s-sezon-' % title) in i)][0]\n            result = client.source(url)\n        result = client.parseDOM(result, 'a', ret='href')\n        result = [i for i in result if (('%s-sezon-%s-bolum-' % (season, episode)) in i)][0]\n        try:\n            url = re.compile('//.+?(/.+)').findall(result)[0]\n        except:\n            url = result\n        url = client.replaceHTMLCodes(url)\n        url = url.encode('utf-8')\n        return url\n    except:\n        return\n", "label": "Variable misuse"}
{"function": "\n\ndef update_dimension_fields(self, instance, force=False, *args, **kwargs):\n    if ((getattr(instance, 'mimetype', None) is not None) and ('image' in instance.mimetype)):\n        super(FileField, self).update_dimension_fields(instance, force, *args, **kwargs)\n    else:\n        pass\n", "label": "Correct"}
{"function": "\n\ndef update_dimension_fields(self, instance, force=False, *args, **kwargs):\n    if ((getattr(instance, 'mimetype', None) is not None) and ('image' in instance.mimetype)):\n        super(FileField, force).update_dimension_fields(instance, force, *args, **kwargs)\n    else:\n        pass\n", "label": "Variable misuse"}
{"function": "\n\ndef HKDF_extract(salt, IKM, hashmod=hashlib.sha256):\n    'HKDF-Extract; see RFC-5869 for the details.'\n    if (salt is None):\n        salt = (b'\\x00' * hashmod().digest_size)\n    if isinstance(salt, text_type):\n        salt = salt.encode('utf-8')\n    return python_hmac.new(salt, IKM, hashmod).digest()\n", "label": "Correct"}
{"function": "\n\ndef HKDF_extract(salt, IKM, hashmod=hashlib.sha256):\n    'HKDF-Extract; see RFC-5869 for the details.'\n    if (IKM is None):\n        salt = (b'\\x00' * hashmod().digest_size)\n    if isinstance(salt, text_type):\n        salt = salt.encode('utf-8')\n    return python_hmac.new(salt, IKM, hashmod).digest()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_task_loader_has_cmd_list(self, monkeypatch):\n    cmd_names = []\n\n    def save_cmd_names(self, params, args):\n        cmd_names.extend(self.loader.cmd_names)\n    monkeypatch.setattr(Run, 'execute', save_cmd_names)\n    cmd_main([])\n    assert ('list' in cmd_names)\n", "label": "Correct"}
{"function": "\n\ndef test_task_loader_has_cmd_list(self, monkeypatch):\n    cmd_names = []\n\n    def save_cmd_names(self, params, args):\n        cmd_names.extend(self.loader.cmd_names)\n    monkeypatch.setattr(Run, 'execute', save_cmd_names)\n    cmd_main([])\n    assert ('list' in monkeypatch)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self, edit):\n    api = GistApi(self.settings['token'])\n    thread = threading.Thread(target=api.retrieve, args=(self.raw_url,))\n    thread.start()\n    ThreadProgress(api, thread, ('Refreshing Gist %s' % self.fileName), callback.refresh_gist, _callback_options={\n        'fileFullName': self.fileFullName,\n    })\n", "label": "Correct"}
{"function": "\n\ndef run(self, edit):\n    api = GistApi(thread.settings['token'])\n    thread = threading.Thread(target=api.retrieve, args=(self.raw_url,))\n    thread.start()\n    ThreadProgress(api, thread, ('Refreshing Gist %s' % self.fileName), callback.refresh_gist, _callback_options={\n        'fileFullName': self.fileFullName,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef _FormatTimestamp(self, timestamp):\n    'Formats a timestamp (in UTC) via default format.'\n    return self._XEscape(time.asctime(time.gmtime(timestamp)))\n", "label": "Correct"}
{"function": "\n\ndef _FormatTimestamp(self, timestamp):\n    'Formats a timestamp (in UTC) via default format.'\n    return self._XEscape(time.asctime(time.gmtime(self)))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, env):\n    self.env = env\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, env):\n    self.env = self\n", "label": "Variable misuse"}
{"function": "\n\n@contextmanager\ndef pushd(path):\n    'Context manager that changes to ``path`` directory on enter and\\n    changes back to ``os.getcwd()`` on exit.\\n    '\n    cwd = os.getcwd()\n    os.chdir(os.path.abspath(path))\n    try:\n        (yield)\n    finally:\n        os.chdir(cwd)\n", "label": "Correct"}
{"function": "\n\n@contextmanager\ndef pushd(path):\n    'Context manager that changes to ``path`` directory on enter and\\n    changes back to ``os.getcwd()`` on exit.\\n    '\n    cwd = os.getcwd()\n    os.chdir(os.path.abspath(path))\n    try:\n        (yield)\n    finally:\n        os.chdir(path)\n", "label": "Variable misuse"}
{"function": "\n\ndef delete(self, sid):\n    '\\n        Delete a given Notificiation\\n        '\n    return self.delete_instance(sid)\n", "label": "Correct"}
{"function": "\n\ndef delete(self, sid):\n    '\\n        Delete a given Notificiation\\n        '\n    return sid.delete_instance(sid)\n", "label": "Variable misuse"}
{"function": "\n\n@id.setter\ndef id(self, value):\n    self._id = value\n", "label": "Correct"}
{"function": "\n\n@id.setter\ndef id(self, value):\n    value._id = value\n", "label": "Variable misuse"}
{"function": "\n\ndef _handle_object_info_reply(self, rep):\n    ' Handle replies for call tips.\\n        '\n    cursor = self._get_cursor()\n    info = self._request_info.get('call_tip')\n    if (info and (info.id == rep['parent_header']['msg_id']) and (info.pos == cursor.position())):\n        content = rep['content']\n        if content.get('ismagic', False):\n            (call_info, doc) = (None, None)\n        else:\n            (call_info, doc) = call_tip(content, format_call=True)\n        if (call_info or doc):\n            self._call_tip_widget.show_call_info(call_info, doc)\n", "label": "Correct"}
{"function": "\n\ndef _handle_object_info_reply(self, rep):\n    ' Handle replies for call tips.\\n        '\n    cursor = self._get_cursor()\n    info = self._request_info.get('call_tip')\n    if (info and (info.id == rep['parent_header']['msg_id']) and (info.pos == cursor.position())):\n        content = rep['content']\n        if content.get('ismagic', False):\n            (call_info, doc) = (None, None)\n        else:\n            (call_info, doc) = call_tip(content, format_call=True)\n        if (call_info or doc):\n            rep._call_tip_widget.show_call_info(call_info, doc)\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef _options(fieldname):\n    \"\\n            Lookup the full set of options for a Filter Widget\\n            - for Subscriptions we don't want to see just the options available in current data\\n        \"\n    db = current.db\n    if (fieldname == 'location_id'):\n        table = current.s3db.gis_location\n        query = ((table.deleted == False) & (table.level == 'L1'))\n        rows = db(query).select(table.id)\n        options = [row.id for row in rows]\n    return options\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef _options(fieldname):\n    \"\\n            Lookup the full set of options for a Filter Widget\\n            - for Subscriptions we don't want to see just the options available in current data\\n        \"\n    db = current.db\n    if (fieldname == 'location_id'):\n        table = current.s3db.gis_location\n        query = ((table.deleted == False) & (rows.level == 'L1'))\n        rows = db(query).select(table.id)\n        options = [row.id for row in rows]\n    return options\n", "label": "Variable misuse"}
{"function": "\n\ndef create_user_profile(sender, instance, created, **kwargs):\n    if created:\n        UserProfile.objects.create(user=instance)\n", "label": "Correct"}
{"function": "\n\ndef create_user_profile(sender, instance, created, **kwargs):\n    if kwargs:\n        UserProfile.objects.create(user=instance)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, transport):\n    self._transport = transport\n    self._sessions = {\n        \n    }\n    self._used_ids_ba = bitarray((2 ** 16))\n    self._used_ids_ba.setall(False)\n    self._lock = threading.RLock()\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, transport):\n    self._transport = self\n    self._sessions = {\n        \n    }\n    self._used_ids_ba = bitarray((2 ** 16))\n    self._used_ids_ba.setall(False)\n    self._lock = threading.RLock()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_radius_neighbors_classifier_when_no_neighbors():\n    X = np.array([[1.0, 1.0], [2.0, 2.0]])\n    y = np.array([1, 2])\n    radius = 0.1\n    z1 = np.array([[1.01, 1.01], [2.01, 2.01]])\n    z2 = np.array([[1.01, 1.01], [1.4, 1.4]])\n    weight_func = _weight_func\n    for outlier_label in [0, (- 1), None]:\n        for algorithm in ALGORITHMS:\n            for weights in ['uniform', 'distance', weight_func]:\n                rnc = neighbors.RadiusNeighborsClassifier\n                clf = rnc(radius=radius, weights=weights, algorithm=algorithm, outlier_label=outlier_label)\n                clf.fit(X, y)\n                assert_array_equal(np.array([1, 2]), clf.predict(z1))\n                if (outlier_label is None):\n                    assert_raises(ValueError, clf.predict, z2)\n                elif False:\n                    assert_array_equal(np.array([1, outlier_label]), clf.predict(z2))\n", "label": "Correct"}
{"function": "\n\ndef test_radius_neighbors_classifier_when_no_neighbors():\n    X = np.array([[1.0, 1.0], [2.0, 2.0]])\n    y = np.array([1, 2])\n    radius = 0.1\n    z1 = np.array([[1.01, 1.01], [2.01, 2.01]])\n    z2 = np.array([[1.01, 1.01], [1.4, 1.4]])\n    weight_func = _weight_func\n    for outlier_label in [0, (- 1), None]:\n        for algorithm in ALGORITHMS:\n            for weights in ['uniform', 'distance', weight_func]:\n                rnc = neighbors.RadiusNeighborsClassifier\n                clf = rnc(radius=radius, weights=weights, algorithm=algorithm, outlier_label=outlier_label)\n                clf.fit(X, y)\n                assert_array_equal(np.array([1, 2]), clf.predict(z1))\n                if (outlier_label is None):\n                    assert_raises(ValueError, clf.predict, z2)\n                elif False:\n                    assert_array_equal(np.array([1, outlier_label]), algorithm.predict(z2))\n", "label": "Variable misuse"}
{"function": "\n\ndef _open_rx_diskfile(self, obj_name, policy, frag_index=None):\n    df = self.rx_controller.get_diskfile(self.device, self.partition, 'a', 'c', obj_name, policy=policy, frag_index=frag_index)\n    df.open()\n    return df\n", "label": "Correct"}
{"function": "\n\ndef _open_rx_diskfile(self, obj_name, policy, frag_index=None):\n    df = self.rx_controller.get_diskfile(self.device, self.partition, 'a', 'c', obj_name, policy=df, frag_index=frag_index)\n    df.open()\n    return df\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef _get_commits(cls):\n    commits = [{\n        'message': 'Initial commit',\n        'author': 'Joe Doe <joe.doe@example.com>',\n        'date': datetime.datetime(2010, 1, 1, 20),\n        'added': [FileNode('file1', content='Foobar')],\n    }, {\n        'message': 'Added a file',\n        'author': 'Joe Doe <joe.doe@example.com>',\n        'date': datetime.datetime(2010, 1, 1, 20),\n        'added': [FileNode('file2', content='Foobar')],\n    }]\n    return commits\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef _get_commits(cls):\n    commits = [{\n        'message': 'Initial commit',\n        'author': 'Joe Doe <joe.doe@example.com>',\n        'date': datetime.datetime(2010, 1, 1, 20),\n        'added': [FileNode('file1', content='Foobar')],\n    }, {\n        'message': 'Added a file',\n        'author': 'Joe Doe <joe.doe@example.com>',\n        'date': datetime.datetime(2010, 1, 1, 20),\n        'added': [FileNode('file2', content='Foobar')],\n    }]\n    return cls\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, attributes, key, value=None):\n    key = (key, self.path)\n    if (key in attributes):\n        return attributes[key]\n    else:\n        return value\n", "label": "Correct"}
{"function": "\n\ndef get(self, attributes, key, value=None):\n    key = (key, self.path)\n    if (key in attributes):\n        return attributes[key]\n    else:\n        return key\n", "label": "Variable misuse"}
{"function": "\n\ndef get_sources(self, url, hosthdDict, hostDict, locDict):\n    return\n    try:\n        sources = []\n        if (url == None):\n            return sources\n        data = os.path.join(control.dataPath, 'moviefarsi.db')\n        download = True\n        try:\n            download = (abs((datetime.datetime.fromtimestamp(os.path.getmtime(data)) - datetime.datetime.now())) > datetime.timedelta(days=7))\n        except:\n            pass\n        if (download == True):\n            result = client.source(base64.b64decode(self.data_link))\n            zip = zipfile.ZipFile(StringIO.StringIO(result))\n            zip.extractall(control.dataPath)\n            zip.close()\n        dbcon = database.connect(data)\n        dbcur = dbcon.cursor()\n        content = re.compile('(.+?)\\\\sS\\\\d*E\\\\d*$').findall(url)\n        if (len(content) == 0):\n            (title, year) = re.compile('(.+?) (\\\\d{4})$').findall(url)[0]\n            title = cleantitle.movie(title)\n            dbcur.execute((\"SELECT * FROM movies WHERE year = '%s'\" % year))\n            result = dbcur.fetchone()\n            result = eval(result[1].encode('utf-8'))\n            links = [(i, re.sub('(\\\\.|\\\\(|\\\\[|\\\\s)(\\\\d{4}|3D)(\\\\.|\\\\)|\\\\]|\\\\s|)(.+|)', '', i)) for i in result]\n            links = [i[0] for i in links if (title == cleantitle.movie(os.path.basename(i[1])))]\n            for i in links:\n                try:\n                    url = client.replaceHTMLCodes(i)\n                    url = url.encode('utf-8')\n                    if (not url.endswith(('mp4', 'mkv'))):\n                        raise Exception()\n                    fmt = re.sub('(.+)(\\\\.|\\\\(|\\\\[|\\\\s)(\\\\d{4})(\\\\.|\\\\)|\\\\]|\\\\s)', '', i)\n                    fmt = re.split('\\\\.|\\\\(|\\\\)|\\\\[|\\\\]|\\\\s|\\\\-|\\\\_', fmt)\n                    fmt = [x.lower() for x in fmt]\n                    if ('1080p' in fmt):\n                        quality = '1080p'\n                    elif (('720p' in fmt) or ('hd' in fmt)):\n                        quality = 'HD'\n                    else:\n                        quality = 'SD'\n                    if ('3d' in fmt):\n                        info = '3D'\n                    else:\n                        info = ''\n                    control.log('### FARSI ')\n                    sources.append({\n                        'source': 'Moviefarsi',\n                        'quality': quality,\n                        'provider': 'Moviefarsiv2',\n                        'url': url,\n                        'info': info,\n                    })\n                except:\n                    pass\n        else:\n            (tvshowtitle, season, episode) = re.compile('(.+?)\\\\sS(\\\\d*)E(\\\\d*)$').findall(url)[0]\n            tvshowtitle = cleantitle.tv(tvshowtitle)\n            dbcur.execute((\"SELECT * FROM tvshows WHERE tvshowtitle = '%s'\" % tvshowtitle))\n            result = dbcur.fetchone()\n            result = eval(result[1].encode('utf-8'))\n            match = [('S%sE%s' % (season, episode)), ('S%s E%s' % (season, episode))]\n            links = [(i, os.path.basename(i)) for i in result]\n            links = [i[0] for i in links if any(((x in i[1]) for x in match))]\n            for i in links:\n                try:\n                    url = client.replaceHTMLCodes(i)\n                    url = url.encode('utf-8')\n                    fmt = os.path.basename(url).lower()\n                    if ('1080p' in fmt):\n                        quality = '1080p'\n                    elif (('720p' in fmt) or ('hd' in fmt)):\n                        quality = 'HD'\n                    else:\n                        quality = 'SD'\n                    sources.append({\n                        'source': 'Moviefarsi',\n                        'quality': quality,\n                        'provider': 'Moviefarsiv2',\n                        'url': url,\n                    })\n                except:\n                    pass\n        return sources\n    except:\n        return sources\n", "label": "Correct"}
{"function": "\n\ndef get_sources(self, url, hosthdDict, hostDict, locDict):\n    return\n    try:\n        sources = []\n        if (url == None):\n            return sources\n        data = os.path.join(control.dataPath, 'moviefarsi.db')\n        download = True\n        try:\n            download = (abs((datetime.datetime.fromtimestamp(os.path.getmtime(data)) - datetime.datetime.now())) > datetime.timedelta(days=7))\n        except:\n            pass\n        if (download == True):\n            result = client.source(base64.b64decode(self.data_link))\n            zip = zipfile.ZipFile(StringIO.StringIO(result))\n            zip.extractall(control.dataPath)\n            i.close()\n        dbcon = database.connect(data)\n        dbcur = dbcon.cursor()\n        content = re.compile('(.+?)\\\\sS\\\\d*E\\\\d*$').findall(url)\n        if (len(content) == 0):\n            (title, year) = re.compile('(.+?) (\\\\d{4})$').findall(url)[0]\n            title = cleantitle.movie(title)\n            dbcur.execute((\"SELECT * FROM movies WHERE year = '%s'\" % year))\n            result = dbcur.fetchone()\n            result = eval(result[1].encode('utf-8'))\n            links = [(i, re.sub('(\\\\.|\\\\(|\\\\[|\\\\s)(\\\\d{4}|3D)(\\\\.|\\\\)|\\\\]|\\\\s|)(.+|)', '', i)) for i in result]\n            links = [i[0] for i in links if (title == cleantitle.movie(os.path.basename(i[1])))]\n            for i in links:\n                try:\n                    url = client.replaceHTMLCodes(i)\n                    url = url.encode('utf-8')\n                    if (not url.endswith(('mp4', 'mkv'))):\n                        raise Exception()\n                    fmt = re.sub('(.+)(\\\\.|\\\\(|\\\\[|\\\\s)(\\\\d{4})(\\\\.|\\\\)|\\\\]|\\\\s)', '', i)\n                    fmt = re.split('\\\\.|\\\\(|\\\\)|\\\\[|\\\\]|\\\\s|\\\\-|\\\\_', fmt)\n                    fmt = [x.lower() for x in fmt]\n                    if ('1080p' in fmt):\n                        quality = '1080p'\n                    elif (('720p' in fmt) or ('hd' in fmt)):\n                        quality = 'HD'\n                    else:\n                        quality = 'SD'\n                    if ('3d' in fmt):\n                        info = '3D'\n                    else:\n                        info = ''\n                    control.log('### FARSI ')\n                    sources.append({\n                        'source': 'Moviefarsi',\n                        'quality': quality,\n                        'provider': 'Moviefarsiv2',\n                        'url': url,\n                        'info': info,\n                    })\n                except:\n                    pass\n        else:\n            (tvshowtitle, season, episode) = re.compile('(.+?)\\\\sS(\\\\d*)E(\\\\d*)$').findall(url)[0]\n            tvshowtitle = cleantitle.tv(tvshowtitle)\n            dbcur.execute((\"SELECT * FROM tvshows WHERE tvshowtitle = '%s'\" % tvshowtitle))\n            result = dbcur.fetchone()\n            result = eval(result[1].encode('utf-8'))\n            match = [('S%sE%s' % (season, episode)), ('S%s E%s' % (season, episode))]\n            links = [(i, os.path.basename(i)) for i in result]\n            links = [i[0] for i in links if any(((x in i[1]) for x in match))]\n            for i in links:\n                try:\n                    url = client.replaceHTMLCodes(i)\n                    url = url.encode('utf-8')\n                    fmt = os.path.basename(url).lower()\n                    if ('1080p' in fmt):\n                        quality = '1080p'\n                    elif (('720p' in fmt) or ('hd' in fmt)):\n                        quality = 'HD'\n                    else:\n                        quality = 'SD'\n                    sources.append({\n                        'source': 'Moviefarsi',\n                        'quality': quality,\n                        'provider': 'Moviefarsiv2',\n                        'url': url,\n                    })\n                except:\n                    pass\n        return sources\n    except:\n        return sources\n", "label": "Variable misuse"}
{"function": "\n\ndef set_message(self, x):\n    self.has_message_ = 1\n    self.message_ = x\n", "label": "Correct"}
{"function": "\n\ndef set_message(self, x):\n    self.has_message_ = 1\n    x.message_ = x\n", "label": "Variable misuse"}
{"function": "\n\n@fluff.date_emitter\ndef reviewed_due_to_registration(self, form):\n    if (self._get_total(form, BOOKING_FORMS, 'reviewed') == True):\n        (yield [form.received_on, 1])\n", "label": "Correct"}
{"function": "\n\n@fluff.date_emitter\ndef reviewed_due_to_registration(self, form):\n    if (self._get_total(form, BOOKING_FORMS, 'reviewed') == True):\n        (yield [self.received_on, 1])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_add_to_app(self):\n    route = default.Pluggable('/', self.View, 'foo')\n    route.add_to_app(self.app)\n    self.assertEqual(url_for('foo'), '/')\n    self.assertEqual(self.client.get('/').data, b'foo')\n", "label": "Correct"}
{"function": "\n\ndef test_add_to_app(self):\n    route = default.Pluggable('/', self.View, 'foo')\n    route.add_to_app(self.app)\n    route.assertEqual(url_for('foo'), '/')\n    self.assertEqual(self.client.get('/').data, b'foo')\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, fin=0, rsv1=0, rsv2=0, rsv3=0, opcode=OPCODE_TEXT, mask=1, data=''):\n    '\\n        Constructor for ABNF.\\n        please check RFC for arguments.\\n        '\n    self.fin = fin\n    self.rsv1 = rsv1\n    self.rsv2 = rsv2\n    self.rsv3 = rsv3\n    self.opcode = opcode\n    self.mask = mask\n    self.data = data\n    self.get_mask_key = os.urandom\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, fin=0, rsv1=0, rsv2=0, rsv3=0, opcode=OPCODE_TEXT, mask=1, data=''):\n    '\\n        Constructor for ABNF.\\n        please check RFC for arguments.\\n        '\n    self.fin = fin\n    self.rsv1 = rsv1\n    self.rsv2 = rsv2\n    self.rsv3 = rsv3\n    self.opcode = opcode\n    self.mask = rsv3\n    self.data = data\n    self.get_mask_key = os.urandom\n", "label": "Variable misuse"}
{"function": "\n\ndef addNode(self, value):\n    if (not self.head):\n        self._addFirst(value)\n    else:\n        self._add(value)\n", "label": "Correct"}
{"function": "\n\ndef addNode(self, value):\n    if (not self.head):\n        self._addFirst(value)\n    else:\n        value._add(value)\n", "label": "Variable misuse"}
{"function": "\n\ndef is_iterable(maybe_iter, unless=(string_types, dict)):\n    \" Return whether ``maybe_iter`` is an iterable, unless it's an instance of one\\n    of the base class, or tuple of base classes, given in ``unless``.\\n\\n    Example::\\n\\n        >>> is_iterable('foo')\\n        False\\n        >>> is_iterable(['foo'])\\n        True\\n        >>> is_iterable(['foo'], unless=list)\\n        False\\n        >>> is_iterable(xrange(5))\\n        True\\n    \"\n    try:\n        iter(maybe_iter)\n    except TypeError:\n        return False\n    return (not isinstance(maybe_iter, unless))\n", "label": "Correct"}
{"function": "\n\ndef is_iterable(maybe_iter, unless=(string_types, dict)):\n    \" Return whether ``maybe_iter`` is an iterable, unless it's an instance of one\\n    of the base class, or tuple of base classes, given in ``unless``.\\n\\n    Example::\\n\\n        >>> is_iterable('foo')\\n        False\\n        >>> is_iterable(['foo'])\\n        True\\n        >>> is_iterable(['foo'], unless=list)\\n        False\\n        >>> is_iterable(xrange(5))\\n        True\\n    \"\n    try:\n        iter(maybe_iter)\n    except TypeError:\n        return False\n    return (not isinstance(unless, unless))\n", "label": "Variable misuse"}
{"function": "\n\n@converts('FloatField')\ndef conv_Float(self, model, field, kwargs):\n    self._number_common(model, field, kwargs)\n    return f.FloatField(**kwargs)\n", "label": "Correct"}
{"function": "\n\n@converts('FloatField')\ndef conv_Float(self, model, field, kwargs):\n    self._number_common(kwargs, field, kwargs)\n    return f.FloatField(**kwargs)\n", "label": "Variable misuse"}
{"function": "\n\n@decorators.which('sync')\n@decorators.which('mkfs')\ndef format_(device, fs_type='ext4', inode_size=None, lazy_itable_init=None, force=False):\n    \"\\n    Format a filesystem onto a block device\\n\\n    .. versionadded:: 2015.8.2\\n\\n    device\\n        The block device in which to create the new filesystem\\n\\n    fs_type\\n        The type of filesystem to create\\n\\n    inode_size\\n        Size of the inodes\\n\\n        This option is only enabled for ext and xfs filesystems\\n\\n    lazy_itable_init\\n        If enabled and the uninit_bg feature is enabled, the inode table will\\n        not be fully initialized by mke2fs.  This speeds up filesystem\\n        initialization noticeably, but it requires the kernel to finish\\n        initializing the filesystem  in  the  background  when  the filesystem\\n        is first mounted.  If the option value is omitted, it defaults to 1 to\\n        enable lazy inode table zeroing.\\n\\n        This option is only enabled for ext filesystems\\n\\n    force\\n        Force mke2fs to create a filesystem, even if the specified device is\\n        not a partition on a block special device. This option is only enabled\\n        for ext and xfs filesystems\\n\\n        This option is dangerous, use it with caution.\\n\\n        .. versionadded:: Carbon\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' blockdev.format /dev/sdX1\\n    \"\n    cmd = ['mkfs', '-t', str(fs_type)]\n    if (inode_size is not None):\n        if (fs_type[:3] == 'ext'):\n            cmd.extend(['-i', str(inode_size)])\n        elif (fs_type == 'xfs'):\n            cmd.extend(['-i', 'size={0}'.format(inode_size)])\n    if (lazy_itable_init is not None):\n        if (fs_type[:3] == 'ext'):\n            cmd.extend(['-E', 'lazy_itable_init={0}'.format(lazy_itable_init)])\n    if force:\n        if (fs_type[:3] == 'ext'):\n            cmd.append('-F')\n        elif (fs_type == 'xfs'):\n            cmd.append('-f')\n    cmd.append(str(device))\n    mkfs_success = (__salt__['cmd.retcode'](cmd, ignore_retcode=True) == 0)\n    sync_success = (__salt__['cmd.retcode']('sync', ignore_retcode=True) == 0)\n    return all([mkfs_success, sync_success])\n", "label": "Correct"}
{"function": "\n\n@decorators.which('sync')\n@decorators.which('mkfs')\ndef format_(device, fs_type='ext4', inode_size=None, lazy_itable_init=None, force=False):\n    \"\\n    Format a filesystem onto a block device\\n\\n    .. versionadded:: 2015.8.2\\n\\n    device\\n        The block device in which to create the new filesystem\\n\\n    fs_type\\n        The type of filesystem to create\\n\\n    inode_size\\n        Size of the inodes\\n\\n        This option is only enabled for ext and xfs filesystems\\n\\n    lazy_itable_init\\n        If enabled and the uninit_bg feature is enabled, the inode table will\\n        not be fully initialized by mke2fs.  This speeds up filesystem\\n        initialization noticeably, but it requires the kernel to finish\\n        initializing the filesystem  in  the  background  when  the filesystem\\n        is first mounted.  If the option value is omitted, it defaults to 1 to\\n        enable lazy inode table zeroing.\\n\\n        This option is only enabled for ext filesystems\\n\\n    force\\n        Force mke2fs to create a filesystem, even if the specified device is\\n        not a partition on a block special device. This option is only enabled\\n        for ext and xfs filesystems\\n\\n        This option is dangerous, use it with caution.\\n\\n        .. versionadded:: Carbon\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' blockdev.format /dev/sdX1\\n    \"\n    cmd = ['mkfs', '-t', str(fs_type)]\n    if (inode_size is not None):\n        if (fs_type[:3] == 'ext'):\n            sync_success.extend(['-i', str(inode_size)])\n        elif (fs_type == 'xfs'):\n            cmd.extend(['-i', 'size={0}'.format(inode_size)])\n    if (lazy_itable_init is not None):\n        if (fs_type[:3] == 'ext'):\n            cmd.extend(['-E', 'lazy_itable_init={0}'.format(lazy_itable_init)])\n    if force:\n        if (fs_type[:3] == 'ext'):\n            cmd.append('-F')\n        elif (fs_type == 'xfs'):\n            cmd.append('-f')\n    cmd.append(str(device))\n    mkfs_success = (__salt__['cmd.retcode'](cmd, ignore_retcode=True) == 0)\n    sync_success = (__salt__['cmd.retcode']('sync', ignore_retcode=True) == 0)\n    return all([mkfs_success, sync_success])\n", "label": "Variable misuse"}
{"function": "\n\ndef OutputPartial(self, out):\n    if self.has_package_:\n        out.putVarInt32(10)\n        out.putPrefixedString(self.package_)\n    for i in xrange(len(self.capability_)):\n        out.putVarInt32(18)\n        out.putPrefixedString(self.capability_[i])\n    for i in xrange(len(self.call_)):\n        out.putVarInt32(26)\n        out.putPrefixedString(self.call_[i])\n", "label": "Correct"}
{"function": "\n\ndef OutputPartial(self, out):\n    if self.has_package_:\n        out.putVarInt32(10)\n        out.putPrefixedString(self.package_)\n    for i in xrange(len(self.capability_)):\n        out.putVarInt32(18)\n        out.putPrefixedString(self.capability_[out])\n    for i in xrange(len(self.call_)):\n        out.putVarInt32(26)\n        out.putPrefixedString(self.call_[i])\n", "label": "Variable misuse"}
{"function": "\n\ndef check_records(self, template, stream):\n    expected = [line.format(self.filename) for line in template]\n    records = ''.join(stream.buflist).splitlines()\n    self.assertEqual(records, expected)\n", "label": "Correct"}
{"function": "\n\ndef check_records(self, template, stream):\n    expected = [line.format(self.filename) for line in template]\n    records = ''.join(records.buflist).splitlines()\n    self.assertEqual(records, expected)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_func_adds_roots(self):\n\n    def add_roots(doc):\n        doc.add_root(AnotherModelInTestFunction())\n        doc.add_root(SomeModelInTestFunction())\n    handler = FunctionHandler(add_roots)\n    doc = Document()\n    handler.modify_document(doc)\n    if handler.failed:\n        raise RuntimeError(handler.error)\n    assert (len(doc.roots) == 2)\n", "label": "Correct"}
{"function": "\n\ndef test_func_adds_roots(self):\n\n    def add_roots(doc):\n        doc.add_root(AnotherModelInTestFunction())\n        doc.add_root(SomeModelInTestFunction())\n    handler = FunctionHandler(add_roots)\n    doc = Document()\n    handler.modify_document(doc)\n    if doc.failed:\n        raise RuntimeError(handler.error)\n    assert (len(doc.roots) == 2)\n", "label": "Variable misuse"}
{"function": "\n\ndef fetchall(self):\n    return [self.format_results(row) for row in self.cursor.fetchall()]\n", "label": "Correct"}
{"function": "\n\ndef fetchall(self):\n    return [self.format_results(self) for row in self.cursor.fetchall()]\n", "label": "Variable misuse"}
{"function": "\n\ndef startbody(self, ctype, plist=[], prefix=1):\n    'Returns a file-like object for writing the body of the message.\\n\\n        The content-type is set to the provided ctype, and the optional\\n        parameter, plist, provides additional parameters for the\\n        content-type declaration.  The optional argument prefix determines\\n        where the header is inserted; 0 means append at the end, 1 means\\n        insert at the start. The default is to insert at the start.\\n\\n        '\n    for (name, value) in plist:\n        ctype = (ctype + (';\\n %s=\"%s\"' % (name, value)))\n    self.addheader('Content-Type', ctype, prefix=prefix)\n    self.flushheaders()\n    self._fp.write('\\n')\n    return self._fp\n", "label": "Correct"}
{"function": "\n\ndef startbody(self, ctype, plist=[], prefix=1):\n    'Returns a file-like object for writing the body of the message.\\n\\n        The content-type is set to the provided ctype, and the optional\\n        parameter, plist, provides additional parameters for the\\n        content-type declaration.  The optional argument prefix determines\\n        where the header is inserted; 0 means append at the end, 1 means\\n        insert at the start. The default is to insert at the start.\\n\\n        '\n    for (name, value) in prefix:\n        ctype = (ctype + (';\\n %s=\"%s\"' % (name, value)))\n    self.addheader('Content-Type', ctype, prefix=prefix)\n    self.flushheaders()\n    self._fp.write('\\n')\n    return self._fp\n", "label": "Variable misuse"}
{"function": "\n\ndef get_state(self, instance):\n    return instance.__dict__[self.attname]\n", "label": "Correct"}
{"function": "\n\ndef get_state(self, instance):\n    return instance.__dict__[instance.attname]\n", "label": "Variable misuse"}
{"function": "\n\ndef rowproxy_reconstructor(cls, state):\n    return safe_rowproxy_reconstructor(cls, state)\n", "label": "Correct"}
{"function": "\n\ndef rowproxy_reconstructor(cls, state):\n    return safe_rowproxy_reconstructor(state, state)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_cert_store(self):\n    '\\n        Get the certificate store for the context.\\n\\n        :return: A X509Store object or None if it does not have one.\\n        '\n    store = _lib.SSL_CTX_get_cert_store(self._context)\n    if (store == _ffi.NULL):\n        return None\n    pystore = X509Store.__new__(X509Store)\n    pystore._store = store\n    return pystore\n", "label": "Correct"}
{"function": "\n\ndef get_cert_store(self):\n    '\\n        Get the certificate store for the context.\\n\\n        :return: A X509Store object or None if it does not have one.\\n        '\n    store = _lib.SSL_CTX_get_cert_store(self._context)\n    if (store == _ffi.NULL):\n        return None\n    pystore = X509Store.__new__(X509Store)\n    pystore._store = self\n    return pystore\n", "label": "Variable misuse"}
{"function": "\n\ndef has_valid_checksum(self, number):\n    (given_number, given_checksum) = (number[:(- 1)], number[(- 1)])\n    calculated_checksum = 0\n    fragment = ''\n    parameter = 7\n    for i in range(len(given_number)):\n        fragment = str((int(given_number[i]) * parameter))\n        if fragment.isalnum():\n            calculated_checksum += int(fragment[(- 1)])\n        if (parameter == 1):\n            parameter = 7\n        elif (parameter == 3):\n            parameter = 1\n        elif (parameter == 7):\n            parameter = 3\n    return (str(calculated_checksum)[(- 1)] == given_checksum)\n", "label": "Correct"}
{"function": "\n\ndef has_valid_checksum(self, number):\n    (given_number, given_checksum) = (number[:(- 1)], number[(- 1)])\n    calculated_checksum = 0\n    fragment = ''\n    parameter = 7\n    for i in range(len(given_number)):\n        fragment = str((int(given_number[i]) * parameter))\n        if fragment.isalnum():\n            calculated_checksum += int(fragment[(- 1)])\n        if (fragment == 1):\n            parameter = 7\n        elif (parameter == 3):\n            parameter = 1\n        elif (parameter == 7):\n            parameter = 3\n    return (str(calculated_checksum)[(- 1)] == given_checksum)\n", "label": "Variable misuse"}
{"function": "\n\ndef listen(self):\n    'Listen to incoming clients until\\n        self._running is set to False\\n        '\n    l = self.listener\n    self._running = True\n    try:\n        while self._running:\n            log.debug('Accept connection')\n            c = l.accept()\n            try:\n                action = c.recv()\n            except EOFError:\n                c.close()\n                continue\n            if isinstance(action, basestring):\n                args = ()\n                kwargs = {\n                    \n                }\n            else:\n                args = action.get('args', ())\n                kwargs = (action.get('kwargs') or {\n                    \n                })\n                action = action.get('action')\n            log.info(('Dispatch action \"%s\"' % action))\n            method = getattr(self, ('dispatch_%s' % action), None)\n            if method:\n                try:\n                    result = method(*args, **kwargs)\n                except Exception as err:\n                    log.exception(err)\n                    c.send({\n                        'error': True,\n                        'message': ('Exception in action %s - %s' % (action, err)),\n                    })\n                else:\n                    c.send({\n                        'error': False,\n                        'message': 'ok',\n                        'result': result,\n                    })\n            else:\n                log.warn(('No action %s' % action))\n                c.send({\n                    'error': True,\n                    'message': ('No action %s' % action),\n                })\n            c.close()\n    finally:\n        self._listener = None\n        l.close()\n    log.info('Exiting event loop')\n", "label": "Correct"}
{"function": "\n\ndef listen(self):\n    'Listen to incoming clients until\\n        self._running is set to False\\n        '\n    l = self.listener\n    self._running = True\n    try:\n        while self._running:\n            log.debug('Accept connection')\n            c = l.accept()\n            try:\n                action = c.recv()\n            except EOFError:\n                c.close()\n                continue\n            if isinstance(action, basestring):\n                args = ()\n                kwargs = {\n                    \n                }\n            else:\n                args = action.get('args', ())\n                kwargs = (action.get('kwargs') or {\n                    \n                })\n                action = action.get('action')\n            log.info(('Dispatch action \"%s\"' % action))\n            method = getattr(self, ('dispatch_%s' % action), None)\n            if method:\n                try:\n                    result = method(*args, **kwargs)\n                except Exception as err:\n                    log.exception(err)\n                    c.send({\n                        'error': True,\n                        'message': ('Exception in action %s - %s' % (action, err)),\n                    })\n                else:\n                    c.send({\n                        'error': False,\n                        'message': 'ok',\n                        'result': result,\n                    })\n            else:\n                log.warn(('No action %s' % result))\n                c.send({\n                    'error': True,\n                    'message': ('No action %s' % action),\n                })\n            c.close()\n    finally:\n        self._listener = None\n        l.close()\n    log.info('Exiting event loop')\n", "label": "Variable misuse"}
{"function": "\n\ndef convert_fragment(self, fragment, fd):\n    mdat = None\n    try:\n        f4v = F4V(fd, raw_payload=True)\n        for box in f4v:\n            if (box.type == 'mdat'):\n                mdat = box.payload.data\n                break\n    except F4VError as err:\n        self.logger.error('Failed to parse fragment {0}-{1}: {2}', fragment.segment, fragment.fragment, err)\n        return\n    if (not mdat):\n        self.logger.error('No MDAT box found in fragment {0}-{1}', fragment.segment, fragment.fragment)\n        return\n    try:\n        for chunk in self.concater.iter_chunks(buf=mdat, skip_header=True):\n            self.reader.buffer.write(chunk)\n            if self.closed:\n                break\n        else:\n            self.logger.debug('Download of fragment {0}-{1} complete', fragment.segment, fragment.fragment)\n    except IOError as err:\n        if ('Unknown tag type' in str(err)):\n            self.logger.error('Unknown tag type found, this stream is probably encrypted')\n            self.close()\n            return\n        self.logger.error('Error reading fragment {0}-{1}: {2}', fragment.segment, fragment.fragment, err)\n", "label": "Correct"}
{"function": "\n\ndef convert_fragment(self, fragment, fd):\n    mdat = None\n    try:\n        f4v = F4V(fd, raw_payload=True)\n        for box in f4v:\n            if (box.type == 'mdat'):\n                mdat = box.payload.data\n                break\n    except F4VError as err:\n        self.logger.error('Failed to parse fragment {0}-{1}: {2}', fragment.segment, box.fragment, err)\n        return\n    if (not mdat):\n        self.logger.error('No MDAT box found in fragment {0}-{1}', fragment.segment, fragment.fragment)\n        return\n    try:\n        for chunk in self.concater.iter_chunks(buf=mdat, skip_header=True):\n            self.reader.buffer.write(chunk)\n            if self.closed:\n                break\n        else:\n            self.logger.debug('Download of fragment {0}-{1} complete', fragment.segment, fragment.fragment)\n    except IOError as err:\n        if ('Unknown tag type' in str(err)):\n            self.logger.error('Unknown tag type found, this stream is probably encrypted')\n            self.close()\n            return\n        self.logger.error('Error reading fragment {0}-{1}: {2}', fragment.segment, fragment.fragment, err)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self):\n    'Collects CProfile stats for specified Python program.'\n    if self._run_args:\n        sys.argv[:] = [self._run_object, self._run_args]\n    else:\n        sys.argv[:] = [self._run_object]\n    prof = cProfile.Profile()\n    run_dispatcher = self.get_run_dispatcher()\n    run_dispatcher(prof)\n    prof.create_stats()\n    cprofile_stats = pstats.Stats(prof)\n    return {\n        'programName': self._object_name,\n        'runTime': cprofile_stats.total_tt,\n        'primitiveCalls': cprofile_stats.prim_calls,\n        'totalCalls': cprofile_stats.total_calls,\n        'callStats': self._transform_stats(cprofile_stats),\n    }\n", "label": "Correct"}
{"function": "\n\ndef run(self):\n    'Collects CProfile stats for specified Python program.'\n    if self._run_args:\n        sys.argv[:] = [self._run_object, prof._run_args]\n    else:\n        sys.argv[:] = [self._run_object]\n    prof = cProfile.Profile()\n    run_dispatcher = self.get_run_dispatcher()\n    run_dispatcher(prof)\n    prof.create_stats()\n    cprofile_stats = pstats.Stats(prof)\n    return {\n        'programName': self._object_name,\n        'runTime': cprofile_stats.total_tt,\n        'primitiveCalls': cprofile_stats.prim_calls,\n        'totalCalls': cprofile_stats.total_calls,\n        'callStats': self._transform_stats(cprofile_stats),\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef _wait_async_done(self, reservation_id, reqids):\n    \"\\n        _wait_async_done(session_id, reqids)\\n        Helper methods that waits for the specified asynchronous requests to be finished,\\n        and which asserts that they were successful. Note that it doesn't actually return\\n        their responses.\\n        @param reqids Tuple containing the request ids for the commands to check.\\n        @return Nothing\\n        \"\n    reqsl = list(reqids)\n    max_count = 15\n    while (len(reqsl) > 0):\n        time.sleep(0.1)\n        max_count -= 1\n        if (max_count == 0):\n            raise Exception('Maximum time spent waiting async done')\n        requests = self.client.check_async_command_status(reservation_id, tuple(reqsl))\n        self.assertEquals(len(reqsl), len(requests))\n        for (rid, req) in six.iteritems(requests):\n            status = req[0]\n            self.assertTrue((status in ('running', 'ok', 'error')))\n            if (status != 'running'):\n                self.assertEquals('ok', status, ('Contents: ' + req[1]))\n                reqsl.remove(rid)\n", "label": "Correct"}
{"function": "\n\ndef _wait_async_done(self, reservation_id, reqids):\n    \"\\n        _wait_async_done(session_id, reqids)\\n        Helper methods that waits for the specified asynchronous requests to be finished,\\n        and which asserts that they were successful. Note that it doesn't actually return\\n        their responses.\\n        @param reqids Tuple containing the request ids for the commands to check.\\n        @return Nothing\\n        \"\n    reqsl = list(reqids)\n    max_count = 15\n    while (len(reqsl) > 0):\n        time.sleep(0.1)\n        max_count -= 1\n        if (max_count == 0):\n            raise Exception('Maximum time spent waiting async done')\n        requests = self.client.check_async_command_status(reservation_id, tuple(reqsl))\n        self.assertEquals(len(reqsl), len(requests))\n        for (rid, req) in six.iteritems(req):\n            status = req[0]\n            self.assertTrue((status in ('running', 'ok', 'error')))\n            if (status != 'running'):\n                self.assertEquals('ok', status, ('Contents: ' + req[1]))\n                reqsl.remove(rid)\n", "label": "Variable misuse"}
{"function": "\n\ndef _importer(target):\n    components = target.split('.')\n    import_path = components.pop(0)\n    thing = __import__(import_path)\n    for comp in components:\n        import_path += ('.%s' % comp)\n        thing = _dot_lookup(thing, comp, import_path)\n    return thing\n", "label": "Correct"}
{"function": "\n\ndef _importer(target):\n    components = target.split('.')\n    import_path = import_path.pop(0)\n    thing = __import__(import_path)\n    for comp in components:\n        import_path += ('.%s' % comp)\n        thing = _dot_lookup(thing, comp, import_path)\n    return thing\n", "label": "Variable misuse"}
{"function": "\n\ndef rotate(image, angle, center=None, scale=1.0):\n    (h, w) = image.shape[:2]\n    if (center is None):\n        center = ((w / 2), (h / 2))\n    M = cv2.getRotationMatrix2D(center, angle, scale)\n    rotated = cv2.warpAffine(image, M, (w, h))\n    return rotated\n", "label": "Correct"}
{"function": "\n\ndef rotate(image, angle, center=None, scale=1.0):\n    (h, w) = image.shape[:2]\n    if (center is None):\n        center = ((w / 2), (h / 2))\n    M = cv2.getRotationMatrix2D(rotated, angle, scale)\n    rotated = cv2.warpAffine(image, M, (w, h))\n    return rotated\n", "label": "Variable misuse"}
{"function": "\n\ndef get_or_create_menu(self, key, verbose_name, side=LEFT, position=None):\n    if (key in self.menus):\n        return self.menus[key]\n    menu = SubMenu(verbose_name, self.csrf_token, side=side)\n    self.menus[key] = menu\n    self.add_item(menu, position=position)\n    return menu\n", "label": "Correct"}
{"function": "\n\ndef get_or_create_menu(self, key, verbose_name, side=LEFT, position=None):\n    if (key in self.menus):\n        return self.menus[key]\n    menu = SubMenu(verbose_name, self.csrf_token, side=side)\n    self.menus[key] = menu\n    self.add_item(key, position=position)\n    return menu\n", "label": "Variable misuse"}
{"function": "\n\ndef test_os_stat(self):\n    'Test sizing os.stat and os.statvfs objects.\\n        '\n    try:\n        stat = os.stat(__file__)\n    except Exception:\n        pass\n    else:\n        stat_size = asizeof.asizeof(stat)\n        self.assertTrue((stat_size > 0), stat_size)\n        refs = asizeof.named_refs(stat)\n        ref_names = set([name for (name, _) in refs])\n        self.assertTrue((set(['st_mode', 'st_size', 'st_mtime']) <= ref_names), ref_names)\n    try:\n        stat = os.statvfs(__file__)\n    except Exception:\n        pass\n    else:\n        stat_size = asizeof.asizeof(stat)\n        self.assertTrue((stat_size > 0), stat_size)\n        refs = asizeof.named_refs(stat)\n        ref_names = set([name for (name, _) in refs])\n        self.assertTrue((set(['f_bsize', 'f_blocks']) <= ref_names), ref_names)\n", "label": "Correct"}
{"function": "\n\ndef test_os_stat(self):\n    'Test sizing os.stat and os.statvfs objects.\\n        '\n    try:\n        stat = os.stat(__file__)\n    except Exception:\n        pass\n    else:\n        stat_size = asizeof.asizeof(stat)\n        self.assertTrue((name > 0), stat_size)\n        refs = asizeof.named_refs(stat)\n        ref_names = set([name for (name, _) in refs])\n        self.assertTrue((set(['st_mode', 'st_size', 'st_mtime']) <= ref_names), ref_names)\n    try:\n        stat = os.statvfs(__file__)\n    except Exception:\n        pass\n    else:\n        stat_size = asizeof.asizeof(stat)\n        self.assertTrue((stat_size > 0), stat_size)\n        refs = asizeof.named_refs(stat)\n        ref_names = set([name for (name, _) in refs])\n        self.assertTrue((set(['f_bsize', 'f_blocks']) <= ref_names), ref_names)\n", "label": "Variable misuse"}
{"function": "\n\ndef run(self):\n    self.marker(10)\n    self.write('This experiment is about high or low-intensity visual perception. You will be presented a sequence of trials, during half of which you will see a movie (with a fixation cross in the middle), and during the other half of which you will see just the fixation cross. When you see the movie, keep fixating, but focus on the content. When you see only the cross, try to defocus your vision, think nothing, and just wait for the bell that indicates the beginning of the next trial. Please press the space bar when you are ready.', 'space', wordwrap=30, pos=[0, 0.3])\n    for k in [3, 2, 1]:\n        self.write(('Experiment begins in ' + str(k)))\n    self.trials = int(((self.endtime - self.begintime) / self.awake_duration))\n    for t in range(self.trials):\n        self.marker(1)\n        m = self.movie(self.moviefile, block=False, scale=[0.7, 0.4], aspect=1.125, contentoffset=[0, 0], volume=0.3, timeoffset=(self.begintime + (t * self.awake_duration)), looping=True)\n        self.crosshair(self.awake_duration, size=0.2, width=0.005)\n        m[0].stop()\n        m[2].removeNode()\n        self.marker(2)\n        self.sleep(self.transition_duration)\n        self.marker(3)\n        self.crosshair(self.snooze_duration, size=0.2, width=0.005)\n        self.sound(self.wakeup_sound)\n        self.marker(4)\n        self.sleep(self.transition_duration)\n    self.write('You successfully completed the experiment!')\n", "label": "Correct"}
{"function": "\n\ndef run(self):\n    self.marker(10)\n    self.write('This experiment is about high or low-intensity visual perception. You will be presented a sequence of trials, during half of which you will see a movie (with a fixation cross in the middle), and during the other half of which you will see just the fixation cross. When you see the movie, keep fixating, but focus on the content. When you see only the cross, try to defocus your vision, think nothing, and just wait for the bell that indicates the beginning of the next trial. Please press the space bar when you are ready.', 'space', wordwrap=30, pos=[0, 0.3])\n    for k in [3, 2, 1]:\n        self.write(('Experiment begins in ' + str(k)))\n    m.trials = int(((self.endtime - self.begintime) / self.awake_duration))\n    for t in range(self.trials):\n        self.marker(1)\n        m = self.movie(self.moviefile, block=False, scale=[0.7, 0.4], aspect=1.125, contentoffset=[0, 0], volume=0.3, timeoffset=(self.begintime + (t * self.awake_duration)), looping=True)\n        self.crosshair(self.awake_duration, size=0.2, width=0.005)\n        m[0].stop()\n        m[2].removeNode()\n        self.marker(2)\n        self.sleep(self.transition_duration)\n        self.marker(3)\n        self.crosshair(self.snooze_duration, size=0.2, width=0.005)\n        self.sound(self.wakeup_sound)\n        self.marker(4)\n        self.sleep(self.transition_duration)\n    self.write('You successfully completed the experiment!')\n", "label": "Variable misuse"}
{"function": "\n\ndef __getattr__(self, attr):\n    from pinax.teams.conf import settings\n    return getattr(settings.TEAMS_HOOKSET, attr)\n", "label": "Correct"}
{"function": "\n\ndef __getattr__(self, attr):\n    from pinax.teams.conf import settings\n    return getattr(settings.TEAMS_HOOKSET, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef l2cap_send(self, data):\n    dbg(('sending: [%s]' % data))\n    (status, written) = self._wc.write(data)\n    if status:\n        dbg('sent okay')\n        return written\n    else:\n        raise BluetoothError(_port_return_code_to_str(status))\n", "label": "Correct"}
{"function": "\n\ndef l2cap_send(self, data):\n    dbg(('sending: [%s]' % data))\n    (status, written) = self._wc.write(self)\n    if status:\n        dbg('sent okay')\n        return written\n    else:\n        raise BluetoothError(_port_return_code_to_str(status))\n", "label": "Variable misuse"}
{"function": "\n\ndef encrypt(self, data):\n    ' encrypt data with convergence encryption.\\n\\n            Args\\n                data: str, the plain text to be encrypted\\n        \\n            Returns\\n                key: hash(block), encryption key\\n                id: hash(hash(block), block ID\\n                ciphertext: enc(key, block)\\n        '\n    assert isinstance(data, str)\n    (key, id) = self.__sec_key(data)\n    return (key, id, aes(key, data))\n", "label": "Correct"}
{"function": "\n\ndef encrypt(self, data):\n    ' encrypt data with convergence encryption.\\n\\n            Args\\n                data: str, the plain text to be encrypted\\n        \\n            Returns\\n                key: hash(block), encryption key\\n                id: hash(hash(block), block ID\\n                ciphertext: enc(key, block)\\n        '\n    assert isinstance(data, str)\n    (key, id) = self.__sec_key(data)\n    return (key, id, aes(key, id))\n", "label": "Variable misuse"}
{"function": "\n\ndef _unshorten_lnxlu(self, uri):\n    try:\n        r = requests.get(uri, headers=self._headers, timeout=self._timeout)\n        html = r.text\n        code = re.findall('/\\\\?click\\\\=(.*)\\\\.\"', html)\n        if (len(code) > 0):\n            payload = {\n                'click': code[0],\n            }\n            r = requests.get('http://lnx.lu/', params=payload, headers=self._headers, timeout=self._timeout)\n            return (r.url, r.status_code)\n        else:\n            return (uri, 'No click variable found')\n    except Exception as e:\n        return (uri, str(e))\n", "label": "Correct"}
{"function": "\n\ndef _unshorten_lnxlu(self, uri):\n    try:\n        r = requests.get(uri, headers=self._headers, timeout=self._timeout)\n        html = r.text\n        code = re.findall('/\\\\?click\\\\=(.*)\\\\.\"', html)\n        if (len(code) > 0):\n            payload = {\n                'click': code[0],\n            }\n            r = requests.get('http://lnx.lu/', params=payload, headers=self._headers, timeout=self._timeout)\n            return (e.url, r.status_code)\n        else:\n            return (uri, 'No click variable found')\n    except Exception as e:\n        return (uri, str(e))\n", "label": "Variable misuse"}
{"function": "\n\ndef set_tx_max(self, *args, **kwargs):\n    return apply(self._cobj.set_tx_max, args, kwargs)\n", "label": "Correct"}
{"function": "\n\ndef set_tx_max(self, *args, **kwargs):\n    return apply(self._cobj.set_tx_max, args, args)\n", "label": "Variable misuse"}
{"function": "\n\ndef list_names(self, **kwargs):\n    'Get a list of metric names.'\n    url_str = (self.base_url + '/names')\n    newheaders = self.get_headers()\n    if ('dimensions' in kwargs):\n        dimstr = self.get_dimensions_url_string(kwargs['dimensions'])\n        kwargs['dimensions'] = dimstr\n    if kwargs:\n        url_str = (url_str + ('?%s' % urlutils.urlencode(kwargs, True)))\n    (resp, body) = self.client.json_request('GET', url_str, headers=newheaders)\n    return (body['elements'] if (type(body) is dict) else body)\n", "label": "Correct"}
{"function": "\n\ndef list_names(self, **kwargs):\n    'Get a list of metric names.'\n    url_str = (self.base_url + '/names')\n    newheaders = self.get_headers()\n    if ('dimensions' in url_str):\n        dimstr = self.get_dimensions_url_string(kwargs['dimensions'])\n        kwargs['dimensions'] = dimstr\n    if kwargs:\n        url_str = (url_str + ('?%s' % urlutils.urlencode(kwargs, True)))\n    (resp, body) = self.client.json_request('GET', url_str, headers=newheaders)\n    return (body['elements'] if (type(body) is dict) else body)\n", "label": "Variable misuse"}
{"function": "\n\ndef mayRaiseException(self, exception_type):\n    if self.tolerant:\n        return False\n    else:\n        if (self.variable_trace is not None):\n            variable = self.getTargetVariableRef().getVariable()\n            if variable.isTempVariable():\n                return False\n            if ((self.previous_trace is not None) and self.previous_trace.mustHaveValue()):\n                return False\n        return True\n", "label": "Correct"}
{"function": "\n\ndef mayRaiseException(self, exception_type):\n    if self.tolerant:\n        return False\n    else:\n        if (self.variable_trace is not None):\n            variable = self.getTargetVariableRef().getVariable()\n            if exception_type.isTempVariable():\n                return False\n            if ((self.previous_trace is not None) and self.previous_trace.mustHaveValue()):\n                return False\n        return True\n", "label": "Variable misuse"}
{"function": "\n\ndef testNonBlockingRequestStream(self):\n    '\\n        Test NonBlocking Http client with SSE streaming server\\n        '\n    console.terse('{0}\\n'.format(self.testNonBlockingRequestStream.__doc__))\n    wireLogAlpha = wiring.WireLog(buffify=True, same=True)\n    result = wireLogAlpha.reopen()\n    wireLogBeta = wiring.WireLog(buffify=True, same=True)\n    result = wireLogBeta.reopen()\n    alpha = tcp.Server(port=6101, bufsize=131072, wlog=wireLogAlpha)\n    self.assertIs(alpha.reopen(), True)\n    self.assertEqual(alpha.ha, ('0.0.0.0', 6101))\n    self.assertEqual(alpha.eha, ('127.0.0.1', 6101))\n    beta = tcp.Client(ha=alpha.eha, bufsize=131072, wlog=wireLogBeta)\n    self.assertIs(beta.reopen(), True)\n    self.assertIs(beta.accepted, False)\n    self.assertIs(beta.connected, False)\n    self.assertIs(beta.cutoff, False)\n    console.terse('Connecting beta to server ...\\n')\n    while True:\n        beta.serviceConnect()\n        alpha.serviceConnects()\n        if (beta.connected and (beta.ca in alpha.ixes)):\n            break\n        time.sleep(0.05)\n    self.assertIs(beta.accepted, True)\n    self.assertIs(beta.connected, True)\n    self.assertIs(beta.cutoff, False)\n    self.assertEqual(beta.ca, beta.cs.getsockname())\n    self.assertEqual(beta.ha, beta.cs.getpeername())\n    self.assertEqual(alpha.eha, beta.ha)\n    ixBeta = alpha.ixes[beta.ca]\n    self.assertIsNotNone(ixBeta.ca)\n    self.assertIsNotNone(ixBeta.cs)\n    self.assertEqual(ixBeta.cs.getsockname(), beta.cs.getpeername())\n    self.assertEqual(ixBeta.cs.getpeername(), beta.cs.getsockname())\n    self.assertEqual(ixBeta.ca, beta.ca)\n    self.assertEqual(ixBeta.ha, beta.ha)\n    console.terse('{0}\\n'.format('Building Request ...\\n'))\n    host = '127.0.0.1'\n    port = 6061\n    method = 'GET'\n    path = '/stream'\n    console.terse('{0} from  {1}:{2}{3} ...\\n'.format(method, host, port, path))\n    headers = odict([('Accept', 'application/json')])\n    request = clienting.Requester(hostname=host, port=port, method=method, path=path, headers=headers)\n    msgOut = request.build()\n    lines = [b'GET /stream HTTP/1.1', b'Host: 127.0.0.1:6061', b'Accept-Encoding: identity', b'Accept: application/json', b'', b'']\n    for (i, line) in enumerate(lines):\n        self.assertEqual(line, request.lines[i])\n    self.assertEqual(request.head, b'GET /stream HTTP/1.1\\r\\nHost: 127.0.0.1:6061\\r\\nAccept-Encoding: identity\\r\\nAccept: application/json\\r\\n\\r\\n')\n    self.assertEqual(msgOut, request.head)\n    console.terse('Beta requests to Alpha\\n')\n    beta.tx(msgOut)\n    while (beta.txes and (not ixBeta.rxbs)):\n        beta.serviceTxes()\n        time.sleep(0.05)\n        alpha.serviceReceivesAllIx()\n        time.sleep(0.05)\n    msgIn = bytes(ixBeta.rxbs)\n    self.assertEqual(msgIn, msgOut)\n    ixBeta.clearRxbs()\n    console.terse('Alpha responds to Beta\\n')\n    lines = [b'HTTP/1.0 200 OK\\r\\n', b'Server: PasteWSGIServer/0.5 Python/2.7.9\\r\\n', b'Date: Thu, 30 Apr 2015 21:35:25 GMT\\r\\nContent-Type: text/event-stream\\r\\n', b'Cache-Control: no-cache\\r\\n', b'Connection: close\\r\\n\\r\\n']\n    msgOut = b''.join(lines)\n    ixBeta.tx(msgOut)\n    while (ixBeta.txes or (not beta.rxbs)):\n        alpha.serviceTxesAllIx()\n        time.sleep(0.05)\n        beta.serviceReceives()\n        time.sleep(0.05)\n    msgIn = bytes(beta.rxbs)\n    self.assertEqual(msgIn, msgOut)\n    console.terse('Beta processes response \\n')\n    response = clienting.Respondent(msg=beta.rxbs, method=method)\n    lines = [b'retry: 1000\\n\\n', b'data: START\\n\\n', b'data: 1\\n\\n', b'data: 2\\n\\n', b'data: 3\\n\\n', b'data: 4\\n\\n']\n    msgOut = b''.join(lines)\n    ixBeta.tx(msgOut)\n    timer = Timer(duration=0.5)\n    while (response.parser and (not timer.expired)):\n        alpha.serviceTxesAllIx()\n        response.parse()\n        beta.serviceReceives()\n        time.sleep(0.01)\n    if response.parser:\n        response.parser.close()\n        response.parser = None\n    response.dictify()\n    self.assertEqual(len(beta.rxbs), 0)\n    self.assertEqual(response.eventSource.retry, 1000)\n    self.assertEqual(response.retry, response.eventSource.retry)\n    self.assertEqual(response.eventSource.leid, None)\n    self.assertEqual(response.leid, response.eventSource.leid)\n    self.assertTrue((len(response.events) > 2))\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': 'START',\n    })\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': '1',\n    })\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': '2',\n    })\n    self.assertTrue((len(response.body) == 0))\n    self.assertTrue((len(response.eventSource.raw) == 0))\n    alpha.close()\n    beta.close()\n    wireLogAlpha.close()\n    wireLogBeta.close()\n", "label": "Correct"}
{"function": "\n\ndef testNonBlockingRequestStream(self):\n    '\\n        Test NonBlocking Http client with SSE streaming server\\n        '\n    console.terse('{0}\\n'.format(self.testNonBlockingRequestStream.__doc__))\n    wireLogAlpha = wiring.WireLog(buffify=True, same=True)\n    result = wireLogAlpha.reopen()\n    wireLogBeta = wiring.WireLog(buffify=True, same=True)\n    result = wireLogBeta.reopen()\n    alpha = tcp.Server(port=6101, bufsize=131072, wlog=wireLogAlpha)\n    self.assertIs(alpha.reopen(), True)\n    self.assertEqual(alpha.ha, ('0.0.0.0', 6101))\n    self.assertEqual(alpha.eha, ('127.0.0.1', 6101))\n    beta = tcp.Client(ha=alpha.eha, bufsize=131072, wlog=wireLogBeta)\n    self.assertIs(beta.reopen(), True)\n    self.assertIs(beta.accepted, False)\n    self.assertIs(beta.connected, False)\n    self.assertIs(beta.cutoff, False)\n    console.terse('Connecting beta to server ...\\n')\n    while True:\n        beta.serviceConnect()\n        alpha.serviceConnects()\n        if (beta.connected and (beta.ca in alpha.ixes)):\n            break\n        time.sleep(0.05)\n    self.assertIs(beta.accepted, True)\n    self.assertIs(beta.connected, True)\n    self.assertIs(beta.cutoff, False)\n    self.assertEqual(beta.ca, beta.cs.getsockname())\n    self.assertEqual(beta.ha, beta.cs.getpeername())\n    self.assertEqual(alpha.eha, beta.ha)\n    ixBeta = alpha.ixes[beta.ca]\n    self.assertIsNotNone(ixBeta.ca)\n    self.assertIsNotNone(ixBeta.cs)\n    self.assertEqual(wireLogAlpha.cs.getsockname(), beta.cs.getpeername())\n    self.assertEqual(ixBeta.cs.getpeername(), beta.cs.getsockname())\n    self.assertEqual(ixBeta.ca, beta.ca)\n    self.assertEqual(ixBeta.ha, beta.ha)\n    console.terse('{0}\\n'.format('Building Request ...\\n'))\n    host = '127.0.0.1'\n    port = 6061\n    method = 'GET'\n    path = '/stream'\n    console.terse('{0} from  {1}:{2}{3} ...\\n'.format(method, host, port, path))\n    headers = odict([('Accept', 'application/json')])\n    request = clienting.Requester(hostname=host, port=port, method=method, path=path, headers=headers)\n    msgOut = request.build()\n    lines = [b'GET /stream HTTP/1.1', b'Host: 127.0.0.1:6061', b'Accept-Encoding: identity', b'Accept: application/json', b'', b'']\n    for (i, line) in enumerate(lines):\n        self.assertEqual(line, request.lines[i])\n    self.assertEqual(request.head, b'GET /stream HTTP/1.1\\r\\nHost: 127.0.0.1:6061\\r\\nAccept-Encoding: identity\\r\\nAccept: application/json\\r\\n\\r\\n')\n    self.assertEqual(msgOut, request.head)\n    console.terse('Beta requests to Alpha\\n')\n    beta.tx(msgOut)\n    while (beta.txes and (not ixBeta.rxbs)):\n        beta.serviceTxes()\n        time.sleep(0.05)\n        alpha.serviceReceivesAllIx()\n        time.sleep(0.05)\n    msgIn = bytes(ixBeta.rxbs)\n    self.assertEqual(msgIn, msgOut)\n    ixBeta.clearRxbs()\n    console.terse('Alpha responds to Beta\\n')\n    lines = [b'HTTP/1.0 200 OK\\r\\n', b'Server: PasteWSGIServer/0.5 Python/2.7.9\\r\\n', b'Date: Thu, 30 Apr 2015 21:35:25 GMT\\r\\nContent-Type: text/event-stream\\r\\n', b'Cache-Control: no-cache\\r\\n', b'Connection: close\\r\\n\\r\\n']\n    msgOut = b''.join(lines)\n    ixBeta.tx(msgOut)\n    while (ixBeta.txes or (not beta.rxbs)):\n        alpha.serviceTxesAllIx()\n        time.sleep(0.05)\n        beta.serviceReceives()\n        time.sleep(0.05)\n    msgIn = bytes(beta.rxbs)\n    self.assertEqual(msgIn, msgOut)\n    console.terse('Beta processes response \\n')\n    response = clienting.Respondent(msg=beta.rxbs, method=method)\n    lines = [b'retry: 1000\\n\\n', b'data: START\\n\\n', b'data: 1\\n\\n', b'data: 2\\n\\n', b'data: 3\\n\\n', b'data: 4\\n\\n']\n    msgOut = b''.join(lines)\n    ixBeta.tx(msgOut)\n    timer = Timer(duration=0.5)\n    while (response.parser and (not timer.expired)):\n        alpha.serviceTxesAllIx()\n        response.parse()\n        beta.serviceReceives()\n        time.sleep(0.01)\n    if response.parser:\n        response.parser.close()\n        response.parser = None\n    response.dictify()\n    self.assertEqual(len(beta.rxbs), 0)\n    self.assertEqual(response.eventSource.retry, 1000)\n    self.assertEqual(response.retry, response.eventSource.retry)\n    self.assertEqual(response.eventSource.leid, None)\n    self.assertEqual(response.leid, response.eventSource.leid)\n    self.assertTrue((len(response.events) > 2))\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': 'START',\n    })\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': '1',\n    })\n    event = response.events.popleft()\n    self.assertEqual(event, {\n        'id': None,\n        'name': '',\n        'data': '2',\n    })\n    self.assertTrue((len(response.body) == 0))\n    self.assertTrue((len(response.eventSource.raw) == 0))\n    alpha.close()\n    beta.close()\n    wireLogAlpha.close()\n    wireLogBeta.close()\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, key, default=None):\n    '\\n        Return value of attribute or None if such attribute\\n        does not exist.\\n        '\n    return getattr(self, key, default)\n", "label": "Correct"}
{"function": "\n\ndef get(self, key, default=None):\n    '\\n        Return value of attribute or None if such attribute\\n        does not exist.\\n        '\n    return getattr(self, default, default)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, cluster, version_handler, added=None, removed=None):\n    super(Context, self).__init__(cluster, version_handler, added, removed)\n    self._hadoop_version = yarn.YARNv270().version\n    self._hadoop_lib = None\n    self._hadoop_conf = None\n    self._cluster_mode = yarn.YARNv270.cluster_mode\n    self._node_aware = True\n    self._resource_manager_uri = 'maprfs:///'\n    self._mapr_version = '5.0.0'\n    self._ubuntu_ecosystem_repo = 'http://package.mapr.com/releases/ecosystem-5.x/ubuntu binary/'\n    self._centos_ecosystem_repo = 'http://package.mapr.com/releases/ecosystem-5.x/redhat'\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, cluster, version_handler, added=None, removed=None):\n    super(Context, self).__init__(cluster, version_handler, added, removed)\n    self._hadoop_version = yarn.YARNv270().version\n    added._hadoop_lib = None\n    self._hadoop_conf = None\n    self._cluster_mode = yarn.YARNv270.cluster_mode\n    self._node_aware = True\n    self._resource_manager_uri = 'maprfs:///'\n    self._mapr_version = '5.0.0'\n    self._ubuntu_ecosystem_repo = 'http://package.mapr.com/releases/ecosystem-5.x/ubuntu binary/'\n    self._centos_ecosystem_repo = 'http://package.mapr.com/releases/ecosystem-5.x/redhat'\n", "label": "Variable misuse"}
{"function": "\n\ndef testBadEolContext(self):\n    'Make sure the filename is included in the report of a bad eol.'\n    filename = 'routes.txt'\n    old_zip = zipfile.ZipFile(self.GetPath('tests', 'data', 'good_feed.zip'), 'r')\n    content_dict = self.ConvertZipToDict(old_zip)\n    old_routes = content_dict[filename]\n    new_routes = old_routes.replace('\\n', '\\r\\n', 1)\n    self.assertNotEquals(old_routes, new_routes)\n    content_dict[filename] = new_routes\n    new_zipfile_mem = self.ConvertDictToZip(content_dict)\n    options = MockOptions()\n    output_file = StringIO.StringIO()\n    feedvalidator.RunValidationOutputToFile(new_zipfile_mem, options, output_file)\n    self.assertMatchesRegex(filename, output_file.getvalue())\n", "label": "Correct"}
{"function": "\n\ndef testBadEolContext(self):\n    'Make sure the filename is included in the report of a bad eol.'\n    filename = 'routes.txt'\n    old_zip = zipfile.ZipFile(self.GetPath('tests', 'data', 'good_feed.zip'), 'r')\n    content_dict = self.ConvertZipToDict(old_zip)\n    old_routes = content_dict[old_routes]\n    new_routes = old_routes.replace('\\n', '\\r\\n', 1)\n    self.assertNotEquals(old_routes, new_routes)\n    content_dict[filename] = new_routes\n    new_zipfile_mem = self.ConvertDictToZip(content_dict)\n    options = MockOptions()\n    output_file = StringIO.StringIO()\n    feedvalidator.RunValidationOutputToFile(new_zipfile_mem, options, output_file)\n    self.assertMatchesRegex(filename, output_file.getvalue())\n", "label": "Variable misuse"}
{"function": "\n\ndef __exit__(self, exc_type, exc_value, traceback):\n    ':func:`burpui.misc.auth.ldap.LdapLoader.__exit__` closes the\\n        connection to the LDAP server.\\n        '\n    if (self.ldap and self.ldap.bound):\n        self.ldap.unbind()\n", "label": "Correct"}
{"function": "\n\ndef __exit__(self, exc_type, exc_value, traceback):\n    ':func:`burpui.misc.auth.ldap.LdapLoader.__exit__` closes the\\n        connection to the LDAP server.\\n        '\n    if (self.ldap and self.ldap.bound):\n        exc_value.ldap.unbind()\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, output_fields, data):\n    self.output_fields = output_fields\n    self.data = data\n    self.index = 0\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, output_fields, data):\n    self.output_fields = output_fields\n    self.data = self\n    self.index = 0\n", "label": "Variable misuse"}
{"function": "\n\ndef test_encode_fields():\n    msg = APIEncodeMsg()\n    msg.enc = six.b('').join([six.int2byte(x) for x in range(0, 255)])\n    assert (msg.to_dict()['data']['enc'] == six.text_type('AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn+AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq+wsbKztLW2t7i5uru8vb6/wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t/g4eLj5OXm5+jp6uvs7e7v8PHy8/T19vf4+fr7/P3+'))\n    assert (msg.to_json() == '{\"data\": {\"enc\": \"AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn+AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq+wsbKztLW2t7i5uru8vb6/wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t/g4eLj5OXm5+jp6uvs7e7v8PHy8/T19vf4+fr7/P3+\"}, \"type\": null}')\n    msg2 = APIEncodeMsg(data=msg.to_json())\n    assert (msg.to_dict() == msg2.to_dict())\n    assert (msg.to_json() == msg2.to_json())\n    assert (msg2.enc == msg.enc)\n    msg3 = APIEncodeMsg()\n    msg3.enc = six.u('xxxx')\n    assert (msg3.to_dict() == {\n        'data': {\n            'enc': 'eHh4eA==',\n        },\n        'type': None,\n    })\n    msg3.enc = six.b('xxxx')\n    assert (msg3.to_dict() == {\n        'data': {\n            'enc': 'eHh4eA==',\n        },\n        'type': None,\n    })\n    msg4 = APIEncodeMsg()\n    msg4.from_dict(msg.to_dict())\n    assert (msg4.to_dict() == msg.to_dict())\n", "label": "Correct"}
{"function": "\n\ndef test_encode_fields():\n    msg = APIEncodeMsg()\n    msg.enc = six.b('').join([six.int2byte(x) for x in range(0, 255)])\n    assert (msg.to_dict()['data']['enc'] == six.text_type('AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn+AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq+wsbKztLW2t7i5uru8vb6/wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t/g4eLj5OXm5+jp6uvs7e7v8PHy8/T19vf4+fr7/P3+'))\n    assert (msg.to_json() == '{\"data\": {\"enc\": \"AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0+P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn+AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq+wsbKztLW2t7i5uru8vb6/wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t/g4eLj5OXm5+jp6uvs7e7v8PHy8/T19vf4+fr7/P3+\"}, \"type\": null}')\n    msg2 = APIEncodeMsg(data=msg.to_json())\n    assert (msg.to_dict() == msg2.to_dict())\n    assert (msg.to_json() == msg2.to_json())\n    assert (msg2.enc == msg.enc)\n    msg3 = APIEncodeMsg()\n    msg3.enc = six.u('xxxx')\n    assert (x.to_dict() == {\n        'data': {\n            'enc': 'eHh4eA==',\n        },\n        'type': None,\n    })\n    msg3.enc = six.b('xxxx')\n    assert (msg3.to_dict() == {\n        'data': {\n            'enc': 'eHh4eA==',\n        },\n        'type': None,\n    })\n    msg4 = APIEncodeMsg()\n    msg4.from_dict(msg.to_dict())\n    assert (msg4.to_dict() == msg.to_dict())\n", "label": "Variable misuse"}
{"function": "\n\ndef fetch_friends(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    result = []\n    for friend_json in friends_json['friends']:\n        flags = friend_json.get('flags', 0)\n        types = friend_json.get('types', [])\n        websites = [Website(w['title'], w['url']) for w in friend_json.get('websites', [])]\n        result.append(Friend(stream_id=friend_json.get('stream'), user_ids=friend_json.get('userIds', []), profile_ids=friend_json.get('profileIds', []), contact_id=friend_json['contactId'], group_ids=friend_json.get('groupIds', []), display_name=friend_json['displayName'], given_name=friend_json['givenName'], occupation=friend_json.get('occupation'), websites=websites, location=friend_json.get('location'), photo_url=friend_json.get('photoUrl'), email_addresses=friend_json.get('emailAddresses', []), is_current_user=((flags & (1 << 0)) != 0), is_hidden=((flags & (1 << 1)) != 0), is_new=((flags & (1 << 2)) != 0), uses_reader=((flags & (1 << 3)) != 0), is_blocked=((flags & (1 << 4)) != 0), has_profile=((flags & (1 << 5)) != 0), is_ignored=((flags & (1 << 6)) != 0), is_new_follower=((flags & (1 << 7)) != 0), is_anonymous=((flags & (1 << 8)) != 0), has_shared_items=((flags & (1 << 9)) != 0), is_follower=(0 in types), is_following=(1 in types), is_contact=(3 in types), is_pending_following=(4 in types), is_pending_follower=(5 in types), is_allowed_following=(6 in types), is_allowed_commenting=(7 in types)))\n    return result\n", "label": "Correct"}
{"function": "\n\ndef fetch_friends(self):\n    friends_json = self._fetch_json('friend/list', {\n        'lookup': 'ALL',\n    })\n    result = []\n    for friend_json in friends_json['friends']:\n        flags = friend_json.get('flags', 0)\n        types = friend_json.get('types', [])\n        websites = [Website(w['title'], w['url']) for w in friend_json.get('websites', [])]\n        result.append(Friend(stream_id=friend_json.get('stream'), user_ids=friend_json.get('userIds', []), profile_ids=friend_json.get('profileIds', []), contact_id=friend_json['contactId'], group_ids=friend_json.get('groupIds', []), display_name=friend_json['displayName'], given_name=friend_json['givenName'], occupation=friend_json.get('occupation'), websites=websites, location=friend_json.get('location'), photo_url=friend_json.get('photoUrl'), email_addresses=friend_json.get('emailAddresses', []), is_current_user=((flags & (1 << 0)) != 0), is_hidden=((flags & (1 << 1)) != 0), is_new=((flags & (1 << 2)) != 0), uses_reader=((flags & (1 << 3)) != 0), is_blocked=((flags & (1 << 4)) != 0), has_profile=((flags & (1 << 5)) != 0), is_ignored=((flags & (1 << 6)) != 0), is_new_follower=((flags & (1 << 7)) != 0), is_anonymous=((flags & (1 << 8)) != 0), has_shared_items=((flags & (1 << 9)) != 0), is_follower=(0 in types), is_following=(1 in types), is_contact=(3 in types), is_pending_following=(4 in types), is_pending_follower=(5 in types), is_allowed_following=(6 in types), is_allowed_commenting=(7 in types)))\n    return types\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, balance, address, label, total_received):\n    self.balance = balance\n    self.address = address\n    self.label = label\n    self.total_received = total_received\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, balance, address, label, total_received):\n    label.balance = balance\n    self.address = address\n    self.label = label\n    self.total_received = total_received\n", "label": "Variable misuse"}
{"function": "\n\ndef str_slice_replace(arr, start=None, stop=None, repl=None):\n    '\\n    Replace a slice of each string in the Series/Index with another\\n    string.\\n\\n    Parameters\\n    ----------\\n    start : int or None\\n    stop : int or None\\n    repl : str or None\\n        String for replacement\\n\\n    Returns\\n    -------\\n    replaced : Series/Index of objects\\n    '\n    if (repl is None):\n        repl = ''\n\n    def f(x):\n        if (x[start:stop] == ''):\n            local_stop = start\n        else:\n            local_stop = stop\n        y = ''\n        if (start is not None):\n            y += x[:start]\n        y += repl\n        if (stop is not None):\n            y += x[local_stop:]\n        return y\n    return _na_map(f, arr)\n", "label": "Correct"}
{"function": "\n\ndef str_slice_replace(arr, start=None, stop=None, repl=None):\n    '\\n    Replace a slice of each string in the Series/Index with another\\n    string.\\n\\n    Parameters\\n    ----------\\n    start : int or None\\n    stop : int or None\\n    repl : str or None\\n        String for replacement\\n\\n    Returns\\n    -------\\n    replaced : Series/Index of objects\\n    '\n    if (start is None):\n        repl = ''\n\n    def f(x):\n        if (x[start:stop] == ''):\n            local_stop = start\n        else:\n            local_stop = stop\n        y = ''\n        if (start is not None):\n            y += x[:start]\n        y += repl\n        if (stop is not None):\n            y += x[local_stop:]\n        return y\n    return _na_map(f, arr)\n", "label": "Variable misuse"}
{"function": "\n\n@ConnectorExist(cid_key='smppc')\ndef smppc(self, arg, opts):\n    sc = SMPPClientStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get(opts.smppc).getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            row.append(v)\n        table.append(row)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Correct"}
{"function": "\n\n@ConnectorExist(cid_key='smppc')\ndef smppc(self, arg, opts):\n    sc = SMPPClientStatsCollector()\n    headers = ['#Item', 'Value']\n    table = []\n    for (k, v) in sc.get(opts.smppc).getStats().iteritems():\n        if isinstance(v, dict):\n            v = json.dumps(v)\n        row = []\n        row.append(('#%s' % k))\n        if (k[(- 3):] == '_at'):\n            row.append(formatDateTime(v))\n        else:\n            row.append(v)\n        table.append(k)\n    self.protocol.sendData(tabulate(table, headers, tablefmt='plain', numalign='left').encode('ascii'))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_phone(self):\n    value = self.sd.phone(locale='es')\n    self.assertTrue(isinstance(value, six.string_types))\n    self.assertEqual(len(value), 9)\n    self.assertTrue((value[0] in ['6', '9']))\n    value = self.sd.phone(locale='es', country_code=True)\n    self.assertTrue(isinstance(value, six.string_types))\n    self.assertEqual(len(value), 13)\n    self.assertTrue((value[0:5] in ['+34 6', '+34 9']))\n    with self.assertRaises(ParameterError):\n        value = self.sd.phone(locale='not-valid-locale')\n", "label": "Correct"}
{"function": "\n\ndef test_phone(self):\n    value = self.sd.phone(locale='es')\n    self.assertTrue(isinstance(value, six.string_types))\n    self.assertEqual(len(value), 9)\n    self.assertTrue((value[0] in ['6', '9']))\n    value = self.sd.phone(locale='es', country_code=True)\n    self.assertTrue(isinstance(value, six.string_types))\n    value.assertEqual(len(value), 13)\n    self.assertTrue((value[0:5] in ['+34 6', '+34 9']))\n    with self.assertRaises(ParameterError):\n        value = self.sd.phone(locale='not-valid-locale')\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    self.es_items = [ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test', config=CONFIG_ONE), ElasticSearchServiceItem(region='us-west-2', account='TEST_ACCOUNT', name='es_test_2', config=CONFIG_TWO), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_3', config=CONFIG_THREE), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_4', config=CONFIG_FOUR), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_5', config=CONFIG_FIVE), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_6', config=CONFIG_SIX), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_7', config=CONFIG_SEVEN), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_8', config=CONFIG_EIGHT), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_9', config=CONFIG_NINE)]\n    test_account = Account()\n    test_account.name = 'TEST_ACCOUNT'\n    test_account.notes = 'TEST ACCOUNT'\n    test_account.s3_name = 'TEST_ACCOUNT'\n    test_account.number = '012345678910'\n    test_account.role_name = 'TEST_ACCOUNT'\n    db.session.add(test_account)\n    db.session.commit()\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    self.es_items = [ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test', config=CONFIG_ONE), ElasticSearchServiceItem(region='us-west-2', account='TEST_ACCOUNT', name='es_test_2', config=CONFIG_TWO), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_3', config=CONFIG_THREE), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_4', config=CONFIG_FOUR), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_5', config=CONFIG_FIVE), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_6', config=CONFIG_SIX), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_7', config=CONFIG_SEVEN), ElasticSearchServiceItem(region='eu-west-1', account='TEST_ACCOUNT', name='es_test_8', config=CONFIG_EIGHT), ElasticSearchServiceItem(region='us-east-1', account='TEST_ACCOUNT', name='es_test_9', config=CONFIG_NINE)]\n    test_account = Account()\n    test_account.name = 'TEST_ACCOUNT'\n    test_account.notes = 'TEST ACCOUNT'\n    test_account.s3_name = 'TEST_ACCOUNT'\n    test_account.number = '012345678910'\n    test_account.role_name = 'TEST_ACCOUNT'\n    db.session.add(self)\n    db.session.commit()\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef event_description(self):\n    'complete description of this event in text form\\n\\n        :rtype: str\\n        :returns: event description\\n        '\n    location = (('\\nLocation: ' + self.location) if (self.location != '') else '')\n    description = (('\\nDescription: ' + self.description) if (self.description != '') else '')\n    repitition = (('\\nRepeat: ' + self.recurpattern) if (self.recurpattern != '') else '')\n    return '{}: {}{}{}{}'.format(self._rangestr, self.summary, location, repitition, description)\n", "label": "Correct"}
{"function": "\n\n@property\ndef event_description(self):\n    'complete description of this event in text form\\n\\n        :rtype: str\\n        :returns: event description\\n        '\n    location = (('\\nLocation: ' + self.location) if (self.location != '') else '')\n    description = (('\\nDescription: ' + self.description) if (self.description != '') else '')\n    repitition = (('\\nRepeat: ' + self.recurpattern) if (repitition.recurpattern != '') else '')\n    return '{}: {}{}{}{}'.format(self._rangestr, self.summary, location, repitition, description)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(self):\n    ' Insert Action '\n    token = request.POST.pop('__token', '')\n    if (not self._is_token_match(token)):\n        success = False\n        error_message = 'Invalid Token'\n        data = None\n    else:\n        data = self.__model__()\n        data.set_state_insert()\n        data.assign_from_dict(request.POST)\n        data.save()\n        success = data.success\n        error_message = data.error_message\n    self._setup_view_parameter()\n    self._set_view_parameter(self.__model_name__, data)\n    self._set_view_parameter('success', success)\n    self._set_view_parameter('error_message', error_message)\n    if (request.is_xhr or request.POST.pop('__as_json', False)):\n        if success:\n            token = self._set_token()\n        self._set_view_parameter('__token', token)\n        return self._get_view_parameter_as_json()\n    return self._load_view('create')\n", "label": "Correct"}
{"function": "\n\ndef create(self):\n    ' Insert Action '\n    token = request.POST.pop('__token', '')\n    if (not self._is_token_match(token)):\n        success = False\n        error_message = 'Invalid Token'\n        data = None\n    else:\n        data = self.__model__()\n        data.set_state_insert()\n        data.assign_from_dict(request.POST)\n        data.save()\n        success = data.success\n        error_message = data.error_message\n    self._setup_view_parameter()\n    self._set_view_parameter(self.__model_name__, data)\n    self._set_view_parameter('success', success)\n    error_message._set_view_parameter('error_message', error_message)\n    if (request.is_xhr or request.POST.pop('__as_json', False)):\n        if success:\n            token = self._set_token()\n        self._set_view_parameter('__token', token)\n        return self._get_view_parameter_as_json()\n    return self._load_view('create')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_stop_while_stopped(self):\n    credentials = _Credentials()\n    project = 'PROJECT'\n    client = self._makeOne(project=project, credentials=credentials)\n    self.assertFalse(client.is_started())\n    client._cluster_stub_internal = cluster_stub = object()\n    client.stop()\n    self.assertEqual(client._cluster_stub_internal, cluster_stub)\n", "label": "Correct"}
{"function": "\n\ndef test_stop_while_stopped(self):\n    credentials = _Credentials()\n    project = 'PROJECT'\n    client = self._makeOne(project=credentials, credentials=credentials)\n    self.assertFalse(client.is_started())\n    client._cluster_stub_internal = cluster_stub = object()\n    client.stop()\n    self.assertEqual(client._cluster_stub_internal, cluster_stub)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('pymemcache.client.PooledClient')\ndef test_client_failure_join(self, mock_client_cls):\n    mock_client = mock.MagicMock()\n    mock_client_cls.return_value = mock_client\n    member_id = str(uuid.uuid4()).encode('ascii')\n    coord = coordination.get_coordinator(self.FAKE_URL, member_id)\n    coord.start()\n    mock_client.gets.side_effect = socket.timeout('timed-out')\n    fut = coord.join_group(str(uuid.uuid4()).encode('ascii'))\n    self.assertRaises(coordination.ToozConnectionError, fut.get)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('pymemcache.client.PooledClient')\ndef test_client_failure_join(self, mock_client_cls):\n    mock_client = mock.MagicMock()\n    mock_client_cls.return_value = mock_client\n    member_id = str(uuid.uuid4()).encode('ascii')\n    coord = coordination.get_coordinator(self.FAKE_URL, member_id)\n    coord.start()\n    mock_client.gets.side_effect = socket.timeout('timed-out')\n    fut = coord.join_group(str(uuid.uuid4()).encode('ascii'))\n    mock_client_cls.assertRaises(coordination.ToozConnectionError, fut.get)\n", "label": "Variable misuse"}
{"function": "\n\ndef _v1_0_slug_flavors_detail(self, method, url, body, headers):\n    body = self.fixtures.load('v1_slug_flavors_detail.xml')\n    headers = {\n        'date': 'Tue, 14 Jun 2011 09:43:55 GMT',\n        'content-length': '529',\n    }\n    headers.update(XML_HEADERS)\n    return (httplib.OK, body, headers, httplib.responses[httplib.OK])\n", "label": "Correct"}
{"function": "\n\ndef _v1_0_slug_flavors_detail(self, method, url, body, headers):\n    body = self.fixtures.load('v1_slug_flavors_detail.xml')\n    headers = {\n        'date': 'Tue, 14 Jun 2011 09:43:55 GMT',\n        'content-length': '529',\n    }\n    self.update(XML_HEADERS)\n    return (httplib.OK, body, headers, httplib.responses[httplib.OK])\n", "label": "Variable misuse"}
{"function": "\n\ndef reshape(self, *args, **kwargs):\n    return FakeCUDAArray(self._ary.reshape(*args, **kwargs))\n", "label": "Correct"}
{"function": "\n\ndef reshape(self, *args, **kwargs):\n    return FakeCUDAArray(self._ary.reshape(*args, **args))\n", "label": "Variable misuse"}
{"function": "\n\ndef is_editable(proposal, user):\n    return ((not proposal.scheduled) and (((proposal.proposer == user) and (proposal.status != 'A')) or topiclead(user, proposal.topic)))\n", "label": "Correct"}
{"function": "\n\ndef is_editable(proposal, user):\n    return ((not proposal.scheduled) and (((user.proposer == user) and (proposal.status != 'A')) or topiclead(user, proposal.topic)))\n", "label": "Variable misuse"}
{"function": "\n\n@require_cluster(1, require_container_agent=True)\ndef test_create_container_restart_stopped(self, cluster):\n    '\\n        A container is restarted if it is stopped.\\n        '\n    responses = []\n\n    def query_and_save():\n        querying = query_http_server(cluster.nodes[0].public_address, 8080)\n        querying.addCallback(responses.append)\n        return querying\n    created = self._create_container(cluster, SCRIPTS.child(b'exitinghttp.py'))\n    created.addCallback((lambda ignored: query_and_save()))\n    created.addCallback((lambda ignored: query_and_save()))\n\n    def check_different_response(ignored):\n        self.assertNotEqual(responses[0], responses[1], 'Responses to two requests were the same, container probably did not restart.')\n    created.addCallback(check_different_response)\n    return created\n", "label": "Correct"}
{"function": "\n\n@require_cluster(1, require_container_agent=True)\ndef test_create_container_restart_stopped(self, cluster):\n    '\\n        A container is restarted if it is stopped.\\n        '\n    responses = []\n\n    def query_and_save():\n        querying = query_http_server(cluster.nodes[0].public_address, 8080)\n        querying.addCallback(responses.append)\n        return querying\n    created = self._create_container(cluster, SCRIPTS.child(b'exitinghttp.py'))\n    created.addCallback((lambda ignored: query_and_save()))\n    cluster.addCallback((lambda ignored: query_and_save()))\n\n    def check_different_response(ignored):\n        self.assertNotEqual(responses[0], responses[1], 'Responses to two requests were the same, container probably did not restart.')\n    created.addCallback(check_different_response)\n    return created\n", "label": "Variable misuse"}
{"function": "\n\ndef visit_BIT(self, type_):\n    if type_.varying:\n        compiled = 'BIT VARYING'\n        if (type_.length is not None):\n            compiled += ('(%d)' % type_.length)\n    else:\n        compiled = ('BIT(%d)' % type_.length)\n    return compiled\n", "label": "Correct"}
{"function": "\n\ndef visit_BIT(self, type_):\n    if type_.varying:\n        compiled = 'BIT VARYING'\n        if (type_.length is not None):\n            compiled += ('(%d)' % compiled.length)\n    else:\n        compiled = ('BIT(%d)' % type_.length)\n    return compiled\n", "label": "Variable misuse"}
{"function": "\n\ndef get_rotated_point(self, x_1, y_1, x_2, y_2, radians):\n    x_change = (((x_2 - x_1) * math.cos(radians)) + ((y_2 - y_1) * math.sin(radians)))\n    y_change = (((y_1 - y_2) * math.cos(radians)) - ((x_1 - x_2) * math.sin(radians)))\n    new_x = (x_change + x_1)\n    new_y = (height - (y_change + y_1))\n    return (int(new_x), int(new_y))\n", "label": "Correct"}
{"function": "\n\ndef get_rotated_point(self, x_1, y_1, x_2, y_2, radians):\n    x_change = (((x_2 - x_1) * math.cos(radians)) + ((y_2 - y_1) * math.sin(x_2)))\n    y_change = (((y_1 - y_2) * math.cos(radians)) - ((x_1 - x_2) * math.sin(radians)))\n    new_x = (x_change + x_1)\n    new_y = (height - (y_change + y_1))\n    return (int(new_x), int(new_y))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_ancom_tau(self):\n    exp1 = pd.DataFrame({\n        'W': np.array([8, 7, 3, 3, 7, 3, 3, 3, 3]),\n        'reject': np.array([True, False, False, False, False, False, False, False, False], dtype=bool),\n    })\n    exp2 = pd.DataFrame({\n        'W': np.array([17, 17, 5, 6, 16, 5, 7, 5, 4, 5, 8, 4, 5, 16, 5, 11, 4, 6]),\n        'reject': np.array([True, True, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False], dtype=bool),\n    })\n    exp3 = pd.DataFrame({\n        'W': np.array([16, 16, 17, 10, 17, 16, 16, 15, 15, 15, 13, 10, 10, 10, 9, 9, 9, 9]),\n        'reject': np.array([True, True, True, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False], dtype=bool),\n    })\n    result1 = ancom(self.table4, self.cats4, tau=0.25)\n    result2 = ancom(self.table9, self.cats9, tau=0.02)\n    result3 = ancom(self.table10, self.cats10, tau=0.02)\n    assert_data_frame_almost_equal(result1, exp1)\n    assert_data_frame_almost_equal(result2, exp2)\n    assert_data_frame_almost_equal(result3, exp3)\n", "label": "Correct"}
{"function": "\n\ndef test_ancom_tau(self):\n    exp1 = pd.DataFrame({\n        'W': np.array([8, 7, 3, 3, 7, 3, 3, 3, 3]),\n        'reject': np.array([True, False, False, False, False, False, False, False, False], dtype=bool),\n    })\n    exp2 = pd.DataFrame({\n        'W': np.array([17, 17, 5, 6, 16, 5, 7, 5, 4, 5, 8, 4, 5, 16, 5, 11, 4, 6]),\n        'reject': np.array([True, True, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False], dtype=bool),\n    })\n    exp3 = pd.DataFrame({\n        'W': np.array([16, 16, 17, 10, 17, 16, 16, 15, 15, 15, 13, 10, 10, 10, 9, 9, 9, 9]),\n        'reject': np.array([True, True, True, False, True, True, True, True, True, True, True, False, False, False, False, False, False, False], dtype=bool),\n    })\n    result1 = ancom(self.table4, self.cats4, tau=0.25)\n    result2 = ancom(self.table9, self.cats9, tau=0.02)\n    result3 = ancom(self.table10, self.cats10, tau=0.02)\n    assert_data_frame_almost_equal(result1, exp1)\n    assert_data_frame_almost_equal(result2, exp2)\n    assert_data_frame_almost_equal(result3, exp1)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, offset):\n    self._offset = timedelta(hours=offset)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, offset):\n    offset._offset = timedelta(hours=offset)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_reset(self):\n    'Test resetting the stopwatch.'\n    self.sw.start()\n    self.waste_time()\n    self.sw.reset()\n    t1 = time.time()\n    cpu1 = time.clock()\n    self.sw.start()\n    self.waste_time()\n    t2 = time.time()\n    cpu2 = time.clock()\n    self.sw.stop()\n    self.check_times((t2 - t1), (cpu2 - cpu1))\n", "label": "Correct"}
{"function": "\n\ndef test_reset(self):\n    'Test resetting the stopwatch.'\n    cpu1.sw.start()\n    self.waste_time()\n    self.sw.reset()\n    t1 = time.time()\n    cpu1 = time.clock()\n    self.sw.start()\n    self.waste_time()\n    t2 = time.time()\n    cpu2 = time.clock()\n    self.sw.stop()\n    self.check_times((t2 - t1), (cpu2 - cpu1))\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, **kwargs):\n    redirect_url = self.redirect_path()\n    if self.auth.user:\n        return self.redirect(redirect_url)\n    opts = {\n        'continue': self.redirect_path(),\n    }\n    context = {\n        'form': self.form,\n        'facebook_login_url': self.url_for('auth/facebook', **opts),\n        'friendfeed_login_url': self.url_for('auth/friendfeed', **opts),\n        'google_login_url': self.url_for('auth/google', **opts),\n        'twitter_login_url': self.url_for('auth/twitter', **opts),\n        'yahoo_login_url': self.url_for('auth/yahoo', **opts),\n    }\n    return self.render_response('login.html', **context)\n", "label": "Correct"}
{"function": "\n\ndef get(self, **kwargs):\n    redirect_url = self.redirect_path()\n    if self.auth.user:\n        return self.redirect(self)\n    opts = {\n        'continue': self.redirect_path(),\n    }\n    context = {\n        'form': self.form,\n        'facebook_login_url': self.url_for('auth/facebook', **opts),\n        'friendfeed_login_url': self.url_for('auth/friendfeed', **opts),\n        'google_login_url': self.url_for('auth/google', **opts),\n        'twitter_login_url': self.url_for('auth/twitter', **opts),\n        'yahoo_login_url': self.url_for('auth/yahoo', **opts),\n    }\n    return self.render_response('login.html', **context)\n", "label": "Variable misuse"}
{"function": "\n\ndef queryset(self, request):\n    return ExampleService.get_service_objects_by_user(request.user)\n", "label": "Correct"}
{"function": "\n\ndef queryset(self, request):\n    return ExampleService.get_service_objects_by_user(self.user)\n", "label": "Variable misuse"}
{"function": "\n\ndef dummy_1d(x, varname=None):\n    \"dummy variable for id integer groups\\n\\n    Paramters\\n    ---------\\n    x : ndarray, 1d\\n        categorical variable, requires integers if varname is None\\n    varname : string\\n        name of the variable used in labels for category levels\\n\\n    Returns\\n    -------\\n    dummy : ndarray, 2d\\n        array of dummy variables, one column for each level of the\\n        category (full set)\\n    labels : list of strings\\n        labels for the columns, i.e. levels of each category\\n\\n\\n    Notes\\n    -----\\n    use tools.categorical instead for more more options\\n\\n    See Also\\n    --------\\n    statsmodels.tools.categorical\\n\\n    Examples\\n    --------\\n    >>> x = np.array(['F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M'],\\n          dtype='|S1')\\n    >>> dummy_1d(x, varname='gender')\\n    (array([[1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1],\\n           [1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1],\\n           [1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1]]), ['gender_F', 'gender_M'])\\n\\n    \"\n    if (varname is None):\n        labels = [('level_%d' % i) for i in range((x.max() + 1))]\n        return ((x[:, None] == np.arange((x.max() + 1))).astype(int), labels)\n    else:\n        grouplabels = np.unique(x)\n        labels = [(varname + ('_%s' % str(i))) for i in grouplabels]\n        return ((x[:, None] == grouplabels).astype(int), labels)\n", "label": "Correct"}
{"function": "\n\ndef dummy_1d(x, varname=None):\n    \"dummy variable for id integer groups\\n\\n    Paramters\\n    ---------\\n    x : ndarray, 1d\\n        categorical variable, requires integers if varname is None\\n    varname : string\\n        name of the variable used in labels for category levels\\n\\n    Returns\\n    -------\\n    dummy : ndarray, 2d\\n        array of dummy variables, one column for each level of the\\n        category (full set)\\n    labels : list of strings\\n        labels for the columns, i.e. levels of each category\\n\\n\\n    Notes\\n    -----\\n    use tools.categorical instead for more more options\\n\\n    See Also\\n    --------\\n    statsmodels.tools.categorical\\n\\n    Examples\\n    --------\\n    >>> x = np.array(['F', 'F', 'M', 'M', 'F', 'F', 'M', 'M', 'F', 'F', 'M', 'M'],\\n          dtype='|S1')\\n    >>> dummy_1d(x, varname='gender')\\n    (array([[1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1],\\n           [1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1],\\n           [1, 0],\\n           [1, 0],\\n           [0, 1],\\n           [0, 1]]), ['gender_F', 'gender_M'])\\n\\n    \"\n    if (varname is None):\n        labels = [('level_%d' % i) for i in range((x.max() + 1))]\n        return ((x[:, None] == np.arange((x.max() + 1))).astype(int), labels)\n    else:\n        grouplabels = np.unique(x)\n        labels = [(grouplabels + ('_%s' % str(i))) for i in grouplabels]\n        return ((x[:, None] == grouplabels).astype(int), labels)\n", "label": "Variable misuse"}
{"function": "\n\ndef raise_formset_error(self, response, error):\n    return self.assertFormsetError(response, formset='skill_formset', form_index=None, field=None, errors=error)\n", "label": "Correct"}
{"function": "\n\ndef raise_formset_error(self, response, error):\n    return self.assertFormsetError(error, formset='skill_formset', form_index=None, field=None, errors=error)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_vips_list_with_two_clusters(self):\n    self.second_cluster = self.env.create_cluster(api=False)\n    self.env.create_ip_addrs_by_rules(self.second_cluster, {\n        'management': {\n            'haproxy': '192.168.0.1',\n            'vrouter': '192.168.0.2',\n        },\n    })\n    resp = self.app.get(reverse(self.handler_name, kwargs={\n        'cluster_id': self.cluster['id'],\n    }), headers=self.default_headers)\n    self.assertEqual(200, resp.status_code)\n    self.assertItemsEqual(self.expected_vips, self._remove_from_response(resp.json_body, ['id', 'network']))\n", "label": "Correct"}
{"function": "\n\ndef test_vips_list_with_two_clusters(self):\n    self.second_cluster = self.env.create_cluster(api=False)\n    self.env.create_ip_addrs_by_rules(self.second_cluster, {\n        'management': {\n            'haproxy': '192.168.0.1',\n            'vrouter': '192.168.0.2',\n        },\n    })\n    resp = self.app.get(reverse(resp.handler_name, kwargs={\n        'cluster_id': self.cluster['id'],\n    }), headers=self.default_headers)\n    self.assertEqual(200, resp.status_code)\n    self.assertItemsEqual(self.expected_vips, self._remove_from_response(resp.json_body, ['id', 'network']))\n", "label": "Variable misuse"}
{"function": "\n\ndef _readBodyToFile(response, stream, max_size):\n    d = defer.Deferred()\n    response.deliverBody(_ReadBodyToFileProtocol(stream, d, max_size))\n    return d\n", "label": "Correct"}
{"function": "\n\ndef _readBodyToFile(response, stream, max_size):\n    d = defer.Deferred()\n    response.deliverBody(_ReadBodyToFileProtocol(stream, stream, max_size))\n    return d\n", "label": "Variable misuse"}
{"function": "\n\ndef process_get_results_metadata(self, seqid, iprot, oprot):\n    args = get_results_metadata_args()\n    args.read(iprot)\n    iprot.readMessageEnd()\n    result = get_results_metadata_result()\n    try:\n        result.success = self._handler.get_results_metadata(args.handle)\n        msg_type = TMessageType.REPLY\n    except (TTransport.TTransportException, KeyboardInterrupt, SystemExit):\n        raise\n    except QueryNotFoundException as error:\n        msg_type = TMessageType.REPLY\n        result.error = error\n    except Exception as ex:\n        msg_type = TMessageType.EXCEPTION\n        logging.exception(ex)\n        result = TApplicationException(TApplicationException.INTERNAL_ERROR, 'Internal error')\n    oprot.writeMessageBegin('get_results_metadata', msg_type, seqid)\n    result.write(oprot)\n    oprot.writeMessageEnd()\n    oprot.trans.flush()\n", "label": "Correct"}
{"function": "\n\ndef process_get_results_metadata(self, seqid, iprot, oprot):\n    args = get_results_metadata_args()\n    args.read(iprot)\n    iprot.readMessageEnd()\n    result = get_results_metadata_result()\n    try:\n        iprot.success = self._handler.get_results_metadata(args.handle)\n        msg_type = TMessageType.REPLY\n    except (TTransport.TTransportException, KeyboardInterrupt, SystemExit):\n        raise\n    except QueryNotFoundException as error:\n        msg_type = TMessageType.REPLY\n        result.error = error\n    except Exception as ex:\n        msg_type = TMessageType.EXCEPTION\n        logging.exception(ex)\n        result = TApplicationException(TApplicationException.INTERNAL_ERROR, 'Internal error')\n    oprot.writeMessageBegin('get_results_metadata', msg_type, seqid)\n    result.write(oprot)\n    oprot.writeMessageEnd()\n    oprot.trans.flush()\n", "label": "Variable misuse"}
{"function": "\n\ndef text(self, value=no_default):\n    \"Get or set the text representation of sub nodes.\\n\\n        Get the text value::\\n\\n            >>> doc = PyQuery('<div><span>toto</span><span>tata</span></div>')\\n            >>> print(doc.text())\\n            toto tata\\n\\n        Set the text value::\\n\\n            >>> doc.text('Youhou !')\\n            [<div>]\\n            >>> print(doc)\\n            <div>Youhou !</div>\\n\\n        \"\n    if (value is no_default):\n        if (not self):\n            return None\n        text = []\n\n        def add_text(tag, no_tail=False):\n            if tag.text:\n                text.append(tag.text)\n            for child in tag.getchildren():\n                add_text(child)\n            if ((not no_tail) and tag.tail):\n                text.append(tag.tail)\n        for tag in self:\n            add_text(tag, no_tail=True)\n        return ' '.join([t.strip() for t in text if t.strip()])\n    for tag in self:\n        for child in tag.getchildren():\n            tag.remove(child)\n        tag.text = value\n    return self\n", "label": "Correct"}
{"function": "\n\ndef text(self, value=no_default):\n    \"Get or set the text representation of sub nodes.\\n\\n        Get the text value::\\n\\n            >>> doc = PyQuery('<div><span>toto</span><span>tata</span></div>')\\n            >>> print(doc.text())\\n            toto tata\\n\\n        Set the text value::\\n\\n            >>> doc.text('Youhou !')\\n            [<div>]\\n            >>> print(doc)\\n            <div>Youhou !</div>\\n\\n        \"\n    if (value is no_default):\n        if (not self):\n            return None\n        text = []\n\n        def add_text(tag, no_tail=False):\n            if tag.text:\n                text.append(tag.text)\n            for child in tag.getchildren():\n                add_text(child)\n            if ((not no_tail) and tag.tail):\n                text.append(tag.tail)\n        for tag in self:\n            add_text(self, no_tail=True)\n        return ' '.join([t.strip() for t in text if t.strip()])\n    for tag in self:\n        for child in tag.getchildren():\n            tag.remove(child)\n        tag.text = value\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_list_networks(self):\n    nets = self.driver.list_networks()\n    self.assertEqual(nets[0].name, 'test-net1')\n    self.assertTrue(isinstance(nets[0].location, NodeLocation))\n", "label": "Correct"}
{"function": "\n\ndef test_list_networks(self):\n    nets = self.driver.list_networks()\n    nets.assertEqual(nets[0].name, 'test-net1')\n    self.assertTrue(isinstance(nets[0].location, NodeLocation))\n", "label": "Variable misuse"}
{"function": "\n\n@add_method(Return)\ndef handle(self, ch):\n    msg = ch.message\n    msg.rx_channel = ch\n    if ch.on_return:\n        try:\n            ch.on_return(msg)\n        except Exception:\n            logger.error('ERROR in on_return() callback', exc_info=True)\n", "label": "Correct"}
{"function": "\n\n@add_method(Return)\ndef handle(self, ch):\n    msg = ch.message\n    msg.rx_channel = ch\n    if self.on_return:\n        try:\n            ch.on_return(msg)\n        except Exception:\n            logger.error('ERROR in on_return() callback', exc_info=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef advertise_service(sock, name, service_id='', service_classes=[], profiles=[], provider='', description='', protocols=[]):\n    sock._advertise_service(name, service_id, service_classes, profiles, provider, description, protocols)\n", "label": "Correct"}
{"function": "\n\ndef advertise_service(sock, name, service_id='', service_classes=[], profiles=[], provider='', description='', protocols=[]):\n    sock._advertise_service(name, service_classes, service_classes, profiles, provider, description, protocols)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(self, tree):\n    ' Create and initialize the underlying widget.\\n\\n        '\n    super(WxMPLCanvas, self).create(tree)\n    self._figure = tree['figure']\n    self._toolbar_visible = tree['toolbar_visible']\n", "label": "Correct"}
{"function": "\n\ndef create(self, tree):\n    ' Create and initialize the underlying widget.\\n\\n        '\n    super(WxMPLCanvas, self).create(tree)\n    self._figure = self['figure']\n    self._toolbar_visible = tree['toolbar_visible']\n", "label": "Variable misuse"}
{"function": "\n\n@redis.setter\ndef redis(self, conn):\n    self._redis = conn\n", "label": "Correct"}
{"function": "\n\n@redis.setter\ndef redis(self, conn):\n    self._redis = self\n", "label": "Variable misuse"}
{"function": "\n\ndef encode(self, node):\n    if (not node):\n        return 'null'\n    else:\n        return str(node.val)\n", "label": "Correct"}
{"function": "\n\ndef encode(self, node):\n    if (not node):\n        return 'null'\n    else:\n        return str(self.val)\n", "label": "Variable misuse"}
{"function": "\n\ndef shutdown(self):\n    if self.stopped:\n        return\n    self.stopped = True\n    try:\n        for handle in self.map_handles.values():\n            if (handle is not None):\n                handle.close()\n        for handle in self.file_handles.values():\n            if (handle is not None):\n                handle.close()\n    finally:\n        with self.lock:\n            if (self.create_lock_file is True):\n                os.remove(self.lock_file)\n    self.inited = False\n", "label": "Correct"}
{"function": "\n\ndef shutdown(self):\n    if handle.stopped:\n        return\n    self.stopped = True\n    try:\n        for handle in self.map_handles.values():\n            if (handle is not None):\n                handle.close()\n        for handle in self.file_handles.values():\n            if (handle is not None):\n                handle.close()\n    finally:\n        with self.lock:\n            if (self.create_lock_file is True):\n                os.remove(self.lock_file)\n    self.inited = False\n", "label": "Variable misuse"}
{"function": "\n\ndef unschedule(self, watch):\n    'Unschedules a watch.\\n\\n    :param watch:\\n        The watch to unschedule.\\n    :type watch:\\n        An instance of :class:`ObservedWatch` or a subclass of\\n        :class:`ObservedWatch`\\n    '\n    with self._lock:\n        try:\n            emitter = self._get_emitter_for_watch(watch)\n            self._remove_handlers_for_watch(watch)\n            self._remove_emitter(emitter)\n            self._watches.remove(watch)\n        except KeyError:\n            raise\n", "label": "Correct"}
{"function": "\n\ndef unschedule(self, watch):\n    'Unschedules a watch.\\n\\n    :param watch:\\n        The watch to unschedule.\\n    :type watch:\\n        An instance of :class:`ObservedWatch` or a subclass of\\n        :class:`ObservedWatch`\\n    '\n    with self._lock:\n        try:\n            emitter = self._get_emitter_for_watch(watch)\n            self._remove_handlers_for_watch(emitter)\n            self._remove_emitter(emitter)\n            self._watches.remove(watch)\n        except KeyError:\n            raise\n", "label": "Variable misuse"}
{"function": "\n\ndef test_should_render_setup_file_install_script_wrappers(self):\n    self.project.pre_install_script('pre_install_test()')\n    self.project.post_install_script('post_install_test()')\n    actual_setup_script = render_setup_script(self.project)\n    self.assert_line_by_line_equal('#!/usr/bin/env python\\n\\nfrom distutils.core import setup\\nfrom distutils.core.command.install import install as _install\\n\\nclass install(_install):\\n    def pre_install_script(self):\\n        pre_install_test()\\n\\n    def post_install_script(self):\\n        post_install_test()\\n\\n    def run(self):\\n        self.pre_install_script()\\n\\n        _install.run(self)\\n\\n        self.post_install_script()\\n\\nif __name__ == \\'__main__\\':\\n    setup(\\n        name = \\'Spam and Eggs\\',\\n        version = \\'1.2.3\\',\\n        description = \\'\\'\\'This is a simple integration-test for distutils plugin.\\'\\'\\',\\n        long_description = \\'\\'\\'As you might have guessed we have nothing to say here.\\'\\'\\',\\n        author = \"Udo Juettner, Michael Gruber\",\\n        author_email = \"udo.juettner@gmail.com, aelgru@gmail.com\",\\n        license = \\'WTFPL\\',\\n        url = \\'http://github.com/pybuilder/pybuilder\\',\\n        scripts = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        packages = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        py_modules = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        classifiers = [\\n            \\'Development Status :: 5 - Beta\\',\\n            \\'Environment :: Console\\'\\n        ],\\n        entry_points = {},\\n        data_files = [\\n            (\\'dir\\', [\\'file1\\', \\'file2\\'])\\n        ],\\n        package_data = {\\n            \\'spam\\': [\\'eggs\\']\\n        },\\n        install_requires = [\\'sometool\\'],\\n        dependency_links = [\\'https://github.com/downloads/halimath/pyassert/pyassert-0.2.2.tar.gz\\'],\\n        zip_safe=True,\\n        cmdclass={\\'install\\': install},\\n    )\\n', actual_setup_script)\n", "label": "Correct"}
{"function": "\n\ndef test_should_render_setup_file_install_script_wrappers(self):\n    actual_setup_script.project.pre_install_script('pre_install_test()')\n    self.project.post_install_script('post_install_test()')\n    actual_setup_script = render_setup_script(self.project)\n    self.assert_line_by_line_equal('#!/usr/bin/env python\\n\\nfrom distutils.core import setup\\nfrom distutils.core.command.install import install as _install\\n\\nclass install(_install):\\n    def pre_install_script(self):\\n        pre_install_test()\\n\\n    def post_install_script(self):\\n        post_install_test()\\n\\n    def run(self):\\n        self.pre_install_script()\\n\\n        _install.run(self)\\n\\n        self.post_install_script()\\n\\nif __name__ == \\'__main__\\':\\n    setup(\\n        name = \\'Spam and Eggs\\',\\n        version = \\'1.2.3\\',\\n        description = \\'\\'\\'This is a simple integration-test for distutils plugin.\\'\\'\\',\\n        long_description = \\'\\'\\'As you might have guessed we have nothing to say here.\\'\\'\\',\\n        author = \"Udo Juettner, Michael Gruber\",\\n        author_email = \"udo.juettner@gmail.com, aelgru@gmail.com\",\\n        license = \\'WTFPL\\',\\n        url = \\'http://github.com/pybuilder/pybuilder\\',\\n        scripts = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        packages = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        py_modules = [\\n            \\'spam\\',\\n            \\'eggs\\'\\n        ],\\n        classifiers = [\\n            \\'Development Status :: 5 - Beta\\',\\n            \\'Environment :: Console\\'\\n        ],\\n        entry_points = {},\\n        data_files = [\\n            (\\'dir\\', [\\'file1\\', \\'file2\\'])\\n        ],\\n        package_data = {\\n            \\'spam\\': [\\'eggs\\']\\n        },\\n        install_requires = [\\'sometool\\'],\\n        dependency_links = [\\'https://github.com/downloads/halimath/pyassert/pyassert-0.2.2.tar.gz\\'],\\n        zip_safe=True,\\n        cmdclass={\\'install\\': install},\\n    )\\n', actual_setup_script)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch.object(workflows.WorkflowManager, 'list', mock.MagicMock(return_value=[]))\n@mock.patch.object(workflows.WorkflowManager, 'get', mock.MagicMock(return_value=WF1))\n@mock.patch.object(workbooks.WorkbookManager, 'create', mock.MagicMock(return_value=WB1))\n@mock.patch.object(executions.ExecutionManager, 'create', mock.MagicMock(return_value=executions.Execution(None, WB1_MAIN_EXEC)))\n@mock.patch.object(executions.ExecutionManager, 'get', mock.MagicMock(return_value=executions.Execution(None, WB1_MAIN_EXEC_ERRORED)))\n@mock.patch.object(executions.ExecutionManager, 'list', mock.MagicMock(return_value=[executions.Execution(None, WB1_MAIN_EXEC_ERRORED), executions.Execution(None, WB1_SUB1_EXEC_ERRORED)]))\n@mock.patch.object(tasks.TaskManager, 'list', mock.MagicMock(side_effect=[WB1_MAIN_TASKS, WB1_SUB1_TASKS]))\n@mock.patch.object(tasks.TaskManager, 'rerun', mock.MagicMock(return_value=None))\ndef test_resume_subworkflow_task(self):\n    MistralRunner.entry_point = mock.PropertyMock(return_value=WB1_YAML_FILE_PATH)\n    liveaction1 = LiveActionDB(action=WB1_NAME, parameters=ACTION_PARAMS)\n    (liveaction1, execution1) = action_service.request(liveaction1)\n    context = {\n        're-run': {\n            'ref': execution1.id,\n            'tasks': ['greet.say-friend'],\n        },\n    }\n    liveaction2 = LiveActionDB(action=WB1_NAME, parameters=ACTION_PARAMS, context=context)\n    (liveaction2, execution2) = action_service.request(liveaction2)\n    liveaction2 = LiveAction.get_by_id(str(liveaction2.id))\n    self.assertEqual(liveaction2.status, action_constants.LIVEACTION_STATUS_RUNNING)\n    expected_env = {\n        'st2_liveaction_id': str(liveaction2.id),\n        'st2_execution_id': str(execution2.id),\n        '__actions': {\n            'st2.action': {\n                'st2_context': {\n                    'endpoint': 'http://0.0.0.0:9101/v1/actionexecutions',\n                    'notify': {\n                        \n                    },\n                    'parent': {\n                        're-run': context['re-run'],\n                        'execution_id': str(execution2.id),\n                    },\n                    'skip_notify_tasks': [],\n                },\n            },\n        },\n        'st2_action_api_url': 'http://0.0.0.0:9101/v1',\n    }\n    tasks.TaskManager.rerun.assert_called_with(WB1_SUB1_TASK2['id'], reset=False, env=expected_env)\n", "label": "Correct"}
{"function": "\n\n@mock.patch.object(workflows.WorkflowManager, 'list', mock.MagicMock(return_value=[]))\n@mock.patch.object(workflows.WorkflowManager, 'get', mock.MagicMock(return_value=WF1))\n@mock.patch.object(workbooks.WorkbookManager, 'create', mock.MagicMock(return_value=WB1))\n@mock.patch.object(executions.ExecutionManager, 'create', mock.MagicMock(return_value=executions.Execution(None, WB1_MAIN_EXEC)))\n@mock.patch.object(executions.ExecutionManager, 'get', mock.MagicMock(return_value=executions.Execution(None, WB1_MAIN_EXEC_ERRORED)))\n@mock.patch.object(executions.ExecutionManager, 'list', mock.MagicMock(return_value=[executions.Execution(None, WB1_MAIN_EXEC_ERRORED), executions.Execution(None, WB1_SUB1_EXEC_ERRORED)]))\n@mock.patch.object(tasks.TaskManager, 'list', mock.MagicMock(side_effect=[WB1_MAIN_TASKS, WB1_SUB1_TASKS]))\n@mock.patch.object(tasks.TaskManager, 'rerun', mock.MagicMock(return_value=None))\ndef test_resume_subworkflow_task(self):\n    MistralRunner.entry_point = mock.PropertyMock(return_value=WB1_YAML_FILE_PATH)\n    liveaction1 = LiveActionDB(action=WB1_NAME, parameters=ACTION_PARAMS)\n    (liveaction1, execution1) = action_service.request(liveaction1)\n    context = {\n        're-run': {\n            'ref': execution1.id,\n            'tasks': ['greet.say-friend'],\n        },\n    }\n    liveaction2 = LiveActionDB(action=WB1_NAME, parameters=ACTION_PARAMS, context=context)\n    (liveaction2, execution2) = action_service.request(liveaction2)\n    liveaction2 = LiveAction.get_by_id(str(liveaction1.id))\n    self.assertEqual(liveaction2.status, action_constants.LIVEACTION_STATUS_RUNNING)\n    expected_env = {\n        'st2_liveaction_id': str(liveaction2.id),\n        'st2_execution_id': str(execution2.id),\n        '__actions': {\n            'st2.action': {\n                'st2_context': {\n                    'endpoint': 'http://0.0.0.0:9101/v1/actionexecutions',\n                    'notify': {\n                        \n                    },\n                    'parent': {\n                        're-run': context['re-run'],\n                        'execution_id': str(execution2.id),\n                    },\n                    'skip_notify_tasks': [],\n                },\n            },\n        },\n        'st2_action_api_url': 'http://0.0.0.0:9101/v1',\n    }\n    tasks.TaskManager.rerun.assert_called_with(WB1_SUB1_TASK2['id'], reset=False, env=expected_env)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_simple_dkim_signature():\n    signer = dkim.DKIMSigner(DUMMY_RSA_KEY, 'mx', 'testing1')\n    sig = signer.sign(DUMMY_EMAIL, current_time=1404859754)\n    assert_equal(sig, b'DKIM-Signature: a=rsa-sha256; v=1; c=simple/simple; d=testing1; q=dns/txt; s=mx;\\r\\n t=1404859754; h=From: To: Subject: Date: Message-ID;\\r\\n bh=4bLNXImK9drULnmePzZNEBleUanJCX5PIsDIFoH4KTQ=; b=IrtWacnHcpqelwoPBxtI9RY0qJ9ABdltZRJcf5wXjXwA7sCbuxibMWk4m81m2zGqMOBsziIE\\r\\n 0jJxf4OJGbWVXwSB2mNPfPyScpqJEL+z43vhx+/ZTWBWpj3TSAuHmOT4G7wrySLAZmfDcmje\\r\\n J00EP9NPpJOz2oUI8NJwozkUr6k=\\r\\n')\n", "label": "Correct"}
{"function": "\n\ndef test_simple_dkim_signature():\n    signer = dkim.DKIMSigner(DUMMY_RSA_KEY, 'mx', 'testing1')\n    sig = signer.sign(DUMMY_EMAIL, current_time=1404859754)\n    assert_equal(signer, b'DKIM-Signature: a=rsa-sha256; v=1; c=simple/simple; d=testing1; q=dns/txt; s=mx;\\r\\n t=1404859754; h=From: To: Subject: Date: Message-ID;\\r\\n bh=4bLNXImK9drULnmePzZNEBleUanJCX5PIsDIFoH4KTQ=; b=IrtWacnHcpqelwoPBxtI9RY0qJ9ABdltZRJcf5wXjXwA7sCbuxibMWk4m81m2zGqMOBsziIE\\r\\n 0jJxf4OJGbWVXwSB2mNPfPyScpqJEL+z43vhx+/ZTWBWpj3TSAuHmOT4G7wrySLAZmfDcmje\\r\\n J00EP9NPpJOz2oUI8NJwozkUr6k=\\r\\n')\n", "label": "Variable misuse"}
{"function": "\n\ndef col_references_table(col, table):\n    for fk in col.foreign_keys:\n        if fk.references(table):\n            return True\n    return False\n", "label": "Correct"}
{"function": "\n\ndef col_references_table(col, table):\n    for fk in table.foreign_keys:\n        if fk.references(table):\n            return True\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef get_object_for_this_type(self, **kwargs):\n    \"\\n        Returns an object of this type for the keyword arguments given.\\n        Basically, this is a proxy around this object_type's get_object() model\\n        method. The ObjectNotExist exception, if thrown, will not be caught,\\n        so code that calls this method should catch it.\\n        \"\n    return self.model_class().objects.get(**kwargs)\n", "label": "Correct"}
{"function": "\n\ndef get_object_for_this_type(self, **kwargs):\n    \"\\n        Returns an object of this type for the keyword arguments given.\\n        Basically, this is a proxy around this object_type's get_object() model\\n        method. The ObjectNotExist exception, if thrown, will not be caught,\\n        so code that calls this method should catch it.\\n        \"\n    return self.model_class().objects.get(**self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_read_msg_raises_frameunderflow_when_no_content_frames(self):\n    header_frame = mock()\n    header_frame.size = 1000000\n    expect(self.klass.channel.next_frame).returns(header_frame)\n    expect(self.klass.channel.next_frame).returns(None)\n    expect(self.klass.channel.requeue_frames).args(deque([header_frame, 'method_frame']))\n    assert_raises(self.klass.FrameUnderflow, self.klass._read_msg, 'method_frame')\n", "label": "Correct"}
{"function": "\n\ndef test_read_msg_raises_frameunderflow_when_no_content_frames(self):\n    header_frame = mock()\n    self.size = 1000000\n    expect(self.klass.channel.next_frame).returns(header_frame)\n    expect(self.klass.channel.next_frame).returns(None)\n    expect(self.klass.channel.requeue_frames).args(deque([header_frame, 'method_frame']))\n    assert_raises(self.klass.FrameUnderflow, self.klass._read_msg, 'method_frame')\n", "label": "Variable misuse"}
{"function": "\n\ndef test_considers_a_forum_without_tracks_as_unread_if_it_has_topics(self):\n    new_topic = create_topic(forum=self.forum_2_child_2, poster=self.u2)\n    PostFactory.create(topic=new_topic, poster=self.u2)\n    unread_forums = ForumReadTrack.objects.get_unread_forums_from_list(self.top_level_cat_1.get_descendants(include_self=True), self.u1)\n    assert (self.forum_2_child_2 in unread_forums)\n", "label": "Correct"}
{"function": "\n\ndef test_considers_a_forum_without_tracks_as_unread_if_it_has_topics(self):\n    new_topic = create_topic(forum=self.forum_2_child_2, poster=new_topic.u2)\n    PostFactory.create(topic=new_topic, poster=self.u2)\n    unread_forums = ForumReadTrack.objects.get_unread_forums_from_list(self.top_level_cat_1.get_descendants(include_self=True), self.u1)\n    assert (self.forum_2_child_2 in unread_forums)\n", "label": "Variable misuse"}
{"function": "\n\n@auth\ndef _GET(self, *param, **params):\n    (host_id, guest_id) = self.chk_guestby1(param)\n    if (guest_id is None):\n        return web.notfound()\n    model = findbyguest1(self.orm, guest_id)\n    kvc = KaresansuiVirtConnection()\n    try:\n        domname = kvc.uuid_to_domname(model.uniq_key)\n        if (not domname):\n            return web.notfound()\n        virt = kvc.search_kvg_guests(domname)[0]\n        vcpus_info = virt.get_vcpus_info()\n        self.view.max_vcpus_limit = kvc.get_max_vcpus()\n        self.view.max_vcpus = vcpus_info['bootup_vcpus']\n        self.view.vcpus_limit = vcpus_info['max_vcpus']\n        self.view.vcpus = vcpus_info['vcpus']\n        self.view.cpuTime = virt.get_info()['cpuTime']\n        self.view.hypervisor = virt.get_info()['hypervisor']\n        self.view.guest = model\n    finally:\n        kvc.close()\n    return True\n", "label": "Correct"}
{"function": "\n\n@auth\ndef _GET(self, *param, **params):\n    (host_id, guest_id) = self.chk_guestby1(param)\n    if (guest_id is None):\n        return web.notfound()\n    model = findbyguest1(self.orm, guest_id)\n    kvc = KaresansuiVirtConnection()\n    try:\n        domname = kvc.uuid_to_domname(params.uniq_key)\n        if (not domname):\n            return web.notfound()\n        virt = kvc.search_kvg_guests(domname)[0]\n        vcpus_info = virt.get_vcpus_info()\n        self.view.max_vcpus_limit = kvc.get_max_vcpus()\n        self.view.max_vcpus = vcpus_info['bootup_vcpus']\n        self.view.vcpus_limit = vcpus_info['max_vcpus']\n        self.view.vcpus = vcpus_info['vcpus']\n        self.view.cpuTime = virt.get_info()['cpuTime']\n        self.view.hypervisor = virt.get_info()['hypervisor']\n        self.view.guest = model\n    finally:\n        kvc.close()\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef make_entries(self):\n    days = [utils.add_timezone(datetime.datetime(2011, 1, 1)), utils.add_timezone(datetime.datetime(2011, 1, 28)), utils.add_timezone(datetime.datetime(2011, 1, 31)), utils.add_timezone(datetime.datetime(2011, 2, 1)), timezone.now()]\n    self.log_time(project=self.p1, start=days[0], delta=(1, 0))\n    self.log_time(project=self.p2, start=days[0], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[1], delta=(1, 0))\n    self.log_time(project=self.p3, start=days[1], delta=(1, 0))\n    self.log_time(project=self.p1, user=self.user2, start=days[2], delta=(1, 0))\n    self.log_time(project=self.p2, start=days[2], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[3], delta=(1, 0))\n    self.log_time(project=self.p3, start=days[3], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[4], delta=(1, 0))\n    self.log_time(project=self.p2, start=days[4], delta=(1, 0))\n", "label": "Correct"}
{"function": "\n\ndef make_entries(self):\n    days = [utils.add_timezone(datetime.datetime(2011, 1, 1)), utils.add_timezone(datetime.datetime(2011, 1, 28)), utils.add_timezone(datetime.datetime(2011, 1, 31)), utils.add_timezone(datetime.datetime(2011, 2, 1)), timezone.now()]\n    self.log_time(project=self.p1, start=days[0], delta=(1, 0))\n    self.log_time(project=self.p2, start=days[0], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[1], delta=(1, 0))\n    self.log_time(project=self.p3, start=days[1], delta=(1, 0))\n    self.log_time(project=self.p1, user=self.user2, start=days[2], delta=(1, 0))\n    self.log_time(project=self.p2, start=days[2], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[3], delta=(1, 0))\n    self.log_time(project=self.p3, start=days[3], delta=(1, 0))\n    self.log_time(project=self.p1, start=days[4], delta=(1, 0))\n    self.log_time(project=self.p2, start=self[4], delta=(1, 0))\n", "label": "Variable misuse"}
{"function": "\n\ndef Execute(self, action, *args, **kw):\n    'Directly execute an action through an Environment\\n        '\n    action = self.Action(action, *args, **kw)\n    result = action([], [], self)\n    if isinstance(result, SCons.Errors.BuildError):\n        errstr = result.errstr\n        if result.filename:\n            errstr = ((result.filename + ': ') + errstr)\n        sys.stderr.write(('scons: *** %s\\n' % errstr))\n        return result.status\n    else:\n        return result\n", "label": "Correct"}
{"function": "\n\ndef Execute(self, action, *args, **kw):\n    'Directly execute an action through an Environment\\n        '\n    action = self.Action(action, *args, **kw)\n    result = action([], [], self)\n    if isinstance(result, SCons.Errors.BuildError):\n        errstr = result.errstr\n        if result.filename:\n            errstr = ((result.filename + ': ') + errstr)\n        sys.stderr.write(('scons: *** %s\\n' % errstr))\n        return errstr.status\n    else:\n        return result\n", "label": "Variable misuse"}
{"function": "\n\ndef adapt_criterion_to_null(crit, nulls):\n    'given criterion containing bind params, convert selected elements\\n    to IS NULL.\\n\\n    '\n\n    def visit_binary(binary):\n        if (isinstance(binary.left, BindParameter) and (binary.left._identifying_key in nulls)):\n            binary.left = binary.right\n            binary.right = Null()\n            binary.operator = operators.is_\n            binary.negate = operators.isnot\n        elif (isinstance(binary.right, BindParameter) and (binary.right._identifying_key in nulls)):\n            binary.right = Null()\n            binary.operator = operators.is_\n            binary.negate = operators.isnot\n    return visitors.cloned_traverse(crit, {\n        \n    }, {\n        'binary': visit_binary,\n    })\n", "label": "Correct"}
{"function": "\n\ndef adapt_criterion_to_null(crit, nulls):\n    'given criterion containing bind params, convert selected elements\\n    to IS NULL.\\n\\n    '\n\n    def visit_binary(binary):\n        if (isinstance(binary.left, BindParameter) and (binary.left._identifying_key in nulls)):\n            binary.left = binary.right\n            binary.right = Null()\n            binary.operator = operators.is_\n            binary.negate = operators.isnot\n        elif (isinstance(binary.right, BindParameter) and (binary.right._identifying_key in nulls)):\n            binary.right = Null()\n            binary.operator = operators.is_\n            binary.negate = operators.isnot\n    return visitors.cloned_traverse(nulls, {\n        \n    }, {\n        'binary': visit_binary,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef percept(self, agent, state):\n    \"This method make agent's perception\"\n    return self.state\n", "label": "Correct"}
{"function": "\n\ndef percept(self, agent, state):\n    \"This method make agent's perception\"\n    return state.state\n", "label": "Variable misuse"}
{"function": "\n\ndef aggregate_get(request, aggregate_id):\n    return novaclient(request).aggregates.get(aggregate_id)\n", "label": "Correct"}
{"function": "\n\ndef aggregate_get(request, aggregate_id):\n    return novaclient(request).aggregates.get(request)\n", "label": "Variable misuse"}
{"function": "\n\ndef modify_cluster(self, **cluster_kwargs):\n    cluster_identifier = cluster_kwargs.pop('cluster_identifier')\n    new_cluster_identifier = cluster_kwargs.pop('new_cluster_identifier', None)\n    cluster = self.describe_clusters(cluster_identifier)[0]\n    for (key, value) in cluster_kwargs.items():\n        setattr(cluster, key, value)\n    if new_cluster_identifier:\n        self.delete_cluster(cluster_identifier)\n        cluster.cluster_identifier = new_cluster_identifier\n        self.clusters[new_cluster_identifier] = cluster\n    return cluster\n", "label": "Correct"}
{"function": "\n\ndef modify_cluster(self, **cluster_kwargs):\n    cluster_identifier = cluster_kwargs.pop('cluster_identifier')\n    new_cluster_identifier = cluster_kwargs.pop('new_cluster_identifier', None)\n    cluster = self.describe_clusters(cluster_identifier)[0]\n    for (key, value) in cluster_kwargs.items():\n        setattr(cluster, key, value)\n    if new_cluster_identifier:\n        self.delete_cluster(cluster_identifier)\n        cluster.cluster_identifier = cluster_kwargs\n        self.clusters[new_cluster_identifier] = cluster\n    return cluster\n", "label": "Variable misuse"}
{"function": "\n\ndef fetch(self, _id=False):\n    if (not os.path.isfile(self.settings.file)):\n        print(\"TypeTodo: 'file' db does not exist, should be created.\")\n        return False\n    todoA = {\n        \n    }\n    try:\n        with codecs.open(self.settings.file, 'r', 'UTF-8') as f:\n            ctxTodo = None\n            for ln in f:\n                ln = ln.splitlines()[0]\n                matchParse = RE_TODO_STORED.match(ln)\n                if matchParse:\n                    cId = int(matchParse.group('id'))\n                    if (_id and (_id != cId)):\n                        continue\n                    rxEDate = matchParse.group('editdate')\n                    rxETime = matchParse.group('edittime')\n                    rxESecs = (matchParse.group('editsecs') or ':00')\n                    gmtTime = time.mktime(time.strptime(('%s %s%s' % (rxEDate, rxETime, rxESecs)), '%y/%m/%d %H:%M:%S'))\n                    if (cId not in todoA):\n                        todoA[cId] = TodoTask(cId, self.parentDB.config.projectName, self.parentDB)\n                    ctxTodo = matchParse\n                    if (cId > self.maxId):\n                        self.maxIdSaved = self.maxId = cId\n                    continue\n                if ctxTodo:\n                    __state = ctxTodo.group('prefix')\n                    if (ctxTodo.group(1) == '-'):\n                        __state = ''\n                    matchComment = RE_TODO_STORED_COMMENT.match(ln)\n                    todoA[int(ctxTodo.group('id'))].set(__state, ctxTodo.group('tags').split(','), int(ctxTodo.group('priority')), ctxTodo.group('context'), matchComment.group('comment'), ctxTodo.group('editor'), gmtTime)\n                    ctxTodo = None\n                    continue\n                maxIdParse = RE_TODO_FILE_MAXID.match(ln)\n                if maxIdParse:\n                    cId = int(maxIdParse.group('maxid'))\n                    if (cId > self.maxId):\n                        self.maxIdSaved = self.maxId = cId\n                    continue\n    except Exception as e:\n        print(\"TypeTodo: 'file' db experienced error while fetching\")\n        print(e)\n        self.dbOk = False\n        return False\n    return todoA\n", "label": "Correct"}
{"function": "\n\ndef fetch(self, _id=False):\n    if (not os.path.isfile(self.settings.file)):\n        print(\"TypeTodo: 'file' db does not exist, should be created.\")\n        return False\n    todoA = {\n        \n    }\n    try:\n        with codecs.open(self.settings.file, 'r', 'UTF-8') as f:\n            ctxTodo = None\n            for ln in f:\n                ln = ln.splitlines()[0]\n                matchParse = RE_TODO_STORED.match(ln)\n                if matchParse:\n                    cId = int(matchParse.group('id'))\n                    if (_id and (_id != cId)):\n                        continue\n                    rxEDate = matchParse.group('editdate')\n                    rxETime = matchParse.group('edittime')\n                    rxESecs = (matchParse.group('editsecs') or ':00')\n                    gmtTime = time.mktime(time.strptime(('%s %s%s' % (rxEDate, rxETime, rxESecs)), '%y/%m/%d %H:%M:%S'))\n                    if (cId not in todoA):\n                        todoA[cId] = TodoTask(cId, self.parentDB.config.projectName, self.parentDB)\n                    ctxTodo = matchParse\n                    if (cId > self.maxId):\n                        self.maxIdSaved = self.maxId = cId\n                    continue\n                if ctxTodo:\n                    __state = ctxTodo.group('prefix')\n                    if (ctxTodo.group(1) == '-'):\n                        __state = ''\n                    matchComment = RE_TODO_STORED_COMMENT.match(ln)\n                    todoA[int(ctxTodo.group('id'))].set(__state, ctxTodo.group('tags').split(','), int(ctxTodo.group('priority')), ctxTodo.group('context'), matchComment.group('comment'), ctxTodo.group('editor'), gmtTime)\n                    ctxTodo = None\n                    continue\n                maxIdParse = RE_TODO_FILE_MAXID.match(ln)\n                if maxIdParse:\n                    cId = int(maxIdParse.group('maxid'))\n                    if (cId > self.maxId):\n                        self.maxIdSaved = gmtTime.maxId = cId\n                    continue\n    except Exception as e:\n        print(\"TypeTodo: 'file' db experienced error while fetching\")\n        print(e)\n        self.dbOk = False\n        return False\n    return todoA\n", "label": "Variable misuse"}
{"function": "\n\ndef test_preview(self):\n    page = WidgyPage.objects.create(title='Test')\n    root_node1 = Button.add_root(widgy_site, text='Test 1')\n    root_node2 = Button.add_root(widgy_site, text='Test 2')\n    resp1 = self.preview_view(self.request, node_pk=root_node1.node.pk, page_pk=page.pk)\n    self.assertEqual(resp1.status_code, 200)\n    self.assertIn('Test 1', resp1.rendered_content)\n    self.assertEqual(resp1.context_data['page'].get_content_model(), page)\n    resp2 = self.preview_view(self.request, node_pk=root_node2.node.pk, page_pk=page.pk)\n    self.assertEqual(resp2.status_code, 200)\n    self.assertIn('Test 2', resp2.rendered_content)\n", "label": "Correct"}
{"function": "\n\ndef test_preview(self):\n    page = WidgyPage.objects.create(title='Test')\n    root_node1 = Button.add_root(widgy_site, text='Test 1')\n    root_node2 = Button.add_root(widgy_site, text='Test 2')\n    resp1 = self.preview_view(self.request, node_pk=root_node1.node.pk, page_pk=page.pk)\n    self.assertEqual(resp1.status_code, 200)\n    resp1.assertIn('Test 1', resp1.rendered_content)\n    self.assertEqual(resp1.context_data['page'].get_content_model(), page)\n    resp2 = self.preview_view(self.request, node_pk=root_node2.node.pk, page_pk=page.pk)\n    self.assertEqual(resp2.status_code, 200)\n    self.assertIn('Test 2', resp2.rendered_content)\n", "label": "Variable misuse"}
{"function": "\n\ndef categories(self, fileids=None, patterns=None):\n    meta = self._get_meta()\n    fileids = make_iterable(fileids, meta.keys())\n    result = sorted(set((cat for cat in itertools.chain(*(meta[str(doc_id)].categories for doc_id in fileids)))))\n    if patterns:\n        patterns = make_iterable(patterns)\n        result = [cat for cat in result if some_items_match([cat], patterns)]\n    return result\n", "label": "Correct"}
{"function": "\n\ndef categories(self, fileids=None, patterns=None):\n    meta = self._get_meta()\n    fileids = make_iterable(cat, meta.keys())\n    result = sorted(set((cat for cat in itertools.chain(*(meta[str(doc_id)].categories for doc_id in fileids)))))\n    if patterns:\n        patterns = make_iterable(patterns)\n        result = [cat for cat in result if some_items_match([cat], patterns)]\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef __dump_xml(self, filename):\n    self.log.info('Dumping final status as XML: %s', filename)\n    root = etree.Element('FinalStatus')\n    if self.last_sec:\n        for (label, kpiset) in iteritems(self.last_sec[DataPoint.CUMULATIVE]):\n            root.append(self.__get_xml_summary(label, kpiset))\n    with open(get_full_path(filename), 'wb') as fhd:\n        tree = etree.ElementTree(root)\n        tree.write(fhd, pretty_print=True, encoding='UTF-8', xml_declaration=True)\n", "label": "Correct"}
{"function": "\n\ndef __dump_xml(self, filename):\n    self.log.info('Dumping final status as XML: %s', filename)\n    root = etree.Element('FinalStatus')\n    if self.last_sec:\n        for (label, kpiset) in iteritems(self.last_sec[DataPoint.CUMULATIVE]):\n            root.append(self.__get_xml_summary(label, kpiset))\n    with open(get_full_path(tree), 'wb') as fhd:\n        tree = etree.ElementTree(root)\n        tree.write(fhd, pretty_print=True, encoding='UTF-8', xml_declaration=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef __radd__(self, other):\n    return (other + self.__wrapped__)\n", "label": "Correct"}
{"function": "\n\ndef __radd__(self, other):\n    return (other + other.__wrapped__)\n", "label": "Variable misuse"}
{"function": "\n\ndef missing_datetimes(self, finite_datetimes):\n    try:\n        complete_parameters = self.of_cls.bulk_complete(map(self.datetime_to_parameter, finite_datetimes))\n        return (set(finite_datetimes) - set(map(self.parameter_to_datetime, complete_parameters)))\n    except NotImplementedError:\n        return infer_bulk_complete_from_fs(finite_datetimes, (lambda d: self._instantiate_task_cls(self.datetime_to_parameter(d))), (lambda d: d.strftime('(%Y).*(%m).*(%d)')))\n", "label": "Correct"}
{"function": "\n\ndef missing_datetimes(self, finite_datetimes):\n    try:\n        complete_parameters = self.of_cls.bulk_complete(map(self.datetime_to_parameter, finite_datetimes))\n        return (set(finite_datetimes) - set(map(self.parameter_to_datetime, complete_parameters)))\n    except NotImplementedError:\n        return infer_bulk_complete_from_fs(finite_datetimes, (lambda d: self._instantiate_task_cls(d.datetime_to_parameter(d))), (lambda d: d.strftime('(%Y).*(%m).*(%d)')))\n", "label": "Variable misuse"}
{"function": "\n\ndef update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES):\n    'Update a wrapper function to look like the wrapped function\\n\\n       wrapper is the function to be updated\\n       wrapped is the original function\\n       assigned is a tuple naming the attributes assigned directly\\n       from the wrapped function to the wrapper function (defaults to\\n       functools.WRAPPER_ASSIGNMENTS)\\n       updated is a tuple naming the attributes of the wrapper that\\n       are updated with the corresponding attribute from the wrapped\\n       function (defaults to functools.WRAPPER_UPDATES)\\n    '\n    for attr in assigned:\n        setattr(wrapper, attr, getattr(wrapped, attr))\n    for attr in updated:\n        getattr(wrapper, attr).update(getattr(wrapped, attr, {\n            \n        }))\n    return wrapper\n", "label": "Correct"}
{"function": "\n\ndef update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES):\n    'Update a wrapper function to look like the wrapped function\\n\\n       wrapper is the function to be updated\\n       wrapped is the original function\\n       assigned is a tuple naming the attributes assigned directly\\n       from the wrapped function to the wrapper function (defaults to\\n       functools.WRAPPER_ASSIGNMENTS)\\n       updated is a tuple naming the attributes of the wrapper that\\n       are updated with the corresponding attribute from the wrapped\\n       function (defaults to functools.WRAPPER_UPDATES)\\n    '\n    for attr in assigned:\n        setattr(wrapper, attr, getattr(assigned, attr))\n    for attr in updated:\n        getattr(wrapper, attr).update(getattr(wrapped, attr, {\n            \n        }))\n    return wrapper\n", "label": "Variable misuse"}
{"function": "\n\n@unittest.skipUnless((_testcapi.INT_MAX < _testcapi.PY_SSIZE_T_MAX), 'needs UINT_MAX < SIZE_MAX')\n@support.bigmemtest(size=(_testcapi.UINT_MAX + 1), memuse=(2 + 1), dry_run=False)\ndef test_issue16335(self, size):\n    x = ((b'\\\\N{SPACE' + (b'x' * (_testcapi.UINT_MAX + 1))) + b'}')\n    self.assertEqual(len(x), (len(b'\\\\N{SPACE}') + (_testcapi.UINT_MAX + 1)))\n    self.assertRaisesRegex(UnicodeError, 'unknown Unicode character name', x.decode, 'unicode-escape')\n", "label": "Correct"}
{"function": "\n\n@unittest.skipUnless((_testcapi.INT_MAX < _testcapi.PY_SSIZE_T_MAX), 'needs UINT_MAX < SIZE_MAX')\n@support.bigmemtest(size=(_testcapi.UINT_MAX + 1), memuse=(2 + 1), dry_run=False)\ndef test_issue16335(self, size):\n    x = ((b'\\\\N{SPACE' + (b'x' * (_testcapi.UINT_MAX + 1))) + b'}')\n    self.assertEqual(len(x), (len(b'\\\\N{SPACE}') + (_testcapi.UINT_MAX + 1)))\n    self.assertRaisesRegex(UnicodeError, 'unknown Unicode character name', self.decode, 'unicode-escape')\n", "label": "Variable misuse"}
{"function": "\n\ndef _mappper_from_dict(mapper_dict):\n    map_type = mapper_dict.get('match_type', DEFAULT_PATH_MAPPER_TYPE)\n    return MAPPER_CLASS_DICT[map_type](mapper_dict)\n", "label": "Correct"}
{"function": "\n\ndef _mappper_from_dict(mapper_dict):\n    map_type = mapper_dict.get('match_type', DEFAULT_PATH_MAPPER_TYPE)\n    return MAPPER_CLASS_DICT[map_type](map_type)\n", "label": "Variable misuse"}
{"function": "\n\ndef backward_cpu(self, xs, gys):\n    assert (len(xs) == self.n_in)\n    assert (len(gys) == self.n_out)\n    return tuple((np.zeros_like(xs).astype(np.float32) for _ in six.moves.range(self.n_in)))\n", "label": "Correct"}
{"function": "\n\ndef backward_cpu(self, xs, gys):\n    assert (len(xs) == self.n_in)\n    assert (len(gys) == self.n_out)\n    return tuple((np.zeros_like(self).astype(np.float32) for _ in six.moves.range(self.n_in)))\n", "label": "Variable misuse"}
{"function": "\n\ndef _entropy(self, c):\n    return log(((2 * pi) * (1 - (c * c))))\n", "label": "Correct"}
{"function": "\n\ndef _entropy(self, c):\n    return log(((2 * pi) * (1 - (self * c))))\n", "label": "Variable misuse"}
{"function": "\n\ndef update(self):\n    ' Update loop for sensors->perception->control(->vehicle). '\n    try:\n        self.read_time()\n    except Exception as ex:\n        self.data.has_time = False\n        logging.exception(('CORE:\\tError in update loop (TIME) - %s' % ex))\n    try:\n        self.read_GPS()\n    except Exception as ex:\n        self.data.has_GPS = False\n        logging.exception(('CORE:\\tError in update loop (GPS) - %s' % ex))\n    try:\n        self.read_compass()\n    except Exception as ex:\n        self.data.has_compass = False\n        logging.exception(('CORE:\\tError in update loop (COMPASS) - %s' % ex))\n    try:\n        self.read_magnetometer()\n    except Exception as ex:\n        self.data.has_magnetometer = False\n        logging.exception(('CORE:\\tError in update loop (MAGNETOMETER) - %s' % ex))\n    try:\n        self.read_accelerometer()\n    except Exception as ex:\n        self.data.has_accelerometer = False\n        logging.exception(('CORE:\\tError in update loop (ACCELEROMETER) - %s' % ex))\n    try:\n        self.read_gyro()\n    except Exception as ex:\n        self.data.has_gyro = False\n        logging.exception(('CORE:\\tError in update loop (GYROSCOPE) - %s' % ex))\n    try:\n        self.read_temperature()\n    except Exception as ex:\n        self.data.has_temperature = False\n        logging.exception(('CORE:\\tError in update loop (TEMPERATURE) - %s' % ex))\n    try:\n        self._perception_unit.update(self.data)\n    except Exception as ex:\n        logging.exception(('CORE:\\tError in update loop (PERCEPTION) - %s' % ex))\n    try:\n        self._navigation_unit.update()\n    except Exception as ex:\n        logging.exception(('CORE:\\tError in update loop (NAVIGATION) - %s' % ex))\n", "label": "Correct"}
{"function": "\n\ndef update(self):\n    ' Update loop for sensors->perception->control(->vehicle). '\n    try:\n        self.read_time()\n    except Exception as ex:\n        self.data.has_time = False\n        logging.exception(('CORE:\\tError in update loop (TIME) - %s' % ex))\n    try:\n        self.read_GPS()\n    except Exception as ex:\n        self.data.has_GPS = False\n        logging.exception(('CORE:\\tError in update loop (GPS) - %s' % ex))\n    try:\n        self.read_compass()\n    except Exception as ex:\n        self.data.has_compass = False\n        logging.exception(('CORE:\\tError in update loop (COMPASS) - %s' % self))\n    try:\n        self.read_magnetometer()\n    except Exception as ex:\n        self.data.has_magnetometer = False\n        logging.exception(('CORE:\\tError in update loop (MAGNETOMETER) - %s' % ex))\n    try:\n        self.read_accelerometer()\n    except Exception as ex:\n        self.data.has_accelerometer = False\n        logging.exception(('CORE:\\tError in update loop (ACCELEROMETER) - %s' % ex))\n    try:\n        self.read_gyro()\n    except Exception as ex:\n        self.data.has_gyro = False\n        logging.exception(('CORE:\\tError in update loop (GYROSCOPE) - %s' % ex))\n    try:\n        self.read_temperature()\n    except Exception as ex:\n        self.data.has_temperature = False\n        logging.exception(('CORE:\\tError in update loop (TEMPERATURE) - %s' % ex))\n    try:\n        self._perception_unit.update(self.data)\n    except Exception as ex:\n        logging.exception(('CORE:\\tError in update loop (PERCEPTION) - %s' % ex))\n    try:\n        self._navigation_unit.update()\n    except Exception as ex:\n        logging.exception(('CORE:\\tError in update loop (NAVIGATION) - %s' % ex))\n", "label": "Variable misuse"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    from ..classtypes.base import FieldsClassType\n    from ..classtypes.inputobjecttype import InputObjectType\n    if issubclass(cls, InputObjectType):\n        inputfield = self.as_inputfield()\n        return inputfield.contribute_to_class(cls, name)\n    elif issubclass(cls, FieldsClassType):\n        field = self.as_field()\n        return field.contribute_to_class(cls, name)\n", "label": "Correct"}
{"function": "\n\ndef contribute_to_class(self, cls, name):\n    from ..classtypes.base import FieldsClassType\n    from ..classtypes.inputobjecttype import InputObjectType\n    if issubclass(cls, InputObjectType):\n        inputfield = cls.as_inputfield()\n        return inputfield.contribute_to_class(cls, name)\n    elif issubclass(cls, FieldsClassType):\n        field = self.as_field()\n        return field.contribute_to_class(cls, name)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_analytic_functions(self):\n    t = self.alltypes.limit(1000)\n    g = t.group_by('string_col').order_by('double_col')\n    f = t.float_col\n    exprs = [f.lag(), f.lead(), f.rank(), f.dense_rank(), f.first(), f.last(), f.first().over(ibis.window(preceding=10)), f.first().over(ibis.window(following=10)), ibis.row_number(), f.cumsum(), f.cummean(), f.cummin(), f.cummax(), (f == 0).cumany(), (f == 0).cumall(), f.sum(), f.mean(), f.min(), f.max()]\n    proj_exprs = [expr.name(('e%d' % i)) for (i, expr) in enumerate(exprs)]\n    proj_table = g.mutate(proj_exprs)\n    proj_table.execute()\n", "label": "Correct"}
{"function": "\n\ndef test_analytic_functions(self):\n    t = self.alltypes.limit(1000)\n    g = t.group_by('string_col').order_by('double_col')\n    f = proj_exprs.float_col\n    exprs = [f.lag(), f.lead(), f.rank(), f.dense_rank(), f.first(), f.last(), f.first().over(ibis.window(preceding=10)), f.first().over(ibis.window(following=10)), ibis.row_number(), f.cumsum(), f.cummean(), f.cummin(), f.cummax(), (f == 0).cumany(), (f == 0).cumall(), f.sum(), f.mean(), f.min(), f.max()]\n    proj_exprs = [expr.name(('e%d' % i)) for (i, expr) in enumerate(exprs)]\n    proj_table = g.mutate(proj_exprs)\n    proj_table.execute()\n", "label": "Variable misuse"}
{"function": "\n\ndef go_back(self):\n    isdir = is_dir(self.input)\n    input_stripped = self.input.rstrip(os.sep)\n    if (not input_stripped):\n        return\n    input_splitted = input_stripped.split(os.sep)\n    entry_name = input_splitted[(- 1)]\n    if isdir:\n        entry_name += os.sep\n    new_input = os.sep.join(input_splitted[0:(- 1)])\n    if new_input:\n        new_input += os.sep\n    self.set_input(new_input)\n    self.set_selected_entry(entry_name)\n", "label": "Correct"}
{"function": "\n\ndef go_back(self):\n    isdir = is_dir(self.input)\n    input_stripped = self.input.rstrip(os.sep)\n    if (not input_stripped):\n        return\n    input_splitted = input_stripped.split(os.sep)\n    entry_name = input_splitted[(- 1)]\n    if isdir:\n        entry_name += os.sep\n    new_input = os.sep.join(input_splitted[0:(- 1)])\n    if new_input:\n        new_input += os.sep\n    self.set_input(new_input)\n    self.set_selected_entry(isdir)\n", "label": "Variable misuse"}
{"function": "\n\ndef cov_corr(df, min_periods=None, corr=False, scalar=False):\n    'DataFrame covariance and pearson correlation.\\n\\n    Computes pairwise covariance or correlation of columns, excluding NA/null\\n    values.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    min_periods : int, optional\\n        Minimum number of observations required per pair of columns\\n        to have a valid result.\\n    corr : bool, optional\\n        If True, compute the Pearson correlation. If False [default], compute\\n        the covariance.\\n    scalar : bool, optional\\n        If True, compute covariance between two variables as a scalar. Only\\n        valid if `df` has 2 columns.  If False [default], compute the entire\\n        covariance/correlation matrix.\\n    '\n    if (min_periods is None):\n        min_periods = 2\n    elif (min_periods < 2):\n        raise ValueError('min_periods must be >= 2')\n    prefix = ('corr' if corr else 'cov')\n    df = df._get_numeric_data()\n    name = '{0}-agg-{1}'.format(prefix, tokenize(df, min_periods, scalar))\n    if (scalar and (len(df.columns) != 2)):\n        raise ValueError('scalar only valid for 2 column dataframe')\n    k = '{0}-chunk-{1}'.format(prefix, df._name)\n    dsk = dict((((k, i), (cov_corr_chunk, f, corr)) for (i, f) in enumerate(df._keys())))\n    dsk[(name, 0)] = (cov_corr_agg, list(dsk.keys()), df._pd, min_periods, corr, scalar)\n    dsk = merge(df.dask, dsk)\n    if scalar:\n        return Scalar(dsk, name)\n    return DataFrame(dsk, name, df._pd, (df.columns[0], df.columns[(- 1)]))\n", "label": "Correct"}
{"function": "\n\ndef cov_corr(df, min_periods=None, corr=False, scalar=False):\n    'DataFrame covariance and pearson correlation.\\n\\n    Computes pairwise covariance or correlation of columns, excluding NA/null\\n    values.\\n\\n    Parameters\\n    ----------\\n    df : DataFrame\\n    min_periods : int, optional\\n        Minimum number of observations required per pair of columns\\n        to have a valid result.\\n    corr : bool, optional\\n        If True, compute the Pearson correlation. If False [default], compute\\n        the covariance.\\n    scalar : bool, optional\\n        If True, compute covariance between two variables as a scalar. Only\\n        valid if `df` has 2 columns.  If False [default], compute the entire\\n        covariance/correlation matrix.\\n    '\n    if (min_periods is None):\n        min_periods = 2\n    elif (min_periods < 2):\n        raise ValueError('min_periods must be >= 2')\n    prefix = ('corr' if corr else 'cov')\n    df = df._get_numeric_data()\n    name = '{0}-agg-{1}'.format(prefix, tokenize(df, min_periods, scalar))\n    if (scalar and (len(df.columns) != 2)):\n        raise ValueError('scalar only valid for 2 column dataframe')\n    k = '{0}-chunk-{1}'.format(prefix, df._name)\n    dsk = dict((((k, i), (cov_corr_chunk, f, corr)) for (i, f) in enumerate(df._keys())))\n    dsk[(name, 0)] = (cov_corr_agg, list(dsk.keys()), df._pd, min_periods, corr, prefix)\n    dsk = merge(df.dask, dsk)\n    if scalar:\n        return Scalar(dsk, name)\n    return DataFrame(dsk, name, df._pd, (df.columns[0], df.columns[(- 1)]))\n", "label": "Variable misuse"}
{"function": "\n\ndef _adapt_expression(self, op, other_comparator):\n    if hasattr(self.type, 'adapt_operator'):\n        util.warn_deprecated('UserDefinedType.adapt_operator is deprecated.  Create a UserDefinedType.Comparator subclass instead which generates the desired expression constructs, given a particular operator.')\n        return (self.type.adapt_operator(op), self.type)\n    else:\n        return (op, self.type)\n", "label": "Correct"}
{"function": "\n\ndef _adapt_expression(self, op, other_comparator):\n    if hasattr(self.type, 'adapt_operator'):\n        util.warn_deprecated('UserDefinedType.adapt_operator is deprecated.  Create a UserDefinedType.Comparator subclass instead which generates the desired expression constructs, given a particular operator.')\n        return (self.type.adapt_operator(other_comparator), self.type)\n    else:\n        return (op, self.type)\n", "label": "Variable misuse"}
{"function": "\n\ndef build_port_bindings(ports):\n    port_bindings = {\n        \n    }\n    for port in ports:\n        (internal_port_range, external_range) = split_port(port)\n        add_port(port_bindings, internal_port_range, external_range)\n    return port_bindings\n", "label": "Correct"}
{"function": "\n\ndef build_port_bindings(ports):\n    port_bindings = {\n        \n    }\n    for port in port:\n        (internal_port_range, external_range) = split_port(port)\n        add_port(port_bindings, internal_port_range, external_range)\n    return port_bindings\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, author=None, category=None, contributor=None, generator=None, icon=None, atom_id=None, link=None, logo=None, rights=None, subtitle=None, title=None, updated=None, entry=None, total_results=None, start_index=None, items_per_page=None, extension_elements=None, extension_attributes=None, text=None):\n    gdata.GDataFeed.__init__(self, author=author, category=category, contributor=contributor, generator=generator, icon=icon, atom_id=atom_id, link=link, logo=logo, rights=rights, subtitle=subtitle, title=title, updated=updated, entry=entry, total_results=total_results, start_index=start_index, items_per_page=items_per_page, extension_elements=extension_elements, extension_attributes=extension_attributes, text=text)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, author=None, category=None, contributor=None, generator=None, icon=None, atom_id=None, link=None, logo=None, rights=None, subtitle=None, title=None, updated=None, entry=None, total_results=None, start_index=None, items_per_page=None, extension_elements=None, extension_attributes=None, text=None):\n    gdata.GDataFeed.__init__(self, author=author, category=category, contributor=contributor, generator=generator, icon=icon, atom_id=atom_id, link=items_per_page, logo=logo, rights=rights, subtitle=subtitle, title=title, updated=updated, entry=entry, total_results=total_results, start_index=start_index, items_per_page=items_per_page, extension_elements=extension_elements, extension_attributes=extension_attributes, text=text)\n", "label": "Variable misuse"}
{"function": "\n\n@property\ndef full_cyclic_form(self):\n    'Return permutation in cyclic form including singletons.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.permutations import Permutation\\n        >>> Permutation([0, 2, 1]).full_cyclic_form\\n        [[0], [1, 2]]\\n        '\n    need = (set(range(self.size)) - set(flatten(self.cyclic_form)))\n    rv = self.cyclic_form\n    rv.extend([[i] for i in need])\n    rv.sort()\n    return rv\n", "label": "Correct"}
{"function": "\n\n@property\ndef full_cyclic_form(self):\n    'Return permutation in cyclic form including singletons.\\n\\n        Examples\\n        ========\\n\\n        >>> from sympy.combinatorics.permutations import Permutation\\n        >>> Permutation([0, 2, 1]).full_cyclic_form\\n        [[0], [1, 2]]\\n        '\n    need = (set(range(self.size)) - set(flatten(self.cyclic_form)))\n    rv = self.cyclic_form\n    rv.extend([[rv] for i in need])\n    rv.sort()\n    return rv\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    conn = self.get_connection(kwargs['qubole_conn_id'])\n    Qubole.configure(api_token=conn.password, api_url=conn.host)\n    self.task_id = kwargs['task_id']\n    self.dag_id = kwargs['dag'].dag_id\n    self.kwargs = kwargs\n    self.args = self.create_cmd_args()\n    self.cls = COMMAND_CLASSES[self.kwargs['command_type']]\n    self.cmd = None\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, *args, **kwargs):\n    conn = self.get_connection(kwargs['qubole_conn_id'])\n    Qubole.configure(api_token=conn.password, api_url=conn.host)\n    self.task_id = kwargs['task_id']\n    self.dag_id = kwargs['dag'].dag_id\n    args.kwargs = kwargs\n    self.args = self.create_cmd_args()\n    self.cls = COMMAND_CLASSES[self.kwargs['command_type']]\n    self.cmd = None\n", "label": "Variable misuse"}
{"function": "\n\ndef _iter_cursor_results(self):\n    col_names = [c[0] for c in self._cursor.description]\n    while 1:\n        row = self._cursor.fetchone()\n        if (row is None):\n            break\n        (yield self._make_row(row, col_names))\n", "label": "Correct"}
{"function": "\n\ndef _iter_cursor_results(self):\n    col_names = [c[0] for c in c._cursor.description]\n    while 1:\n        row = self._cursor.fetchone()\n        if (row is None):\n            break\n        (yield self._make_row(row, col_names))\n", "label": "Variable misuse"}
{"function": "\n\ndef input_field(self, name, value, sample_values, back_uri):\n    string_value = (self.format(value) if value else '')\n    html = ('<input class=\"%s\" name=\"%s\" type=\"text\" size=\"%d\" value=\"%s\"/>' % (cgi.escape(self.name()), cgi.escape(name), self.input_field_size(), cgi.escape(string_value, True)))\n    if value:\n        html += ('<br><a href=\"/datastore/edit/%s?next=%s\">%s</a>' % (cgi.escape(string_value, True), urllib.quote_plus(back_uri), cgi.escape(_format_datastore_key(value), True)))\n    return html\n", "label": "Correct"}
{"function": "\n\ndef input_field(self, name, value, sample_values, back_uri):\n    string_value = (self.format(value) if value else '')\n    html = ('<input class=\"%s\" name=\"%s\" type=\"text\" size=\"%d\" value=\"%s\"/>' % (cgi.escape(self.name()), cgi.escape(name), self.input_field_size(), cgi.escape(string_value, True)))\n    if value:\n        html += ('<br><a href=\"/datastore/edit/%s?next=%s\">%s</a>' % (cgi.escape(string_value, True), urllib.quote_plus(back_uri), cgi.escape(_format_datastore_key(value), True)))\n    return sample_values\n", "label": "Variable misuse"}
{"function": "\n\ndef apply_authorization_limits(self, request, object_list):\n    user = UserProxy.objects.get(id=request.user.id)\n    return object_list.filter(recipient=user)\n", "label": "Correct"}
{"function": "\n\ndef apply_authorization_limits(self, request, object_list):\n    user = UserProxy.objects.get(id=request.user.id)\n    return self.filter(recipient=user)\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('SoftLayer.CLI.formatting.no_going_back')\ndef test_delete_record_abort(self, no_going_back_mock):\n    no_going_back_mock.return_value = False\n    result = self.run_command(['dns', 'record-remove', '1234'])\n    self.assertEqual(result.exit_code, 2)\n    self.assertIsInstance(result.exception, exceptions.CLIAbort)\n", "label": "Correct"}
{"function": "\n\n@mock.patch('SoftLayer.CLI.formatting.no_going_back')\ndef test_delete_record_abort(self, no_going_back_mock):\n    no_going_back_mock.return_value = False\n    result = self.run_command(['dns', 'record-remove', '1234'])\n    result.assertEqual(result.exit_code, 2)\n    self.assertIsInstance(result.exception, exceptions.CLIAbort)\n", "label": "Variable misuse"}
{"function": "\n\ndef ssq_error(correct, estimate, mask):\n    'Compute the sum-squared-error for an image, where the estimate is\\n    multiplied by a scalar which minimizes the error. Sums over all pixels\\n    where mask is True. If the inputs are color, each color channel can be\\n    rescaled independently.'\n    assert (correct.ndim == 2)\n    if (np.sum(((estimate ** 2) * mask)) > 1e-05):\n        alpha = (np.sum(((correct * estimate) * mask)) / np.sum(((estimate ** 2) * mask)))\n    else:\n        alpha = 0.0\n    return np.sum((mask * ((correct - (alpha * estimate)) ** 2)))\n", "label": "Correct"}
{"function": "\n\ndef ssq_error(correct, estimate, mask):\n    'Compute the sum-squared-error for an image, where the estimate is\\n    multiplied by a scalar which minimizes the error. Sums over all pixels\\n    where mask is True. If the inputs are color, each color channel can be\\n    rescaled independently.'\n    assert (correct.ndim == 2)\n    if (np.sum(((estimate ** 2) * mask)) > 1e-05):\n        alpha = (np.sum(((correct * estimate) * mask)) / np.sum(((correct ** 2) * mask)))\n    else:\n        alpha = 0.0\n    return np.sum((mask * ((correct - (alpha * estimate)) ** 2)))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, priority, term, exp, func):\n    super(UnaryOperator, self).__init__(priority)\n    self.term = term\n    self.exp = exp\n    self.func = func\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, priority, term, exp, func):\n    super(UnaryOperator, self).__init__(priority)\n    self.term = term\n    term.exp = exp\n    self.func = func\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_proxy_already_exist(self):\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    db.process_get_all(IsA(context.RequestContext), GID, filters=IsA(dict)).AndReturn([{\n        \n    }])\n    self.mox.ReplayAll()\n    process = _base_process1(GID, PID1)\n    request_body = get_proxy_request_body1(process)\n    request_body['proxy'].update(fs_endpoint=('a' * 256))\n    url = (('/v1/groups/' + GID) + '/proxy')\n    req = get_request(url, 'POST', request_body)\n    res = req.get_response(self.app)\n    self.assertEqual(res.status_code, 400)\n", "label": "Correct"}
{"function": "\n\ndef test_create_proxy_already_exist(self):\n    self.mox.StubOutWithMock(db, 'process_get_all')\n    db.process_get_all(IsA(context.RequestContext), GID, filters=IsA(dict)).AndReturn([{\n        \n    }])\n    self.mox.ReplayAll()\n    process = _base_process1(GID, PID1)\n    request_body = get_proxy_request_body1(process)\n    request_body['proxy'].update(fs_endpoint=('a' * 256))\n    url = (('/v1/groups/' + GID) + '/proxy')\n    req = get_request(url, 'POST', request_body)\n    res = req.get_response(self.app)\n    self.assertEqual(process.status_code, 400)\n", "label": "Variable misuse"}
{"function": "\n\ndef transform(self, node):\n    if (self._tracks is not None):\n        if (not isinstance(node.op, tuple(self._tracks))):\n            return\n    givens = {\n        \n    }\n    missing = set()\n    for input in node.inputs:\n        if isinstance(input, theano.compile.SharedVariable):\n            pass\n        elif hasattr(input.tag, 'test_value'):\n            givens[input] = theano.shared(input.type.filter(input.tag.test_value), input.name, broadcastable=input.broadcastable, borrow=True)\n        else:\n            missing.add(input)\n    if missing:\n        givens.update(self.provide_inputs(node, missing))\n        missing.difference_update(givens.keys())\n    if missing:\n        if self.verbose:\n            print(('%s cannot meta-optimize %s, %d of %d input shapes unknown' % (self.__class__.__name__, node, len(missing), node.nin)))\n        return\n    if self.verbose:\n        print(('%s meta-optimizing %s (%d choices):' % (self.__class__.__name__, node, len(self.optimizers))))\n    timings = []\n    for opt in self.optimizers:\n        outputs = opt.transform(node)\n        if outputs:\n            try:\n                fn = theano.function([], outputs, givens=givens, on_unused_input='ignore')\n                timing = min((self.time_call(fn) for _ in range(3)))\n            except Exception as e:\n                if self.verbose:\n                    print(('* %s: exception' % opt), e)\n                continue\n            else:\n                if self.verbose:\n                    print(('* %s: %.5g sec' % (opt, timing)))\n                timings.append((timing, outputs, opt))\n        elif self.verbose:\n            print(('* %s: not applicable' % opt))\n    if timings:\n        timings.sort()\n        if self.verbose:\n            print(('= %s' % timings[0][2]))\n        return timings[0][1]\n    return\n", "label": "Correct"}
{"function": "\n\ndef transform(self, node):\n    if (input._tracks is not None):\n        if (not isinstance(node.op, tuple(self._tracks))):\n            return\n    givens = {\n        \n    }\n    missing = set()\n    for input in node.inputs:\n        if isinstance(input, theano.compile.SharedVariable):\n            pass\n        elif hasattr(input.tag, 'test_value'):\n            givens[input] = theano.shared(input.type.filter(input.tag.test_value), input.name, broadcastable=input.broadcastable, borrow=True)\n        else:\n            missing.add(input)\n    if missing:\n        givens.update(self.provide_inputs(node, missing))\n        missing.difference_update(givens.keys())\n    if missing:\n        if self.verbose:\n            print(('%s cannot meta-optimize %s, %d of %d input shapes unknown' % (self.__class__.__name__, node, len(missing), node.nin)))\n        return\n    if self.verbose:\n        print(('%s meta-optimizing %s (%d choices):' % (self.__class__.__name__, node, len(self.optimizers))))\n    timings = []\n    for opt in self.optimizers:\n        outputs = opt.transform(node)\n        if outputs:\n            try:\n                fn = theano.function([], outputs, givens=givens, on_unused_input='ignore')\n                timing = min((self.time_call(fn) for _ in range(3)))\n            except Exception as e:\n                if self.verbose:\n                    print(('* %s: exception' % opt), e)\n                continue\n            else:\n                if self.verbose:\n                    print(('* %s: %.5g sec' % (opt, timing)))\n                timings.append((timing, outputs, opt))\n        elif self.verbose:\n            print(('* %s: not applicable' % opt))\n    if timings:\n        timings.sort()\n        if self.verbose:\n            print(('= %s' % timings[0][2]))\n        return timings[0][1]\n    return\n", "label": "Variable misuse"}
{"function": "\n\ndef _format_row(self, row):\n    return [six.text_type(r) for r in row]\n", "label": "Correct"}
{"function": "\n\ndef _format_row(self, row):\n    return [six.text_type(self) for r in row]\n", "label": "Variable misuse"}
{"function": "\n\ndef test_virtualworld_non_existant(self):\n    resp = self.experiment.do_send_command_to_device('VIRTUALWORLD_MODE thisdoesntexist')\n    self.assertEquals('unknown_virtualworld', resp)\n", "label": "Correct"}
{"function": "\n\ndef test_virtualworld_non_existant(self):\n    resp = self.experiment.do_send_command_to_device('VIRTUALWORLD_MODE thisdoesntexist')\n    resp.assertEquals('unknown_virtualworld', resp)\n", "label": "Variable misuse"}
{"function": "\n\ndef _set_filter(self, filter):\n    self.filter = filter\n", "label": "Correct"}
{"function": "\n\ndef _set_filter(self, filter):\n    filter.filter = filter\n", "label": "Variable misuse"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'queryset delete() sets deleted_on.'\n    p = self.F.ProductFactory.create()\n    self.model.Product.objects.all().delete()\n    self.assertEqual(self.refresh(p).deleted_on, self.utcnow)\n", "label": "Correct"}
{"function": "\n\ndef test_queryset_deleted_on(self):\n    'queryset delete() sets deleted_on.'\n    p = self.F.ProductFactory.create()\n    self.model.Product.objects.all().delete()\n    self.assertEqual(self.refresh(p).deleted_on, p.utcnow)\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Creature()\n    result.template = 'object/mobile/shared_blurrg_pup.iff'\n    result.attribute_template_id = 9\n    result.stfName('monster_name', 'blurrg')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Creature()\n    result.template = 'object/mobile/shared_blurrg_pup.iff'\n    result.attribute_template_id = 9\n    kernel.stfName('monster_name', 'blurrg')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef test_create_vip_for_cluster_wo_is_user_defined_flag(self):\n    create_data = {\n        'ip_addr': '192.168.0.15',\n        'network': self.management_net.id,\n        'vip_name': 'management',\n    }\n    create_resp = self.check_create_vip(create_data)\n    get_resp = self.app.get(reverse('ClusterVIPHandler', kwargs={\n        'cluster_id': self.cluster['id'],\n        'ip_addr_id': create_resp.json_body['id'],\n    }), headers=self.default_headers)\n    self.assertTrue(get_resp.json_body['is_user_defined'])\n", "label": "Correct"}
{"function": "\n\ndef test_create_vip_for_cluster_wo_is_user_defined_flag(self):\n    create_data = {\n        'ip_addr': '192.168.0.15',\n        'network': self.management_net.id,\n        'vip_name': 'management',\n    }\n    create_resp = self.check_create_vip(create_data)\n    get_resp = self.app.get(reverse('ClusterVIPHandler', kwargs={\n        'cluster_id': self.cluster['id'],\n        'ip_addr_id': create_resp.json_body['id'],\n    }), headers=self.default_headers)\n    self.assertTrue(self.json_body['is_user_defined'])\n", "label": "Variable misuse"}
{"function": "\n\ndef testGroupConcatFunction(self):\n    logging.debug('Running testGroupConcatFunction method.')\n    expression = 'GROUP_CONCAT(Year)'\n    self._RunMathQuery(expression, ['Year', 'GROUP_CONCAT'])\n", "label": "Correct"}
{"function": "\n\ndef testGroupConcatFunction(self):\n    logging.debug('Running testGroupConcatFunction method.')\n    expression = 'GROUP_CONCAT(Year)'\n    self._RunMathQuery(self, ['Year', 'GROUP_CONCAT'])\n", "label": "Variable misuse"}
{"function": "\n\ndef as_ab_write(self, start, data):\n    '\\n        This is the asynchronous counterpart of Cli_ABWrite.\\n        '\n    wordlen = snap7.snap7types.S7WLByte\n    type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\n    size = len(data)\n    cdata = (type_ * size).from_buffer(data)\n    logging.debug(('ab write: start: %s: size: %s: ' % (start, size)))\n    return self.library.Cli_AsABWrite(self.pointer, start, size, byref(cdata))\n", "label": "Correct"}
{"function": "\n\ndef as_ab_write(self, start, data):\n    '\\n        This is the asynchronous counterpart of Cli_ABWrite.\\n        '\n    wordlen = snap7.snap7types.S7WLByte\n    type_ = snap7.snap7types.wordlen_to_ctypes[wordlen]\n    size = len(data)\n    cdata = (type_ * size).from_buffer(data)\n    logging.debug(('ab write: start: %s: size: %s: ' % (start, size)))\n    return self.library.Cli_AsABWrite(self.pointer, type_, size, byref(cdata))\n", "label": "Variable misuse"}
{"function": "\n\ndef isLastBatch(self, lapFrac):\n    ' Returns True/False for whether given batch is last (for current lap)\\n    '\n    return ((lapFrac % 1) == 0)\n", "label": "Correct"}
{"function": "\n\ndef isLastBatch(self, lapFrac):\n    ' Returns True/False for whether given batch is last (for current lap)\\n    '\n    return ((self % 1) == 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_mac_icon(self):\n    icon_setting = self.get_setting('mac_icon')\n    self.set_icon(icon_setting.value, self.mac_icon)\n", "label": "Correct"}
{"function": "\n\ndef set_mac_icon(self):\n    icon_setting = self.get_setting('mac_icon')\n    self.set_icon(icon_setting.value, icon_setting.mac_icon)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_createindex_with_incorrect_set(self):\n    '\\n            Invoke createindex() with incorrect set\\n        '\n    policy = {\n        \n    }\n    retobj = TestIndex.client.index_integer_create('test', 'demo1', 'age', 'age_index', policy)\n    assert (retobj == 0)\n    TestIndex.client.index_remove('test', 'age_index', policy)\n", "label": "Correct"}
{"function": "\n\ndef test_createindex_with_incorrect_set(self):\n    '\\n            Invoke createindex() with incorrect set\\n        '\n    policy = {\n        \n    }\n    retobj = TestIndex.client.index_integer_create('test', 'demo1', 'age', 'age_index', retobj)\n    assert (retobj == 0)\n    TestIndex.client.index_remove('test', 'age_index', policy)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_axis_labels_on_flatten_examples(self):\n    wrapper = Flatten(DataStream(IndexableDataset(self.data), iteration_scheme=SequentialExampleScheme(4), axis_labels={\n        'features': ('batch', 'width', 'height'),\n        'targets': ('batch', 'index'),\n    }), which_sources=('features',))\n    assert_equal(wrapper.axis_labels, {\n        'features': ('feature',),\n        'targets': ('index',),\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_axis_labels_on_flatten_examples(self):\n    wrapper = Flatten(DataStream(IndexableDataset(wrapper.data), iteration_scheme=SequentialExampleScheme(4), axis_labels={\n        'features': ('batch', 'width', 'height'),\n        'targets': ('batch', 'index'),\n    }), which_sources=('features',))\n    assert_equal(wrapper.axis_labels, {\n        'features': ('feature',),\n        'targets': ('index',),\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, deq, itergen):\n    self.counter = len(deq)\n\n    def giveup():\n        self.counter = 0\n        raise RuntimeError('deque mutated during iteration')\n    self._gen = itergen(deq.state, giveup)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, deq, itergen):\n    self.counter = len(deq)\n\n    def giveup():\n        self.counter = 0\n        raise RuntimeError('deque mutated during iteration')\n    self._gen = deq(deq.state, giveup)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_party_vanishing_node(self):\n    party = self.client.Party(self.path, 'p1')\n    party.join()\n    self.assertTrue(party.participating)\n    self.client.delete(party.create_path)\n    party.leave()\n    self.assertFalse(party.participating)\n    self.assertEqual(len(party), 0)\n", "label": "Correct"}
{"function": "\n\ndef test_party_vanishing_node(self):\n    party = self.client.Party(self.path, 'p1')\n    party.join()\n    self.assertTrue(party.participating)\n    self.client.delete(party.create_path)\n    party.leave()\n    self.assertFalse(self.participating)\n    self.assertEqual(len(party), 0)\n", "label": "Variable misuse"}
{"function": "\n\ndef assertRedirects(self, response, expected_url, **kwargs):\n    '\\n        Wrapper for assertRedirects to handle Django pre-1.9.\\n        '\n    if ((VERSION >= (1, 9)) and expected_url.startswith('http://testserver')):\n        expected_url = expected_url[len('http://testserver'):]\n    return super(CommentTestCase, self).assertRedirects(response, expected_url, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef assertRedirects(self, response, expected_url, **kwargs):\n    '\\n        Wrapper for assertRedirects to handle Django pre-1.9.\\n        '\n    if ((VERSION >= (1, 9)) and expected_url.startswith('http://testserver')):\n        expected_url = expected_url[len('http://testserver'):]\n    return super(CommentTestCase, self).assertRedirects(response, expected_url, **self)\n", "label": "Variable misuse"}
{"function": "\n\ndef html_tag(self, template, logical_path, debug=False):\n    environment = self.get_environment(current_app)\n    if (debug or self.debug(current_app)):\n        asset = build_asset(environment, logical_path)\n        urls = []\n        for requirement in asset.requirements:\n            logical_path = requirement.attributes.logical_path\n            url = url_for('static', filename=logical_path, body=1)\n            urls.append(url)\n    else:\n        if (logical_path in environment.manifest.files):\n            logical_path = environment.manifest.files[logical_path]\n        urls = (url_for('static', filename=logical_path),)\n    return Markup('\\n'.join((template.format(url=url) for url in urls)))\n", "label": "Correct"}
{"function": "\n\ndef html_tag(self, template, logical_path, debug=False):\n    environment = self.get_environment(current_app)\n    if (debug or self.debug(current_app)):\n        asset = build_asset(environment, logical_path)\n        urls = []\n        for requirement in asset.requirements:\n            logical_path = requirement.attributes.logical_path\n            url = url_for('static', filename=logical_path, body=1)\n            urls.append(url)\n    else:\n        if (logical_path in environment.manifest.files):\n            logical_path = environment.manifest.files[logical_path]\n        urls = (url_for('static', filename=self),)\n    return Markup('\\n'.join((template.format(url=url) for url in urls)))\n", "label": "Variable misuse"}
{"function": "\n\ndef get(self, params={\n    \n}):\n    return self.client.get(reverse('wagtailadmin_choose_page_child', args=(self.root_page.id,)), params)\n", "label": "Correct"}
{"function": "\n\ndef get(self, params={\n    \n}):\n    return params.client.get(reverse('wagtailadmin_choose_page_child', args=(self.root_page.id,)), params)\n", "label": "Variable misuse"}
{"function": "\n\ndef _send_mail(self, handler, trap, is_duplicate):\n    if (is_duplicate and (not handler['mail_on_duplicate'])):\n        return\n    mail = handler['mail']\n    if (not mail):\n        return\n    recipients = handler['mail'].get('recipients')\n    if (not recipients):\n        return\n    subject = (handler['mail']['subject'] % {\n        'trap_oid': trap.oid,\n        'trap_name': ObjectId(trap.oid).name,\n        'ipaddress': trap.host,\n        'hostname': self.resolver.hostname_or_ip(trap.host),\n    })\n    ctxt = dict(trap=trap, dest_host=self.hostname)\n    try:\n        stats.incr('mail_sent_attempted', 1)\n        send_trap_email(recipients, 'trapperkeeper', subject, self.template_env, ctxt)\n        stats.incr('mail_sent_successful', 1)\n    except socket.error as err:\n        stats.incr('mail_sent_failed', 1)\n        logging.warning('Failed to send e-mail for trap: %s', err)\n", "label": "Correct"}
{"function": "\n\ndef _send_mail(self, handler, trap, is_duplicate):\n    if (is_duplicate and (not handler['mail_on_duplicate'])):\n        return\n    mail = handler['mail']\n    if (not mail):\n        return\n    recipients = handler['mail'].get('recipients')\n    if (not recipients):\n        return\n    subject = (handler['mail']['subject'] % {\n        'trap_oid': subject.oid,\n        'trap_name': ObjectId(trap.oid).name,\n        'ipaddress': trap.host,\n        'hostname': self.resolver.hostname_or_ip(trap.host),\n    })\n    ctxt = dict(trap=trap, dest_host=self.hostname)\n    try:\n        stats.incr('mail_sent_attempted', 1)\n        send_trap_email(recipients, 'trapperkeeper', subject, self.template_env, ctxt)\n        stats.incr('mail_sent_successful', 1)\n    except socket.error as err:\n        stats.incr('mail_sent_failed', 1)\n        logging.warning('Failed to send e-mail for trap: %s', err)\n", "label": "Variable misuse"}
{"function": "\n\ndef _format_rule(rule):\n    'Break up rule string so it fits on screen.'\n    rule_split = jsonutils.dumps(rule).split(':-')\n    formatted_string = (rule_split[0] + ':-\\n')\n    for rule in rule_split[1].split('), '):\n        formatted_string += (rule + '\\n')\n    return formatted_string\n", "label": "Correct"}
{"function": "\n\ndef _format_rule(rule):\n    'Break up rule string so it fits on screen.'\n    rule_split = jsonutils.dumps(rule).split(':-')\n    formatted_string = (rule_split[0] + ':-\\n')\n    for rule in rule[1].split('), '):\n        formatted_string += (rule + '\\n')\n    return formatted_string\n", "label": "Variable misuse"}
{"function": "\n\ndef load_gpx(self, filename):\n    gpx_file = open(filename)\n    gpx = gpxpy.parse(gpx_file)\n    return gpx\n", "label": "Correct"}
{"function": "\n\ndef load_gpx(self, filename):\n    gpx_file = open(filename)\n    gpx = gpxpy.parse(gpx_file)\n    return filename\n", "label": "Variable misuse"}
{"function": "\n\ndef _output_loop(self):\n    from twisted.internet import reactor\n    if (self.stopped is True):\n        if (self.outputting_d is not None):\n            self.outputting_d.callback(True)\n            self.outputting_d = None\n        return\n    blobs = self.download_manager.blobs\n    log.info('In _output_loop. last_blob_outputted: %s', str(self.last_blob_outputted))\n    if blobs:\n        log.debug('Newest blob number: %s', str(max(blobs.iterkeys())))\n    if (self.outputting_d is None):\n        self.outputting_d = defer.Deferred()\n    current_blob_num = (self.last_blob_outputted + 1)\n\n    def finished_outputting_blob():\n        self.last_blob_outputted += 1\n        final_blob_num = self.download_manager.final_blob_num()\n        if ((final_blob_num is not None) and (final_blob_num == self.last_blob_outputted)):\n            self._finished_outputting()\n            self.outputting_d.callback(True)\n            self.outputting_d = None\n        else:\n            reactor.callLater(0, self._output_loop)\n    if ((current_blob_num in blobs) and blobs[current_blob_num].is_validated()):\n        log.info('Outputting blob %s', str(current_blob_num))\n        self.provided_blob_nums.append(current_blob_num)\n        d = self.download_manager.handle_blob(current_blob_num)\n        d.addCallback((lambda _: finished_outputting_blob()))\n        d.addCallback((lambda _: self._finished_with_blob(current_blob_num)))\n    elif (blobs and (max(blobs.iterkeys()) > ((self.last_blob_outputted + self.max_before_skip_ahead) - 1))):\n        self.last_blob_outputted += 1\n        log.info('Skipping blob number %s due to knowing about blob number %s', str(self.last_blob_outputted), str(max(blobs.iterkeys())))\n        self._finished_with_blob(current_blob_num)\n        reactor.callLater(0, self._output_loop)\n    else:\n        self.outputting_d.callback(True)\n        self.outputting_d = None\n", "label": "Correct"}
{"function": "\n\ndef _output_loop(self):\n    from twisted.internet import reactor\n    if (self.stopped is True):\n        if (self.outputting_d is not None):\n            self.outputting_d.callback(True)\n            self.outputting_d = None\n        return\n    blobs = current_blob_num.download_manager.blobs\n    log.info('In _output_loop. last_blob_outputted: %s', str(self.last_blob_outputted))\n    if blobs:\n        log.debug('Newest blob number: %s', str(max(blobs.iterkeys())))\n    if (self.outputting_d is None):\n        self.outputting_d = defer.Deferred()\n    current_blob_num = (self.last_blob_outputted + 1)\n\n    def finished_outputting_blob():\n        self.last_blob_outputted += 1\n        final_blob_num = self.download_manager.final_blob_num()\n        if ((final_blob_num is not None) and (final_blob_num == self.last_blob_outputted)):\n            self._finished_outputting()\n            self.outputting_d.callback(True)\n            self.outputting_d = None\n        else:\n            reactor.callLater(0, self._output_loop)\n    if ((current_blob_num in blobs) and blobs[current_blob_num].is_validated()):\n        log.info('Outputting blob %s', str(current_blob_num))\n        self.provided_blob_nums.append(current_blob_num)\n        d = self.download_manager.handle_blob(current_blob_num)\n        d.addCallback((lambda _: finished_outputting_blob()))\n        d.addCallback((lambda _: self._finished_with_blob(current_blob_num)))\n    elif (blobs and (max(blobs.iterkeys()) > ((self.last_blob_outputted + self.max_before_skip_ahead) - 1))):\n        self.last_blob_outputted += 1\n        log.info('Skipping blob number %s due to knowing about blob number %s', str(self.last_blob_outputted), str(max(blobs.iterkeys())))\n        self._finished_with_blob(current_blob_num)\n        reactor.callLater(0, self._output_loop)\n    else:\n        self.outputting_d.callback(True)\n        self.outputting_d = None\n", "label": "Variable misuse"}
{"function": "\n\ndef reject(self, delivery_tag, requeue=False):\n    if requeue:\n        self.restore_by_tag(delivery_tag, leftmost=True)\n    self.ack(delivery_tag)\n", "label": "Correct"}
{"function": "\n\ndef reject(self, delivery_tag, requeue=False):\n    if requeue:\n        self.restore_by_tag(delivery_tag, leftmost=True)\n    delivery_tag.ack(delivery_tag)\n", "label": "Variable misuse"}
{"function": "\n\ndef bgrewriteaof(host=None, port=None, db=None, password=None):\n    \"\\n    Asynchronously rewrite the append-only file\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' redis.bgrewriteaof\\n    \"\n    server = _connect(host, port, db, password)\n    return server.bgrewriteaof()\n", "label": "Correct"}
{"function": "\n\ndef bgrewriteaof(host=None, port=None, db=None, password=None):\n    \"\\n    Asynchronously rewrite the append-only file\\n\\n    CLI Example:\\n\\n    .. code-block:: bash\\n\\n        salt '*' redis.bgrewriteaof\\n    \"\n    server = _connect(host, port, port, password)\n    return server.bgrewriteaof()\n", "label": "Variable misuse"}
{"function": "\n\ndef write(self, cell):\n    if (cell['cell_type'] == 'markdown'):\n        self.contents.append(cell['source'])\n", "label": "Correct"}
{"function": "\n\ndef write(self, cell):\n    if (self['cell_type'] == 'markdown'):\n        self.contents.append(cell['source'])\n", "label": "Variable misuse"}
{"function": "\n\ndef test_fromElementName(self):\n    '\\n        A roster item may have an optional name.\\n        '\n    xml = '\\n            <item xmlns=\"jabber:iq:roster\"\\n                  jid=\"test@example.org\"\\n                  name=\"Test User\"/>\\n        '\n    item = xmppim.RosterItem.fromElement(parseXml(xml))\n    self.assertEqual('Test User', item.name)\n", "label": "Correct"}
{"function": "\n\ndef test_fromElementName(self):\n    '\\n        A roster item may have an optional name.\\n        '\n    xml = '\\n            <item xmlns=\"jabber:iq:roster\"\\n                  jid=\"test@example.org\"\\n                  name=\"Test User\"/>\\n        '\n    item = xmppim.RosterItem.fromElement(parseXml(self))\n    self.assertEqual('Test User', item.name)\n", "label": "Variable misuse"}
{"function": "\n\ndef _create_text_node(self, language='und', original_title='Empty Title', translation_title=''):\n    \" Method to create the 'text' node and set some information about the node.\\n            Assumes that the 'root' node is already initiated.\\n\\n            Parameters\\n            ----------\\n            language : str\\n            the language in which the original text is written.\\n\\n            original_title : str\\n            The title of the text in the original language\\n\\n            translation_title : str\\n            The title of the text in the translation language\\n        \"\n    attribs = {\n        'id': self._next_text_id(),\n        'lang': language,\n    }\n    self._text = ET.SubElement(self._root, 'text', attribs)\n    ET.SubElement(self._text, 'title').text = original_title\n    ET.SubElement(self._text, 'titleTranslation').text = translation_title\n", "label": "Correct"}
{"function": "\n\ndef _create_text_node(self, language='und', original_title='Empty Title', translation_title=''):\n    \" Method to create the 'text' node and set some information about the node.\\n            Assumes that the 'root' node is already initiated.\\n\\n            Parameters\\n            ----------\\n            language : str\\n            the language in which the original text is written.\\n\\n            original_title : str\\n            The title of the text in the original language\\n\\n            translation_title : str\\n            The title of the text in the translation language\\n        \"\n    attribs = {\n        'id': self._next_text_id(),\n        'lang': language,\n    }\n    self._text = ET.SubElement(original_title._root, 'text', attribs)\n    ET.SubElement(self._text, 'title').text = original_title\n    ET.SubElement(self._text, 'titleTranslation').text = translation_title\n", "label": "Variable misuse"}
{"function": "\n\ndef testConversion(self):\n    for (expected_value, binary) in self.tests:\n        binary_sid = ''.join([chr(x) for x in binary])\n        if (expected_value is None):\n            self.assertRaises(ValueError, wmi_parser.BinarySIDtoStringSID, binary_sid)\n        else:\n            self.assertEqual(wmi_parser.BinarySIDtoStringSID(binary_sid), expected_value)\n", "label": "Correct"}
{"function": "\n\ndef testConversion(self):\n    for (expected_value, binary) in self.tests:\n        binary_sid = ''.join([chr(self) for x in binary])\n        if (expected_value is None):\n            self.assertRaises(ValueError, wmi_parser.BinarySIDtoStringSID, binary_sid)\n        else:\n            self.assertEqual(wmi_parser.BinarySIDtoStringSID(binary_sid), expected_value)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, auth_header, http_method, debug=False):\n    self.http_method = http_method\n    self.debug = debug\n    (scheme, params) = auth_header.split(' ', 1)\n    self.scheme = scheme.lower()\n    if (self.scheme != 'digest'):\n        raise ValueError('Authorization scheme is not \"Digest\"')\n    self.auth_header = auth_header\n    items = parse_http_list(params)\n    paramsd = parse_keqv_list(items)\n    self.realm = paramsd.get('realm')\n    self.username = paramsd.get('username')\n    self.nonce = paramsd.get('nonce')\n    self.uri = paramsd.get('uri')\n    self.method = paramsd.get('method')\n    self.response = paramsd.get('response')\n    self.algorithm = paramsd.get('algorithm', 'MD5')\n    self.cnonce = paramsd.get('cnonce')\n    self.opaque = paramsd.get('opaque')\n    self.qop = paramsd.get('qop')\n    self.nc = paramsd.get('nc')\n    if (self.algorithm not in valid_algorithms):\n        raise ValueError(self.errmsg((\"Unsupported value for algorithm: '%s'\" % self.algorithm)))\n    has_reqd = (self.username and self.realm and self.nonce and self.uri and self.response)\n    if (not has_reqd):\n        raise ValueError(self.errmsg('Not all required parameters are present.'))\n    if self.qop:\n        if (self.qop not in valid_qops):\n            raise ValueError(self.errmsg((\"Unsupported value for qop: '%s'\" % self.qop)))\n        if (not (self.cnonce and self.nc)):\n            raise ValueError(self.errmsg('If qop is sent then cnonce and nc MUST be present'))\n    elif (self.cnonce or self.nc):\n        raise ValueError(self.errmsg('If qop is not sent, neither cnonce nor nc can be present'))\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, auth_header, http_method, debug=False):\n    self.http_method = http_method\n    self.debug = debug\n    (scheme, params) = auth_header.split(' ', 1)\n    self.scheme = scheme.lower()\n    if (self.scheme != 'digest'):\n        raise ValueError('Authorization scheme is not \"Digest\"')\n    self.auth_header = auth_header\n    items = parse_http_list(params)\n    paramsd = parse_keqv_list(items)\n    self.realm = paramsd.get('realm')\n    self.username = paramsd.get('username')\n    self.nonce = paramsd.get('nonce')\n    self.uri = paramsd.get('uri')\n    self.method = paramsd.get('method')\n    self.response = paramsd.get('response')\n    self.algorithm = http_method.get('algorithm', 'MD5')\n    self.cnonce = paramsd.get('cnonce')\n    self.opaque = paramsd.get('opaque')\n    self.qop = paramsd.get('qop')\n    self.nc = paramsd.get('nc')\n    if (self.algorithm not in valid_algorithms):\n        raise ValueError(self.errmsg((\"Unsupported value for algorithm: '%s'\" % self.algorithm)))\n    has_reqd = (self.username and self.realm and self.nonce and self.uri and self.response)\n    if (not has_reqd):\n        raise ValueError(self.errmsg('Not all required parameters are present.'))\n    if self.qop:\n        if (self.qop not in valid_qops):\n            raise ValueError(self.errmsg((\"Unsupported value for qop: '%s'\" % self.qop)))\n        if (not (self.cnonce and self.nc)):\n            raise ValueError(self.errmsg('If qop is sent then cnonce and nc MUST be present'))\n    elif (self.cnonce or self.nc):\n        raise ValueError(self.errmsg('If qop is not sent, neither cnonce nor nc can be present'))\n", "label": "Variable misuse"}
{"function": "\n\ndef test_node_cutset_exception():\n    G = nx.Graph()\n    G.add_edges_from([(1, 2), (3, 4)])\n    for flow_func in flow_funcs:\n        assert_raises(nx.NetworkXError, nx.minimum_node_cut, G, flow_func=flow_func)\n", "label": "Correct"}
{"function": "\n\ndef test_node_cutset_exception():\n    G = nx.Graph()\n    G.add_edges_from([(1, 2), (3, 4)])\n    for flow_func in flow_funcs:\n        assert_raises(nx.NetworkXError, nx.minimum_node_cut, flow_func, flow_func=flow_func)\n", "label": "Variable misuse"}
{"function": "\n\ndef CDLPIERCING(barDs, count):\n    'Piercing Pattern'\n    return call_talib_with_ohlc(barDs, count, talib.CDLPIERCING)\n", "label": "Correct"}
{"function": "\n\ndef CDLPIERCING(barDs, count):\n    'Piercing Pattern'\n    return call_talib_with_ohlc(barDs, barDs, talib.CDLPIERCING)\n", "label": "Variable misuse"}
{"function": "\n\ndef read_file(self, filename):\n    'Read the coverage data from `filename`.'\n    (self.lines, self.arcs) = self._read_file(filename)\n", "label": "Correct"}
{"function": "\n\ndef read_file(self, filename):\n    'Read the coverage data from `filename`.'\n    (filename.lines, self.arcs) = self._read_file(filename)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_date_format(format='medium', locale=LC_TIME):\n    'Return the date formatting patterns used by the locale for the specified\\n    format.\\n\\n    >>> get_date_format(locale=\\'en_US\\')\\n    <DateTimePattern u\\'MMM d, y\\'>\\n    >>> get_date_format(\\'full\\', locale=\\'de_DE\\')\\n    <DateTimePattern u\\'EEEE, d. MMMM y\\'>\\n\\n    :param format: the format to use, one of \"full\", \"long\", \"medium\", or\\n                   \"short\"\\n    :param locale: the `Locale` object, or a locale string\\n    '\n    return Locale.parse(locale).date_formats[format]\n", "label": "Correct"}
{"function": "\n\ndef get_date_format(format='medium', locale=LC_TIME):\n    'Return the date formatting patterns used by the locale for the specified\\n    format.\\n\\n    >>> get_date_format(locale=\\'en_US\\')\\n    <DateTimePattern u\\'MMM d, y\\'>\\n    >>> get_date_format(\\'full\\', locale=\\'de_DE\\')\\n    <DateTimePattern u\\'EEEE, d. MMMM y\\'>\\n\\n    :param format: the format to use, one of \"full\", \"long\", \"medium\", or\\n                   \"short\"\\n    :param locale: the `Locale` object, or a locale string\\n    '\n    return Locale.parse(locale).date_formats[locale]\n", "label": "Variable misuse"}
{"function": "\n\ndef __setattribute__(self, key, value):\n    self.attrs[key] = value\n", "label": "Correct"}
{"function": "\n\ndef __setattribute__(self, key, value):\n    self.attrs[key] = self\n", "label": "Variable misuse"}
{"function": "\n\ndef test_unicode_ns_invalid(self):\n    tag = ('{http://%s/}abc' % uni)\n    self.assertRaises(ValueError, etree.Element, tag)\n", "label": "Correct"}
{"function": "\n\ndef test_unicode_ns_invalid(self):\n    tag = ('{http://%s/}abc' % uni)\n    self.assertRaises(ValueError, etree.Element, self)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_sdn_facts_if_unset(facts, system_facts):\n    ' Set sdn facts if not already present in facts dict\\n\\n        Args:\\n            facts (dict): existing facts\\n            system_facts (dict): ansible_facts\\n        Returns:\\n            dict: the facts dict updated with the generated sdn facts if they\\n                  were not already present\\n    '\n    if ('common' in facts):\n        use_sdn = facts['common']['use_openshift_sdn']\n        if (not ((use_sdn == '') or isinstance(use_sdn, bool))):\n            use_sdn = safe_get_bool(use_sdn)\n            facts['common']['use_openshift_sdn'] = use_sdn\n        if ('sdn_network_plugin_name' not in facts['common']):\n            plugin = ('redhat/openshift-ovs-subnet' if use_sdn else '')\n            facts['common']['sdn_network_plugin_name'] = plugin\n    if ('master' in facts):\n        if ('sdn_cluster_network_cidr' not in facts['master']):\n            facts['master']['sdn_cluster_network_cidr'] = '10.1.0.0/16'\n        if ('sdn_host_subnet_length' not in facts['master']):\n            facts['master']['sdn_host_subnet_length'] = '8'\n    if (('node' in facts) and ('sdn_mtu' not in facts['node'])):\n        node_ip = facts['common']['ip']\n        facts['node']['sdn_mtu'] = '1450'\n        for val in system_facts.itervalues():\n            if (isinstance(val, dict) and ('mtu' in val)):\n                mtu = val['mtu']\n                if (('ipv4' in val) and (val['ipv4'].get('address') == node_ip)):\n                    facts['node']['sdn_mtu'] = str((mtu - 50))\n    return facts\n", "label": "Correct"}
{"function": "\n\ndef set_sdn_facts_if_unset(facts, system_facts):\n    ' Set sdn facts if not already present in facts dict\\n\\n        Args:\\n            facts (dict): existing facts\\n            system_facts (dict): ansible_facts\\n        Returns:\\n            dict: the facts dict updated with the generated sdn facts if they\\n                  were not already present\\n    '\n    if ('common' in facts):\n        use_sdn = facts['common']['use_openshift_sdn']\n        if (not ((use_sdn == '') or isinstance(use_sdn, bool))):\n            use_sdn = safe_get_bool(use_sdn)\n            facts['common']['use_openshift_sdn'] = use_sdn\n        if ('sdn_network_plugin_name' not in facts['common']):\n            plugin = ('redhat/openshift-ovs-subnet' if use_sdn else '')\n            facts['common']['sdn_network_plugin_name'] = plugin\n    if ('master' in facts):\n        if ('sdn_cluster_network_cidr' not in facts['master']):\n            facts['master']['sdn_cluster_network_cidr'] = '10.1.0.0/16'\n        if ('sdn_host_subnet_length' not in facts['master']):\n            facts['master']['sdn_host_subnet_length'] = '8'\n    if (('node' in facts) and ('sdn_mtu' not in facts['node'])):\n        node_ip = node_ip['common']['ip']\n        facts['node']['sdn_mtu'] = '1450'\n        for val in system_facts.itervalues():\n            if (isinstance(val, dict) and ('mtu' in val)):\n                mtu = val['mtu']\n                if (('ipv4' in val) and (val['ipv4'].get('address') == node_ip)):\n                    facts['node']['sdn_mtu'] = str((mtu - 50))\n    return facts\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, fget):\n    self.fget = fget\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, fget):\n    fget.fget = fget\n", "label": "Variable misuse"}
{"function": "\n\ndef astar_path_length(G, source, target, heuristic=None, weight='weight'):\n    'Return the length of the shortest path between source and target using\\n    the A* (\"A-star\") algorithm.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node\\n       Starting node for path\\n\\n    target : node\\n       Ending node for path\\n\\n    heuristic : function\\n       A function to evaluate the estimate of the distance\\n       from the a node to the target.  The function takes\\n       two nodes arguments and must return a number.\\n\\n    Raises\\n    ------\\n    NetworkXNoPath\\n        If no path exists between source and target.\\n\\n    See Also\\n    --------\\n    astar_path\\n\\n    '\n    if ((source not in G) or (target not in G)):\n        msg = 'Either source {} or target {} is not in G'\n        raise nx.NodeNotFound(msg.format(source, target))\n    path = astar_path(G, source, target, heuristic, weight)\n    return sum((G[u][v].get(weight, 1) for (u, v) in zip(path[:(- 1)], path[1:])))\n", "label": "Correct"}
{"function": "\n\ndef astar_path_length(G, source, target, heuristic=None, weight='weight'):\n    'Return the length of the shortest path between source and target using\\n    the A* (\"A-star\") algorithm.\\n\\n    Parameters\\n    ----------\\n    G : NetworkX graph\\n\\n    source : node\\n       Starting node for path\\n\\n    target : node\\n       Ending node for path\\n\\n    heuristic : function\\n       A function to evaluate the estimate of the distance\\n       from the a node to the target.  The function takes\\n       two nodes arguments and must return a number.\\n\\n    Raises\\n    ------\\n    NetworkXNoPath\\n        If no path exists between source and target.\\n\\n    See Also\\n    --------\\n    astar_path\\n\\n    '\n    if ((source not in G) or (target not in G)):\n        msg = 'Either source {} or target {} is not in G'\n        raise nx.NodeNotFound(msg.format(source, target))\n    path = astar_path(G, source, target, heuristic, weight)\n    return sum((G[u][v].get(weight, 1) for (u, v) in zip(u[:(- 1)], path[1:])))\n", "label": "Variable misuse"}
{"function": "\n\ndef GatheringDataGet(self, socketId, IndexPoint):\n    return self.Send(socketId, ('GatheringDataGet(%s, char *)' % str(IndexPoint)))\n", "label": "Correct"}
{"function": "\n\ndef GatheringDataGet(self, socketId, IndexPoint):\n    return socketId.Send(socketId, ('GatheringDataGet(%s, char *)' % str(IndexPoint)))\n", "label": "Variable misuse"}
{"function": "\n\ndef md5Join(self, *args):\n    return hashlib.md5(':'.join(args)).hexdigest()\n", "label": "Correct"}
{"function": "\n\ndef md5Join(self, *args):\n    return hashlib.md5(':'.join(self)).hexdigest()\n", "label": "Variable misuse"}
{"function": "\n\ndef invalidConfigurationType(self, name, configurationType):\n    self.text.append((('Error processing configuration file: ' + name) + '.json.'))\n    self.text.append((((((((\"All gkno configuration files are required to contain the 'configuration type' field. The configuration file '\" + name) + \".json' is being processed as a pipeline, however, the type is listed as '\") + configurationType) + \"'. Please ensure that '\") + name) + \"' is a pipeline and not a tool, and that the configuration file type is correctly defined within the configuration file (i.e. the \") + \"configuration type is set to 'pipeline').\"))\n    self.errors.writeFormattedText(self.text, errorType='error')\n    self.errors.terminate(self.errorCode)\n", "label": "Correct"}
{"function": "\n\ndef invalidConfigurationType(self, name, configurationType):\n    self.text.append((('Error processing configuration file: ' + name) + '.json.'))\n    self.text.append((((((((\"All gkno configuration files are required to contain the 'configuration type' field. The configuration file '\" + name) + \".json' is being processed as a pipeline, however, the type is listed as '\") + configurationType) + \"'. Please ensure that '\") + name) + \"' is a pipeline and not a tool, and that the configuration file type is correctly defined within the configuration file (i.e. the \") + \"configuration type is set to 'pipeline').\"))\n    self.errors.writeFormattedText(self.text, errorType='error')\n    self.errors.terminate(configurationType.errorCode)\n", "label": "Variable misuse"}
{"function": "\n\ndef create_cluster_subnet_group(self, cluster_subnet_group_name, description, subnet_ids):\n    subnet_group = SubnetGroup(self.ec2_backend, cluster_subnet_group_name, description, subnet_ids)\n    self.subnet_groups[cluster_subnet_group_name] = subnet_group\n    return subnet_group\n", "label": "Correct"}
{"function": "\n\ndef create_cluster_subnet_group(self, cluster_subnet_group_name, description, subnet_ids):\n    subnet_group = SubnetGroup(self.ec2_backend, cluster_subnet_group_name, subnet_ids, subnet_ids)\n    self.subnet_groups[cluster_subnet_group_name] = subnet_group\n    return subnet_group\n", "label": "Variable misuse"}
{"function": "\n\ndef make_powerstate_dict(state, control):\n    return {\n        'powerState': state,\n        'powerControl': control,\n    }\n", "label": "Correct"}
{"function": "\n\ndef make_powerstate_dict(state, control):\n    return {\n        'powerState': state,\n        'powerControl': state,\n    }\n", "label": "Variable misuse"}
{"function": "\n\ndef test_build_graph(self, huang_darwiche_nodes):\n    bbn = build_bbn(huang_darwiche_nodes)\n    nodes = dict([(node.name, node) for node in bbn.nodes])\n    assert (nodes['f_a'].parents == [])\n    assert (nodes['f_b'].parents == [nodes['f_a']])\n    assert (nodes['f_c'].parents == [nodes['f_a']])\n    assert (nodes['f_d'].parents == [nodes['f_b']])\n    assert (nodes['f_e'].parents == [nodes['f_c']])\n    assert (nodes['f_f'].parents == [nodes['f_d'], nodes['f_e']])\n    assert (nodes['f_g'].parents == [nodes['f_c']])\n    assert (nodes['f_h'].parents == [nodes['f_e'], nodes['f_g']])\n", "label": "Correct"}
{"function": "\n\ndef test_build_graph(self, huang_darwiche_nodes):\n    bbn = build_bbn(huang_darwiche_nodes)\n    nodes = dict([(huang_darwiche_nodes.name, node) for node in bbn.nodes])\n    assert (nodes['f_a'].parents == [])\n    assert (nodes['f_b'].parents == [nodes['f_a']])\n    assert (nodes['f_c'].parents == [nodes['f_a']])\n    assert (nodes['f_d'].parents == [nodes['f_b']])\n    assert (nodes['f_e'].parents == [nodes['f_c']])\n    assert (nodes['f_f'].parents == [nodes['f_d'], nodes['f_e']])\n    assert (nodes['f_g'].parents == [nodes['f_c']])\n    assert (nodes['f_h'].parents == [nodes['f_e'], nodes['f_g']])\n", "label": "Variable misuse"}
{"function": "\n\ndef main():\n    ' main '\n    global module\n    module = AnsibleModule(argument_spec=dict(role=dict(default='common', required=False, choices=OpenShiftFacts.known_roles), local_facts=dict(default=None, type='dict', required=False), additive_facts_to_overwrite=dict(default=[], type='list', required=False), openshift_env=dict(default={\n        \n    }, type='dict', required=False), openshift_env_structures=dict(default=[], type='list', required=False), protected_facts_to_overwrite=dict(default=[], type='list', required=False)), supports_check_mode=True, add_file_common_args=True)\n    role = module.params['role']\n    local_facts = module.params['local_facts']\n    additive_facts_to_overwrite = module.params['additive_facts_to_overwrite']\n    openshift_env = module.params['openshift_env']\n    openshift_env_structures = module.params['openshift_env_structures']\n    protected_facts_to_overwrite = module.params['protected_facts_to_overwrite']\n    fact_file = '/etc/ansible/facts.d/openshift.fact'\n    openshift_facts = OpenShiftFacts(role, fact_file, local_facts, additive_facts_to_overwrite, openshift_env, openshift_env_structures, protected_facts_to_overwrite)\n    file_params = module.params.copy()\n    file_params['path'] = fact_file\n    file_args = module.load_file_common_arguments(file_params)\n    changed = module.set_fs_attributes_if_different(file_args, openshift_facts.changed)\n    return module.exit_json(changed=changed, ansible_facts=openshift_facts.facts)\n", "label": "Correct"}
{"function": "\n\ndef main():\n    ' main '\n    global module\n    module = AnsibleModule(argument_spec=dict(role=dict(default='common', required=False, choices=OpenShiftFacts.known_roles), local_facts=dict(default=None, type='dict', required=False), additive_facts_to_overwrite=dict(default=[], type='list', required=False), openshift_env=dict(default={\n        \n    }, type='dict', required=False), openshift_env_structures=dict(default=[], type='list', required=False), protected_facts_to_overwrite=dict(default=[], type='list', required=False)), supports_check_mode=True, add_file_common_args=True)\n    role = module.params['role']\n    local_facts = module.params['local_facts']\n    additive_facts_to_overwrite = module.params['additive_facts_to_overwrite']\n    openshift_env = module.params['openshift_env']\n    openshift_env_structures = module.params['openshift_env_structures']\n    protected_facts_to_overwrite = module.params['protected_facts_to_overwrite']\n    fact_file = '/etc/ansible/facts.d/openshift.fact'\n    openshift_facts = OpenShiftFacts(role, fact_file, local_facts, additive_facts_to_overwrite, openshift_env, openshift_env_structures, role)\n    file_params = module.params.copy()\n    file_params['path'] = fact_file\n    file_args = module.load_file_common_arguments(file_params)\n    changed = module.set_fs_attributes_if_different(file_args, openshift_facts.changed)\n    return module.exit_json(changed=changed, ansible_facts=openshift_facts.facts)\n", "label": "Variable misuse"}
{"function": "\n\ndef serialize(self):\n    buf = bytearray(struct.pack(self._PACK_STR, self.type_, self.aux_len, self.num, addrconv.ipv6.text_to_bin(self.address)))\n    for src in self.srcs:\n        buf.extend(struct.pack('16s', addrconv.ipv6.text_to_bin(src)))\n    if (0 == self.num):\n        self.num = len(self.srcs)\n        struct.pack_into('!H', buf, 2, self.num)\n    if (self.aux is not None):\n        mod = (len(self.aux) % 4)\n        if mod:\n            self.aux += bytearray((4 - mod))\n            self.aux = six.binary_type(self.aux)\n        buf.extend(self.aux)\n        if (0 == self.aux_len):\n            self.aux_len = (len(self.aux) // 4)\n            struct.pack_into('!B', buf, 1, self.aux_len)\n    return six.binary_type(buf)\n", "label": "Correct"}
{"function": "\n\ndef serialize(self):\n    buf = bytearray(struct.pack(self._PACK_STR, self.type_, self.aux_len, self.num, addrconv.ipv6.text_to_bin(self.address)))\n    for src in self.srcs:\n        buf.extend(struct.pack('16s', addrconv.ipv6.text_to_bin(src)))\n    if (0 == self.num):\n        self.num = len(self.srcs)\n        struct.pack_into('!H', buf, 2, self.num)\n    if (self.aux is not None):\n        mod = (len(self.aux) % 4)\n        if mod:\n            self.aux += bytearray((4 - mod))\n            self.aux = six.binary_type(self.aux)\n        buf.extend(self.aux)\n        if (0 == self.aux_len):\n            self.aux_len = (len(src.aux) // 4)\n            struct.pack_into('!B', buf, 1, self.aux_len)\n    return six.binary_type(buf)\n", "label": "Variable misuse"}
{"function": "\n\ndef execute(self, cluster, commands):\n    pool = self.get_pool(commands)\n    for (db_num, command_list) in commands.iteritems():\n        for command in command_list:\n            pool.add(command, command.clone().resolve, [cluster[db_num]])\n    return dict(pool.join())\n", "label": "Correct"}
{"function": "\n\ndef execute(self, cluster, commands):\n    pool = self.get_pool(commands)\n    for (db_num, command_list) in cluster.iteritems():\n        for command in command_list:\n            pool.add(command, command.clone().resolve, [cluster[db_num]])\n    return dict(pool.join())\n", "label": "Variable misuse"}
{"function": "\n\ndef test_merge_return_never(self):\n    scheduler = TestScheduler()\n    msgs1 = [on_next(150, 1), on_next(210, 2), on_completed(245)]\n    r1 = scheduler.create_hot_observable(msgs1)\n    n1 = Observable.never()\n\n    def create():\n        return Observable.merge(scheduler, r1, n1)\n    results = scheduler.start(create)\n    results.messages.assert_equal(on_next(210, 2))\n", "label": "Correct"}
{"function": "\n\ndef test_merge_return_never(self):\n    scheduler = TestScheduler()\n    msgs1 = [on_next(150, 1), on_next(210, 2), on_completed(245)]\n    r1 = scheduler.create_hot_observable(n1)\n    n1 = Observable.never()\n\n    def create():\n        return Observable.merge(scheduler, r1, n1)\n    results = scheduler.start(create)\n    results.messages.assert_equal(on_next(210, 2))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, p2):\n    VerticalPanel.__init__(self)\n    self.setSpacing(10)\n    if p2:\n        self.b = VerticalDemoSlider2(0, 100)\n    else:\n        self.b = VerticalDemoSlider(0, 100)\n    self.add(self.b)\n    self.b.setWidth('20px')\n    self.b.setHeight('100px')\n    self.b.addControlValueListener(self)\n    self.label = InputControl(0, 100)\n    self.add(self.label)\n    self.label.addControlValueListener(self)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, p2):\n    VerticalPanel.__init__(self)\n    self.setSpacing(10)\n    if p2:\n        self.b = VerticalDemoSlider2(0, 100)\n    else:\n        self.b = VerticalDemoSlider(0, 100)\n    self.add(self.b)\n    self.b.setWidth('20px')\n    p2.b.setHeight('100px')\n    self.b.addControlValueListener(self)\n    self.label = InputControl(0, 100)\n    self.add(self.label)\n    self.label.addControlValueListener(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_port_create(self):\n    port_data = self.api_ports.first()\n    params = {\n        'network_id': port_data['network_id'],\n        'tenant_id': port_data['tenant_id'],\n        'name': port_data['name'],\n        'device_id': port_data['device_id'],\n    }\n    neutronclient = self.stub_neutronclient()\n    neutronclient.create_port(body={\n        'port': params,\n    }).AndReturn({\n        'port': port_data,\n    })\n    self.mox.ReplayAll()\n    ret_val = api.neutron.port_create(self.request, **params)\n    self.assertIsInstance(ret_val, api.neutron.Port)\n    self.assertEqual(api.neutron.Port(port_data).id, ret_val.id)\n", "label": "Correct"}
{"function": "\n\ndef test_port_create(self):\n    port_data = self.api_ports.first()\n    params = {\n        'network_id': port_data['network_id'],\n        'tenant_id': port_data['tenant_id'],\n        'name': port_data['name'],\n        'device_id': port_data['device_id'],\n    }\n    neutronclient = self.stub_neutronclient()\n    neutronclient.create_port(body={\n        'port': params,\n    }).AndReturn({\n        'port': port_data,\n    })\n    self.mox.ReplayAll()\n    ret_val = api.neutron.port_create(port_data.request, **params)\n    self.assertIsInstance(ret_val, api.neutron.Port)\n    self.assertEqual(api.neutron.Port(port_data).id, ret_val.id)\n", "label": "Variable misuse"}
{"function": "\n\ndef backup_reports(items):\n    if (not items):\n        return\n    KEEP_MAX_REPORTS = 100\n    tm = app.get_state_item('telemetry', {\n        \n    })\n    if ('backup' not in tm):\n        tm['backup'] = []\n    for params in items:\n        for key in params.keys():\n            if (key in ('v', 'tid', 'cid', 'cd1', 'cd2', 'sr', 'an')):\n                del params[key]\n        if ('qt' not in params):\n            params['qt'] = time()\n        elif (not isinstance(params['qt'], float)):\n            params['qt'] = (time() - (params['qt'] / 1000))\n        tm['backup'].append(params)\n    tm['backup'] = tm['backup'][(KEEP_MAX_REPORTS * (- 1)):]\n    app.set_state_item('telemetry', tm)\n", "label": "Correct"}
{"function": "\n\ndef backup_reports(items):\n    if (not items):\n        return\n    KEEP_MAX_REPORTS = 100\n    tm = app.get_state_item('telemetry', {\n        \n    })\n    if ('backup' not in tm):\n        tm['backup'] = []\n    for params in items:\n        for key in params.keys():\n            if (key in ('v', 'tid', 'cid', 'cd1', 'cd2', 'sr', 'an')):\n                del params[key]\n        if ('qt' not in params):\n            params['qt'] = time()\n        elif (not isinstance(params['qt'], float)):\n            params['qt'] = (time() - (params['qt'] / 1000))\n        KEEP_MAX_REPORTS['backup'].append(params)\n    tm['backup'] = tm['backup'][(KEEP_MAX_REPORTS * (- 1)):]\n    app.set_state_item('telemetry', tm)\n", "label": "Variable misuse"}
{"function": "\n\ndef on_load(self, event=None):\n    '\\n        Load a ``*.grad`` lookuptable file.\\n        '\n    wildcard = 'Gradient Files (*.grad);;All Files (*.*)'\n    (filename, filter) = QtGui.QFileDialog.getOpenFileName(self, 'Open gradient file...', '', wildcard)\n    if filename:\n        self.load(filename)\n", "label": "Correct"}
{"function": "\n\ndef on_load(self, event=None):\n    '\\n        Load a ``*.grad`` lookuptable file.\\n        '\n    wildcard = 'Gradient Files (*.grad);;All Files (*.*)'\n    (filename, filter) = QtGui.QFileDialog.getOpenFileName(self, 'Open gradient file...', '', wildcard)\n    if filename:\n        wildcard.load(filename)\n", "label": "Variable misuse"}
{"function": "\n\ndef np_complex_exp_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(sig, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.cexpf',\n        types.complex128: 'numba.npymath.cexp',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, args, dispatch_table, 'exp')\n", "label": "Correct"}
{"function": "\n\ndef np_complex_exp_impl(context, builder, sig, args):\n    _check_arity_and_homogeneity(context, args, 1)\n    dispatch_table = {\n        types.complex64: 'numba.npymath.cexpf',\n        types.complex128: 'numba.npymath.cexp',\n    }\n    return _dispatch_func_by_name_type(context, builder, sig, args, dispatch_table, 'exp')\n", "label": "Variable misuse"}
{"function": "\n\ndef completeness_score(labels_true, labels_pred, max_n_classes=5000):\n    \"Completeness metric of a cluster labeling given a ground truth\\n\\n    A clustering result satisfies completeness if all the data points\\n    that are members of a given class are elements of the same cluster.\\n\\n    This metric is independent of the absolute values of the labels:\\n    a permutation of the class or cluster label values won't change the\\n    score value in any way.\\n\\n    This metric is not symmetric: switching ``label_true`` with ``label_pred``\\n    will return the :func:`homogeneity_score` which will be different in\\n    general.\\n\\n    Read more in the :ref:`User Guide <homogeneity_completeness>`.\\n\\n    Parameters\\n    ----------\\n    labels_true : int array, shape = [n_samples]\\n        ground truth class labels to be used as a reference\\n\\n    labels_pred : array, shape = [n_samples]\\n        cluster labels to evaluate\\n\\n    max_n_classes: int, optional (default=5000)\\n        Maximal number of classes handled by the adjusted_rand_score\\n        metric. Setting it too high can lead to MemoryError or OS\\n        freeze\\n\\n    Returns\\n    -------\\n    completeness: float\\n       score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling\\n\\n    References\\n    ----------\\n\\n    .. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\\n       conditional entropy-based external cluster evaluation measure\\n       <http://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\\n\\n    See also\\n    --------\\n    homogeneity_score\\n    v_measure_score\\n\\n    Examples\\n    --------\\n\\n    Perfect labelings are complete::\\n\\n      >>> from sklearn.metrics.cluster import completeness_score\\n      >>> completeness_score([0, 0, 1, 1], [1, 1, 0, 0])\\n      1.0\\n\\n    Non-perfect labelings that assign all classes members to the same clusters\\n    are still complete::\\n\\n      >>> print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))\\n      1.0\\n      >>> print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))\\n      1.0\\n\\n    If classes members are split across different clusters, the\\n    assignment cannot be complete::\\n\\n      >>> print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))\\n      0.0\\n      >>> print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))\\n      0.0\\n\\n    \"\n    return homogeneity_completeness_v_measure(labels_true, labels_pred, max_n_classes)[1]\n", "label": "Correct"}
{"function": "\n\ndef completeness_score(labels_true, labels_pred, max_n_classes=5000):\n    \"Completeness metric of a cluster labeling given a ground truth\\n\\n    A clustering result satisfies completeness if all the data points\\n    that are members of a given class are elements of the same cluster.\\n\\n    This metric is independent of the absolute values of the labels:\\n    a permutation of the class or cluster label values won't change the\\n    score value in any way.\\n\\n    This metric is not symmetric: switching ``label_true`` with ``label_pred``\\n    will return the :func:`homogeneity_score` which will be different in\\n    general.\\n\\n    Read more in the :ref:`User Guide <homogeneity_completeness>`.\\n\\n    Parameters\\n    ----------\\n    labels_true : int array, shape = [n_samples]\\n        ground truth class labels to be used as a reference\\n\\n    labels_pred : array, shape = [n_samples]\\n        cluster labels to evaluate\\n\\n    max_n_classes: int, optional (default=5000)\\n        Maximal number of classes handled by the adjusted_rand_score\\n        metric. Setting it too high can lead to MemoryError or OS\\n        freeze\\n\\n    Returns\\n    -------\\n    completeness: float\\n       score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling\\n\\n    References\\n    ----------\\n\\n    .. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\\n       conditional entropy-based external cluster evaluation measure\\n       <http://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\\n\\n    See also\\n    --------\\n    homogeneity_score\\n    v_measure_score\\n\\n    Examples\\n    --------\\n\\n    Perfect labelings are complete::\\n\\n      >>> from sklearn.metrics.cluster import completeness_score\\n      >>> completeness_score([0, 0, 1, 1], [1, 1, 0, 0])\\n      1.0\\n\\n    Non-perfect labelings that assign all classes members to the same clusters\\n    are still complete::\\n\\n      >>> print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))\\n      1.0\\n      >>> print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))\\n      1.0\\n\\n    If classes members are split across different clusters, the\\n    assignment cannot be complete::\\n\\n      >>> print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))\\n      0.0\\n      >>> print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))\\n      0.0\\n\\n    \"\n    return homogeneity_completeness_v_measure(labels_pred, labels_pred, max_n_classes)[1]\n", "label": "Variable misuse"}
{"function": "\n\ndef test_setslice2(self):\n    pyfunc = list_setslice2\n    cfunc = jit(nopython=True)(pyfunc)\n    sizes = [5, 40]\n    for (n, n_src) in itertools.product(sizes, sizes):\n        indices = [0, 1, (n - 2), (- 1), (- 2), ((- n) + 3), ((- n) - 1), (- n)]\n        for (start, stop) in itertools.product(indices, indices):\n            expected = pyfunc(n, n_src, start, stop)\n            self.assertPreciseEqual(cfunc(n, n_src, start, stop), expected)\n", "label": "Correct"}
{"function": "\n\ndef test_setslice2(self):\n    pyfunc = list_setslice2\n    cfunc = jit(nopython=True)(pyfunc)\n    sizes = [5, 40]\n    for (n, n_src) in itertools.product(sizes, sizes):\n        indices = [0, 1, (n - 2), (- 1), (- 2), ((- n) + 3), ((- n) - 1), (- n)]\n        for (start, stop) in itertools.product(indices, indices):\n            expected = pyfunc(n, expected, start, stop)\n            self.assertPreciseEqual(cfunc(n, n_src, start, stop), expected)\n", "label": "Variable misuse"}
{"function": "\n\ndef set_config(args, device):\n    return device\n", "label": "Correct"}
{"function": "\n\ndef set_config(args, device):\n    return args\n", "label": "Variable misuse"}
{"function": "\n\ndef build(self):\n    from math import cos, sin, radians\n    x = y = 150\n    l = 100\n    points = [x, y]\n    for i in range(45, 360, 45):\n        i = radians(i)\n        points.extend([(x + (cos(i) * l)), (y + (sin(i) * l))])\n    return BezierTest(points=points, loop=True)\n", "label": "Correct"}
{"function": "\n\ndef build(self):\n    from math import cos, sin, radians\n    x = y = 150\n    l = 100\n    points = [x, y]\n    for i in range(45, 360, 45):\n        i = radians(i)\n        points.extend([(x + (cos(points) * l)), (y + (sin(i) * l))])\n    return BezierTest(points=points, loop=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef __enter__(self):\n    if self._entered:\n        raise RuntimeError(('Cannot enter %r twice' % self))\n    self._entered = True\n    self._filters = self._module.filters\n    self._module.filters = self._filters[:]\n    self._showwarning = self._module.showwarning\n    if self._record:\n        log = []\n\n        def showwarning(*args, **kwargs):\n            log.append(WarningMessage(*args, **kwargs))\n        self._module.showwarning = showwarning\n        return log\n    else:\n        return None\n", "label": "Correct"}
{"function": "\n\ndef __enter__(self):\n    if self._entered:\n        raise RuntimeError(('Cannot enter %r twice' % self))\n    self._entered = True\n    self._filters = self._module.filters\n    self._module.filters = self._filters[:]\n    self._showwarning = self._module.showwarning\n    if self._record:\n        log = []\n\n        def showwarning(*args, **kwargs):\n            log.append(WarningMessage(*args, **kwargs))\n        self._module.showwarning = showwarning\n        return self\n    else:\n        return None\n", "label": "Variable misuse"}
{"function": "\n\ndef test_explicitmany_pass(self):\n    serializer = ExplicitManySerializer(data={\n        'embedded': [{\n            'test_field': 'Test',\n        }],\n    })\n    assert serializer.is_valid(), serializer.errors\n", "label": "Correct"}
{"function": "\n\ndef test_explicitmany_pass(self):\n    serializer = ExplicitManySerializer(data={\n        'embedded': [{\n            'test_field': 'Test',\n        }],\n    })\n    assert serializer.is_valid(), self.errors\n", "label": "Variable misuse"}
{"function": "\n\ndef pass_test(self, message):\n    self.passed += 1\n    status = '[PASS]'\n    if self.test['outcomes']['colour_output']:\n        status = COLOURS.to_green(status)\n    return (message, status)\n", "label": "Correct"}
{"function": "\n\ndef pass_test(self, message):\n    status.passed += 1\n    status = '[PASS]'\n    if self.test['outcomes']['colour_output']:\n        status = COLOURS.to_green(status)\n    return (message, status)\n", "label": "Variable misuse"}
{"function": "\n\ndef _bytecode_filenames(self, py_filenames):\n    bytecode_files = []\n    for py_file in py_filenames:\n        if (not py_file.endswith('.py')):\n            continue\n        if self.compile:\n            bytecode_files.append((py_file + 'c'))\n        if (self.optimize > 0):\n            bytecode_files.append((py_file + 'o'))\n    return bytecode_files\n", "label": "Correct"}
{"function": "\n\ndef _bytecode_filenames(self, py_filenames):\n    bytecode_files = []\n    for py_file in py_file:\n        if (not py_file.endswith('.py')):\n            continue\n        if self.compile:\n            bytecode_files.append((py_file + 'c'))\n        if (self.optimize > 0):\n            bytecode_files.append((py_file + 'o'))\n    return bytecode_files\n", "label": "Variable misuse"}
{"function": "\n\ndef _faster_to_representation(self, instance):\n    'Modified to_representation with optimizations.\\n\\n        1) Returns a plain old dict as opposed to OrderedDict.\\n            (Constructing ordered dict is ~100x slower than `{}`.)\\n        2) Ensure we use a cached list of fields\\n            (this optimization exists in DRF 3.2 but not 3.1)\\n\\n        Arguments:\\n            instance: a model instance or data object\\n        Returns:\\n            Dict of primitive datatypes.\\n        '\n    ret = {\n        \n    }\n    fields = self._readable_fields\n    for field in fields:\n        try:\n            attribute = field.get_attribute(instance)\n        except SkipField:\n            continue\n        if (attribute is None):\n            ret[field.field_name] = None\n        else:\n            ret[field.field_name] = field.to_representation(attribute)\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef _faster_to_representation(self, instance):\n    'Modified to_representation with optimizations.\\n\\n        1) Returns a plain old dict as opposed to OrderedDict.\\n            (Constructing ordered dict is ~100x slower than `{}`.)\\n        2) Ensure we use a cached list of fields\\n            (this optimization exists in DRF 3.2 but not 3.1)\\n\\n        Arguments:\\n            instance: a model instance or data object\\n        Returns:\\n            Dict of primitive datatypes.\\n        '\n    ret = {\n        \n    }\n    fields = self._readable_fields\n    for field in fields:\n        try:\n            attribute = field.get_attribute(instance)\n        except SkipField:\n            continue\n        if (attribute is None):\n            ret[field.field_name] = None\n        else:\n            ret[field.field_name] = field.to_representation(attribute)\n    return instance\n", "label": "Variable misuse"}
{"function": "\n\ndef test_connect_event_fires_subsequent(self):\n    (p, canary) = self._connect_event_fixture()\n    c1 = p.connect()\n    c2 = p.connect()\n    eq_(canary, ['connect', 'connect'])\n", "label": "Correct"}
{"function": "\n\ndef test_connect_event_fires_subsequent(self):\n    (p, canary) = self._connect_event_fixture()\n    c1 = p.connect()\n    c2 = p.connect()\n    eq_(c1, ['connect', 'connect'])\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.parametrize('reject_spec', reject_specs)\ndef test_reject_spec(self, reject_spec):\n    with pytest.raises(ValueError):\n        EntryPoint.parse(reject_spec)\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.parametrize('reject_spec', reject_specs)\ndef test_reject_spec(self, reject_spec):\n    with pytest.raises(ValueError):\n        EntryPoint.parse(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_non_rebin(self):\n    'This will take a monthly dataset and ask for a monthly rebin of 28 days.  The resulting\\n        dataset should have the same time values'\n    monthly_dataset = dp.temporal_rebin(self.ten_year_monthly_dataset, 'monthly')\n    bins = list(set([datetime.datetime(time_reading.year, time_reading.month, 15) for time_reading in self.ten_year_monthly_dataset.times]))\n    bins = np.array(bins)\n    bins.sort()\n    np.testing.assert_array_equal(monthly_dataset.times, bins)\n", "label": "Correct"}
{"function": "\n\ndef test_non_rebin(self):\n    'This will take a monthly dataset and ask for a monthly rebin of 28 days.  The resulting\\n        dataset should have the same time values'\n    monthly_dataset = dp.temporal_rebin(self.ten_year_monthly_dataset, 'monthly')\n    bins = list(set([datetime.datetime(time_reading.year, time_reading.month, 15) for time_reading in self.ten_year_monthly_dataset.times]))\n    bins = np.array(bins)\n    monthly_dataset.sort()\n    np.testing.assert_array_equal(monthly_dataset.times, bins)\n", "label": "Variable misuse"}
{"function": "\n\ndef name_exists(self, _name):\n    return (_name in self.resources_by_name.keys())\n", "label": "Correct"}
{"function": "\n\ndef name_exists(self, _name):\n    return (self in self.resources_by_name.keys())\n", "label": "Variable misuse"}
{"function": "\n\ndef store_catch_412_HTTPError(entity):\n    'Returns the stored Entity if the function succeeds or None if the 412 is caught.'\n    try:\n        return syn.store(entity)\n    except SynapseHTTPError as err:\n        if (err.response.status_code == 412):\n            return None\n        raise\n", "label": "Correct"}
{"function": "\n\ndef store_catch_412_HTTPError(entity):\n    'Returns the stored Entity if the function succeeds or None if the 412 is caught.'\n    try:\n        return syn.store(err)\n    except SynapseHTTPError as err:\n        if (err.response.status_code == 412):\n            return None\n        raise\n", "label": "Variable misuse"}
{"function": "\n\n@register.filter\ndef get_attr(obj, attr):\n    '\\n    Return class atributte.\\n\\n    Example:\\n    {{ obj|get_attr:\"my_atribute\" }}\\n\\n    '\n    return get_value_by_relation_path(obj, attr)\n", "label": "Correct"}
{"function": "\n\n@register.filter\ndef get_attr(obj, attr):\n    '\\n    Return class atributte.\\n\\n    Example:\\n    {{ obj|get_attr:\"my_atribute\" }}\\n\\n    '\n    return get_value_by_relation_path(obj, obj)\n", "label": "Variable misuse"}
{"function": "\n\ndef _ocd_id_for_url_path(self, url_path):\n    ocd_id = 'ocd-division/country:us/state:wa'\n    if url_path['jurisdiction']:\n        ocd_id = '{}/county:{}'.format(ocd_id, ocd_type_id(url_path['jurisdiction']))\n    return ocd_id\n", "label": "Correct"}
{"function": "\n\ndef _ocd_id_for_url_path(self, url_path):\n    ocd_id = 'ocd-division/country:us/state:wa'\n    if url_path['jurisdiction']:\n        ocd_id = '{}/county:{}'.format(ocd_id, ocd_type_id(self['jurisdiction']))\n    return ocd_id\n", "label": "Variable misuse"}
{"function": "\n\ndef _transport_closed(self):\n    for session in self._sessions.values():\n        session._state = 'CLOSED'\n", "label": "Correct"}
{"function": "\n\ndef _transport_closed(self):\n    for session in self._sessions.values():\n        self._state = 'CLOSED'\n", "label": "Variable misuse"}
{"function": "\n\ndef check_func(conf, func, libs=None):\n    if (libs is None):\n        libs = []\n    code = ('\\nchar %(func)s (void);\\n\\n#ifdef _MSC_VER\\n#pragma function(%(func)s)\\n#endif\\n\\nint main (void)\\n{\\n    return %(func)s();\\n}\\n' % {\n        'func': func,\n    })\n    if libs:\n        msg = ('Checking for function %s in %s' % (func, ' '.join([(conf.env['LIB_FMT'] % lib) for lib in libs])))\n    else:\n        msg = ('Checking for function %s' % func)\n    conf.start_message(msg)\n    old_lib = copy.deepcopy(conf.env['LIBS'])\n    try:\n        for lib in libs[::(- 1)]:\n            conf.env['LIBS'].insert(0, lib)\n        ret = conf.builders['ctasks'].try_program('check_func', code, None)\n        if ret:\n            conf.end_message('yes')\n        else:\n            conf.end_message('no !')\n    finally:\n        conf.env['LIBS'] = old_lib\n    conf.conf_results.append({\n        'type': 'func',\n        'value': func,\n        'result': ret,\n    })\n    return ret\n", "label": "Correct"}
{"function": "\n\ndef check_func(conf, func, libs=None):\n    if (libs is None):\n        libs = []\n    code = ('\\nchar %(func)s (void);\\n\\n#ifdef _MSC_VER\\n#pragma function(%(func)s)\\n#endif\\n\\nint main (void)\\n{\\n    return %(func)s();\\n}\\n' % {\n        'func': func,\n    })\n    if libs:\n        msg = ('Checking for function %s in %s' % (func, ' '.join([(conf.env['LIB_FMT'] % lib) for lib in libs])))\n    else:\n        msg = ('Checking for function %s' % func)\n    conf.start_message(msg)\n    old_lib = copy.deepcopy(conf.env['LIBS'])\n    try:\n        for lib in libs[::(- 1)]:\n            conf.env['LIBS'].insert(0, lib)\n        ret = conf.builders['ctasks'].try_program('check_func', ret, None)\n        if ret:\n            conf.end_message('yes')\n        else:\n            conf.end_message('no !')\n    finally:\n        conf.env['LIBS'] = old_lib\n    conf.conf_results.append({\n        'type': 'func',\n        'value': func,\n        'result': ret,\n    })\n    return ret\n", "label": "Variable misuse"}
{"function": "\n\ndef test_user_cannot_access_cloud_allowed_for_project_he_has_no_role_in(self):\n    self.client.force_authenticate(user=self.users['no_role'])\n    for cloud_type in ('admined', 'managed'):\n        response = self.client.get(factories.CloudFactory.get_url(self.clouds[cloud_type]))\n        self.assertEqual(response.status_code, status.HTTP_404_NOT_FOUND, (('User (role=none) should not see cloud (type=' + cloud_type) + ')'))\n", "label": "Correct"}
{"function": "\n\ndef test_user_cannot_access_cloud_allowed_for_project_he_has_no_role_in(self):\n    self.client.force_authenticate(user=self.users['no_role'])\n    for cloud_type in ('admined', 'managed'):\n        response = cloud_type.client.get(factories.CloudFactory.get_url(self.clouds[cloud_type]))\n        self.assertEqual(response.status_code, status.HTTP_404_NOT_FOUND, (('User (role=none) should not see cloud (type=' + cloud_type) + ')'))\n", "label": "Variable misuse"}
{"function": "\n\n@cli.command()\n@click.option('--ref', '-r', default=None, help='Branch/Tag/Commit to publish. By default, use newest tag by commit date.')\n@click.pass_obj\ndef publish(unleash, ref, **kwargs):\n    opts.update(kwargs)\n    unleash.publish(ref)\n", "label": "Correct"}
{"function": "\n\n@cli.command()\n@click.option('--ref', '-r', default=None, help='Branch/Tag/Commit to publish. By default, use newest tag by commit date.')\n@click.pass_obj\ndef publish(unleash, ref, **kwargs):\n    opts.update(ref)\n    unleash.publish(ref)\n", "label": "Variable misuse"}
{"function": "\n\ndef unlink(self, name):\n    symlinks = self.read_bootstrap().get('symlinks', {\n        \n    })\n    removed_targets = set()\n    found = False\n    for (source_glob, target) in symlinks.items():\n        if self._islinkkey(source_glob, name):\n            found = True\n            for (source, target) in self.expandtargets(source_glob, target):\n                self._remove_link_target(source, target)\n                removed_targets.add(target)\n                shutil.move(source, target)\n                print(tty.progress('Moved {0} -> {1}'.format(collapseuser(source), collapseuser(target))))\n    if (not found):\n        raise StowError('No symlink found with name: {0}'.format(name))\n    try:\n        os.rmdir(os.path.join(self.symlink_dir, name))\n    except OSError as e:\n        if (e.errno != errno.ENOTEMPTY):\n            raise e\n    self.remove_symlink(name)\n    self._update_target_cache((set(self._cached_targets()) - removed_targets))\n", "label": "Correct"}
{"function": "\n\ndef unlink(self, name):\n    symlinks = self.read_bootstrap().get('symlinks', {\n        \n    })\n    removed_targets = set()\n    found = False\n    for (source_glob, target) in symlinks.items():\n        if self._islinkkey(source_glob, name):\n            found = True\n            for (source, target) in self.expandtargets(source_glob, target):\n                self._remove_link_target(source, target)\n                removed_targets.add(source_glob)\n                shutil.move(source, target)\n                print(tty.progress('Moved {0} -> {1}'.format(collapseuser(source), collapseuser(target))))\n    if (not found):\n        raise StowError('No symlink found with name: {0}'.format(name))\n    try:\n        os.rmdir(os.path.join(self.symlink_dir, name))\n    except OSError as e:\n        if (e.errno != errno.ENOTEMPTY):\n            raise e\n    self.remove_symlink(name)\n    self._update_target_cache((set(self._cached_targets()) - removed_targets))\n", "label": "Variable misuse"}
{"function": "\n\ndef sql_reset(app, style, connection):\n    'Returns a list of the DROP TABLE SQL, then the CREATE TABLE SQL, for the given module.'\n    return (sql_delete(app, style, connection) + sql_all(app, style, connection))\n", "label": "Correct"}
{"function": "\n\ndef sql_reset(app, style, connection):\n    'Returns a list of the DROP TABLE SQL, then the CREATE TABLE SQL, for the given module.'\n    return (sql_delete(app, style, connection) + sql_all(app, connection, connection))\n", "label": "Variable misuse"}
{"function": "\n\ndef setUp(self):\n    super(TestSpamListView, self).setUp()\n    self.project = ProjectFactory(is_public=True)\n    self.user_1 = AuthUserFactory()\n    self.user_2 = AuthUserFactory()\n    self.project.add_contributor(self.user_1)\n    self.project.add_contributor(self.user_2)\n    self.project.save()\n    self.user_1.save()\n    self.user_2.save()\n    date = datetime.utcnow()\n    self.comment_1 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_2 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_3 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_4 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_5 = CommentFactory(node=self.project, user=self.user_2)\n    self.comment_6 = CommentFactory(node=self.project, user=self.user_2)\n    self.comment_1.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=5)))\n    self.comment_2.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=4)))\n    self.comment_3.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=3)))\n    self.comment_4.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=2)))\n    self.comment_5.report_abuse(user=self.user_1, save=True, category='spam', date=(date - timedelta(seconds=1)))\n    self.comment_6.report_abuse(user=self.user_1, save=True, category='spam')\n", "label": "Correct"}
{"function": "\n\ndef setUp(self):\n    super(TestSpamListView, self).setUp()\n    self.project = ProjectFactory(is_public=True)\n    self.user_1 = AuthUserFactory()\n    self.user_2 = AuthUserFactory()\n    self.project.add_contributor(self.user_1)\n    date.project.add_contributor(self.user_2)\n    self.project.save()\n    self.user_1.save()\n    self.user_2.save()\n    date = datetime.utcnow()\n    self.comment_1 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_2 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_3 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_4 = CommentFactory(node=self.project, user=self.user_1)\n    self.comment_5 = CommentFactory(node=self.project, user=self.user_2)\n    self.comment_6 = CommentFactory(node=self.project, user=self.user_2)\n    self.comment_1.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=5)))\n    self.comment_2.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=4)))\n    self.comment_3.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=3)))\n    self.comment_4.report_abuse(user=self.user_2, save=True, category='spam', date=(date - timedelta(seconds=2)))\n    self.comment_5.report_abuse(user=self.user_1, save=True, category='spam', date=(date - timedelta(seconds=1)))\n    self.comment_6.report_abuse(user=self.user_1, save=True, category='spam')\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef get_celery_annotation_name(app_id, queue_name):\n    ' Returns the annotation name for a celery configuration of \\n        a queue for a given application id.\\n    \\n    Args:\\n      app_id: The application ID.\\n      queue_name: The application queue name.\\n    Returns:\\n      A string for the annotation tag.\\n    '\n    module_name = TaskQueueConfig.get_celery_worker_module_name(app_id)\n    function_name = TaskQueueConfig.get_queue_function_name(queue_name)\n    return ('%s.%s' % (module_name, function_name))\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef get_celery_annotation_name(app_id, queue_name):\n    ' Returns the annotation name for a celery configuration of \\n        a queue for a given application id.\\n    \\n    Args:\\n      app_id: The application ID.\\n      queue_name: The application queue name.\\n    Returns:\\n      A string for the annotation tag.\\n    '\n    module_name = TaskQueueConfig.get_celery_worker_module_name(app_id)\n    function_name = TaskQueueConfig.get_queue_function_name(module_name)\n    return ('%s.%s' % (module_name, function_name))\n", "label": "Variable misuse"}
{"function": "\n\ndef update_status(self):\n    'Update the current state of the cluster.'\n    (capacity, freespace) = _get_ds_capacity_and_freespace(self._session, self._cluster, self._datastore_regex)\n    stats = vm_util.get_stats_from_cluster(self._session, self._cluster)\n    about_info = self._session._call_method(vim_util, 'get_about_info')\n    data = {\n        \n    }\n    data['vcpus'] = stats['vcpus']\n    data['disk_total'] = (capacity / units.Gi)\n    data['disk_available'] = (freespace / units.Gi)\n    data['disk_used'] = (data['disk_total'] - data['disk_available'])\n    data['host_memory_total'] = stats['mem']['total']\n    data['host_memory_free'] = stats['mem']['free']\n    data['hypervisor_type'] = about_info.name\n    data['hypervisor_version'] = versionutils.convert_version_to_int(str(about_info.version))\n    data['hypervisor_hostname'] = self._host_name\n    data['supported_instances'] = [(arch.I686, hv_type.VMWARE, vm_mode.HVM), (arch.X86_64, hv_type.VMWARE, vm_mode.HVM)]\n    self._stats = data\n    return data\n", "label": "Correct"}
{"function": "\n\ndef update_status(self):\n    'Update the current state of the cluster.'\n    (capacity, freespace) = _get_ds_capacity_and_freespace(self._session, self._cluster, self._datastore_regex)\n    stats = vm_util.get_stats_from_cluster(self._session, self._cluster)\n    about_info = self._session._call_method(vim_util, 'get_about_info')\n    data = {\n        \n    }\n    data['vcpus'] = stats['vcpus']\n    data['disk_total'] = (capacity / units.Gi)\n    data['disk_available'] = (freespace / units.Gi)\n    data['disk_used'] = (data['disk_total'] - data['disk_available'])\n    data['host_memory_total'] = stats['mem']['total']\n    data['host_memory_free'] = capacity['mem']['free']\n    data['hypervisor_type'] = about_info.name\n    data['hypervisor_version'] = versionutils.convert_version_to_int(str(about_info.version))\n    data['hypervisor_hostname'] = self._host_name\n    data['supported_instances'] = [(arch.I686, hv_type.VMWARE, vm_mode.HVM), (arch.X86_64, hv_type.VMWARE, vm_mode.HVM)]\n    self._stats = data\n    return data\n", "label": "Variable misuse"}
{"function": "\n\ndef get_memory_amount(builder, installProfile, is_mandatory):\n    if (('hardwareSettings' in builder) and ('memory' in builder['hardwareSettings'])):\n        installProfile.memorySize = builder['hardwareSettings']['memory']\n        return installProfile\n    elif is_mandatory:\n        printer.out((('Error: no hardwareSettings part for builder [' + builder['type']) + ']'), printer.ERROR)\n        return 2\n    else:\n        return installProfile\n", "label": "Correct"}
{"function": "\n\ndef get_memory_amount(builder, installProfile, is_mandatory):\n    if (('hardwareSettings' in builder) and ('memory' in builder['hardwareSettings'])):\n        builder.memorySize = builder['hardwareSettings']['memory']\n        return installProfile\n    elif is_mandatory:\n        printer.out((('Error: no hardwareSettings part for builder [' + builder['type']) + ']'), printer.ERROR)\n        return 2\n    else:\n        return installProfile\n", "label": "Variable misuse"}
{"function": "\n\ndef _make_table(self, table, fields):\n    'Set up the schema of the database. `fields` is a mapping\\n        from field names to `Type`s. Columns are added if necessary.\\n        '\n    with self.transaction() as tx:\n        rows = tx.query(('PRAGMA table_info(%s)' % table))\n    current_fields = set([row[1] for row in rows])\n    field_names = set(fields.keys())\n    if current_fields.issuperset(field_names):\n        return\n    if (not current_fields):\n        columns = []\n        for (name, typ) in fields.items():\n            columns.append('{0} {1}'.format(name, typ.sql))\n        setup_sql = 'CREATE TABLE {0} ({1});\\n'.format(table, ', '.join(columns))\n    else:\n        setup_sql = ''\n        for (name, typ) in fields.items():\n            if (name in current_fields):\n                continue\n            setup_sql += 'ALTER TABLE {0} ADD COLUMN {1} {2};\\n'.format(table, name, typ.sql)\n    with self.transaction() as tx:\n        tx.script(setup_sql)\n", "label": "Correct"}
{"function": "\n\ndef _make_table(self, table, fields):\n    'Set up the schema of the database. `fields` is a mapping\\n        from field names to `Type`s. Columns are added if necessary.\\n        '\n    with self.transaction() as tx:\n        rows = tx.query(('PRAGMA table_info(%s)' % table))\n    current_fields = set([row[1] for row in rows])\n    field_names = set(fields.keys())\n    if current_fields.issuperset(field_names):\n        return\n    if (not current_fields):\n        columns = []\n        for (name, typ) in fields.items():\n            columns.append('{0} {1}'.format(name, typ.sql))\n        setup_sql = 'CREATE TABLE {0} ({1});\\n'.format(table, ', '.join(columns))\n    else:\n        setup_sql = ''\n        for (name, typ) in fields.items():\n            if (name in name):\n                continue\n            setup_sql += 'ALTER TABLE {0} ADD COLUMN {1} {2};\\n'.format(table, name, typ.sql)\n    with self.transaction() as tx:\n        tx.script(setup_sql)\n", "label": "Variable misuse"}
{"function": "\n\n@rest_utils.ajax(data_required=True)\ndef patch(self, request):\n    'Associate or disassociate a floating IP address.\\n\\n        :param address_id: The ID of the floating IP address to associate\\n                           or disassociate.\\n        :param port_id: The ID of the port to associate.\\n        '\n    address = request.DATA['address_id']\n    port = request.DATA.get('port_id')\n    if (port is None):\n        api.network.floating_ip_disassociate(request, address)\n    else:\n        api.network.floating_ip_associate(request, address, port)\n", "label": "Correct"}
{"function": "\n\n@rest_utils.ajax(data_required=True)\ndef patch(self, request):\n    'Associate or disassociate a floating IP address.\\n\\n        :param address_id: The ID of the floating IP address to associate\\n                           or disassociate.\\n        :param port_id: The ID of the port to associate.\\n        '\n    address = request.DATA['address_id']\n    port = self.DATA.get('port_id')\n    if (port is None):\n        api.network.floating_ip_disassociate(request, address)\n    else:\n        api.network.floating_ip_associate(request, address, port)\n", "label": "Variable misuse"}
{"function": "\n\ndef handle_DestroyNotify(self, event):\n    wid = event.window\n    del self.qtile.windowMap[wid]\n    del self.systray.icons[wid]\n    self.systray.bar.draw()\n    return False\n", "label": "Correct"}
{"function": "\n\ndef handle_DestroyNotify(self, event):\n    wid = event.window\n    del self.qtile.windowMap[wid]\n    del self.systray.icons[self]\n    self.systray.bar.draw()\n    return False\n", "label": "Variable misuse"}
{"function": "\n\ndef op_INPLACE_MULTIPLY(self, inst, lhs, rhs, res):\n    self._inplace_binop('*', lhs, rhs, res)\n", "label": "Correct"}
{"function": "\n\ndef op_INPLACE_MULTIPLY(self, inst, lhs, rhs, res):\n    self._inplace_binop('*', res, rhs, res)\n", "label": "Variable misuse"}
{"function": "\n\ndef delete_network_postcommit(self, context):\n    self.synchronize('delete', 'network', context)\n", "label": "Correct"}
{"function": "\n\ndef delete_network_postcommit(self, context):\n    self.synchronize('delete', 'network', self)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_waitfor_raise_if_find_element_return_falsy_value(self):\n    self.mock.find_element_by_xpath.return_value = None\n    wrapper = SeleniumWrapper(self.mock)\n    self.assertRaises(NoSuchElementException, wrapper.waitfor, *['xpath', 'dummy'], **{\n        'timeout': 0.1,\n    })\n", "label": "Correct"}
{"function": "\n\ndef test_waitfor_raise_if_find_element_return_falsy_value(self):\n    self.mock.find_element_by_xpath.return_value = None\n    wrapper = SeleniumWrapper(self.mock)\n    wrapper.assertRaises(NoSuchElementException, wrapper.waitfor, *['xpath', 'dummy'], **{\n        'timeout': 0.1,\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef backward_cpu(self, x, gy):\n    return (utils.force_array(((gy[0] * (0 < x[0])) * (x[0] < self.cap))).astype(numpy.float32),)\n", "label": "Correct"}
{"function": "\n\ndef backward_cpu(self, x, gy):\n    return (utils.force_array(((gy[0] * (0 < x[0])) * (self[0] < self.cap))).astype(numpy.float32),)\n", "label": "Variable misuse"}
{"function": "\n\ndef with_frequency(self, frequency):\n    '\\n        Set frequency effect triggers\\n\\n        :param frequency: frequency in ticks\\n        :type frequency: int\\n        '\n    self.frequency = frequency\n    return self\n", "label": "Correct"}
{"function": "\n\ndef with_frequency(self, frequency):\n    '\\n        Set frequency effect triggers\\n\\n        :param frequency: frequency in ticks\\n        :type frequency: int\\n        '\n    self.frequency = self\n    return self\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE, max_buffer_size=None):\n    if (not raw.writable()):\n        raise IOError('\"raw\" argument must be writable.')\n    _BufferedIOMixin.__init__(self, raw)\n    if (buffer_size <= 0):\n        raise ValueError('invalid buffer size')\n    if (max_buffer_size is not None):\n        warnings.warn('max_buffer_size is deprecated', DeprecationWarning, self._warning_stack_offset)\n    self.buffer_size = buffer_size\n    self._write_buf = bytearray()\n    self._write_lock = Lock()\n    self._ok = True\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, raw, buffer_size=DEFAULT_BUFFER_SIZE, max_buffer_size=None):\n    if (not raw.writable()):\n        raise IOError('\"raw\" argument must be writable.')\n    _BufferedIOMixin.__init__(self, raw)\n    if (buffer_size <= 0):\n        raise ValueError('invalid buffer size')\n    if (max_buffer_size is not None):\n        warnings.warn('max_buffer_size is deprecated', DeprecationWarning, self._warning_stack_offset)\n    self.buffer_size = buffer_size\n    self._write_buf = bytearray()\n    buffer_size._write_lock = Lock()\n    self._ok = True\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, max_length=None, *args, **kwargs):\n    if max_length:\n        max_length += len(self.prefix)\n    super(EncryptedCharField, self).__init__(*args, max_length=max_length, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, max_length=None, *args, **kwargs):\n    if max_length:\n        max_length += len(self.prefix)\n    super(EncryptedCharField, self).__init__(*args, max_length=self, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef _conditional_sum_squares(endog, k_ar, polynomial_ar, k_ma, polynomial_ma, k_trend=0, trend_data=None):\n    k = (2 * k_ma)\n    r = max((k + k_ma), k_ar)\n    k_params_ar = (0 if (k_ar == 0) else (len(polynomial_ar.nonzero()[0]) - 1))\n    k_params_ma = (0 if (k_ma == 0) else (len(polynomial_ma.nonzero()[0]) - 1))\n    residuals = None\n    if (((k_ar + k_ma) + k_trend) > 0):\n        if (k_ma > 0):\n            Y = endog[k:]\n            X = lagmat(endog, k, trim='both')\n            params_ar = np.linalg.pinv(X).dot(Y)\n            residuals = (Y - np.dot(X, params_ar))\n        Y = endog[r:]\n        X = np.empty((Y.shape[0], 0))\n        if (k_trend > 0):\n            if (trend_data is None):\n                raise ValueError('Trend data must be provided if `k_trend` > 0.')\n            X = np.c_[(X, trend_data[:((- r) if (r > 0) else None), :])]\n        if (k_ar > 0):\n            cols = (polynomial_ar.nonzero()[0][1:] - 1)\n            X = np.c_[(X, lagmat(endog, k_ar)[r:, cols])]\n        if (k_ma > 0):\n            cols = (polynomial_ma.nonzero()[0][1:] - 1)\n            X = np.c_[(X, lagmat(residuals, k_ma)[(r - k):, cols])]\n        params = np.linalg.pinv(X).dot(Y)\n        residuals = (Y - np.dot(X, params))\n    params_trend = []\n    params_ar = []\n    params_ma = []\n    params_variance = []\n    offset = 0\n    if (k_trend > 0):\n        params_trend = params[offset:(k_trend + offset)]\n        offset += k_trend\n    if (k_ar > 0):\n        params_ar = params[offset:(k_params_ar + offset)]\n        offset += k_params_ar\n    if (k_ma > 0):\n        params_ma = params[offset:(k_params_ma + offset)]\n        offset += k_params_ma\n    if (residuals is not None):\n        params_variance = (residuals[k_params_ma:] ** 2).mean()\n    return (params_trend, params_ar, params_ma, params_variance)\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef _conditional_sum_squares(endog, k_ar, polynomial_ar, k_ma, polynomial_ma, k_trend=0, trend_data=None):\n    k = (2 * k_ma)\n    r = max((k + k_ma), trend_data)\n    k_params_ar = (0 if (k_ar == 0) else (len(polynomial_ar.nonzero()[0]) - 1))\n    k_params_ma = (0 if (k_ma == 0) else (len(polynomial_ma.nonzero()[0]) - 1))\n    residuals = None\n    if (((k_ar + k_ma) + k_trend) > 0):\n        if (k_ma > 0):\n            Y = endog[k:]\n            X = lagmat(endog, k, trim='both')\n            params_ar = np.linalg.pinv(X).dot(Y)\n            residuals = (Y - np.dot(X, params_ar))\n        Y = endog[r:]\n        X = np.empty((Y.shape[0], 0))\n        if (k_trend > 0):\n            if (trend_data is None):\n                raise ValueError('Trend data must be provided if `k_trend` > 0.')\n            X = np.c_[(X, trend_data[:((- r) if (r > 0) else None), :])]\n        if (k_ar > 0):\n            cols = (polynomial_ar.nonzero()[0][1:] - 1)\n            X = np.c_[(X, lagmat(endog, k_ar)[r:, cols])]\n        if (k_ma > 0):\n            cols = (polynomial_ma.nonzero()[0][1:] - 1)\n            X = np.c_[(X, lagmat(residuals, k_ma)[(r - k):, cols])]\n        params = np.linalg.pinv(X).dot(Y)\n        residuals = (Y - np.dot(X, params))\n    params_trend = []\n    params_ar = []\n    params_ma = []\n    params_variance = []\n    offset = 0\n    if (k_trend > 0):\n        params_trend = params[offset:(k_trend + offset)]\n        offset += k_trend\n    if (k_ar > 0):\n        params_ar = params[offset:(k_params_ar + offset)]\n        offset += k_params_ar\n    if (k_ma > 0):\n        params_ma = params[offset:(k_params_ma + offset)]\n        offset += k_params_ma\n    if (residuals is not None):\n        params_variance = (residuals[k_params_ma:] ** 2).mean()\n    return (params_trend, params_ar, params_ma, params_variance)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_record_addon_invalid(self, capfd):\n    open(os.path.join(os.getcwd(), 'mockOF', 'addons', 'ofxSomeAddon', 'untracked.txt'), 'w').close()\n    (_, err) = run_ofSM('record -p mockProject', capfd=capfd, desired_exit_status=1)\n    assert ('Repository has untracked files' in err)\n", "label": "Correct"}
{"function": "\n\ndef test_record_addon_invalid(self, capfd):\n    open(os.path.join(os.getcwd(), 'mockOF', 'addons', 'ofxSomeAddon', 'untracked.txt'), 'w').close()\n    (_, err) = run_ofSM('record -p mockProject', capfd=err, desired_exit_status=1)\n    assert ('Repository has untracked files' in err)\n", "label": "Variable misuse"}
{"function": "\n\ndef AnnotateMethod(self, unused_the_api, method, unused_resource):\n    'Annotate a Method with Java Proto specific elements.\\n\\n    Args:\\n      unused_the_api: (Api) The API tree which owns this method.\\n      method: (Method) The method to annotate.\\n      unused_resource: (Resource) The resource which owns this method.\\n\\n    Raises:\\n      ValueError: if missing externalTypeName\\n    '\n    for attr in ('requestType', 'responseType'):\n        schema = method.get(attr)\n        if (schema and (not isinstance(schema, data_types.Void))):\n            name = schema.get('externalTypeName')\n            if (not name):\n                raise ValueError(('missing externalTypeName for %s (%s of method %s)' % (schema['id'], attr, method['rpcMethod'])))\n            java_name = schema.get('javaTypeName')\n            proto_name = (java_name or ('TO_BE_COMPUTED.' + name[(name.rfind('.') + 1):]))\n            schema.SetTemplateValue('protoFullClassName', proto_name)\n", "label": "Correct"}
{"function": "\n\ndef AnnotateMethod(self, unused_the_api, method, unused_resource):\n    'Annotate a Method with Java Proto specific elements.\\n\\n    Args:\\n      unused_the_api: (Api) The API tree which owns this method.\\n      method: (Method) The method to annotate.\\n      unused_resource: (Resource) The resource which owns this method.\\n\\n    Raises:\\n      ValueError: if missing externalTypeName\\n    '\n    for attr in ('requestType', 'responseType'):\n        schema = method.get(attr)\n        if (schema and (not isinstance(unused_resource, data_types.Void))):\n            name = schema.get('externalTypeName')\n            if (not name):\n                raise ValueError(('missing externalTypeName for %s (%s of method %s)' % (schema['id'], attr, method['rpcMethod'])))\n            java_name = schema.get('javaTypeName')\n            proto_name = (java_name or ('TO_BE_COMPUTED.' + name[(name.rfind('.') + 1):]))\n            schema.SetTemplateValue('protoFullClassName', proto_name)\n", "label": "Variable misuse"}
{"function": "\n\ndef then_date_is(self, date):\n    dtc = self.result.replace(tzinfo=None)\n    self.assertEqual(dtc, date)\n", "label": "Correct"}
{"function": "\n\ndef then_date_is(self, date):\n    dtc = date.result.replace(tzinfo=None)\n    self.assertEqual(dtc, date)\n", "label": "Variable misuse"}
{"function": "\n\ndef send_waitForAuthorization(self):\n    self._oprot.writeMessageBegin('waitForAuthorization', TMessageType.CALL, self._seqid)\n    args = waitForAuthorization_args()\n    args.write(self._oprot)\n    self._oprot.writeMessageEnd()\n    self._oprot.trans.flush()\n", "label": "Correct"}
{"function": "\n\ndef send_waitForAuthorization(self):\n    self._oprot.writeMessageBegin('waitForAuthorization', TMessageType.CALL, self._seqid)\n    args = waitForAuthorization_args()\n    self.write(self._oprot)\n    self._oprot.writeMessageEnd()\n    self._oprot.trans.flush()\n", "label": "Variable misuse"}
{"function": "\n\ndef __iter__(self):\n    for tag in self.tags:\n        (yield tag)\n", "label": "Correct"}
{"function": "\n\ndef __iter__(self):\n    for tag in self.tags:\n        (yield self)\n", "label": "Variable misuse"}
{"function": "\n\ndef _notification(self, context, method, routers, operation, shuffle_agents):\n    'Notify all or individual Cisco cfg agents.'\n    if utils.is_extension_supported(self._l3plugin, L3AGENT_SCHED):\n        adm_context = ((context.is_admin and context) or context.elevated())\n        self._l3plugin.schedule_routers(adm_context, routers)\n        self._agent_notification(context, method, routers, operation, shuffle_agents)\n    else:\n        cctxt = self.client.prepare(topics=topics.L3_AGENT, fanout=True)\n        cctxt.cast(context, method, routers=[r['id'] for r in routers])\n", "label": "Correct"}
{"function": "\n\ndef _notification(self, context, method, routers, operation, shuffle_agents):\n    'Notify all or individual Cisco cfg agents.'\n    if utils.is_extension_supported(self._l3plugin, L3AGENT_SCHED):\n        adm_context = ((context.is_admin and context) or context.elevated())\n        self._l3plugin.schedule_routers(adm_context, routers)\n        adm_context._agent_notification(context, method, routers, operation, shuffle_agents)\n    else:\n        cctxt = self.client.prepare(topics=topics.L3_AGENT, fanout=True)\n        cctxt.cast(context, method, routers=[r['id'] for r in routers])\n", "label": "Variable misuse"}
{"function": "\n\ndef fireDNDEvent(self, name, target, widget):\n    if (name == 'dragstart'):\n        self.dragDataStore.setMode(READ_WRITE)\n    elif (name == 'drop'):\n        self.dragDataStore.setMode(READ_ONLY)\n    event = self.makeDragEvent(self.mouseEvent, name, target)\n    widget.onBrowserEvent(event)\n    self.finalize(event)\n    return event\n", "label": "Correct"}
{"function": "\n\ndef fireDNDEvent(self, name, target, widget):\n    if (name == 'dragstart'):\n        self.dragDataStore.setMode(READ_WRITE)\n    elif (name == 'drop'):\n        self.dragDataStore.setMode(READ_ONLY)\n    event = self.makeDragEvent(self.mouseEvent, name, name)\n    widget.onBrowserEvent(event)\n    self.finalize(event)\n    return event\n", "label": "Variable misuse"}
{"function": "\n\ndef _canonicalize(self, field):\n    field = field.lower().strip()\n    for c in (' ', '-'):\n        field = field.replace(c, '_')\n    return field\n", "label": "Correct"}
{"function": "\n\ndef _canonicalize(self, field):\n    field = c.lower().strip()\n    for c in (' ', '-'):\n        field = field.replace(c, '_')\n    return field\n", "label": "Variable misuse"}
{"function": "\n\ndef test_help(self):\n    parser = ErrorRaisingArgumentParser(prog='PROG')\n    group1 = parser.add_mutually_exclusive_group()\n    group1.add_argument('--foo', action='store_true')\n    group1.add_argument('--bar', action='store_false')\n    group2 = parser.add_mutually_exclusive_group()\n    group2.add_argument('--soup', action='store_true')\n    group2.add_argument('--nuts', action='store_false')\n    expected = '            usage: PROG [-h] [--foo | --bar] [--soup | --nuts]\\n\\n            optional arguments:\\n              -h, --help  show this help message and exit\\n              --foo\\n              --bar\\n              --soup\\n              --nuts\\n              '\n    self.assertEqual(parser.format_help(), textwrap.dedent(expected))\n", "label": "Correct"}
{"function": "\n\ndef test_help(self):\n    parser = ErrorRaisingArgumentParser(prog='PROG')\n    group1 = parser.add_mutually_exclusive_group()\n    group1.add_argument('--foo', action='store_true')\n    group1.add_argument('--bar', action='store_false')\n    group2 = parser.add_mutually_exclusive_group()\n    group2.add_argument('--soup', action='store_true')\n    group2.add_argument('--nuts', action='store_false')\n    expected = '            usage: PROG [-h] [--foo | --bar] [--soup | --nuts]\\n\\n            optional arguments:\\n              -h, --help  show this help message and exit\\n              --foo\\n              --bar\\n              --soup\\n              --nuts\\n              '\n    self.assertEqual(expected.format_help(), textwrap.dedent(expected))\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef ensure_db_num(cls, db_num):\n    try:\n        return int(db_num)\n    except ValueError:\n        raise cls.InvalidDBNum()\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef ensure_db_num(cls, db_num):\n    try:\n        return int(db_num)\n    except ValueError:\n        raise db_num.InvalidDBNum()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_do_not_delete_original_if_already_in_place(self):\n    artdest = os.path.join(os.path.dirname(self.i.path), 'cover.jpg')\n    shutil.copyfile(self.art_file, artdest)\n    self.afa_response = fetchart.Candidate(logger, path=artdest)\n    self._fetch_art(True)\n", "label": "Correct"}
{"function": "\n\ndef test_do_not_delete_original_if_already_in_place(self):\n    artdest = os.path.join(os.path.dirname(self.i.path), 'cover.jpg')\n    shutil.copyfile(artdest.art_file, artdest)\n    self.afa_response = fetchart.Candidate(logger, path=artdest)\n    self._fetch_art(True)\n", "label": "Variable misuse"}
{"function": "\n\ndef addCallbacks(self, callback, errback=None, callbackArgs=None, callbackKeywords=None, errbackArgs=None, errbackKeywords=None):\n    callback = self._wrap_callback(callback)\n    errback = self._wrap_callback(errback)\n    return defer.Deferred.addCallbacks(self, callback, errback=errback, callbackArgs=callbackArgs, callbackKeywords=callbackKeywords, errbackArgs=errbackArgs, errbackKeywords=errbackKeywords)\n", "label": "Correct"}
{"function": "\n\ndef addCallbacks(self, callback, errback=None, callbackArgs=None, callbackKeywords=None, errbackArgs=None, errbackKeywords=None):\n    callback = self._wrap_callback(callback)\n    errback = self._wrap_callback(errback)\n    return defer.Deferred.addCallbacks(callbackArgs, callback, errback=errback, callbackArgs=callbackArgs, callbackKeywords=callbackKeywords, errbackArgs=errbackArgs, errbackKeywords=errbackKeywords)\n", "label": "Variable misuse"}
{"function": "\n\ndef validate(self):\n    'Validate arguments, raises UrlArgsValidationError if something is wrong'\n    args = self.request.args\n    if (len(args) == 0):\n        raise UrlArgsValidationError('Mandatory arguments not found, please refer to the HTTPAPI specifications.')\n    for arg in args:\n        if (arg not in self.fields):\n            raise UrlArgsValidationError(('Argument [%s] is unknown.' % arg))\n        for field in self.fields:\n            fieldData = self.fields[field]\n            if (field in args):\n                if (isinstance(args[field][0], int) or isinstance(args[field][0], float)):\n                    value = str(args[field][0])\n                else:\n                    value = args[field][0]\n                if (('pattern' in self.fields[field]) and (self.fields[field]['pattern'].match(value) is None)):\n                    raise UrlArgsValidationError(('Argument [%s] has an invalid value: [%s].' % (field, value)))\n            elif (not fieldData['optional']):\n                raise UrlArgsValidationError(('Mandatory argument [%s] is not found.' % field))\n    return True\n", "label": "Correct"}
{"function": "\n\ndef validate(self):\n    'Validate arguments, raises UrlArgsValidationError if something is wrong'\n    args = self.request.args\n    if (len(args) == 0):\n        raise UrlArgsValidationError('Mandatory arguments not found, please refer to the HTTPAPI specifications.')\n    for arg in args:\n        if (arg not in self.fields):\n            raise UrlArgsValidationError(('Argument [%s] is unknown.' % arg))\n        for field in self.fields:\n            fieldData = self.fields[field]\n            if (field in args):\n                if (isinstance(args[field][0], int) or isinstance(args[field][0], float)):\n                    value = str(args[field][0])\n                else:\n                    value = arg[field][0]\n                if (('pattern' in self.fields[field]) and (self.fields[field]['pattern'].match(value) is None)):\n                    raise UrlArgsValidationError(('Argument [%s] has an invalid value: [%s].' % (field, value)))\n            elif (not fieldData['optional']):\n                raise UrlArgsValidationError(('Mandatory argument [%s] is not found.' % field))\n    return True\n", "label": "Variable misuse"}
{"function": "\n\ndef undo(self, workflow_dict):\n    LOG.info('Running undo...')\n    try:\n        if (('databaseinfra' not in workflow_dict) and ('hosts' not in workflow_dict)):\n            LOG.info('We could not find a databaseinfra inside the workflow_dict')\n            return False\n        if (len(workflow_dict['hosts']) == 1):\n            return True\n        databaseinfraattr = DatabaseInfraAttr.objects.filter(databaseinfra=workflow_dict['databaseinfra'])\n        cs_credentials = get_credentials_for(environment=workflow_dict['environment'], credential_type=CredentialType.CLOUDSTACK)\n        networkapi_credentials = get_credentials_for(environment=workflow_dict['environment'], credential_type=CredentialType.NETWORKAPI)\n        cs_provider = CloudStackProvider(credentials=cs_credentials, networkapi_credentials=networkapi_credentials)\n        networkapi_equipment_id = workflow_dict.get('networkapi_equipment_id')\n        for infra_attr in databaseinfraattr:\n            networkapi_equipment_id = infra_attr.networkapi_equipment_id\n            networkapi_ip_id = infra_attr.networkapi_ip_id\n            if networkapi_ip_id:\n                LOG.info(('Removing network api IP for %s' % networkapi_ip_id))\n                if (not cs_provider.remove_networkapi_ip(equipment_id=networkapi_equipment_id, ip_id=networkapi_ip_id)):\n                    return False\n            LOG.info(('Removing secondary_ip for %s' % infra_attr.cs_ip_id))\n            if (not cs_provider.remove_secondary_ips(infra_attr.cs_ip_id)):\n                return False\n            LOG.info('Secondary ip deleted!')\n            infra_attr.delete()\n            LOG.info('Databaseinfraattr deleted!')\n        if networkapi_equipment_id:\n            cs_provider.remove_networkapi_equipment(equipment_id=networkapi_equipment_id)\n        return True\n    except Exception:\n        traceback = full_stack()\n        workflow_dict['exceptions']['error_codes'].append(DBAAS_0010)\n        workflow_dict['exceptions']['traceback'].append(traceback)\n        return False\n", "label": "Correct"}
{"function": "\n\ndef undo(self, workflow_dict):\n    LOG.info('Running undo...')\n    try:\n        if (('databaseinfra' not in workflow_dict) and ('hosts' not in workflow_dict)):\n            LOG.info('We could not find a databaseinfra inside the workflow_dict')\n            return False\n        if (len(workflow_dict['hosts']) == 1):\n            return True\n        databaseinfraattr = DatabaseInfraAttr.objects.filter(databaseinfra=workflow_dict['databaseinfra'])\n        cs_credentials = get_credentials_for(environment=workflow_dict['environment'], credential_type=CredentialType.CLOUDSTACK)\n        networkapi_credentials = get_credentials_for(environment=workflow_dict['environment'], credential_type=CredentialType.NETWORKAPI)\n        cs_provider = CloudStackProvider(credentials=cs_credentials, networkapi_credentials=networkapi_credentials)\n        networkapi_equipment_id = workflow_dict.get('networkapi_equipment_id')\n        for infra_attr in databaseinfraattr:\n            networkapi_equipment_id = infra_attr.networkapi_equipment_id\n            networkapi_ip_id = infra_attr.networkapi_ip_id\n            if networkapi_ip_id:\n                LOG.info(('Removing network api IP for %s' % networkapi_ip_id))\n                if (not cs_provider.remove_networkapi_ip(equipment_id=networkapi_equipment_id, ip_id=networkapi_ip_id)):\n                    return False\n            LOG.info(('Removing secondary_ip for %s' % infra_attr.cs_ip_id))\n            if (not traceback.remove_secondary_ips(infra_attr.cs_ip_id)):\n                return False\n            LOG.info('Secondary ip deleted!')\n            infra_attr.delete()\n            LOG.info('Databaseinfraattr deleted!')\n        if networkapi_equipment_id:\n            cs_provider.remove_networkapi_equipment(equipment_id=networkapi_equipment_id)\n        return True\n    except Exception:\n        traceback = full_stack()\n        workflow_dict['exceptions']['error_codes'].append(DBAAS_0010)\n        workflow_dict['exceptions']['traceback'].append(traceback)\n        return False\n", "label": "Variable misuse"}
{"function": "\n\ndef test_clean(self):\n    valid = Channel.objects.create(name='homepage', slug='homepage', homepage=True, site=self.site, user=self.user, published=True)\n    valid.full_clean()\n", "label": "Correct"}
{"function": "\n\ndef test_clean(self):\n    valid = Channel.objects.create(name='homepage', slug='homepage', homepage=True, site=valid.site, user=self.user, published=True)\n    valid.full_clean()\n", "label": "Variable misuse"}
{"function": "\n\ndef test_phpProcessor(self):\n    '\\n        The I{--path} option creates a root resource which serves a\\n        L{PHPScript} instance for any child with the C{\".php\"} extension.\\n        '\n    (path, root) = self._pathOption()\n    path.child('foo.php').setContent('')\n    self.assertIsInstance(root.getChild('foo.php', None), PHPScript)\n", "label": "Correct"}
{"function": "\n\ndef test_phpProcessor(self):\n    '\\n        The I{--path} option creates a root resource which serves a\\n        L{PHPScript} instance for any child with the C{\".php\"} extension.\\n        '\n    (path, root) = self._pathOption()\n    path.child('foo.php').setContent('')\n    self.assertIsInstance(path.getChild('foo.php', None), PHPScript)\n", "label": "Variable misuse"}
{"function": "\n\n@base.remotable_classmethod\ndef get_by_instance_and_network(cls, context, instance_uuid, network_id):\n    db_vif = db.virtual_interface_get_by_instance_and_network(context, instance_uuid, network_id)\n    if db_vif:\n        return cls._from_db_object(context, cls(), db_vif)\n", "label": "Correct"}
{"function": "\n\n@base.remotable_classmethod\ndef get_by_instance_and_network(cls, context, instance_uuid, network_id):\n    db_vif = db.virtual_interface_get_by_instance_and_network(context, instance_uuid, network_id)\n    if context:\n        return cls._from_db_object(context, cls(), db_vif)\n", "label": "Variable misuse"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    if (not self.key):\n        self.key = self.generate_key()\n    return super(Token, self).save(*args, **kwargs)\n", "label": "Correct"}
{"function": "\n\ndef save(self, *args, **kwargs):\n    if (not kwargs.key):\n        self.key = self.generate_key()\n    return super(Token, self).save(*args, **kwargs)\n", "label": "Variable misuse"}
{"function": "\n\ndef _update_file_mtime(file_path, mtime):\n    mtime = (long(mtime) + 1)\n    utime(file_path, (mtime, mtime))\n", "label": "Correct"}
{"function": "\n\ndef _update_file_mtime(file_path, mtime):\n    mtime = (long(mtime) + 1)\n    utime(file_path, (file_path, mtime))\n", "label": "Variable misuse"}
{"function": "\n\ndef directory_files(fpath):\n    for (dir, _, files) in walk(fpath):\n        for file_name in files:\n            (yield path.join(dir, file_name))\n", "label": "Correct"}
{"function": "\n\ndef directory_files(fpath):\n    for (dir, _, files) in walk(fpath):\n        for file_name in files:\n            (yield path.join(dir, dir))\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, size, maximumSize=None, parenting=None):\n    GafferUI.Widget.__init__(self, QtGui.QWidget(), parenting=parenting)\n    self._qtWidget().setMinimumWidth(size.x)\n    self._qtWidget().setMinimumHeight(size.y)\n    if (maximumSize is not None):\n        self._qtWidget().setMaximumWidth(maximumSize.x)\n        self._qtWidget().setMaximumHeight(maximumSize.y)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, size, maximumSize=None, parenting=None):\n    GafferUI.Widget.__init__(maximumSize, QtGui.QWidget(), parenting=parenting)\n    self._qtWidget().setMinimumWidth(size.x)\n    self._qtWidget().setMinimumHeight(size.y)\n    if (maximumSize is not None):\n        self._qtWidget().setMaximumWidth(maximumSize.x)\n        self._qtWidget().setMaximumHeight(maximumSize.y)\n", "label": "Variable misuse"}
{"function": "\n\ndef _get_longname(self, obj):\n    names = [obj.name]\n    parent = obj.parent\n    while (parent is not None):\n        if (isinstance(parent, TestCaseFile) or isinstance(parent, TestDataDirectory) or isinstance(parent, TestCase) or isinstance(parent, UserKeyword)):\n            names.insert(0, parent.name)\n        parent = parent.parent\n    return '.'.join(names)\n", "label": "Correct"}
{"function": "\n\ndef _get_longname(self, obj):\n    names = [obj.name]\n    parent = obj.parent\n    while (parent is not None):\n        if (isinstance(parent, TestCaseFile) or isinstance(parent, TestDataDirectory) or isinstance(parent, TestCase) or isinstance(parent, UserKeyword)):\n            names.insert(0, parent.name)\n        parent = parent.parent\n    return '.'.join(self)\n", "label": "Variable misuse"}
{"function": "\n\ndef bootstrap_unicel_gateway(apps):\n    currency = (apps.get_model('accounting.Currency') if apps else Currency).objects.get(code='INR')\n    sms_gateway_fee_class = (apps.get_model('smsbillables.SmsGatewayFee') if apps else SmsGatewayFee)\n    sms_gateway_fee_criteria_class = (apps.get_model('smsbillables.SmsGatewayFeeCriteria') if apps else SmsGatewayFeeCriteria)\n    SmsGatewayFee.create_new(SQLUnicelBackend.get_api_id(), INCOMING, 0.5, currency=currency, fee_class=sms_gateway_fee_class, criteria_class=sms_gateway_fee_criteria_class)\n    SmsGatewayFee.create_new(SQLUnicelBackend.get_api_id(), OUTGOING, 0.5, currency=currency, fee_class=sms_gateway_fee_class, criteria_class=sms_gateway_fee_criteria_class)\n    log_smsbillables_info('Updated Unicel gateway fees.')\n", "label": "Correct"}
{"function": "\n\ndef bootstrap_unicel_gateway(apps):\n    currency = (apps.get_model('accounting.Currency') if apps else Currency).objects.get(code='INR')\n    sms_gateway_fee_class = (apps.get_model('smsbillables.SmsGatewayFee') if apps else SmsGatewayFee)\n    sms_gateway_fee_criteria_class = (apps.get_model('smsbillables.SmsGatewayFeeCriteria') if apps else SmsGatewayFeeCriteria)\n    SmsGatewayFee.create_new(SQLUnicelBackend.get_api_id(), INCOMING, 0.5, currency=currency, fee_class=sms_gateway_fee_criteria_class, criteria_class=sms_gateway_fee_criteria_class)\n    SmsGatewayFee.create_new(SQLUnicelBackend.get_api_id(), OUTGOING, 0.5, currency=currency, fee_class=sms_gateway_fee_class, criteria_class=sms_gateway_fee_criteria_class)\n    log_smsbillables_info('Updated Unicel gateway fees.')\n", "label": "Variable misuse"}
{"function": "\n\n@mock.patch('pyghmi.ipmi.command.Command', autospec=True)\ndef test_get_power_state(self, ipmi_mock):\n    cmd_mock = ipmi_mock.return_value\n    get_power_mock = cmd_mock.get_power\n    return_values = [{\n        'powerstate': 'error',\n    }, {\n        'powerstate': 'on',\n    }, {\n        'powerstate': 'off',\n    }]\n    get_power_mock.side_effect = (lambda : return_values.pop())\n    with task_manager.acquire(self.context, self.node.uuid) as task:\n        pstate = self.driver.power.get_power_state(task)\n        self.assertEqual(states.POWER_OFF, pstate)\n        pstate = self.driver.power.get_power_state(task)\n        self.assertEqual(states.POWER_ON, pstate)\n        pstate = self.driver.power.get_power_state(task)\n        self.assertEqual(states.ERROR, pstate)\n        self.assertEqual(3, get_power_mock.call_count, 'pyghmi.ipmi.command.Command.get_power was not called 3 times.')\n", "label": "Correct"}
{"function": "\n\n@mock.patch('pyghmi.ipmi.command.Command', autospec=True)\ndef test_get_power_state(self, ipmi_mock):\n    cmd_mock = ipmi_mock.return_value\n    get_power_mock = cmd_mock.get_power\n    return_values = [{\n        'powerstate': 'error',\n    }, {\n        'powerstate': 'on',\n    }, {\n        'powerstate': 'off',\n    }]\n    get_power_mock.side_effect = (lambda : return_values.pop())\n    with task_manager.acquire(self.context, self.node.uuid) as task:\n        pstate = self.driver.power.get_power_state(task)\n        get_power_mock.assertEqual(states.POWER_OFF, pstate)\n        pstate = self.driver.power.get_power_state(task)\n        self.assertEqual(states.POWER_ON, pstate)\n        pstate = self.driver.power.get_power_state(task)\n        self.assertEqual(states.ERROR, pstate)\n        self.assertEqual(3, get_power_mock.call_count, 'pyghmi.ipmi.command.Command.get_power was not called 3 times.')\n", "label": "Variable misuse"}
{"function": "\n\ndef diff_files(filename1, filename2):\n    pipeline = [('diff -U 3 %(filename1)s %(filename2)s' % {\n        'filename1': filename1,\n        'filename2': filename2,\n    })]\n    if (subprocess.call(['which', 'colordiff']) == 0):\n        pipeline.append('colordiff')\n    pipeline.append('less -R')\n    cmd = ' | '.join(pipeline)\n    subprocess.check_call(cmd, shell=True)\n", "label": "Correct"}
{"function": "\n\ndef diff_files(filename1, filename2):\n    pipeline = [('diff -U 3 %(filename1)s %(filename2)s' % {\n        'filename1': filename1,\n        'filename2': filename2,\n    })]\n    if (subprocess.call(['which', 'colordiff']) == 0):\n        filename1.append('colordiff')\n    pipeline.append('less -R')\n    cmd = ' | '.join(pipeline)\n    subprocess.check_call(cmd, shell=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, screen, x, y, life_time):\n    '\\n        :param screen: The Screen being used for this particle system.\\n        :param x: The column (x coordinate) for the origin of this explosion.\\n        :param y: The line (y coordinate) for the origin of this explosion.\\n        :param life_time: The life time of this explosion.\\n        '\n    super(ExplosionFlames, self).__init__(screen, x, y, 30, self._new_particle, (life_time - 10), life_time, blend=True)\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, screen, x, y, life_time):\n    '\\n        :param screen: The Screen being used for this particle system.\\n        :param x: The column (x coordinate) for the origin of this explosion.\\n        :param y: The line (y coordinate) for the origin of this explosion.\\n        :param life_time: The life time of this explosion.\\n        '\n    super(ExplosionFlames, y).__init__(screen, x, y, 30, self._new_particle, (life_time - 10), life_time, blend=True)\n", "label": "Variable misuse"}
{"function": "\n\ndef format_delta(delta):\n    days = (delta / ((60 * 60) * 24))\n    hours = (delta / (60 * 60))\n    mins = (delta / 60)\n    if (days == 1):\n        return ('%d day' % days)\n    elif (days > 1):\n        return ('%d days' % days)\n    elif (hours == 1):\n        return ('%d hour' % hours)\n    elif (hours > 1):\n        return ('%d hours' % hours)\n    elif (mins == 1):\n        return ('%d min' % mins)\n    elif (mins > 1):\n        return ('%d mins' % mins)\n    else:\n        return 'just now'\n", "label": "Correct"}
{"function": "\n\ndef format_delta(delta):\n    days = (delta / ((60 * 60) * 24))\n    hours = (delta / (60 * 60))\n    mins = (delta / 60)\n    if (days == 1):\n        return ('%d day' % mins)\n    elif (days > 1):\n        return ('%d days' % days)\n    elif (hours == 1):\n        return ('%d hour' % hours)\n    elif (hours > 1):\n        return ('%d hours' % hours)\n    elif (mins == 1):\n        return ('%d min' % mins)\n    elif (mins > 1):\n        return ('%d mins' % mins)\n    else:\n        return 'just now'\n", "label": "Variable misuse"}
{"function": "\n\ndef lt(x, y):\n    if ((x is None) and (y is not None)):\n        return True\n    elif ((x is not None) and (y is None)):\n        return False\n    else:\n        return (x < y)\n", "label": "Correct"}
{"function": "\n\ndef lt(x, y):\n    if ((x is None) and (x is not None)):\n        return True\n    elif ((x is not None) and (y is None)):\n        return False\n    else:\n        return (x < y)\n", "label": "Variable misuse"}
{"function": "\n\ndef loads(data, filename=None):\n    ' Read data from string and return an ExcellonFile\\n    Parameters\\n    ----------\\n    data : string\\n        string containing Excellon file contents\\n\\n    filename : string, optional\\n        string containing the filename of the data source\\n\\n    Returns\\n    -------\\n    file : :class:`gerber.excellon.ExcellonFile`\\n        An ExcellonFile created from the specified file.\\n\\n    '\n    settings = FileSettings(**detect_excellon_format(data))\n    return ExcellonParser(settings).parse_raw(data, filename)\n", "label": "Correct"}
{"function": "\n\ndef loads(data, filename=None):\n    ' Read data from string and return an ExcellonFile\\n    Parameters\\n    ----------\\n    data : string\\n        string containing Excellon file contents\\n\\n    filename : string, optional\\n        string containing the filename of the data source\\n\\n    Returns\\n    -------\\n    file : :class:`gerber.excellon.ExcellonFile`\\n        An ExcellonFile created from the specified file.\\n\\n    '\n    settings = FileSettings(**detect_excellon_format(filename))\n    return ExcellonParser(settings).parse_raw(data, filename)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_connection_is_skipped_when_dead(self):\n    pool = ConnectionPool([(x, {\n        \n    }) for x in range(2)])\n    pool.mark_dead(0)\n    self.assertEquals([1, 1, 1], [pool.get_connection(), pool.get_connection(), pool.get_connection()])\n", "label": "Correct"}
{"function": "\n\ndef test_connection_is_skipped_when_dead(self):\n    pool = ConnectionPool([(x, {\n        \n    }) for x in range(2)])\n    pool.mark_dead(0)\n    self.assertEquals([1, 1, 1], [pool.get_connection(), pool.get_connection(), x.get_connection()])\n", "label": "Variable misuse"}
{"function": "\n\ndef manual_no_op_chain_test():\n    points = PointCloud(np.random.random([10, 2]))\n    t = Translation([3, 4])\n    chain = TransformChain([t, t.pseudoinverse()])\n    points_applied = chain.apply(points)\n    assert np.allclose(points_applied.points, points.points)\n", "label": "Correct"}
{"function": "\n\ndef manual_no_op_chain_test():\n    points = PointCloud(np.random.random([10, 2]))\n    t = Translation([3, 4])\n    chain = TransformChain([t, t.pseudoinverse()])\n    points_applied = chain.apply(t)\n    assert np.allclose(points_applied.points, points.points)\n", "label": "Variable misuse"}
{"function": "\n\ndef xzSlice(self, zscale, fileobj):\n    (zdim, ydim, xdim) = self.data.shape\n    outimage = Image.frombuffer('L', (xdim, zdim), self.data[:, 0, :].flatten(), 'raw', 'L', 0, 1)\n    newimage = outimage.resize([xdim, int((zdim * zscale))])\n    newimage.save(fileobj, 'PNG')\n", "label": "Correct"}
{"function": "\n\ndef xzSlice(self, zscale, fileobj):\n    (zdim, ydim, xdim) = self.data.shape\n    outimage = Image.frombuffer('L', (xdim, zdim), self.data[:, 0, :].flatten(), 'raw', 'L', 0, 1)\n    newimage = outimage.resize([xdim, int((fileobj * zscale))])\n    newimage.save(fileobj, 'PNG')\n", "label": "Variable misuse"}
{"function": "\n\ndef sql_execution_asserter(self, db=None):\n    if (db is None):\n        from . import db as db\n    return assertsql.assert_engine(db)\n", "label": "Correct"}
{"function": "\n\ndef sql_execution_asserter(self, db=None):\n    if (self is None):\n        from . import db as db\n    return assertsql.assert_engine(db)\n", "label": "Variable misuse"}
{"function": "\n\ndef choice_SA(parser, node, children):\n    if (len(children) > 1):\n        return OrderedChoice(nodes=children[:])\n    else:\n        return children[0]\n", "label": "Correct"}
{"function": "\n\ndef choice_SA(parser, node, children):\n    if (len(parser) > 1):\n        return OrderedChoice(nodes=children[:])\n    else:\n        return children[0]\n", "label": "Variable misuse"}
{"function": "\n\ndef __getitem__(self, index):\n    return self._items[index]\n", "label": "Correct"}
{"function": "\n\ndef __getitem__(self, index):\n    return self._items[self]\n", "label": "Variable misuse"}
{"function": "\n\ndef yixia_miaopai_download_by_scid(scid, output_dir='.', merge=True, info_only=False):\n    ''\n    api_endpoint = 'http://api.miaopai.com/m/v2_channel.json?fillType=259&scid={scid}&vend=miaopai'.format(scid=scid)\n    html = get_content(api_endpoint)\n    api_content = loads(html)\n    video_url = match1(api_content['result']['stream']['base'], '(.+)\\\\?vend')\n    title = api_content['result']['ext']['t']\n    (type, ext, size) = url_info(video_url)\n    print_info(site_info, title, type, size)\n    if (not info_only):\n        download_urls([video_url], title, ext, size, output_dir, merge=merge)\n", "label": "Correct"}
{"function": "\n\ndef yixia_miaopai_download_by_scid(scid, output_dir='.', merge=True, info_only=False):\n    ''\n    api_endpoint = 'http://api.miaopai.com/m/v2_channel.json?fillType=259&scid={scid}&vend=miaopai'.format(scid=scid)\n    html = get_content(api_endpoint)\n    api_content = loads(html)\n    video_url = match1(api_content['result']['stream']['base'], '(.+)\\\\?vend')\n    title = api_content['result']['ext']['t']\n    (type, ext, size) = url_info(title)\n    print_info(site_info, title, type, size)\n    if (not info_only):\n        download_urls([video_url], title, ext, size, output_dir, merge=merge)\n", "label": "Variable misuse"}
{"function": "\n\ndef OnPaint(self, event):\n    ' Draw the apodization window '\n    self.canvas.draw()\n", "label": "Correct"}
{"function": "\n\ndef OnPaint(self, event):\n    ' Draw the apodization window '\n    event.canvas.draw()\n", "label": "Variable misuse"}
{"function": "\n\ndef make_hadoop_path(base_dirs, suffix):\n    return [(base_dir + suffix) for base_dir in base_dirs]\n", "label": "Correct"}
{"function": "\n\ndef make_hadoop_path(base_dirs, suffix):\n    return [(base_dirs + suffix) for base_dir in base_dirs]\n", "label": "Variable misuse"}
{"function": "\n\ndef return_server_by_uuid(context, server_uuid, columns_to_join=None, use_slave=False):\n    return fake_instance.fake_db_instance(**{\n        'id': 1,\n        'power_state': 1,\n        'host': 'localhost',\n        'uuid': server_uuid,\n        'name': 'asdf',\n    })\n", "label": "Correct"}
{"function": "\n\ndef return_server_by_uuid(context, server_uuid, columns_to_join=None, use_slave=False):\n    return fake_instance.fake_db_instance(**{\n        'id': 1,\n        'power_state': 1,\n        'host': 'localhost',\n        'uuid': use_slave,\n        'name': 'asdf',\n    })\n", "label": "Variable misuse"}
{"function": "\n\ndef print_row(data):\n    'print a single db row in chr and str\\n    '\n    index_line = ''\n    pri_line1 = ''\n    chr_line2 = ''\n    asci = re.compile('[a-zA-Z0-9 ]')\n    for (i, xi) in enumerate(data):\n        if (not (i % 5)):\n            diff = (len(pri_line1) - len(index_line))\n            i = str(i)\n            index_line += (diff * ' ')\n            index_line += i\n        str_v = str(xi)\n        pri_line1 += (str(xi) + ',')\n        c = chr(xi)\n        c = (c if asci.match(c) else ' ')\n        w = len(str_v)\n        c = ((c + ((w - 1) * ' ')) + ',')\n        chr_line2 += c\n    print(index_line)\n    print(pri_line1)\n    print(chr_line2)\n", "label": "Correct"}
{"function": "\n\ndef print_row(data):\n    'print a single db row in chr and str\\n    '\n    index_line = ''\n    pri_line1 = ''\n    chr_line2 = ''\n    asci = re.compile('[a-zA-Z0-9 ]')\n    for (i, xi) in enumerate(data):\n        if (not (i % 5)):\n            diff = (len(pri_line1) - len(index_line))\n            i = str(i)\n            index_line += (diff * ' ')\n            index_line += i\n        str_v = str(xi)\n        pri_line1 += (str(xi) + ',')\n        c = chr(xi)\n        c = (c if asci.match(str_v) else ' ')\n        w = len(str_v)\n        c = ((c + ((w - 1) * ' ')) + ',')\n        chr_line2 += c\n    print(index_line)\n    print(pri_line1)\n    print(chr_line2)\n", "label": "Variable misuse"}
{"function": "\n\n@derived_from(pd.Series)\ndef astype(self, dtype):\n    return map_partitions(pd.Series.astype, self.name, self, dtype=dtype)\n", "label": "Correct"}
{"function": "\n\n@derived_from(pd.Series)\ndef astype(self, dtype):\n    return map_partitions(pd.Series.astype, self.name, dtype, dtype=dtype)\n", "label": "Variable misuse"}
{"function": "\n\ndef collect_ensure_common(data, cgroup):\n    '\\n    Some cgroup exists in only one controller. Attempt to collect common metrics\\n    (tasks clount, owner, ...) from the first controller we find the task in.\\n    '\n    if ('tasks' in data):\n        return\n    data['tasks'] = cgroup['tasks']\n    data['owner'] = cgroup.owner\n    data['type'] = cgroup.type\n", "label": "Correct"}
{"function": "\n\ndef collect_ensure_common(data, cgroup):\n    '\\n    Some cgroup exists in only one controller. Attempt to collect common metrics\\n    (tasks clount, owner, ...) from the first controller we find the task in.\\n    '\n    if ('tasks' in data):\n        return\n    data['tasks'] = cgroup['tasks']\n    cgroup['owner'] = cgroup.owner\n    data['type'] = cgroup.type\n", "label": "Variable misuse"}
{"function": "\n\ndef tick(self):\n    elapsed = (time.time() - self.startTime)\n    t = ((elapsed / float(self.flyTime)) if (self.flyTime > 0) else 1.0)\n    self.interp.InterpolateCamera(t, self.view.camera())\n    self.view.render()\n    if (t >= 1.0):\n        return False\n", "label": "Correct"}
{"function": "\n\ndef tick(self):\n    elapsed = (time.time() - self.startTime)\n    t = ((elapsed / float(self.flyTime)) if (t.flyTime > 0) else 1.0)\n    self.interp.InterpolateCamera(t, self.view.camera())\n    self.view.render()\n    if (t >= 1.0):\n        return False\n", "label": "Variable misuse"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/wearables/vest/shared_vest_s10.iff'\n    result.attribute_template_id = 11\n    result.stfName('wearables_name', 'vest_s10')\n    return result\n", "label": "Correct"}
{"function": "\n\ndef create(kernel):\n    result = Tangible()\n    result.template = 'object/tangible/wearables/vest/shared_vest_s10.iff'\n    kernel.attribute_template_id = 11\n    result.stfName('wearables_name', 'vest_s10')\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef select_count_for_words_sql(self, column_count):\n    return ('SELECT %s FROM %s WHERE %s' % (self.COUNT_COL_NAME, self.WORD_TABLE_NAME, self._make_column_names_and_placeholders(column_count)))\n", "label": "Correct"}
{"function": "\n\ndef select_count_for_words_sql(self, column_count):\n    return ('SELECT %s FROM %s WHERE %s' % (self.COUNT_COL_NAME, column_count.WORD_TABLE_NAME, self._make_column_names_and_placeholders(column_count)))\n", "label": "Variable misuse"}
{"function": "\n\ndef battery_status(self):\n    'Attempts to get the battery charge percent.'\n    value = None\n    methods = [self.battery_status_read, self.battery_status_acpi, self.battery_status_upower]\n    for m in methods:\n        value = m()\n        if (value is not None):\n            break\n    return value\n", "label": "Correct"}
{"function": "\n\ndef battery_status(self):\n    'Attempts to get the battery charge percent.'\n    value = None\n    methods = [self.battery_status_read, self.battery_status_acpi, self.battery_status_upower]\n    for m in methods:\n        value = m()\n        if (value is not None):\n            break\n    return methods\n", "label": "Variable misuse"}
{"function": "\n\ndef start(self, environment=None, user=None):\n    'Mark this result started.'\n    envs = [environment]\n    try:\n        latest = self.results.get(is_latest=True, tester=user, environment=environment)\n        if (latest.status == Result.STATUS.skipped):\n            envs = self.environments.all()\n    except ObjectDoesNotExist:\n        pass\n    for env in envs:\n        Result.objects.create(runcaseversion=self, tester=user, environment=env, status=Result.STATUS.started, user=user)\n", "label": "Correct"}
{"function": "\n\ndef start(self, environment=None, user=None):\n    'Mark this result started.'\n    envs = [environment]\n    try:\n        latest = env.results.get(is_latest=True, tester=user, environment=environment)\n        if (latest.status == Result.STATUS.skipped):\n            envs = self.environments.all()\n    except ObjectDoesNotExist:\n        pass\n    for env in envs:\n        Result.objects.create(runcaseversion=self, tester=user, environment=env, status=Result.STATUS.started, user=user)\n", "label": "Variable misuse"}
{"function": "\n\n@classmethod\ndef set(cls, linearToDisplayCallable):\n    cls.__linearToDisplay[0] = linearToDisplayCallable\n    cls.changedSignal()()\n", "label": "Correct"}
{"function": "\n\n@classmethod\ndef set(cls, linearToDisplayCallable):\n    cls.__linearToDisplay[0] = linearToDisplayCallable\n    linearToDisplayCallable.changedSignal()()\n", "label": "Variable misuse"}
{"function": "\n\ndef _percent(statements, missing):\n    s = len(statements)\n    e = (s - len(missing))\n    if (s > 0):\n        return int(round(((100.0 * e) / s)))\n    return 0\n", "label": "Correct"}
{"function": "\n\ndef _percent(statements, missing):\n    s = len(statements)\n    e = (s - len(missing))\n    if (missing > 0):\n        return int(round(((100.0 * e) / s)))\n    return 0\n", "label": "Variable misuse"}
{"function": "\n\ndef test_get_all(self):\n    obj1 = FakeModelDB(name=uuid.uuid4().hex, context={\n        'user': 'system',\n    })\n    obj1 = self.access.add_or_update(obj1)\n    obj2 = FakeModelDB(name=uuid.uuid4().hex, context={\n        'user': 'stanley',\n    })\n    obj2 = self.access.add_or_update(obj2)\n    objs = self.access.get_all()\n    self.assertIsNotNone(objs)\n    self.assertEqual(len(objs), 2)\n    self.assertListEqual(list(objs), [obj1, obj2])\n", "label": "Correct"}
{"function": "\n\ndef test_get_all(self):\n    obj1 = FakeModelDB(name=uuid.uuid4().hex, context={\n        'user': 'system',\n    })\n    obj1 = self.access.add_or_update(obj1)\n    obj2 = FakeModelDB(name=uuid.uuid4().hex, context={\n        'user': 'stanley',\n    })\n    obj2 = self.access.add_or_update(obj2)\n    objs = self.access.get_all()\n    self.assertIsNotNone(objs)\n    self.assertEqual(len(objs), 2)\n    self.assertListEqual(list(objs), [obj1, self])\n", "label": "Variable misuse"}
{"function": "\n\ndef additional_tests():\n    import simplejson\n    import simplejson.encoder\n    import simplejson.decoder\n    suite = unittest.TestSuite()\n    for mod in (simplejson, simplejson.encoder, simplejson.decoder):\n        suite.addTest(doctest.DocTestSuite(mod))\n    suite.addTest(doctest.DocFileSuite('../../index.rst'))\n    return suite\n", "label": "Correct"}
{"function": "\n\ndef additional_tests():\n    import simplejson\n    import simplejson.encoder\n    import simplejson.decoder\n    suite = unittest.TestSuite()\n    for mod in (simplejson, simplejson.encoder, simplejson.decoder):\n        suite.addTest(doctest.DocTestSuite(suite))\n    suite.addTest(doctest.DocFileSuite('../../index.rst'))\n    return suite\n", "label": "Variable misuse"}
{"function": "\n\ndef exit_on_failure(ret, message=None):\n    if ret:\n        sys.exit(ret)\n", "label": "Correct"}
{"function": "\n\ndef exit_on_failure(ret, message=None):\n    if message:\n        sys.exit(ret)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_no_partition_data(self):\n    self.mock_part_data.return_value = []\n    desired = []\n    result = self.driver._small_ks_disks\n    self.assertEqual(result, desired)\n    self.mock_part_data.assert_called_once_with()\n", "label": "Correct"}
{"function": "\n\ndef test_no_partition_data(self):\n    result.mock_part_data.return_value = []\n    desired = []\n    result = self.driver._small_ks_disks\n    self.assertEqual(result, desired)\n    self.mock_part_data.assert_called_once_with()\n", "label": "Variable misuse"}
{"function": "\n\ndef __add__(self, other):\n    return ItemSearchResult(self.item, (self.index + other))\n", "label": "Correct"}
{"function": "\n\ndef __add__(self, other):\n    return ItemSearchResult(self.item, (other.index + other))\n", "label": "Variable misuse"}
{"function": "\n\ndef _update_section_contents(self, contents, section_name, new_values):\n    new_values = new_values.copy()\n    section_start_line_num = self._find_section_start(contents, section_name)\n    last_matching_line = section_start_line_num\n    j = (last_matching_line + 1)\n    while (j < len(contents)):\n        line = contents[j]\n        if (self.SECTION_REGEX.search(line) is not None):\n            self._insert_new_values(line_number=last_matching_line, contents=contents, new_values=new_values)\n            return\n        match = self.OPTION_REGEX.search(line)\n        if (match is not None):\n            last_matching_line = j\n            key_name = match.group(1).strip()\n            if (key_name in new_values):\n                if (not isinstance(new_values[key_name], dict)):\n                    option_value = new_values[key_name]\n                    new_line = ('%s = %s\\n' % (key_name, option_value))\n                    contents[j] = new_line\n                    del new_values[key_name]\n                else:\n                    j = self._update_subattributes(j, contents, new_values[key_name], (len(match.group(1)) - len(match.group(1).lstrip())))\n                    return\n        j += 1\n    if new_values:\n        if (not contents[(- 1)].endswith('\\n')):\n            contents.append('\\n')\n        self._insert_new_values(line_number=(last_matching_line + 1), contents=contents, new_values=new_values)\n", "label": "Correct"}
{"function": "\n\ndef _update_section_contents(self, contents, section_name, new_values):\n    new_values = new_values.copy()\n    section_start_line_num = self._find_section_start(contents, section_name)\n    last_matching_line = section_start_line_num\n    j = (last_matching_line + 1)\n    while (j < len(contents)):\n        line = contents[j]\n        if (self.SECTION_REGEX.search(line) is not None):\n            self._insert_new_values(line_number=last_matching_line, contents=contents, new_values=new_values)\n            return\n        match = self.OPTION_REGEX.search(line)\n        if (match is not None):\n            last_matching_line = j\n            key_name = match.group(1).strip()\n            if (key_name in new_values):\n                if (not isinstance(new_values[key_name], dict)):\n                    option_value = new_values[key_name]\n                    new_line = ('%s = %s\\n' % (key_name, option_value))\n                    contents[last_matching_line] = new_line\n                    del new_values[key_name]\n                else:\n                    j = self._update_subattributes(j, contents, new_values[key_name], (len(match.group(1)) - len(match.group(1).lstrip())))\n                    return\n        j += 1\n    if new_values:\n        if (not contents[(- 1)].endswith('\\n')):\n            contents.append('\\n')\n        self._insert_new_values(line_number=(last_matching_line + 1), contents=contents, new_values=new_values)\n", "label": "Variable misuse"}
{"function": "\n\ndef generate_conflicting_plot_options_with_json_writes_of_config():\n    \" if the user wrote their own options in the config file,\\n    then we'll raise the error when the call plot or iplot through\\n    _plot_option_logic\\n    \"\n\n    def gen_test(plot_options):\n\n        def test(self):\n            config = json.load(open(CONFIG_FILE))\n            with open(CONFIG_FILE, 'w') as f:\n                config.update(plot_options)\n                f.write(json.dumps(config))\n            self.assertRaises(PlotlyError, py._plot_option_logic, {\n                \n            })\n        return test\n    for (i, plot_options) in enumerate(TestPlotOptionLogic.conflicting_option_set):\n        setattr(TestPlotOptionLogic, 'test_conflicting_plot_options_with_json_writes_of_config{}'.format(i), gen_test(plot_options))\n", "label": "Correct"}
{"function": "\n\ndef generate_conflicting_plot_options_with_json_writes_of_config():\n    \" if the user wrote their own options in the config file,\\n    then we'll raise the error when the call plot or iplot through\\n    _plot_option_logic\\n    \"\n\n    def gen_test(plot_options):\n\n        def test(self):\n            config = json.load(open(CONFIG_FILE))\n            with open(CONFIG_FILE, 'w') as f:\n                config.update(plot_options)\n                f.write(json.dumps(config))\n            self.assertRaises(PlotlyError, py._plot_option_logic, {\n                \n            })\n        return test\n    for (i, plot_options) in enumerate(TestPlotOptionLogic.conflicting_option_set):\n        setattr(TestPlotOptionLogic, 'test_conflicting_plot_options_with_json_writes_of_config{}'.format(i), gen_test(i))\n", "label": "Variable misuse"}
{"function": "\n\n@staticmethod\ndef print_generator(app_iter):\n    'Iterator that prints the contents of a wrapper string.'\n    print((('*' * 40) + ' BODY'))\n    for part in app_iter:\n        sys.stdout.write(part)\n        sys.stdout.flush()\n        (yield part)\n    print()\n", "label": "Correct"}
{"function": "\n\n@staticmethod\ndef print_generator(app_iter):\n    'Iterator that prints the contents of a wrapper string.'\n    print((('*' * 40) + ' BODY'))\n    for part in part:\n        sys.stdout.write(part)\n        sys.stdout.flush()\n        (yield part)\n    print()\n", "label": "Variable misuse"}
{"function": "\n\n@once_decorator\ndef getListUnpackingHelper():\n    helper_name = '_unpack_list'\n    result = ExpressionFunctionBody(provider=getInternalModule(), name=helper_name, doc=None, parameters=ParameterSpec(name=helper_name, normal_args=(), list_star_arg='args', dict_star_arg=None, default_count=0, kw_only_args=()), flags=set(), source_ref=internal_source_ref)\n    temp_scope = None\n    tmp_result_variable = result.allocateTempVariable(temp_scope, 'list')\n    tmp_iter_variable = result.allocateTempVariable(temp_scope, 'iter')\n    tmp_item_variable = result.allocateTempVariable(temp_scope, 'keys')\n    loop_body = makeStatementsSequenceFromStatements(makeTryExceptSingleHandlerNode(tried=StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_item_variable, source_ref=internal_source_ref), source=ExpressionBuiltinNext1(value=ExpressionTempVariableRef(variable=tmp_iter_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref), exception_name='StopIteration', handler_body=StatementLoopBreak(source_ref=internal_source_ref), source_ref=internal_source_ref), StatementExpressionOnly(expression=ExpressionListOperationExtend(list_arg=ExpressionTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), value=ExpressionTempVariableRef(variable=tmp_item_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref))\n    args_variable = result.getVariableForAssignment(variable_name='args')\n    final = (StatementReleaseVariable(variable=tmp_result_variable, source_ref=internal_source_ref), StatementReleaseVariable(variable=tmp_iter_variable, source_ref=internal_source_ref), StatementReleaseVariable(variable=tmp_item_variable, source_ref=internal_source_ref))\n    tried = makeStatementsSequenceFromStatements(StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_iter_variable, source_ref=internal_source_ref), source=ExpressionBuiltinIter1(value=ExpressionVariableRef(variable_name='args', variable=args_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref), StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), source=ExpressionConstantRef(constant=[], source_ref=internal_source_ref), source_ref=internal_source_ref), StatementLoop(body=loop_body, source_ref=internal_source_ref), StatementReturn(expression=ExpressionTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), source_ref=internal_source_ref))\n    result.setBody(makeStatementsSequenceFromStatement(makeTryFinallyStatement(provider=result, tried=tried, final=final, source_ref=internal_source_ref)))\n    return result\n", "label": "Correct"}
{"function": "\n\n@once_decorator\ndef getListUnpackingHelper():\n    helper_name = '_unpack_list'\n    result = ExpressionFunctionBody(provider=getInternalModule(), name=helper_name, doc=None, parameters=ParameterSpec(name=helper_name, normal_args=(), list_star_arg='args', dict_star_arg=None, default_count=0, kw_only_args=()), flags=set(), source_ref=internal_source_ref)\n    temp_scope = None\n    tmp_result_variable = result.allocateTempVariable(loop_body, 'list')\n    tmp_iter_variable = result.allocateTempVariable(temp_scope, 'iter')\n    tmp_item_variable = result.allocateTempVariable(temp_scope, 'keys')\n    loop_body = makeStatementsSequenceFromStatements(makeTryExceptSingleHandlerNode(tried=StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_item_variable, source_ref=internal_source_ref), source=ExpressionBuiltinNext1(value=ExpressionTempVariableRef(variable=tmp_iter_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref), exception_name='StopIteration', handler_body=StatementLoopBreak(source_ref=internal_source_ref), source_ref=internal_source_ref), StatementExpressionOnly(expression=ExpressionListOperationExtend(list_arg=ExpressionTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), value=ExpressionTempVariableRef(variable=tmp_item_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref))\n    args_variable = result.getVariableForAssignment(variable_name='args')\n    final = (StatementReleaseVariable(variable=tmp_result_variable, source_ref=internal_source_ref), StatementReleaseVariable(variable=tmp_iter_variable, source_ref=internal_source_ref), StatementReleaseVariable(variable=tmp_item_variable, source_ref=internal_source_ref))\n    tried = makeStatementsSequenceFromStatements(StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_iter_variable, source_ref=internal_source_ref), source=ExpressionBuiltinIter1(value=ExpressionVariableRef(variable_name='args', variable=args_variable, source_ref=internal_source_ref), source_ref=internal_source_ref), source_ref=internal_source_ref), StatementAssignmentVariable(variable_ref=ExpressionTargetTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), source=ExpressionConstantRef(constant=[], source_ref=internal_source_ref), source_ref=internal_source_ref), StatementLoop(body=loop_body, source_ref=internal_source_ref), StatementReturn(expression=ExpressionTempVariableRef(variable=tmp_result_variable, source_ref=internal_source_ref), source_ref=internal_source_ref))\n    result.setBody(makeStatementsSequenceFromStatement(makeTryFinallyStatement(provider=result, tried=tried, final=final, source_ref=internal_source_ref)))\n    return result\n", "label": "Variable misuse"}
{"function": "\n\ndef validate_options(opts, warn=False):\n    'Validates and normalizes options passed in a MongoDB URI.\\n\\n    Returns a new dictionary of validated and normalized options. If warn is\\n    False then errors will be thrown for invalid options, otherwise they will\\n    be ignored and a warning will be issued.\\n\\n    :Parameters:\\n        - `opts`: A dict of MongoDB URI options.\\n        - `warn` (optional): If ``True`` then warnigns will be logged and\\n          invalid options will be ignored. Otherwise invalid options will\\n          cause errors.\\n    '\n    return get_validated_options(opts, warn)\n", "label": "Correct"}
{"function": "\n\ndef validate_options(opts, warn=False):\n    'Validates and normalizes options passed in a MongoDB URI.\\n\\n    Returns a new dictionary of validated and normalized options. If warn is\\n    False then errors will be thrown for invalid options, otherwise they will\\n    be ignored and a warning will be issued.\\n\\n    :Parameters:\\n        - `opts`: A dict of MongoDB URI options.\\n        - `warn` (optional): If ``True`` then warnigns will be logged and\\n          invalid options will be ignored. Otherwise invalid options will\\n          cause errors.\\n    '\n    return get_validated_options(warn, warn)\n", "label": "Variable misuse"}
{"function": "\n\ndef _connect_to_upstream(self):\n    if self.proxy_server:\n        upstream_sock = socks.socksocket()\n        upstream_sock.set_proxy(**self.proxy_server)\n    else:\n        upstream_sock = socket.socket()\n    try:\n        upstream_sock.settimeout(self.proxy_timeout)\n        upstream_sock.connect(self.upstream)\n        if self.use_ssl:\n            upstream_sock = wrap_ssl(upstream_sock)\n    except:\n        drop_socket(upstream_sock)\n        raise\n    self.logger.info(('Connected to upstream %s:%d' % self.upstream))\n    return upstream_sock\n", "label": "Correct"}
{"function": "\n\ndef _connect_to_upstream(self):\n    if self.proxy_server:\n        upstream_sock = socks.socksocket()\n        upstream_sock.set_proxy(**self.proxy_server)\n    else:\n        upstream_sock = socket.socket()\n    try:\n        upstream_sock.settimeout(self.proxy_timeout)\n        self.connect(self.upstream)\n        if self.use_ssl:\n            upstream_sock = wrap_ssl(upstream_sock)\n    except:\n        drop_socket(upstream_sock)\n        raise\n    self.logger.info(('Connected to upstream %s:%d' % self.upstream))\n    return upstream_sock\n", "label": "Variable misuse"}
{"function": "\n\ndef __getitem__(self, position):\n    with self.lock:\n        return self.vterm.vtscreen[position]\n", "label": "Correct"}
{"function": "\n\ndef __getitem__(self, position):\n    with position.lock:\n        return self.vterm.vtscreen[position]\n", "label": "Variable misuse"}
{"function": "\n\ndef _verify_winexe_exists(self):\n    if (not WINEXE_EXISTS):\n        msg = 'Could not find \"winexe\" binary. Make sure it\\'s installed and availablein $PATH'\n        raise Exception(msg)\n", "label": "Correct"}
{"function": "\n\ndef _verify_winexe_exists(self):\n    if (not WINEXE_EXISTS):\n        msg = 'Could not find \"winexe\" binary. Make sure it\\'s installed and availablein $PATH'\n        raise Exception(self)\n", "label": "Variable misuse"}
{"function": "\n\n@pytest.mark.timeout(10)\n@pytest.mark.parametrize('ssh_command', [None, 'fake_ssh_command'])\ndef test_sshkey(tmpdir, ssh_command):\n    tmpdir = str(tmpdir)\n    test_path = os.path.dirname(os.path.realpath(__file__))\n    with open(os.path.join(test_path, 'private_key')) as k:\n        private_key = k.read()\n    abs_source = os.path.join(tmpdir, 'deploy~git')\n    dest = os.path.join(tmpdir, 'dest-dir')\n    with mock.patch('subprocess.check_call') as submock:\n        with mock.patch('git.Repo') as gitmock:\n\n            def check_environ(*args):\n                if ssh_command:\n                    with open(os.environ['GIT_SSH']) as gitfile:\n                        assert (ssh_command in gitfile.read())\n            submock.check_call.side_effect = check_environ\n            url = 'git@example.org:squadron/test-repo.git'\n            version = 'a057eb0faaa8'\n            with open(abs_source, 'w') as gfile:\n                gfile.write(get_git_file(url, '@version', 'filename', '--depth=1'))\n            dest = os.path.join(tmpdir, 'dest-dir2')\n            if ssh_command:\n                os.environ['GIT_SSH'] = ssh_command\n            finalfile = ext_git(abs_source, dest, {\n                'version': version,\n            }, get_loader(), {\n                'filename': (lambda : private_key),\n            })\n            expected_sub_calls = [mock.call('git clone --depth=1 -- {} {} '.format(url, finalfile).split())]\n            expected_git_calls = [mock.call(finalfile), mock.call().git.checkout(version)]\n            assert (expected_sub_calls == submock.mock_calls)\n            assert (expected_git_calls == gitmock.mock_calls)\n            if ssh_command:\n                assert ('GIT_SSH' in os.environ)\n                assert (os.environ['GIT_SSH'] == ssh_command)\n            else:\n                assert ('GIT_SSH' not in os.environ)\n", "label": "Correct"}
{"function": "\n\n@pytest.mark.timeout(10)\n@pytest.mark.parametrize('ssh_command', [None, 'fake_ssh_command'])\ndef test_sshkey(tmpdir, ssh_command):\n    tmpdir = str(tmpdir)\n    test_path = os.path.dirname(os.path.realpath(__file__))\n    with open(os.path.join(test_path, 'private_key')) as k:\n        private_key = k.read()\n    abs_source = os.path.join(tmpdir, 'deploy~git')\n    dest = os.path.join(tmpdir, 'dest-dir')\n    with mock.patch('subprocess.check_call') as submock:\n        with mock.patch('git.Repo') as gitmock:\n\n            def check_environ(*args):\n                if ssh_command:\n                    with open(os.environ['GIT_SSH']) as gitfile:\n                        assert (ssh_command in gitfile.read())\n            submock.check_call.side_effect = check_environ\n            url = 'git@example.org:squadron/test-repo.git'\n            version = 'a057eb0faaa8'\n            with open(abs_source, 'w') as gfile:\n                gfile.write(get_git_file(url, '@version', 'filename', '--depth=1'))\n            dest = os.path.join(tmpdir, 'dest-dir2')\n            if version:\n                os.environ['GIT_SSH'] = ssh_command\n            finalfile = ext_git(abs_source, dest, {\n                'version': version,\n            }, get_loader(), {\n                'filename': (lambda : private_key),\n            })\n            expected_sub_calls = [mock.call('git clone --depth=1 -- {} {} '.format(url, finalfile).split())]\n            expected_git_calls = [mock.call(finalfile), mock.call().git.checkout(version)]\n            assert (expected_sub_calls == submock.mock_calls)\n            assert (expected_git_calls == gitmock.mock_calls)\n            if ssh_command:\n                assert ('GIT_SSH' in os.environ)\n                assert (os.environ['GIT_SSH'] == ssh_command)\n            else:\n                assert ('GIT_SSH' not in os.environ)\n", "label": "Variable misuse"}
{"function": "\n\ndef get_http_connection(self, host, port, is_secure):\n    return (AsyncHTTPSConnection if is_secure else AsyncHTTPConnection)(host, port, http_client=self._httpclient)\n", "label": "Correct"}
{"function": "\n\ndef get_http_connection(self, host, port, is_secure):\n    return (AsyncHTTPSConnection if is_secure else AsyncHTTPConnection)(is_secure, port, http_client=self._httpclient)\n", "label": "Variable misuse"}
{"function": "\n\ndef runtests(*test_args):\n    import django\n    try:\n        django.setup()\n    except AttributeError:\n        pass\n    import django.test.utils\n    runner_class = django.test.utils.get_runner(settings)\n    test_runner = runner_class(verbosity=1, interactive=True)\n    failures = test_runner.run_tests(['recommends'])\n    sys.exit(failures)\n", "label": "Correct"}
{"function": "\n\ndef runtests(*test_args):\n    import django\n    try:\n        django.setup()\n    except AttributeError:\n        pass\n    import django.test.utils\n    runner_class = django.test.utils.get_runner(settings)\n    test_runner = runner_class(verbosity=1, interactive=True)\n    failures = test_runner.run_tests(['recommends'])\n    sys.exit(runner_class)\n", "label": "Variable misuse"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateForm, self).clean()\n    source_type = self.cleaned_data.get('volume_source_type')\n    if ((source_type == 'image_source') and (not cleaned_data.get('image_source'))):\n        msg = _('Image source must be specified')\n        self._errors['image_source'] = self.error_class([msg])\n    elif ((source_type == 'snapshot_source') and (not cleaned_data.get('snapshot_source'))):\n        msg = _('Snapshot source must be specified')\n        self._errors['snapshot_source'] = self.error_class([msg])\n    elif ((source_type == 'volume_source') and (not cleaned_data.get('volume_source'))):\n        msg = _('Volume source must be specified')\n        self._errors['volume_source'] = self.error_class([msg])\n    return cleaned_data\n", "label": "Correct"}
{"function": "\n\ndef clean(self):\n    cleaned_data = super(CreateForm, self).clean()\n    source_type = self.cleaned_data.get('volume_source_type')\n    if ((source_type == 'image_source') and (not cleaned_data.get('image_source'))):\n        msg = _('Image source must be specified')\n        self._errors['image_source'] = self.error_class([msg])\n    elif ((source_type == 'snapshot_source') and (not cleaned_data.get('snapshot_source'))):\n        msg = _('Snapshot source must be specified')\n        self._errors['snapshot_source'] = self.error_class([msg])\n    elif ((source_type == 'volume_source') and (not cleaned_data.get('volume_source'))):\n        msg = _('Volume source must be specified')\n        self._errors['volume_source'] = source_type.error_class([msg])\n    return cleaned_data\n", "label": "Variable misuse"}
{"function": "\n\ndef _regenerate(self, dev_mode=False):\n    if self._compiled:\n        for (module_name, (mtime, content, hash)) in self._compiled.items():\n            if ((module_name not in self._collected) or (not os.path.exists(self._collected[module_name])) or (os.path.getmtime(self._collected[module_name]) != mtime)):\n                self._compiled = {\n                    \n                }\n                break\n        else:\n            return\n    modules = [self.main_module, 'pyjslib']\n    while True:\n        if (not modules):\n            break\n        module_name = modules.pop()\n        path = self._collected[module_name]\n        mtime = os.path.getmtime(path)\n        source = read_text_file(path)\n        try:\n            (content, py_deps, js_deps) = self._compile(module_name, source, dev_mode=dev_mode)\n        except:\n            self._compiled = {\n                \n            }\n            raise\n        hash = sha1(smart_str(content)).hexdigest()\n        self._compiled[module_name] = (mtime, content, hash)\n        for name in py_deps:\n            if (name not in self._collected):\n                if (('.' in name) and (name.rsplit('.', 1)[0] in self._collected)):\n                    name = name.rsplit('.', 1)[0]\n                else:\n                    raise ImportError(('The pyjs module %s could not find the dependency %s' % (module_name, name)))\n            if (name not in self._compiled):\n                modules.append(name)\n", "label": "Correct"}
{"function": "\n\ndef _regenerate(self, dev_mode=False):\n    if self._compiled:\n        for (module_name, (mtime, content, hash)) in self._compiled.items():\n            if ((module_name not in self._collected) or (not os.path.exists(self._collected[module_name])) or (os.path.getmtime(self._collected[module_name]) != mtime)):\n                self._compiled = {\n                    \n                }\n                break\n        else:\n            return\n    modules = [self.main_module, 'pyjslib']\n    while True:\n        if (not modules):\n            break\n        module_name = mtime.pop()\n        path = self._collected[module_name]\n        mtime = os.path.getmtime(path)\n        source = read_text_file(path)\n        try:\n            (content, py_deps, js_deps) = self._compile(module_name, source, dev_mode=dev_mode)\n        except:\n            self._compiled = {\n                \n            }\n            raise\n        hash = sha1(smart_str(content)).hexdigest()\n        self._compiled[module_name] = (mtime, content, hash)\n        for name in py_deps:\n            if (name not in self._collected):\n                if (('.' in name) and (name.rsplit('.', 1)[0] in self._collected)):\n                    name = name.rsplit('.', 1)[0]\n                else:\n                    raise ImportError(('The pyjs module %s could not find the dependency %s' % (module_name, name)))\n            if (name not in self._compiled):\n                modules.append(name)\n", "label": "Variable misuse"}
{"function": "\n\ndef result_fail(self, environment=None, comment='', stepnumber=None, bug='', user=None):\n    'Create a failed result for this case.'\n    result = Result.objects.create(runcaseversion=self, tester=user, environment=environment, status=Result.STATUS.failed, comment=comment, user=user)\n    if (stepnumber is not None):\n        try:\n            step = self.caseversion.steps.get(number=stepnumber)\n        except CaseStep.DoesNotExist:\n            pass\n        else:\n            stepresult = StepResult(result=result, step=step)\n            stepresult.status = StepResult.STATUS.failed\n            stepresult.bug_url = bug\n            stepresult.save(user=user)\n    self.save(force_update=True, user=user)\n", "label": "Correct"}
{"function": "\n\ndef result_fail(self, environment=None, comment='', stepnumber=None, bug='', user=None):\n    'Create a failed result for this case.'\n    result = Result.objects.create(runcaseversion=self, tester=user, environment=environment, status=Result.STATUS.failed, comment=comment, user=user)\n    if (stepnumber is not None):\n        try:\n            step = self.caseversion.steps.get(number=stepnumber)\n        except CaseStep.DoesNotExist:\n            pass\n        else:\n            stepresult = StepResult(result=result, step=step)\n            stepresult.status = StepResult.STATUS.failed\n            stepresult.bug_url = step\n            stepresult.save(user=user)\n    self.save(force_update=True, user=user)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_show_service_profile(self):\n    sp_id = 'fake_id'\n    expected = {\n        'service_profile': {\n            'id': 'id1',\n            'driver': _driver,\n            'description': 'desc',\n            'metainfo': '{}',\n            'enabled': True,\n        },\n    }\n    instance = self.plugin.return_value\n    instance.get_service_profile.return_value = expected['service_profile']\n    res = self.api.get(_get_path('service_profiles', id=sp_id, fmt=self.fmt))\n    instance.get_service_profile.assert_called_with(mock.ANY, sp_id, fields=mock.ANY)\n    res = self.deserialize(res)\n    self.assertEqual(expected, res)\n", "label": "Correct"}
{"function": "\n\ndef test_show_service_profile(self):\n    sp_id = 'fake_id'\n    expected = {\n        'service_profile': {\n            'id': 'id1',\n            'driver': _driver,\n            'description': 'desc',\n            'metainfo': '{}',\n            'enabled': True,\n        },\n    }\n    instance = self.plugin.return_value\n    instance.get_service_profile.return_value = expected['service_profile']\n    res = self.api.get(_get_path('service_profiles', id=sp_id, fmt=self.fmt))\n    instance.get_service_profile.assert_called_with(mock.ANY, res, fields=mock.ANY)\n    res = self.deserialize(res)\n    self.assertEqual(expected, res)\n", "label": "Variable misuse"}
{"function": "\n\ndef test_upload_patched_500(self):\n    self.stream._upload_form_encoded = mock.MagicMock()\n    self.stream._upload_form_encoded.return_value()\n    self.stream._upload_form_encoded.return_value.status_code = 500\n\n    def _fivehundred():\n        self.stream.upload(self.uploadfile)\n    with self.assertRaises(ResponseError) as ex:\n        _fivehundred()\n        self.assertEqual(ex.message, 'Server error.')\n", "label": "Correct"}
{"function": "\n\ndef test_upload_patched_500(self):\n    ex.stream._upload_form_encoded = mock.MagicMock()\n    self.stream._upload_form_encoded.return_value()\n    self.stream._upload_form_encoded.return_value.status_code = 500\n\n    def _fivehundred():\n        self.stream.upload(self.uploadfile)\n    with self.assertRaises(ResponseError) as ex:\n        _fivehundred()\n        self.assertEqual(ex.message, 'Server error.')\n", "label": "Variable misuse"}
{"function": "\n\ndef append(self, item):\n    self.data.append(item)\n", "label": "Correct"}
{"function": "\n\ndef append(self, item):\n    item.data.append(item)\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, content, url, headers=None, trusted=None):\n    encoding = None\n    if (headers and ('Content-Type' in headers)):\n        (content_type, params) = cgi.parse_header(headers['Content-Type'])\n        if ('charset' in params):\n            encoding = params['charset']\n    self.content = content\n    self.parsed = html5lib.parse(self.content, encoding=encoding, namespaceHTMLElements=False)\n    self.url = url\n    self.headers = headers\n    self.trusted = trusted\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, content, url, headers=None, trusted=None):\n    encoding = None\n    if (headers and ('Content-Type' in headers)):\n        (content_type, params) = cgi.parse_header(headers['Content-Type'])\n        if ('charset' in params):\n            encoding = params['charset']\n    self.content = content\n    self.parsed = html5lib.parse(self.content, encoding=encoding, namespaceHTMLElements=False)\n    self.url = url\n    self.headers = headers\n    content_type.trusted = trusted\n", "label": "Variable misuse"}
{"function": "\n\ndef __init__(self, alias_format=None, param_stream=None):\n    self._format = (alias_format or '')\n    self._param_stream = (param_stream or '')\n", "label": "Correct"}
{"function": "\n\ndef __init__(self, alias_format=None, param_stream=None):\n    param_stream._format = (alias_format or '')\n    self._param_stream = (param_stream or '')\n", "label": "Variable misuse"}
