{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuronPrediction_HiddenLayer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoPao/cubert_keras/blob/main/colab/NeuronPrediction_HiddenLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuron prediction - Hidden layer\n",
        "\n",
        "Questo notebook è stato utilizzato per salvare le previsioni dei layer interni del modello, fornendo in input il dataset etichettato per complessità ciclomatica"
      ],
      "metadata": {
        "id": "I6xwMKvfeJP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJhIuyKtE5RR"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/MatteoPao/cubert_keras.git\n",
        "\n",
        "%cd cubert_keras/src/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                  \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_exceptions /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_exceptions\n",
        "#%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_variablemisuse /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_variablemisuse\n",
        "%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_epochs_2 /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_epochs_2"
      ],
      "metadata": {
        "id": "ysjGaI05FGO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ../requirements.txt\n",
        "\n",
        "from intermediate_layer import read_examples_from_json\n",
        "from keras_bert import load_trained_model_from_checkpoint, get_checkpoint_paths\n",
        "from cubert.full_cubert_tokenizer import FullCuBertTokenizer, CuBertVariableMisuseProcessor, InputExample\n",
        "from cubert import tokenizer_registry\n",
        "import progressbar\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "EZfgH7TCFL0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Importazione degli individui dal file   (*read_example_from_json*)\n",
        "*   Generazione un istanza tokenizer        (*FullCubertTokenizer*)\n",
        "*   Conversione degli esempi in feature     (*convert_examples_to_features*)\n",
        "\n"
      ],
      "metadata": {
        "id": "p2svlmLWep4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"fitness/cubert_fitness/cubert_pretrained_model_variablemisuse\"\n",
        "#model_path = \"fitness/cubert_fitness/cubert_pretrained_model_epochs_2\"\n",
        "\n",
        "data_path = \"../cyclomatic_complexity/final/Final_1to16_2400_FT/data_cc.jsontxt\"\n",
        "#data_path = \"../cyclomatic_complexity/final/Final_1to16_2400_FF/data_cc.jsontxt\"\n",
        "\n",
        "layer_name = \"Encoder-24-FeedForward-Norm\""
      ],
      "metadata": {
        "id": "abAEW3ROIUfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = get_checkpoint_paths(model_path)\n",
        "\n",
        "examples = read_examples_from_json(data_path, \"eval\")\n",
        "\n",
        "#Carica il tokenizer\n",
        "tokenizer = FullCuBertTokenizer(code_tokenizer_class=tokenizer_registry.TokenizerEnum.PYTHON.value, vocab_file=paths.vocab)\n",
        "print(\"Tokenizer loaded\")\n",
        "\n",
        "processor = CuBertVariableMisuseProcessor()\n",
        "label_list = processor.get_labels()\n",
        "\n",
        "#Tokenizza tutto il dataset\n",
        "features = tokenizer.convert_examples_to_features(examples, label_list, 512)\n",
        "print(\"Dataset tokenized\")"
      ],
      "metadata": {
        "id": "xeqG_oCsPL3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il seguente blocco di codice rielabora le feature nella corretta forma accettata dal modello.\n",
        "\n",
        "Nel caso in cui il modello venga importato con il flag *training=True* allora l'input è formato da 3 array [input, segment, mask].\n",
        "\n",
        "In alternativa con *training=False* l'input è formato solo da [input, segment] "
      ],
      "metadata": {
        "id": "GV3Y2C_mhgHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp, seg, mas = [], [], []\n",
        "label = []\n",
        "\n",
        "for f in features:\n",
        "  inp.append(f.input_ids)\n",
        "  seg.append(f.segment_ids)\n",
        "  mas.append(f.input_mask)\n",
        "  label.append(f.label_id)\n",
        "\n",
        "#with open('../label_VM2800.npy', 'wb') as file:\n",
        "#   np.save(file, label)\n",
        "\n",
        "#Nel caso di modello troncato con keras.Model(), utilizzare data_input o data_input_s\n",
        "\"\"\"\n",
        "data_input = [np.array(inp), np.array(seg), np.array(mas)]\n",
        "data_input_s = [np.array(inp), np.array(seg)]\n",
        "\"\"\"\n",
        "\n",
        "#Nel caso di modello troncato con keras.backend l'input deve essere diviso in batch precedentemente\n",
        "#Prima alternativa, training=True\n",
        "\"\"\"\n",
        "batched_input = []\n",
        "for index in range(int(len(inp)/8)):\n",
        "  step = int(index*8)\n",
        "  batched_input.append([np.array(inp[step:step+8]), np.array(seg[step:step+8]), np.array(mas[step:step+8])])\n",
        "\"\"\"\n",
        "\n",
        "#Seconda alternativa, training=False\n",
        "batched_input = []\n",
        "for index in range(int(len(inp)/8)):\n",
        "  step = int(index*8)\n",
        "  batched_input.append([np.array(inp[step:step+8]), np.array(mas[step:step+8])])\n",
        "print(np.asarray(batched_input).shape)"
      ],
      "metadata": {
        "id": "9367rjxXPPvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carica il checkpoint\n",
        "model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, training=False)\n",
        "#model.summary()\n",
        "\n",
        "#Prima alternativa, tronca il modello con keras.backend (Consigliato per risparmiare memoria)\n",
        "model = K.function([model.input], [model.get_layer(layer_name).output])\n",
        "\n",
        "#Seconda alternativa, tronca il modello con keras.Model (Usare solo con dataset di dimensioni ridotte)\n",
        "# model = keras.Model(inputs=model.input, outputs=model.get_layer(layer).output)\n",
        "\n",
        "print(\"Model loaded\")"
      ],
      "metadata": {
        "id": "Sv-DQImaFvyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In caso di modello troncato con keras.backend si usa la prima alternativa per la previsione. Quindi l'output viene direttamente salvato su file. Con la seconda alternativa invece l'output è unico (e molto pesante)"
      ],
      "metadata": {
        "id": "O5dYFqKjPWCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In caso di modello troncato con keras.backend si usa questo metodo per la previsione\n",
        "%mkdir results\n",
        "count = 0\n",
        "for input in progressbar.progressbar(batched_input):\n",
        "  batched_output = model([input, 0])[0]\n",
        "  with open('results/'+ layer_name + '_prediction_' + str(count) + '.npy', 'wb') as file:\n",
        "    np.save(file, batched_output)\n",
        "  count += 1\n",
        "\n",
        "#In caso di modello troncato con keras.Model si usa questo metodo per la previsione\n",
        "\"\"\"\n",
        "pred_results = model.predict(data_input_s, batch_size=16, verbose=1)\n",
        "pred_results = np.transpose(pred_results)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XcPPM9Zvw4sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimo blocco che carica i file nella cartella drive. Il comando *flush_and_unmount()* permette di salvare su drive le modifiche che sono state appportate durante la sessione colab "
      ],
      "metadata": {
        "id": "462rv5SF9S2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/prediction.zip /content/cubert_keras/src/results\n",
        "%cp -r /content/prediction.zip /content/drive/MyDrive/Tesi_Database/FINAL/prediction_1to16_FT_VM/prediction.zip\n",
        "#%cp -r /content/prediction.zip /content/drive/MyDrive/Tesi_Database/FINAL/prediction_1to16_FF_VM/prediction.zip\n",
        "#%cp -r /content/prediction.zip /content/drive/MyDrive/Tesi_Database/FINAL/prediction_1to16_FT_E2/prediction.zip\n",
        "#%cp -r /content/prediction.zip /content/drive/MyDrive/Tesi_Database/FINAL/prediction_1to16_FF_E2/prediction.zip\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "0gdCJo27UlMz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}