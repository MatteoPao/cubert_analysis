{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuronPrediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMTDgx0gsFtohk2GANrZ3N9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoPao/cubert_keras/blob/main/NeuronPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV2nKktt3BO3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/MatteoPao/cubert_keras.git\n",
        "\n",
        "%cd cubert_keras/src/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                               \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# %cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_exceptions /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_exceptions\n",
        "%cp -r /content/drive/MyDrive/Tesi_ModelData/cubert_pretrained_model_variablemisuse /content/cubert_keras/src/fitness/cubert_fitness/cubert_pretrained_model_variablemisuse"
      ],
      "metadata": {
        "id": "62phakBZ3Kqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ../requirements.txt"
      ],
      "metadata": {
        "id": "vVbWfRVX3Pvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from intermediate_layer import read_examples_from_json\n",
        "from keras_bert import load_trained_model_from_checkpoint, get_checkpoint_paths\n",
        "from cubert.full_cubert_tokenizer import FullCuBertTokenizer, CuBertVariableMisuseProcessor, InputExample\n",
        "from cubert import tokenizer_registry\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "9JWv67kbl_fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"fitness/cubert_fitness/cubert_pretrained_model_variablemisuse\"\n",
        "data_path = \"../cyclomatic_complexity/final/data_cc.jsontxt\"\n",
        "\n",
        "paths = get_checkpoint_paths(model_path)\n",
        "\n",
        "examples = read_examples_from_json(data_path, \"eval\")\n",
        "\n",
        "tokenizer = FullCuBertTokenizer(code_tokenizer_class=tokenizer_registry.TokenizerEnum.PYTHON.value, vocab_file=paths.vocab)\n",
        "print(\"Tokenizer loaded\")\n",
        "\n",
        "model = load_trained_model_from_checkpoint(paths.config, paths.checkpoint, training=True, seq_len=128, out_dim=2)\n",
        "print(\"Model loaded\")\n",
        "#model.summary()\n",
        "\n",
        "layer_name = \"NSP-Dense\"\n",
        "layer_name_1 = \"Extract\"\n",
        "model = keras.Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "#model.summary()\n",
        "\n",
        "#tokenizza tutto il dataset\n",
        "features = tokenizer.convert_examples_to_features(examples, [0, 1], 128)\n",
        "print(\"Dataset tokenized\")\n",
        "np.random.shuffle(features)"
      ],
      "metadata": {
        "id": "H39CvECh4BV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = []\n",
        "seg = []\n",
        "mas = []\n",
        "label = []\n",
        "\n",
        "for f in features:\n",
        "  inp.append(f.input_ids)\n",
        "  seg.append(f.segment_ids)\n",
        "  mas.append(f.input_mask)\n",
        "  label.append(f.label_id)\n",
        "  \n",
        "test_input = [np.array(inp), np.array(seg), np.array(mas)]\n",
        "\n",
        "pred_results = model.predict(test_input)\n",
        "pred_results = np.transpose(pred_results)\n",
        "\n",
        "print(\"Prediction completata\")\n",
        "print(\"Neuroni: \", pred_results.shape[0])\n",
        "print(\"Predictions: \", pred_results.shape[1])"
      ],
      "metadata": {
        "id": "PijuFkvvfubR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test singolo input\n",
        "'''\n",
        "feature = tokenizer.convert_single_example(examples[0], [0, 1], 128)\n",
        "\n",
        "pred_results = model.predict([np.array(feature.input_ids, ndmin=2), \n",
        "                            np.array(feature.segment_ids, ndmin=2), \n",
        "                            np.array(feature.input_mask, ndmin=2)])\n",
        "'''\n"
      ],
      "metadata": {
        "id": "S2ie8Qg1jl56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_tanh = np.linspace(-1, 1, num=12)[1:11]\n",
        "label_inv = np.logical_not(label).astype(int)\n",
        "\n",
        "bestAcc = 0\n",
        "bestNeu = 0\n",
        "bestTh = 0\n",
        "for index, neuron in enumerate(pred_results):\n",
        "  best_n = 0\n",
        "  best_t = 0\n",
        "  for t in threshold_tanh:\n",
        "    inv = False\n",
        "    m = tf.keras.metrics.BinaryAccuracy(threshold=t)\n",
        "    m.update_state(label, neuron)\n",
        "    acc = m.result().numpy()\n",
        "    m.reset_state()\n",
        "    m.update_state(label_inv, neuron)\n",
        "    acc_inv = m.result().numpy()\n",
        "    if acc_inv > acc:\n",
        "      acc = acc_inv\n",
        "      inv = True\n",
        "    if acc >= best_n:\n",
        "      best_n = acc\n",
        "      best_t = t\n",
        "      best_inv = inv\n",
        "  if best_n >= bestAcc:\n",
        "    print(\"NEW Best Neuron\")\n",
        "    print(\"Neuron: %d   Acc: %f   inv: %s\" % (index, best_n, best_inv))\n",
        "    bestAcc = best_n\n",
        "    bestNeu = index\n",
        "    bestTh = best_t\n",
        "\n",
        "print(\"BEST FINALE\")\n",
        "print(\"Neurone: \", bestNeu)\n",
        "print(\"Accuratezza: \", bestAcc)\n",
        "print(\"Threshold: \", bestTh)\n",
        "\n",
        "print(label)\n",
        "print(np.where(pred_results[bestNeu] > bestTh, 1, 0))"
      ],
      "metadata": {
        "id": "6w0erJDsuDyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir ../../result\n",
        "outF = open(\"../../result/bestNeuron.txt\", \"x\")\n",
        "outF.write(\"Neurone: \")\n",
        "outF.write(str(bestNeu))\n",
        "outF.write(\"\\nAccuratezza: \")\n",
        "outF.write(str(bestAcc))\n",
        "outF.write(\"\\nThreshold: \")\n",
        "outF.write(str(bestTh))\n",
        "outF.close()\n",
        "\n",
        "!zip -r /content/bestNeuron.zip /content/result\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/bestNeuron.zip\")\n",
        "\n",
        "!rm -r /content/result"
      ],
      "metadata": {
        "id": "W38bdpSv5KT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}